Remove the tensorboard dir
[INFO] main.py:222 > Set the device (cuda)
[INFO] main.py:267 > Using train-transforms Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=4)
    ToTensor()
    Normalize(mean=(0.4914, 0.482158, 0.4465231), std=(0.247032, 0.243485, 0.2615877))
)
[INFO] augment.py:18 > cifar10: autoaugmentation is applied
[INFO] main.py:290 > Using train-transforms [AutoAugment CIFAR10 Policy]
[INFO] main.py:300 > [1] Select a CIL method (rm)
[INFO] method_manager.py:48 > CIL Scenario: 
n_tasks: 5
n_init_cls: 2
n_cls_a_task: 2
total cls: 10
[INFO] main.py:306 > [2] Incrementally training 5 tasks

##################################################
# Task 0 iteration
##################################################

[INFO] main.py:316 > [2-1] Prepare a datalist for the current task
total : 5000  current step :  0
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter:   1/5000. LR: 0.0000. Data: 0.07s. Batch: 0.49s. S_Loss: 2.5301. T_Loss: 2.4255. Mask: 0.0000. :   0%|          | 0/100 [00:00<?, ?it/s]Train Iter:   1/5000. LR: 0.0000. Data: 0.07s. Batch: 0.49s. S_Loss: 2.5301. T_Loss: 2.4255. Mask: 0.0000. :   1%|          | 1/100 [00:00<00:48,  2.02it/s]Train Iter:   2/5000. LR: 0.0000. Data: 0.04s. Batch: 0.79s. S_Loss: 2.4803. T_Loss: 2.5526. Mask: 0.0000. :   1%|          | 1/100 [00:01<00:48,  2.02it/s]Train Iter:   2/5000. LR: 0.0000. Data: 0.04s. Batch: 0.79s. S_Loss: 2.4803. T_Loss: 2.5526. Mask: 0.0000. :   2%|▏         | 2/100 [00:01<01:23,  1.18it/s]Train Iter:   3/5000. LR: 0.0000. Data: 0.03s. Batch: 0.57s. S_Loss: 2.5303. T_Loss: 2.5536. Mask: 0.0000. :   2%|▏         | 2/100 [00:01<01:23,  1.18it/s]Train Iter:   3/5000. LR: 0.0000. Data: 0.03s. Batch: 0.57s. S_Loss: 2.5303. T_Loss: 2.5536. Mask: 0.0000. :   3%|▎         | 3/100 [00:01<00:50,  1.91it/s]Train Iter:   4/5000. LR: 0.0000. Data: 0.02s. Batch: 0.46s. S_Loss: 2.5301. T_Loss: 2.5380. Mask: 0.0078. :   3%|▎         | 3/100 [00:01<00:50,  1.91it/s]Train Iter:   4/5000. LR: 0.0000. Data: 0.02s. Batch: 0.46s. S_Loss: 2.5301. T_Loss: 2.5380. Mask: 0.0078. :   4%|▍         | 4/100 [00:01<00:34,  2.79it/s]Train Iter:   5/5000. LR: 0.0000. Data: 0.02s. Batch: 0.39s. S_Loss: 2.5338. T_Loss: 2.5314. Mask: 0.0063. :   4%|▍         | 4/100 [00:01<00:34,  2.79it/s]Train Iter:   5/5000. LR: 0.0000. Data: 0.02s. Batch: 0.39s. S_Loss: 2.5338. T_Loss: 2.5314. Mask: 0.0063. :   5%|▌         | 5/100 [00:01<00:25,  3.67it/s]Train Iter:   6/5000. LR: 0.0000. Data: 0.02s. Batch: 0.35s. S_Loss: 2.5137. T_Loss: 2.5459. Mask: 0.0052. :   5%|▌         | 5/100 [00:02<00:25,  3.67it/s]Train Iter:   6/5000. LR: 0.0000. Data: 0.02s. Batch: 0.35s. S_Loss: 2.5137. T_Loss: 2.5459. Mask: 0.0052. :   6%|▌         | 6/100 [00:02<00:21,  4.45it/s]Train Iter:   7/5000. LR: 0.0000. Data: 0.02s. Batch: 0.31s. S_Loss: 2.4850. T_Loss: 2.5145. Mask: 0.0045. :   6%|▌         | 6/100 [00:02<00:21,  4.45it/s]Train Iter:   7/5000. LR: 0.0000. Data: 0.02s. Batch: 0.31s. S_Loss: 2.4850. T_Loss: 2.5145. Mask: 0.0045. :   7%|▋         | 7/100 [00:02<00:17,  5.32it/s]Train Iter:   8/5000. LR: 0.0000. Data: 0.01s. Batch: 0.31s. S_Loss: 2.4675. T_Loss: 2.5149. Mask: 0.0039. :   7%|▋         | 7/100 [00:02<00:17,  5.32it/s]Train Iter:   8/5000. LR: 0.0000. Data: 0.01s. Batch: 0.31s. S_Loss: 2.4675. T_Loss: 2.5149. Mask: 0.0039. :   8%|▊         | 8/100 [00:02<00:19,  4.70it/s]Train Iter:   9/5000. LR: 0.0000. Data: 0.01s. Batch: 0.29s. S_Loss: 2.4620. T_Loss: 2.5310. Mask: 0.0035. :   8%|▊         | 8/100 [00:02<00:19,  4.70it/s]Train Iter:   9/5000. LR: 0.0000. Data: 0.01s. Batch: 0.29s. S_Loss: 2.4620. T_Loss: 2.5310. Mask: 0.0035. :   9%|▉         | 9/100 [00:02<00:16,  5.45it/s]Train Iter:  10/5000. LR: 0.0000. Data: 0.01s. Batch: 0.27s. S_Loss: 2.4624. T_Loss: 2.5100. Mask: 0.0031. :   9%|▉         | 9/100 [00:02<00:16,  5.45it/s]Train Iter:  10/5000. LR: 0.0000. Data: 0.01s. Batch: 0.27s. S_Loss: 2.4624. T_Loss: 2.5100. Mask: 0.0031. :  10%|█         | 10/100 [00:02<00:14,  6.10it/s]Train Iter:  11/5000. LR: 0.0000. Data: 0.01s. Batch: 0.26s. S_Loss: 2.4622. T_Loss: 2.4963. Mask: 0.0028. :  10%|█         | 10/100 [00:02<00:14,  6.10it/s]Train Iter:  11/5000. LR: 0.0000. Data: 0.01s. Batch: 0.26s. S_Loss: 2.4622. T_Loss: 2.4963. Mask: 0.0028. :  11%|█         | 11/100 [00:02<00:14,  6.20it/s]Train Iter:  12/5000. LR: 0.0000. Data: 0.01s. Batch: 0.25s. S_Loss: 2.4448. T_Loss: 2.4731. Mask: 0.0026. :  11%|█         | 11/100 [00:03<00:14,  6.20it/s]Train Iter:  12/5000. LR: 0.0000. Data: 0.01s. Batch: 0.25s. S_Loss: 2.4448. T_Loss: 2.4731. Mask: 0.0026. :  12%|█▏        | 12/100 [00:03<00:14,  6.11it/s]Train Iter:  13/5000. LR: 0.0000. Data: 0.01s. Batch: 0.25s. S_Loss: 2.4379. T_Loss: 2.4638. Mask: 0.0024. :  12%|█▏        | 12/100 [00:03<00:14,  6.11it/s]Train Iter:  13/5000. LR: 0.0000. Data: 0.01s. Batch: 0.25s. S_Loss: 2.4379. T_Loss: 2.4638. Mask: 0.0024. :  13%|█▎        | 13/100 [00:03<00:17,  5.05it/s]Train Iter:  14/5000. LR: 0.0000. Data: 0.01s. Batch: 0.24s. S_Loss: 2.4425. T_Loss: 2.4354. Mask: 0.0022. :  13%|█▎        | 13/100 [00:03<00:17,  5.05it/s]Train Iter:  14/5000. LR: 0.0000. Data: 0.01s. Batch: 0.24s. S_Loss: 2.4425. T_Loss: 2.4354. Mask: 0.0022. :  14%|█▍        | 14/100 [00:03<00:14,  5.87it/s]Train Iter:  15/5000. LR: 0.0000. Data: 0.01s. Batch: 0.23s. S_Loss: 2.4369. T_Loss: 2.4203. Mask: 0.0042. :  14%|█▍        | 14/100 [00:03<00:14,  5.87it/s]Train Iter:  15/5000. LR: 0.0000. Data: 0.01s. Batch: 0.23s. S_Loss: 2.4369. T_Loss: 2.4203. Mask: 0.0042. :  15%|█▌        | 15/100 [00:03<00:13,  6.48it/s]Train Iter:  16/5000. LR: 0.0000. Data: 0.02s. Batch: 0.23s. S_Loss: 2.4389. T_Loss: 2.3986. Mask: 0.0039. :  15%|█▌        | 15/100 [00:03<00:13,  6.48it/s]Train Iter:  16/5000. LR: 0.0000. Data: 0.02s. Batch: 0.23s. S_Loss: 2.4389. T_Loss: 2.3986. Mask: 0.0039. :  16%|█▌        | 16/100 [00:03<00:15,  5.52it/s]Train Iter:  17/5000. LR: 0.0000. Data: 0.01s. Batch: 0.23s. S_Loss: 2.4391. T_Loss: 2.3767. Mask: 0.0037. :  16%|█▌        | 16/100 [00:03<00:15,  5.52it/s]Train Iter:  17/5000. LR: 0.0000. Data: 0.01s. Batch: 0.23s. S_Loss: 2.4391. T_Loss: 2.3767. Mask: 0.0037. :  17%|█▋        | 17/100 [00:03<00:13,  6.19it/s]Train Iter:  18/5000. LR: 0.0000. Data: 0.01s. Batch: 0.22s. S_Loss: 2.4454. T_Loss: 2.3596. Mask: 0.0035. :  17%|█▋        | 17/100 [00:04<00:13,  6.19it/s]Train Iter:  18/5000. LR: 0.0000. Data: 0.01s. Batch: 0.22s. S_Loss: 2.4454. T_Loss: 2.3596. Mask: 0.0035. :  18%|█▊        | 18/100 [00:04<00:12,  6.75it/s]Train Iter:  19/5000. LR: 0.0000. Data: 0.01s. Batch: 0.23s. S_Loss: 2.4491. T_Loss: 2.3284. Mask: 0.0033. :  18%|█▊        | 18/100 [00:04<00:12,  6.75it/s]Train Iter:  19/5000. LR: 0.0000. Data: 0.01s. Batch: 0.23s. S_Loss: 2.4491. T_Loss: 2.3284. Mask: 0.0033. :  19%|█▉        | 19/100 [00:04<00:17,  4.66it/s]Train Iter:  20/5000. LR: 0.0000. Data: 0.01s. Batch: 0.22s. S_Loss: 2.4530. T_Loss: 2.2965. Mask: 0.0031. :  19%|█▉        | 19/100 [00:04<00:17,  4.66it/s]Train Iter:  20/5000. LR: 0.0000. Data: 0.01s. Batch: 0.22s. S_Loss: 2.4530. T_Loss: 2.2965. Mask: 0.0031. :  20%|██        | 20/100 [00:04<00:14,  5.38it/s]Train Iter:  21/5000. LR: 0.0000. Data: 0.01s. Batch: 0.22s. S_Loss: 2.4521. T_Loss: 2.2716. Mask: 0.0030. :  20%|██        | 20/100 [00:04<00:14,  5.38it/s]Train Iter:  21/5000. LR: 0.0000. Data: 0.01s. Batch: 0.22s. S_Loss: 2.4521. T_Loss: 2.2716. Mask: 0.0030. :  21%|██        | 21/100 [00:04<00:12,  6.08it/s]Train Iter:  22/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4609. T_Loss: 2.2449. Mask: 0.0043. :  21%|██        | 21/100 [00:04<00:12,  6.08it/s]Train Iter:  22/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4609. T_Loss: 2.2449. Mask: 0.0043. :  22%|██▏       | 22/100 [00:04<00:11,  6.62it/s]Train Iter:  23/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4645. T_Loss: 2.2167. Mask: 0.0068. :  22%|██▏       | 22/100 [00:04<00:11,  6.62it/s]Train Iter:  23/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4645. T_Loss: 2.2167. Mask: 0.0068. :  23%|██▎       | 23/100 [00:04<00:10,  7.13it/s]Train Iter:  24/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4646. T_Loss: 2.1994. Mask: 0.0104. :  23%|██▎       | 23/100 [00:05<00:10,  7.13it/s]Train Iter:  24/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4646. T_Loss: 2.1994. Mask: 0.0104. :  24%|██▍       | 24/100 [00:05<00:12,  5.92it/s]Train Iter:  25/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4701. T_Loss: 2.1773. Mask: 0.0138. :  24%|██▍       | 24/100 [00:05<00:12,  5.92it/s]Train Iter:  25/5000. LR: 0.0000. Data: 0.01s. Batch: 0.21s. S_Loss: 2.4701. T_Loss: 2.1773. Mask: 0.0138. :  25%|██▌       | 25/100 [00:05<00:11,  6.51it/s]total : 5000  current step :  1
total : 5000  current step :  2
total : 5000  current step :  3
total : 5000  current step :  4
total : 5000  current step :  5
total : 5000  current step :  6
total : 5000  current step :  7
total : 5000  current step :  8
total : 5000  current step :  9
total : 5000  current step :  10
total : 5000  current step :  11
total : 5000  current step :  12
total : 5000  current step :  13
total : 5000  current step :  14
total : 5000  current step :  15
total : 5000  current step :  16
total : 5000  current step :  17
total : 5000  current step :  18
total : 5000  current step :  19
total : 5000  current step :  20
total : 5000  current step :  21
total : 5000  current step :  22
total : 5000  current step :  23
total : 5000  current step :  24
total : 5000  current step :  25
Train Iter:  26/5000. LR: 0.0000. Data: 0.09s. Batch: 0.28s. S_Loss: 2.4711. T_Loss: 2.1609. Mask: 0.0252. :  25%|██▌       | 25/100 [00:07<00:11,  6.51it/s]Train Iter:  26/5000. LR: 0.0000. Data: 0.09s. Batch: 0.28s. S_Loss: 2.4711. T_Loss: 2.1609. Mask: 0.0252. :  26%|██▌       | 26/100 [00:07<00:55,  1.35it/s]Train Iter:  27/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4741. T_Loss: 2.1525. Mask: 0.0382. :  26%|██▌       | 26/100 [00:07<00:55,  1.35it/s]Train Iter:  27/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4741. T_Loss: 2.1525. Mask: 0.0382. :  27%|██▋       | 27/100 [00:07<00:41,  1.78it/s]Train Iter:  28/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4732. T_Loss: 2.1370. Mask: 0.0513. :  27%|██▋       | 27/100 [00:07<00:41,  1.78it/s]Train Iter:  28/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4732. T_Loss: 2.1370. Mask: 0.0513. :  28%|██▊       | 28/100 [00:07<00:30,  2.33it/s]Train Iter:  29/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4734. T_Loss: 2.1149. Mask: 0.0636. :  28%|██▊       | 28/100 [00:07<00:30,  2.33it/s]Train Iter:  29/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4734. T_Loss: 2.1149. Mask: 0.0636. :  29%|██▉       | 29/100 [00:07<00:28,  2.52it/s]Train Iter:  30/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4736. T_Loss: 2.1078. Mask: 0.0802. :  29%|██▉       | 29/100 [00:08<00:28,  2.52it/s]Train Iter:  30/5000. LR: 0.0000. Data: 0.08s. Batch: 0.27s. S_Loss: 2.4736. T_Loss: 2.1078. Mask: 0.0802. :  30%|███       | 30/100 [00:08<00:21,  3.20it/s]Train Iter:  31/5000. LR: 0.0000. Data: 0.07s. Batch: 0.26s. S_Loss: 2.4746. T_Loss: 2.0932. Mask: 0.0927. :  30%|███       | 30/100 [00:08<00:21,  3.20it/s]Train Iter:  31/5000. LR: 0.0000. Data: 0.07s. Batch: 0.26s. S_Loss: 2.4746. T_Loss: 2.0932. Mask: 0.0927. :  31%|███       | 31/100 [00:08<00:17,  3.92it/s]Train Iter:  32/5000. LR: 0.0000. Data: 0.07s. Batch: 0.26s. S_Loss: 2.4739. T_Loss: 2.0811. Mask: 0.1104. :  31%|███       | 31/100 [00:08<00:17,  3.92it/s]Train Iter:  32/5000. LR: 0.0000. Data: 0.07s. Batch: 0.26s. S_Loss: 2.4739. T_Loss: 2.0811. Mask: 0.1104. :  32%|███▏      | 32/100 [00:08<00:14,  4.68it/s]Train Iter:  33/5000. LR: 0.0000. Data: 0.07s. Batch: 0.25s. S_Loss: 2.4771. T_Loss: 2.0704. Mask: 0.1231. :  32%|███▏      | 32/100 [00:08<00:14,  4.68it/s]Train Iter:  33/5000. LR: 0.0000. Data: 0.07s. Batch: 0.25s. S_Loss: 2.4771. T_Loss: 2.0704. Mask: 0.1231. :  33%|███▎      | 33/100 [00:08<00:12,  5.26it/s]Train Iter:  34/5000. LR: 0.0000. Data: 0.07s. Batch: 0.25s. S_Loss: 2.4787. T_Loss: 2.0604. Mask: 0.1425. :  33%|███▎      | 33/100 [00:08<00:12,  5.26it/s]Train Iter:  34/5000. LR: 0.0000. Data: 0.07s. Batch: 0.25s. S_Loss: 2.4787. T_Loss: 2.0604. Mask: 0.1425. :  34%|███▍      | 34/100 [00:08<00:10,  6.04it/s]Train Iter:  35/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4831. T_Loss: 2.0497. Mask: 0.1554. :  34%|███▍      | 34/100 [00:08<00:10,  6.04it/s]Train Iter:  35/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4831. T_Loss: 2.0497. Mask: 0.1554. :  35%|███▌      | 35/100 [00:08<00:09,  6.50it/s]Train Iter:  36/5000. LR: 0.0000. Data: 0.06s. Batch: 0.24s. S_Loss: 2.4838. T_Loss: 2.0443. Mask: 0.1762. :  35%|███▌      | 35/100 [00:08<00:09,  6.50it/s]Train Iter:  36/5000. LR: 0.0000. Data: 0.06s. Batch: 0.24s. S_Loss: 2.4838. T_Loss: 2.0443. Mask: 0.1762. :  36%|███▌      | 36/100 [00:08<00:09,  6.99it/s]Train Iter:  37/5000. LR: 0.0000. Data: 0.06s. Batch: 0.24s. S_Loss: 2.4833. T_Loss: 2.0317. Mask: 0.1892. :  36%|███▌      | 36/100 [00:08<00:09,  6.99it/s]Train Iter:  37/5000. LR: 0.0000. Data: 0.06s. Batch: 0.24s. S_Loss: 2.4833. T_Loss: 2.0317. Mask: 0.1892. :  37%|███▋      | 37/100 [00:08<00:08,  7.33it/s]Train Iter:  38/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4842. T_Loss: 2.0215. Mask: 0.2039. :  37%|███▋      | 37/100 [00:08<00:08,  7.33it/s]Train Iter:  38/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4842. T_Loss: 2.0215. Mask: 0.2039. :  38%|███▊      | 38/100 [00:08<00:08,  7.56it/s]Train Iter:  39/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4856. T_Loss: 2.0100. Mask: 0.2155. :  38%|███▊      | 38/100 [00:09<00:08,  7.56it/s]Train Iter:  39/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4856. T_Loss: 2.0100. Mask: 0.2155. :  39%|███▉      | 39/100 [00:09<00:07,  8.13it/s]Train Iter:  40/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4876. T_Loss: 2.0010. Mask: 0.2258. :  39%|███▉      | 39/100 [00:09<00:07,  8.13it/s]Train Iter:  40/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4876. T_Loss: 2.0010. Mask: 0.2258. :  40%|████      | 40/100 [00:09<00:10,  5.61it/s]Train Iter:  41/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4877. T_Loss: 1.9951. Mask: 0.2386. :  40%|████      | 40/100 [00:09<00:10,  5.61it/s]Train Iter:  41/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4877. T_Loss: 1.9951. Mask: 0.2386. :  41%|████      | 41/100 [00:09<00:09,  6.21it/s]Train Iter:  42/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.4849. T_Loss: 1.9801. Mask: 0.2478. :  41%|████      | 41/100 [00:09<00:09,  6.21it/s]Train Iter:  43/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4846. T_Loss: 1.9676. Mask: 0.2573. :  42%|████▏     | 42/100 [00:09<00:09,  6.21it/s]Train Iter:  43/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4846. T_Loss: 1.9676. Mask: 0.2573. :  43%|████▎     | 43/100 [00:09<00:07,  7.76it/s]Train Iter:  44/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4862. T_Loss: 1.9602. Mask: 0.2678. :  43%|████▎     | 43/100 [00:09<00:07,  7.76it/s]Train Iter:  45/5000. LR: 0.0000. Data: 0.05s. Batch: 0.23s. S_Loss: 2.4867. T_Loss: 1.9544. Mask: 0.2792. :  44%|████▍     | 44/100 [00:10<00:07,  7.76it/s]Train Iter:  45/5000. LR: 0.0000. Data: 0.05s. Batch: 0.23s. S_Loss: 2.4867. T_Loss: 1.9544. Mask: 0.2792. :  45%|████▌     | 45/100 [00:10<00:09,  5.59it/s]Train Iter:  46/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4872. T_Loss: 1.9522. Mask: 0.2901. :  45%|████▌     | 45/100 [00:10<00:09,  5.59it/s]Train Iter:  46/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4872. T_Loss: 1.9522. Mask: 0.2901. :  46%|████▌     | 46/100 [00:10<00:09,  5.98it/s]Train Iter:  47/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4877. T_Loss: 1.9435. Mask: 0.2979. :  46%|████▌     | 46/100 [00:10<00:09,  5.98it/s]Train Iter:  47/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4877. T_Loss: 1.9435. Mask: 0.2979. :  47%|████▋     | 47/100 [00:10<00:08,  6.32it/s]Train Iter:  48/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4872. T_Loss: 1.9389. Mask: 0.3079. :  47%|████▋     | 47/100 [00:10<00:08,  6.32it/s]Train Iter:  48/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4872. T_Loss: 1.9389. Mask: 0.3079. :  48%|████▊     | 48/100 [00:10<00:07,  6.97it/s]Train Iter:  49/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4874. T_Loss: 1.9342. Mask: 0.3163. :  48%|████▊     | 48/100 [00:10<00:07,  6.97it/s]Train Iter:  49/5000. LR: 0.0000. Data: 0.05s. Batch: 0.22s. S_Loss: 2.4874. T_Loss: 1.9342. Mask: 0.3163. :  49%|████▉     | 49/100 [00:10<00:06,  7.34it/s]Train Iter:  50/5000. LR: 0.0000. Data: 0.05s. Batch: 0.21s. S_Loss: 2.4879. T_Loss: 1.9288. Mask: 0.3281. :  49%|████▉     | 49/100 [00:10<00:06,  7.34it/s]Train Iter:  50/5000. LR: 0.0000. Data: 0.05s. Batch: 0.21s. S_Loss: 2.4879. T_Loss: 1.9288. Mask: 0.3281. :  50%|█████     | 50/100 [00:10<00:06,  7.66it/s]total : 5000  current step :  26
total : 5000  current step :  27
total : 5000  current step :  28
total : 5000  current step :  29
total : 5000  current step :  30
total : 5000  current step :  31
total : 5000  current step :  32
total : 5000  current step :  33
total : 5000  current step :  34
total : 5000  current step :  35
total : 5000  current step :  36
total : 5000  current step :  37
total : 5000  current step :  38
total : 5000  current step :  39
total : 5000  current step :  40
total : 5000  current step :  41
total : 5000  current step :  42
total : 5000  current step :  43
total : 5000  current step :  44
total : 5000  current step :  45
total : 5000  current step :  46
total : 5000  current step :  47
total : 5000  current step :  48
total : 5000  current step :  49
total : 5000  current step :  50
Train Iter:  51/5000. LR: 0.0000. Data: 0.09s. Batch: 0.26s. S_Loss: 2.4888. T_Loss: 1.9200. Mask: 0.3346. :  50%|█████     | 50/100 [00:13<00:06,  7.66it/s]Train Iter:  51/5000. LR: 0.0000. Data: 0.09s. Batch: 0.26s. S_Loss: 2.4888. T_Loss: 1.9200. Mask: 0.3346. :  51%|█████     | 51/100 [00:13<00:38,  1.28it/s]Train Iter:  52/5000. LR: 0.0000. Data: 0.09s. Batch: 0.26s. S_Loss: 2.4870. T_Loss: 1.9140. Mask: 0.3438. :  51%|█████     | 51/100 [00:13<00:38,  1.28it/s]Train Iter:  52/5000. LR: 0.0000. Data: 0.09s. Batch: 0.26s. S_Loss: 2.4870. T_Loss: 1.9140. Mask: 0.3438. :  52%|█████▏    | 52/100 [00:13<00:28,  1.69it/s]Train Iter:  53/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.4877. T_Loss: 1.9060. Mask: 0.3508. :  52%|█████▏    | 52/100 [00:13<00:28,  1.69it/s]Train Iter:  53/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.4877. T_Loss: 1.9060. Mask: 0.3508. :  53%|█████▎    | 53/100 [00:13<00:21,  2.21it/s]Train Iter:  54/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4876. T_Loss: 1.9012. Mask: 0.3576. :  53%|█████▎    | 53/100 [00:13<00:21,  2.21it/s]Train Iter:  54/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4876. T_Loss: 1.9012. Mask: 0.3576. :  54%|█████▍    | 54/100 [00:13<00:18,  2.42it/s]Train Iter:  55/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4899. T_Loss: 1.8956. Mask: 0.3653. :  54%|█████▍    | 54/100 [00:13<00:18,  2.42it/s]Train Iter:  55/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4899. T_Loss: 1.8956. Mask: 0.3653. :  55%|█████▌    | 55/100 [00:13<00:14,  3.03it/s]Train Iter:  56/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4913. T_Loss: 1.8915. Mask: 0.3717. :  55%|█████▌    | 55/100 [00:14<00:14,  3.03it/s]Train Iter:  56/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4913. T_Loss: 1.8915. Mask: 0.3717. :  56%|█████▌    | 56/100 [00:14<00:11,  3.75it/s]Train Iter:  57/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4900. T_Loss: 1.8880. Mask: 0.3777. :  56%|█████▌    | 56/100 [00:14<00:11,  3.75it/s]Train Iter:  57/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4900. T_Loss: 1.8880. Mask: 0.3777. :  57%|█████▋    | 57/100 [00:14<00:09,  4.45it/s]Train Iter:  58/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.4908. T_Loss: 1.8840. Mask: 0.3836. :  57%|█████▋    | 57/100 [00:14<00:09,  4.45it/s]Train Iter:  58/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.4908. T_Loss: 1.8840. Mask: 0.3836. :  58%|█████▊    | 58/100 [00:14<00:08,  5.17it/s]Train Iter:  59/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4918. T_Loss: 1.8814. Mask: 0.3904. :  58%|█████▊    | 58/100 [00:14<00:08,  5.17it/s]Train Iter:  59/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.4918. T_Loss: 1.8814. Mask: 0.3904. :  59%|█████▉    | 59/100 [00:14<00:10,  4.02it/s]Train Iter:  60/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.4926. T_Loss: 1.8797. Mask: 0.3974. :  59%|█████▉    | 59/100 [00:14<00:10,  4.02it/s]Train Iter:  60/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.4926. T_Loss: 1.8797. Mask: 0.3974. :  60%|██████    | 60/100 [00:14<00:08,  4.68it/s]Train Iter:  61/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.4941. T_Loss: 1.8770. Mask: 0.4047. :  60%|██████    | 60/100 [00:14<00:08,  4.68it/s]Train Iter:  61/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.4941. T_Loss: 1.8770. Mask: 0.4047. :  61%|██████    | 61/100 [00:14<00:07,  5.33it/s]Train Iter:  62/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4962. T_Loss: 1.8749. Mask: 0.4118. :  61%|██████    | 61/100 [00:15<00:07,  5.33it/s]Train Iter:  62/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4962. T_Loss: 1.8749. Mask: 0.4118. :  62%|██████▏   | 62/100 [00:15<00:06,  5.88it/s]Train Iter:  63/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4976. T_Loss: 1.8731. Mask: 0.4196. :  62%|██████▏   | 62/100 [00:15<00:06,  5.88it/s]Train Iter:  63/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4976. T_Loss: 1.8731. Mask: 0.4196. :  63%|██████▎   | 63/100 [00:15<00:05,  6.41it/s]Train Iter:  64/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4987. T_Loss: 1.8710. Mask: 0.4243. :  63%|██████▎   | 63/100 [00:15<00:05,  6.41it/s]Train Iter:  64/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4987. T_Loss: 1.8710. Mask: 0.4243. :  64%|██████▍   | 64/100 [00:15<00:06,  5.89it/s]Train Iter:  65/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4990. T_Loss: 1.8708. Mask: 0.4298. :  64%|██████▍   | 64/100 [00:15<00:06,  5.89it/s]Train Iter:  65/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4990. T_Loss: 1.8708. Mask: 0.4298. :  65%|██████▌   | 65/100 [00:15<00:05,  6.30it/s]Train Iter:  66/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4995. T_Loss: 1.8695. Mask: 0.4356. :  65%|██████▌   | 65/100 [00:15<00:05,  6.30it/s]Train Iter:  66/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.4995. T_Loss: 1.8695. Mask: 0.4356. :  66%|██████▌   | 66/100 [00:15<00:05,  6.28it/s]Train Iter:  67/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.4987. T_Loss: 1.8673. Mask: 0.4398. :  66%|██████▌   | 66/100 [00:15<00:05,  6.28it/s]Train Iter:  67/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.4987. T_Loss: 1.8673. Mask: 0.4398. :  67%|██████▋   | 67/100 [00:15<00:04,  6.74it/s]Train Iter:  68/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.4993. T_Loss: 1.8647. Mask: 0.4453. :  67%|██████▋   | 67/100 [00:15<00:04,  6.74it/s]Train Iter:  68/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.4993. T_Loss: 1.8647. Mask: 0.4453. :  68%|██████▊   | 68/100 [00:15<00:04,  7.11it/s]Train Iter:  69/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5006. T_Loss: 1.8620. Mask: 0.4506. :  68%|██████▊   | 68/100 [00:16<00:04,  7.11it/s]Train Iter:  69/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5006. T_Loss: 1.8620. Mask: 0.4506. :  69%|██████▉   | 69/100 [00:16<00:05,  5.76it/s]Train Iter:  70/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5012. T_Loss: 1.8594. Mask: 0.4562. :  69%|██████▉   | 69/100 [00:16<00:05,  5.76it/s]Train Iter:  70/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5012. T_Loss: 1.8594. Mask: 0.4562. :  70%|███████   | 70/100 [00:16<00:04,  6.43it/s]Train Iter:  71/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5005. T_Loss: 1.8565. Mask: 0.4604. :  70%|███████   | 70/100 [00:16<00:04,  6.43it/s]Train Iter:  71/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5005. T_Loss: 1.8565. Mask: 0.4604. :  71%|███████   | 71/100 [00:16<00:04,  6.88it/s]Train Iter:  72/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5014. T_Loss: 1.8550. Mask: 0.4666. :  71%|███████   | 71/100 [00:16<00:04,  6.88it/s]Train Iter:  72/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5014. T_Loss: 1.8550. Mask: 0.4666. :  72%|███████▏  | 72/100 [00:16<00:03,  7.36it/s]Train Iter:  73/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5013. T_Loss: 1.8524. Mask: 0.4705. :  72%|███████▏  | 72/100 [00:16<00:03,  7.36it/s]Train Iter:  73/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5013. T_Loss: 1.8524. Mask: 0.4705. :  73%|███████▎  | 73/100 [00:16<00:03,  7.96it/s]Train Iter:  74/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5026. T_Loss: 1.8513. Mask: 0.4751. :  73%|███████▎  | 73/100 [00:16<00:03,  7.96it/s]Train Iter:  74/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5026. T_Loss: 1.8513. Mask: 0.4751. :  74%|███████▍  | 74/100 [00:16<00:04,  5.78it/s]Train Iter:  75/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5037. T_Loss: 1.8505. Mask: 0.4800. :  74%|███████▍  | 74/100 [00:16<00:04,  5.78it/s]Train Iter:  75/5000. LR: 0.0000. Data: 0.06s. Batch: 0.23s. S_Loss: 2.5037. T_Loss: 1.8505. Mask: 0.4800. :  75%|███████▌  | 75/100 [00:16<00:03,  6.41it/s]total : 5000  current step :  51
total : 5000  current step :  52
total : 5000  current step :  53
total : 5000  current step :  54
total : 5000  current step :  55
total : 5000  current step :  56
total : 5000  current step :  57
total : 5000  current step :  58
total : 5000  current step :  59
total : 5000  current step :  60
total : 5000  current step :  61
total : 5000  current step :  62
total : 5000  current step :  63
total : 5000  current step :  64
total : 5000  current step :  65
total : 5000  current step :  66
total : 5000  current step :  67
total : 5000  current step :  68
total : 5000  current step :  69
total : 5000  current step :  70
total : 5000  current step :  71
total : 5000  current step :  72
total : 5000  current step :  73
total : 5000  current step :  74
total : 5000  current step :  75
Train Iter:  76/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5040. T_Loss: 1.8506. Mask: 0.4844. :  75%|███████▌  | 75/100 [00:19<00:03,  6.41it/s]Train Iter:  76/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5040. T_Loss: 1.8506. Mask: 0.4844. :  76%|███████▌  | 76/100 [00:19<00:17,  1.34it/s]Train Iter:  77/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5038. T_Loss: 1.8504. Mask: 0.4899. :  76%|███████▌  | 76/100 [00:19<00:17,  1.34it/s]Train Iter:  77/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5038. T_Loss: 1.8504. Mask: 0.4899. :  77%|███████▋  | 77/100 [00:19<00:13,  1.76it/s]Train Iter:  78/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5048. T_Loss: 1.8498. Mask: 0.4956. :  77%|███████▋  | 77/100 [00:19<00:13,  1.76it/s]Train Iter:  78/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5048. T_Loss: 1.8498. Mask: 0.4956. :  78%|███████▊  | 78/100 [00:19<00:09,  2.26it/s]Train Iter:  79/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.5045. T_Loss: 1.8496. Mask: 0.5004. :  78%|███████▊  | 78/100 [00:19<00:09,  2.26it/s]Train Iter:  79/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.5045. T_Loss: 1.8496. Mask: 0.5004. :  79%|███████▉  | 79/100 [00:19<00:07,  2.63it/s]Train Iter:  80/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.5057. T_Loss: 1.8471. Mask: 0.5047. :  79%|███████▉  | 79/100 [00:19<00:07,  2.63it/s]Train Iter:  80/5000. LR: 0.0000. Data: 0.08s. Batch: 0.25s. S_Loss: 2.5057. T_Loss: 1.8471. Mask: 0.5047. :  80%|████████  | 80/100 [00:19<00:06,  3.31it/s]Train Iter:  81/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5076. T_Loss: 1.8484. Mask: 0.5096. :  80%|████████  | 80/100 [00:19<00:06,  3.31it/s]Train Iter:  82/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5080. T_Loss: 1.8517. Mask: 0.5149. :  81%|████████  | 81/100 [00:19<00:05,  3.31it/s]Train Iter:  82/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5080. T_Loss: 1.8517. Mask: 0.5149. :  82%|████████▏ | 82/100 [00:19<00:03,  4.69it/s]Train Iter:  83/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5078. T_Loss: 1.8501. Mask: 0.5181. :  82%|████████▏ | 82/100 [00:20<00:03,  4.69it/s]Train Iter:  84/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5062. T_Loss: 1.8491. Mask: 0.5223. :  83%|████████▎ | 83/100 [00:20<00:03,  4.69it/s]Train Iter:  84/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5062. T_Loss: 1.8491. Mask: 0.5223. :  84%|████████▍ | 84/100 [00:20<00:03,  4.83it/s]Train Iter:  85/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5056. T_Loss: 1.8505. Mask: 0.5265. :  84%|████████▍ | 84/100 [00:20<00:03,  4.83it/s]Train Iter:  85/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5056. T_Loss: 1.8505. Mask: 0.5265. :  85%|████████▌ | 85/100 [00:20<00:02,  5.30it/s]Train Iter:  86/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5055. T_Loss: 1.8498. Mask: 0.5312. :  85%|████████▌ | 85/100 [00:20<00:02,  5.30it/s]Train Iter:  86/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5055. T_Loss: 1.8498. Mask: 0.5312. :  86%|████████▌ | 86/100 [00:20<00:02,  5.77it/s]Train Iter:  87/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5054. T_Loss: 1.8486. Mask: 0.5338. :  86%|████████▌ | 86/100 [00:20<00:02,  5.77it/s]Train Iter:  87/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5054. T_Loss: 1.8486. Mask: 0.5338. :  87%|████████▋ | 87/100 [00:20<00:02,  5.99it/s]Train Iter:  88/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5064. T_Loss: 1.8494. Mask: 0.5384. :  87%|████████▋ | 87/100 [00:20<00:02,  5.99it/s]Train Iter:  88/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5064. T_Loss: 1.8494. Mask: 0.5384. :  88%|████████▊ | 88/100 [00:20<00:01,  6.27it/s]Train Iter:  89/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5065. T_Loss: 1.8491. Mask: 0.5404. :  88%|████████▊ | 88/100 [00:21<00:01,  6.27it/s]Train Iter:  89/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5065. T_Loss: 1.8491. Mask: 0.5404. :  89%|████████▉ | 89/100 [00:21<00:02,  4.33it/s]Train Iter:  90/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.5055. T_Loss: 1.8494. Mask: 0.5437. :  89%|████████▉ | 89/100 [00:21<00:02,  4.33it/s]Train Iter:  90/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.5055. T_Loss: 1.8494. Mask: 0.5437. :  90%|█████████ | 90/100 [00:21<00:02,  4.89it/s]Train Iter:  91/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.5042. T_Loss: 1.8475. Mask: 0.5467. :  90%|█████████ | 90/100 [00:21<00:02,  4.89it/s]Train Iter:  91/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.5042. T_Loss: 1.8475. Mask: 0.5467. :  91%|█████████ | 91/100 [00:21<00:01,  5.25it/s]Train Iter:  92/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.5030. T_Loss: 1.8451. Mask: 0.5493. :  91%|█████████ | 91/100 [00:21<00:01,  5.25it/s]Train Iter:  92/5000. LR: 0.0000. Data: 0.07s. Batch: 0.24s. S_Loss: 2.5030. T_Loss: 1.8451. Mask: 0.5493. :  92%|█████████▏| 92/100 [00:21<00:01,  5.73it/s]Train Iter:  93/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5029. T_Loss: 1.8473. Mask: 0.5528. :  92%|█████████▏| 92/100 [00:21<00:01,  5.73it/s]Train Iter:  93/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5029. T_Loss: 1.8473. Mask: 0.5528. :  93%|█████████▎| 93/100 [00:21<00:01,  6.20it/s]Train Iter:  94/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5023. T_Loss: 1.8478. Mask: 0.5555. :  93%|█████████▎| 93/100 [00:22<00:01,  6.20it/s]Train Iter:  94/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5023. T_Loss: 1.8478. Mask: 0.5555. :  94%|█████████▍| 94/100 [00:22<00:00,  6.23it/s]Train Iter:  95/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5013. T_Loss: 1.8488. Mask: 0.5589. :  94%|█████████▍| 94/100 [00:22<00:00,  6.23it/s]Train Iter:  95/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5013. T_Loss: 1.8488. Mask: 0.5589. :  95%|█████████▌| 95/100 [00:22<00:00,  6.58it/s]Train Iter:  96/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5010. T_Loss: 1.8495. Mask: 0.5609. :  95%|█████████▌| 95/100 [00:22<00:00,  6.58it/s]Train Iter:  96/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5010. T_Loss: 1.8495. Mask: 0.5609. :  96%|█████████▌| 96/100 [00:22<00:00,  6.57it/s]Train Iter:  97/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5010. T_Loss: 1.8494. Mask: 0.5641. :  96%|█████████▌| 96/100 [00:22<00:00,  6.57it/s]Train Iter:  97/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5010. T_Loss: 1.8494. Mask: 0.5641. :  97%|█████████▋| 97/100 [00:22<00:00,  6.89it/s]Train Iter:  98/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5015. T_Loss: 1.8513. Mask: 0.5679. :  97%|█████████▋| 97/100 [00:22<00:00,  6.89it/s]Train Iter:  98/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5015. T_Loss: 1.8513. Mask: 0.5679. :  98%|█████████▊| 98/100 [00:22<00:00,  7.28it/s]Train Iter:  99/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5012. T_Loss: 1.8520. Mask: 0.5710. :  98%|█████████▊| 98/100 [00:22<00:00,  7.28it/s]Train Iter:  99/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5012. T_Loss: 1.8520. Mask: 0.5710. :  99%|█████████▉| 99/100 [00:22<00:00,  5.90it/s]Train Iter: 100/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5017. T_Loss: 1.8542. Mask: 0.5741. :  99%|█████████▉| 99/100 [00:22<00:00,  5.90it/s]Train Iter: 100/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5017. T_Loss: 1.8542. Mask: 0.5741. : 100%|██████████| 100/100 [00:22<00:00,  6.39it/s]Train Iter: 100/5000. LR: 0.0000. Data: 0.07s. Batch: 0.23s. S_Loss: 2.5017. T_Loss: 1.8542. Mask: 0.5741. : 100%|██████████| 100/100 [00:22<00:00,  4.35it/s]
total : 5000  current step :  76
total : 5000  current step :  77
total : 5000  current step :  78
total : 5000  current step :  79
total : 5000  current step :  80
total : 5000  current step :  81
total : 5000  current step :  82
total : 5000  current step :  83
total : 5000  current step :  84
total : 5000  current step :  85
total : 5000  current step :  86
total : 5000  current step :  87
total : 5000  current step :  88
total : 5000  current step :  89
total : 5000  current step :  90
total : 5000  current step :  91
total : 5000  current step :  92
total : 5000  current step :  93
total : 5000  current step :  94
total : 5000  current step :  95
total : 5000  current step :  96
total : 5000  current step :  97
total : 5000  current step :  98
total : 5000  current step :  99
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.76s. Loss: 2.5829. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.76s. Loss: 2.5829. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.76s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 2.5304. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.76s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 2.5164. top1: 0.00. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:49,  1.76s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 2.5376. top1: 0.00. top5: 99.22. :   2%|▏         | 1/63 [00:01<01:49,  1.76s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 2.5218. top1: 0.00. top5: 98.75. :   2%|▏         | 1/63 [00:01<01:49,  1.76s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 2.4949. top1: 0.00. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:49,  1.76s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 2.4949. top1: 0.00. top5: 98.96. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 2.4834. top1: 0.00. top5: 99.11. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 2.4683. top1: 0.00. top5: 99.22. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.4493. top1: 0.00. top5: 99.31. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.4410. top1: 0.00. top5: 99.38. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 2.4387. top1: 0.00. top5: 99.43. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.4427. top1: 0.00. top5: 99.48. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.4463. top1: 0.00. top5: 99.52. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.4480. top1: 0.00. top5: 99.55. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.4453. top1: 0.00. top5: 99.58. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.4387. top1: 0.00. top5: 99.41. :  10%|▉         | 6/63 [00:02<00:13,  4.25it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.4387. top1: 0.00. top5: 99.41. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.4431. top1: 0.00. top5: 99.45. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.4403. top1: 0.00. top5: 99.48. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.4405. top1: 0.00. top5: 99.51. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.4474. top1: 0.00. top5: 99.53. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.4446. top1: 0.00. top5: 99.55. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4466. top1: 0.00. top5: 99.57. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4423. top1: 0.00. top5: 99.59. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4355. top1: 0.00. top5: 99.61. :  25%|██▌       | 16/63 [00:02<00:03, 12.83it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4355. top1: 0.00. top5: 99.61. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4364. top1: 0.00. top5: 99.38. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4396. top1: 0.00. top5: 99.40. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4408. top1: 0.00. top5: 99.42. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4435. top1: 0.00. top5: 99.44. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.4435. top1: 0.00. top5: 99.46. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.4445. top1: 0.00. top5: 99.38. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.4457. top1: 0.00. top5: 99.40. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.4748. top1: 0.00. top5: 99.32. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.4981. top1: 0.00. top5: 99.34. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.5211. top1: 0.00. top5: 99.17. :  38%|███▊      | 24/63 [00:02<00:01, 20.56it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.5211. top1: 0.00. top5: 99.17. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5356. top1: 0.00. top5: 99.20. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5563. top1: 0.00. top5: 99.13. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5792. top1: 0.00. top5: 98.99. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5996. top1: 0.00. top5: 98.93. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6185. top1: 0.00. top5: 98.96. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6418. top1: 0.00. top5: 98.98. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6640. top1: 0.00. top5: 98.93. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6850. top1: 0.00. top5: 98.88. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7028. top1: 0.00. top5: 98.84. :  54%|█████▍    | 34/63 [00:02<00:00, 31.63it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7028. top1: 0.00. top5: 98.84. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7150. top1: 0.00. top5: 98.86. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7321. top1: 0.00. top5: 98.82. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7456. top1: 0.00. top5: 98.85. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7589. top1: 0.00. top5: 98.80. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7747. top1: 0.00. top5: 98.76. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7902. top1: 0.00. top5: 98.79. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8046. top1: 0.00. top5: 98.81. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8195. top1: 0.00. top5: 98.77. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8345. top1: 0.00. top5: 98.74. :  68%|██████▊   | 43/63 [00:02<00:00, 40.83it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8345. top1: 0.00. top5: 98.74. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8460. top1: 0.00. top5: 98.76. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8556. top1: 0.00. top5: 98.73. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8662. top1: 0.00. top5: 98.69. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8736. top1: 0.00. top5: 98.72. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8789. top1: 0.00. top5: 98.63. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8832. top1: 0.00. top5: 98.49. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8899. top1: 0.00. top5: 98.41. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9022. top1: 0.00. top5: 98.39. :  83%|████████▎ | 52/63 [00:02<00:00, 49.56it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9022. top1: 0.00. top5: 98.39. :  95%|█████████▌| 60/63 [00:02<00:00, 51.81it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9116. top1: 0.00. top5: 98.36. :  95%|█████████▌| 60/63 [00:02<00:00, 51.81it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9172. top1: 0.00. top5: 98.34. :  95%|█████████▌| 60/63 [00:02<00:00, 51.81it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9214. top1: 0.00. top5: 98.35. :  95%|█████████▌| 60/63 [00:02<00:00, 51.81it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9214. top1: 0.00. top5: 98.35. : 100%|██████████| 63/63 [00:02<00:00, 22.33it/s]
total : 5000  current step :  100
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 101/5000. LR: 0.0000. Data: 2.15s. Batch: 2.26s. S_Loss: 2.4261. T_Loss: 1.9815. Mask: 0.8125. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 101/5000. LR: 0.0000. Data: 2.15s. Batch: 2.26s. S_Loss: 2.4261. T_Loss: 1.9815. Mask: 0.8125. :   1%|          | 1/100 [00:02<03:43,  2.26s/it]Train Iter: 102/5000. LR: 0.0000. Data: 1.07s. Batch: 1.19s. S_Loss: 2.4647. T_Loss: 2.0082. Mask: 0.7969. :   1%|          | 1/100 [00:02<03:43,  2.26s/it]Train Iter: 102/5000. LR: 0.0000. Data: 1.07s. Batch: 1.19s. S_Loss: 2.4647. T_Loss: 2.0082. Mask: 0.7969. :   2%|▏         | 2/100 [00:02<01:38,  1.00s/it]Train Iter: 103/5000. LR: 0.0000. Data: 0.72s. Batch: 0.83s. S_Loss: 2.4911. T_Loss: 1.9833. Mask: 0.7708. :   2%|▏         | 2/100 [00:02<01:38,  1.00s/it]Train Iter: 103/5000. LR: 0.0000. Data: 0.72s. Batch: 0.83s. S_Loss: 2.4911. T_Loss: 1.9833. Mask: 0.7708. :   3%|▎         | 3/100 [00:02<00:58,  1.66it/s]Train Iter: 104/5000. LR: 0.0000. Data: 0.54s. Batch: 0.70s. S_Loss: 2.4899. T_Loss: 2.0511. Mask: 0.7891. :   3%|▎         | 3/100 [00:02<00:58,  1.66it/s]Train Iter: 104/5000. LR: 0.0000. Data: 0.54s. Batch: 0.70s. S_Loss: 2.4899. T_Loss: 2.0511. Mask: 0.7891. :   4%|▍         | 4/100 [00:02<00:46,  2.06it/s]Train Iter: 105/5000. LR: 0.0000. Data: 0.43s. Batch: 0.59s. S_Loss: 2.4964. T_Loss: 2.0793. Mask: 0.8125. :   4%|▍         | 4/100 [00:02<00:46,  2.06it/s]Train Iter: 105/5000. LR: 0.0000. Data: 0.43s. Batch: 0.59s. S_Loss: 2.4964. T_Loss: 2.0793. Mask: 0.8125. :   5%|▌         | 5/100 [00:02<00:33,  2.81it/s]Train Iter: 106/5000. LR: 0.0000. Data: 0.36s. Batch: 0.51s. S_Loss: 2.5028. T_Loss: 2.0699. Mask: 0.8177. :   5%|▌         | 5/100 [00:03<00:33,  2.81it/s]Train Iter: 106/5000. LR: 0.0000. Data: 0.36s. Batch: 0.51s. S_Loss: 2.5028. T_Loss: 2.0699. Mask: 0.8177. :   6%|▌         | 6/100 [00:03<00:25,  3.63it/s]Train Iter: 107/5000. LR: 0.0000. Data: 0.31s. Batch: 0.45s. S_Loss: 2.5134. T_Loss: 2.0637. Mask: 0.8125. :   6%|▌         | 6/100 [00:03<00:25,  3.63it/s]Train Iter: 107/5000. LR: 0.0000. Data: 0.31s. Batch: 0.45s. S_Loss: 2.5134. T_Loss: 2.0637. Mask: 0.8125. :   7%|▋         | 7/100 [00:03<00:21,  4.37it/s]Train Iter: 108/5000. LR: 0.0000. Data: 0.27s. Batch: 0.42s. S_Loss: 2.5237. T_Loss: 2.0657. Mask: 0.8203. :   7%|▋         | 7/100 [00:03<00:21,  4.37it/s]Train Iter: 108/5000. LR: 0.0000. Data: 0.27s. Batch: 0.42s. S_Loss: 2.5237. T_Loss: 2.0657. Mask: 0.8203. :   8%|▊         | 8/100 [00:03<00:18,  4.94it/s]Train Iter: 109/5000. LR: 0.0000. Data: 0.24s. Batch: 0.38s. S_Loss: 2.5182. T_Loss: 2.0827. Mask: 0.8299. :   8%|▊         | 8/100 [00:03<00:18,  4.94it/s]Train Iter: 109/5000. LR: 0.0000. Data: 0.24s. Batch: 0.38s. S_Loss: 2.5182. T_Loss: 2.0827. Mask: 0.8299. :   9%|▉         | 9/100 [00:03<00:16,  5.60it/s]Train Iter: 110/5000. LR: 0.0000. Data: 0.22s. Batch: 0.36s. S_Loss: 2.5214. T_Loss: 2.0741. Mask: 0.8375. :   9%|▉         | 9/100 [00:03<00:16,  5.60it/s]Train Iter: 110/5000. LR: 0.0000. Data: 0.22s. Batch: 0.36s. S_Loss: 2.5214. T_Loss: 2.0741. Mask: 0.8375. :  10%|█         | 10/100 [00:03<00:14,  6.07it/s]Train Iter: 111/5000. LR: 0.0000. Data: 0.20s. Batch: 0.34s. S_Loss: 2.5218. T_Loss: 2.0787. Mask: 0.8381. :  10%|█         | 10/100 [00:03<00:14,  6.07it/s]Train Iter: 111/5000. LR: 0.0000. Data: 0.20s. Batch: 0.34s. S_Loss: 2.5218. T_Loss: 2.0787. Mask: 0.8381. :  11%|█         | 11/100 [00:03<00:13,  6.68it/s]Train Iter: 112/5000. LR: 0.0000. Data: 0.18s. Batch: 0.32s. S_Loss: 2.5143. T_Loss: 2.0825. Mask: 0.8464. :  11%|█         | 11/100 [00:03<00:13,  6.68it/s]Train Iter: 112/5000. LR: 0.0000. Data: 0.18s. Batch: 0.32s. S_Loss: 2.5143. T_Loss: 2.0825. Mask: 0.8464. :  12%|█▏        | 12/100 [00:03<00:11,  7.42it/s]Train Iter: 113/5000. LR: 0.0000. Data: 0.17s. Batch: 0.30s. S_Loss: 2.5066. T_Loss: 2.0670. Mask: 0.8413. :  12%|█▏        | 12/100 [00:03<00:11,  7.42it/s]Train Iter: 113/5000. LR: 0.0000. Data: 0.17s. Batch: 0.30s. S_Loss: 2.5066. T_Loss: 2.0670. Mask: 0.8413. :  13%|█▎        | 13/100 [00:03<00:11,  7.75it/s]Train Iter: 114/5000. LR: 0.0000. Data: 0.16s. Batch: 0.31s. S_Loss: 2.5038. T_Loss: 2.0769. Mask: 0.8438. :  13%|█▎        | 13/100 [00:04<00:11,  7.75it/s]Train Iter: 114/5000. LR: 0.0000. Data: 0.16s. Batch: 0.31s. S_Loss: 2.5038. T_Loss: 2.0769. Mask: 0.8438. :  14%|█▍        | 14/100 [00:04<00:17,  4.80it/s]Train Iter: 115/5000. LR: 0.0000. Data: 0.15s. Batch: 0.30s. S_Loss: 2.5105. T_Loss: 2.0693. Mask: 0.8458. :  14%|█▍        | 14/100 [00:04<00:17,  4.80it/s]Train Iter: 115/5000. LR: 0.0000. Data: 0.15s. Batch: 0.30s. S_Loss: 2.5105. T_Loss: 2.0693. Mask: 0.8458. :  15%|█▌        | 15/100 [00:04<00:15,  5.45it/s]Train Iter: 116/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5064. T_Loss: 2.0835. Mask: 0.8516. :  15%|█▌        | 15/100 [00:04<00:15,  5.45it/s]Train Iter: 116/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5064. T_Loss: 2.0835. Mask: 0.8516. :  16%|█▌        | 16/100 [00:04<00:13,  6.06it/s]Train Iter: 117/5000. LR: 0.0000. Data: 0.13s. Batch: 0.27s. S_Loss: 2.5128. T_Loss: 2.0941. Mask: 0.8585. :  16%|█▌        | 16/100 [00:04<00:13,  6.06it/s]Train Iter: 117/5000. LR: 0.0000. Data: 0.13s. Batch: 0.27s. S_Loss: 2.5128. T_Loss: 2.0941. Mask: 0.8585. :  17%|█▋        | 17/100 [00:04<00:12,  6.73it/s]Train Iter: 118/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5125. T_Loss: 2.0898. Mask: 0.8542. :  17%|█▋        | 17/100 [00:05<00:12,  6.73it/s]Train Iter: 118/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5125. T_Loss: 2.0898. Mask: 0.8542. :  18%|█▊        | 18/100 [00:05<00:18,  4.46it/s]Train Iter: 119/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5143. T_Loss: 2.0886. Mask: 0.8586. :  18%|█▊        | 18/100 [00:05<00:18,  4.46it/s]Train Iter: 119/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5143. T_Loss: 2.0886. Mask: 0.8586. :  19%|█▉        | 19/100 [00:05<00:15,  5.16it/s]Train Iter: 120/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5159. T_Loss: 2.0927. Mask: 0.8609. :  19%|█▉        | 19/100 [00:05<00:15,  5.16it/s]Train Iter: 120/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5159. T_Loss: 2.0927. Mask: 0.8609. :  20%|██        | 20/100 [00:05<00:13,  5.81it/s]Train Iter: 121/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5174. T_Loss: 2.0896. Mask: 0.8586. :  20%|██        | 20/100 [00:05<00:13,  5.81it/s]Train Iter: 121/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5174. T_Loss: 2.0896. Mask: 0.8586. :  21%|██        | 21/100 [00:05<00:12,  6.40it/s]Train Iter: 122/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5203. T_Loss: 2.0914. Mask: 0.8580. :  21%|██        | 21/100 [00:05<00:12,  6.40it/s]Train Iter: 122/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5203. T_Loss: 2.0914. Mask: 0.8580. :  22%|██▏       | 22/100 [00:05<00:11,  6.76it/s]Train Iter: 123/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5179. T_Loss: 2.0903. Mask: 0.8587. :  22%|██▏       | 22/100 [00:05<00:11,  6.76it/s]Train Iter: 123/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5179. T_Loss: 2.0903. Mask: 0.8587. :  23%|██▎       | 23/100 [00:05<00:10,  7.03it/s]Train Iter: 124/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5182. T_Loss: 2.0797. Mask: 0.8568. :  23%|██▎       | 23/100 [00:05<00:10,  7.03it/s]Train Iter: 124/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5182. T_Loss: 2.0797. Mask: 0.8568. :  24%|██▍       | 24/100 [00:05<00:10,  7.22it/s]Train Iter: 125/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5181. T_Loss: 2.0918. Mask: 0.8600. :  24%|██▍       | 24/100 [00:05<00:10,  7.22it/s]Train Iter: 125/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5181. T_Loss: 2.0918. Mask: 0.8600. :  25%|██▌       | 25/100 [00:05<00:10,  7.49it/s]total : 5000  current step :  101
total : 5000  current step :  102
total : 5000  current step :  103
total : 5000  current step :  104
total : 5000  current step :  105
total : 5000  current step :  106
total : 5000  current step :  107
total : 5000  current step :  108
total : 5000  current step :  109
total : 5000  current step :  110
total : 5000  current step :  111
total : 5000  current step :  112
total : 5000  current step :  113
total : 5000  current step :  114
total : 5000  current step :  115
total : 5000  current step :  116
total : 5000  current step :  117
total : 5000  current step :  118
total : 5000  current step :  119
total : 5000  current step :  120
total : 5000  current step :  121
total : 5000  current step :  122
total : 5000  current step :  123
total : 5000  current step :  124
total : 5000  current step :  125
Train Iter: 126/5000. LR: 0.0000. Data: 0.16s. Batch: 0.31s. S_Loss: 2.5237. T_Loss: 2.0846. Mask: 0.8594. :  25%|██▌       | 25/100 [00:08<00:10,  7.49it/s]Train Iter: 126/5000. LR: 0.0000. Data: 0.16s. Batch: 0.31s. S_Loss: 2.5237. T_Loss: 2.0846. Mask: 0.8594. :  26%|██▌       | 26/100 [00:08<00:52,  1.41it/s]Train Iter: 127/5000. LR: 0.0000. Data: 0.15s. Batch: 0.30s. S_Loss: 2.5262. T_Loss: 2.0756. Mask: 0.8565. :  26%|██▌       | 26/100 [00:08<00:52,  1.41it/s]Train Iter: 127/5000. LR: 0.0000. Data: 0.15s. Batch: 0.30s. S_Loss: 2.5262. T_Loss: 2.0756. Mask: 0.8565. :  27%|██▋       | 27/100 [00:08<00:38,  1.90it/s]Train Iter: 128/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 2.5255. T_Loss: 2.0790. Mask: 0.8571. :  27%|██▋       | 27/100 [00:08<00:38,  1.90it/s]Train Iter: 128/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 2.5255. T_Loss: 2.0790. Mask: 0.8571. :  28%|██▊       | 28/100 [00:08<00:28,  2.50it/s]Train Iter: 129/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.5221. T_Loss: 2.0864. Mask: 0.8588. :  28%|██▊       | 28/100 [00:08<00:28,  2.50it/s]Train Iter: 129/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.5221. T_Loss: 2.0864. Mask: 0.8588. :  29%|██▉       | 29/100 [00:08<00:22,  3.19it/s]Train Iter: 130/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.5207. T_Loss: 2.0857. Mask: 0.8604. :  29%|██▉       | 29/100 [00:08<00:22,  3.19it/s]Train Iter: 130/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.5207. T_Loss: 2.0857. Mask: 0.8604. :  30%|███       | 30/100 [00:08<00:22,  3.06it/s]Train Iter: 131/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5161. T_Loss: 2.0988. Mask: 0.8619. :  30%|███       | 30/100 [00:08<00:22,  3.06it/s]Train Iter: 131/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5161. T_Loss: 2.0988. Mask: 0.8619. :  31%|███       | 31/100 [00:08<00:18,  3.78it/s]Train Iter: 132/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5177. T_Loss: 2.1011. Mask: 0.8633. :  31%|███       | 31/100 [00:08<00:18,  3.78it/s]Train Iter: 132/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5177. T_Loss: 2.1011. Mask: 0.8633. :  32%|███▏      | 32/100 [00:08<00:15,  4.50it/s]Train Iter: 133/5000. LR: 0.0000. Data: 0.13s. Batch: 0.27s. S_Loss: 2.5168. T_Loss: 2.1044. Mask: 0.8655. :  32%|███▏      | 32/100 [00:09<00:15,  4.50it/s]Train Iter: 133/5000. LR: 0.0000. Data: 0.13s. Batch: 0.27s. S_Loss: 2.5168. T_Loss: 2.1044. Mask: 0.8655. :  33%|███▎      | 33/100 [00:09<00:12,  5.17it/s]Train Iter: 134/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5163. T_Loss: 2.1089. Mask: 0.8640. :  33%|███▎      | 33/100 [00:09<00:12,  5.17it/s]Train Iter: 134/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5163. T_Loss: 2.1089. Mask: 0.8640. :  34%|███▍      | 34/100 [00:09<00:11,  5.92it/s]Train Iter: 135/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5174. T_Loss: 2.1143. Mask: 0.8634. :  34%|███▍      | 34/100 [00:09<00:11,  5.92it/s]Train Iter: 135/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5174. T_Loss: 2.1143. Mask: 0.8634. :  35%|███▌      | 35/100 [00:09<00:14,  4.52it/s]Train Iter: 136/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5190. T_Loss: 2.1207. Mask: 0.8637. :  35%|███▌      | 35/100 [00:09<00:14,  4.52it/s]Train Iter: 136/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5190. T_Loss: 2.1207. Mask: 0.8637. :  36%|███▌      | 36/100 [00:09<00:12,  5.24it/s]Train Iter: 137/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5247. T_Loss: 2.1223. Mask: 0.8632. :  36%|███▌      | 36/100 [00:09<00:12,  5.24it/s]Train Iter: 138/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5257. T_Loss: 2.1305. Mask: 0.8651. :  37%|███▋      | 37/100 [00:09<00:12,  5.24it/s]Train Iter: 138/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5257. T_Loss: 2.1305. Mask: 0.8651. :  38%|███▊      | 38/100 [00:09<00:08,  7.13it/s]Train Iter: 139/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5271. T_Loss: 2.1373. Mask: 0.8654. :  38%|███▊      | 38/100 [00:10<00:08,  7.13it/s]Train Iter: 139/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5271. T_Loss: 2.1373. Mask: 0.8654. :  39%|███▉      | 39/100 [00:10<00:11,  5.10it/s]Train Iter: 140/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5250. T_Loss: 2.1361. Mask: 0.8633. :  39%|███▉      | 39/100 [00:10<00:11,  5.10it/s]Train Iter: 140/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5250. T_Loss: 2.1361. Mask: 0.8633. :  40%|████      | 40/100 [00:10<00:10,  5.66it/s]Train Iter: 141/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5238. T_Loss: 2.1429. Mask: 0.8628. :  40%|████      | 40/100 [00:10<00:10,  5.66it/s]Train Iter: 141/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5238. T_Loss: 2.1429. Mask: 0.8628. :  41%|████      | 41/100 [00:10<00:09,  6.17it/s]Train Iter: 142/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5239. T_Loss: 2.1501. Mask: 0.8631. :  41%|████      | 41/100 [00:10<00:09,  6.17it/s]Train Iter: 142/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5239. T_Loss: 2.1501. Mask: 0.8631. :  42%|████▏     | 42/100 [00:10<00:08,  6.53it/s]Train Iter: 143/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5211. T_Loss: 2.1509. Mask: 0.8612. :  42%|████▏     | 42/100 [00:10<00:08,  6.53it/s]Train Iter: 143/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5211. T_Loss: 2.1509. Mask: 0.8612. :  43%|████▎     | 43/100 [00:10<00:08,  6.78it/s]Train Iter: 144/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 2.5195. T_Loss: 2.1591. Mask: 0.8601. :  43%|████▎     | 43/100 [00:10<00:08,  6.78it/s]Train Iter: 144/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 2.5195. T_Loss: 2.1591. Mask: 0.8601. :  44%|████▍     | 44/100 [00:10<00:07,  7.13it/s]Train Iter: 145/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5216. T_Loss: 2.1678. Mask: 0.8583. :  44%|████▍     | 44/100 [00:11<00:07,  7.13it/s]Train Iter: 145/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5216. T_Loss: 2.1678. Mask: 0.8583. :  45%|████▌     | 45/100 [00:11<00:10,  5.04it/s]Train Iter: 146/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5209. T_Loss: 2.1744. Mask: 0.8580. :  45%|████▌     | 45/100 [00:11<00:10,  5.04it/s]Train Iter: 146/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5209. T_Loss: 2.1744. Mask: 0.8580. :  46%|████▌     | 46/100 [00:11<00:09,  5.54it/s]Train Iter: 147/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5189. T_Loss: 2.1782. Mask: 0.8584. :  46%|████▌     | 46/100 [00:11<00:09,  5.54it/s]Train Iter: 147/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5189. T_Loss: 2.1782. Mask: 0.8584. :  47%|████▋     | 47/100 [00:11<00:08,  6.00it/s]Train Iter: 148/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5185. T_Loss: 2.1799. Mask: 0.8594. :  47%|████▋     | 47/100 [00:11<00:08,  6.00it/s]Train Iter: 148/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5185. T_Loss: 2.1799. Mask: 0.8594. :  48%|████▊     | 48/100 [00:11<00:07,  6.53it/s]Train Iter: 149/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5173. T_Loss: 2.1807. Mask: 0.8597. :  48%|████▊     | 48/100 [00:11<00:07,  6.53it/s]Train Iter: 149/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5173. T_Loss: 2.1807. Mask: 0.8597. :  49%|████▉     | 49/100 [00:11<00:10,  5.06it/s]Train Iter: 150/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5158. T_Loss: 2.1839. Mask: 0.8619. :  49%|████▉     | 49/100 [00:11<00:10,  5.06it/s]Train Iter: 150/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5158. T_Loss: 2.1839. Mask: 0.8619. :  50%|█████     | 50/100 [00:11<00:08,  5.73it/s]total : 5000  current step :  126
total : 5000  current step :  127
total : 5000  current step :  128
total : 5000  current step :  129
total : 5000  current step :  130
total : 5000  current step :  131
total : 5000  current step :  132
total : 5000  current step :  133
total : 5000  current step :  134
total : 5000  current step :  135
total : 5000  current step :  136
total : 5000  current step :  137
total : 5000  current step :  138
total : 5000  current step :  139
total : 5000  current step :  140
total : 5000  current step :  141
total : 5000  current step :  142
total : 5000  current step :  143
total : 5000  current step :  144
total : 5000  current step :  145
total : 5000  current step :  146
total : 5000  current step :  147
total : 5000  current step :  148
total : 5000  current step :  149
total : 5000  current step :  150
Train Iter: 151/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5146. T_Loss: 2.2014. Mask: 0.8627. :  50%|█████     | 50/100 [00:13<00:08,  5.73it/s]Train Iter: 151/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5146. T_Loss: 2.2014. Mask: 0.8627. :  51%|█████     | 51/100 [00:13<00:36,  1.36it/s]Train Iter: 152/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5148. T_Loss: 2.2008. Mask: 0.8630. :  51%|█████     | 51/100 [00:14<00:36,  1.36it/s]Train Iter: 152/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5148. T_Loss: 2.2008. Mask: 0.8630. :  52%|█████▏    | 52/100 [00:14<00:27,  1.77it/s]Train Iter: 153/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5154. T_Loss: 2.2010. Mask: 0.8638. :  52%|█████▏    | 52/100 [00:14<00:27,  1.77it/s]Train Iter: 153/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5154. T_Loss: 2.2010. Mask: 0.8638. :  53%|█████▎    | 53/100 [00:14<00:20,  2.32it/s]Train Iter: 154/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5167. T_Loss: 2.1998. Mask: 0.8646. :  53%|█████▎    | 53/100 [00:14<00:20,  2.32it/s]Train Iter: 154/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5167. T_Loss: 2.1998. Mask: 0.8646. :  54%|█████▍    | 54/100 [00:14<00:15,  2.95it/s]Train Iter: 155/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5166. T_Loss: 2.2001. Mask: 0.8659. :  54%|█████▍    | 54/100 [00:14<00:15,  2.95it/s]Train Iter: 155/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5166. T_Loss: 2.2001. Mask: 0.8659. :  55%|█████▌    | 55/100 [00:14<00:12,  3.62it/s]Train Iter: 156/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5156. T_Loss: 2.1999. Mask: 0.8666. :  55%|█████▌    | 55/100 [00:14<00:12,  3.62it/s]Train Iter: 156/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5156. T_Loss: 2.1999. Mask: 0.8666. :  56%|█████▌    | 56/100 [00:14<00:10,  4.32it/s]Train Iter: 157/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5144. T_Loss: 2.2073. Mask: 0.8679. :  56%|█████▌    | 56/100 [00:14<00:10,  4.32it/s]Train Iter: 157/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5144. T_Loss: 2.2073. Mask: 0.8679. :  57%|█████▋    | 57/100 [00:14<00:08,  5.12it/s]Train Iter: 158/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5145. T_Loss: 2.2157. Mask: 0.8685. :  57%|█████▋    | 57/100 [00:14<00:08,  5.12it/s]Train Iter: 158/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5145. T_Loss: 2.2157. Mask: 0.8685. :  58%|█████▊    | 58/100 [00:14<00:07,  5.79it/s]Train Iter: 159/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5129. T_Loss: 2.2131. Mask: 0.8681. :  58%|█████▊    | 58/100 [00:15<00:07,  5.79it/s]Train Iter: 159/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5129. T_Loss: 2.2131. Mask: 0.8681. :  59%|█████▉    | 59/100 [00:15<00:09,  4.26it/s]Train Iter: 160/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5132. T_Loss: 2.2158. Mask: 0.8698. :  59%|█████▉    | 59/100 [00:15<00:09,  4.26it/s]Train Iter: 160/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5132. T_Loss: 2.2158. Mask: 0.8698. :  60%|██████    | 60/100 [00:15<00:08,  4.93it/s]Train Iter: 161/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5128. T_Loss: 2.2204. Mask: 0.8694. :  60%|██████    | 60/100 [00:15<00:08,  4.93it/s]Train Iter: 161/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5128. T_Loss: 2.2204. Mask: 0.8694. :  61%|██████    | 61/100 [00:15<00:07,  5.53it/s]Train Iter: 162/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5132. T_Loss: 2.2256. Mask: 0.8705. :  61%|██████    | 61/100 [00:15<00:07,  5.53it/s]Train Iter: 162/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5132. T_Loss: 2.2256. Mask: 0.8705. :  62%|██████▏   | 62/100 [00:15<00:06,  5.97it/s]Train Iter: 163/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5152. T_Loss: 2.2309. Mask: 0.8700. :  62%|██████▏   | 62/100 [00:15<00:06,  5.97it/s]Train Iter: 163/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5152. T_Loss: 2.2309. Mask: 0.8700. :  63%|██████▎   | 63/100 [00:15<00:05,  6.59it/s]Train Iter: 164/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5161. T_Loss: 2.2351. Mask: 0.8706. :  63%|██████▎   | 63/100 [00:15<00:05,  6.59it/s]Train Iter: 164/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5161. T_Loss: 2.2351. Mask: 0.8706. :  64%|██████▍   | 64/100 [00:15<00:05,  6.97it/s]Train Iter: 165/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5158. T_Loss: 2.2404. Mask: 0.8712. :  64%|██████▍   | 64/100 [00:16<00:05,  6.97it/s]Train Iter: 165/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5158. T_Loss: 2.2404. Mask: 0.8712. :  65%|██████▌   | 65/100 [00:16<00:07,  4.71it/s]Train Iter: 166/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5170. T_Loss: 2.2441. Mask: 0.8712. :  65%|██████▌   | 65/100 [00:16<00:07,  4.71it/s]Train Iter: 166/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5170. T_Loss: 2.2441. Mask: 0.8712. :  66%|██████▌   | 66/100 [00:16<00:06,  5.17it/s]Train Iter: 167/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5177. T_Loss: 2.2484. Mask: 0.8713. :  66%|██████▌   | 66/100 [00:16<00:06,  5.17it/s]Train Iter: 167/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5177. T_Loss: 2.2484. Mask: 0.8713. :  67%|██████▋   | 67/100 [00:16<00:05,  5.93it/s]Train Iter: 168/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5180. T_Loss: 2.2502. Mask: 0.8704. :  67%|██████▋   | 67/100 [00:16<00:05,  5.93it/s]Train Iter: 168/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5180. T_Loss: 2.2502. Mask: 0.8704. :  68%|██████▊   | 68/100 [00:16<00:04,  6.48it/s]Train Iter: 169/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5180. T_Loss: 2.2557. Mask: 0.8709. :  68%|██████▊   | 68/100 [00:17<00:04,  6.48it/s]Train Iter: 169/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5180. T_Loss: 2.2557. Mask: 0.8709. :  69%|██████▉   | 69/100 [00:17<00:06,  4.59it/s]Train Iter: 170/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5171. T_Loss: 2.2539. Mask: 0.8710. :  69%|██████▉   | 69/100 [00:17<00:06,  4.59it/s]Train Iter: 170/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5171. T_Loss: 2.2539. Mask: 0.8710. :  70%|███████   | 70/100 [00:17<00:05,  5.21it/s]Train Iter: 171/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5171. T_Loss: 2.2570. Mask: 0.8719. :  70%|███████   | 70/100 [00:17<00:05,  5.21it/s]Train Iter: 171/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5171. T_Loss: 2.2570. Mask: 0.8719. :  71%|███████   | 71/100 [00:17<00:04,  5.88it/s]Train Iter: 172/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5171. T_Loss: 2.2617. Mask: 0.8724. :  71%|███████   | 71/100 [00:17<00:04,  5.88it/s]Train Iter: 172/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5171. T_Loss: 2.2617. Mask: 0.8724. :  72%|███████▏  | 72/100 [00:17<00:04,  6.53it/s]Train Iter: 173/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5157. T_Loss: 2.2638. Mask: 0.8737. :  72%|███████▏  | 72/100 [00:17<00:04,  6.53it/s]Train Iter: 173/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5157. T_Loss: 2.2638. Mask: 0.8737. :  73%|███████▎  | 73/100 [00:17<00:03,  6.82it/s]Train Iter: 174/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5151. T_Loss: 2.2669. Mask: 0.8750. :  73%|███████▎  | 73/100 [00:17<00:03,  6.82it/s]Train Iter: 174/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5151. T_Loss: 2.2669. Mask: 0.8750. :  74%|███████▍  | 74/100 [00:17<00:03,  7.15it/s]Train Iter: 175/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5142. T_Loss: 2.2702. Mask: 0.8750. :  74%|███████▍  | 74/100 [00:17<00:03,  7.15it/s]Train Iter: 175/5000. LR: 0.0000. Data: 0.08s. Batch: 0.24s. S_Loss: 2.5142. T_Loss: 2.2702. Mask: 0.8750. :  75%|███████▌  | 75/100 [00:17<00:03,  7.15it/s]total : 5000  current step :  151
total : 5000  current step :  152
total : 5000  current step :  153
total : 5000  current step :  154
total : 5000  current step :  155
total : 5000  current step :  156
total : 5000  current step :  157
total : 5000  current step :  158
total : 5000  current step :  159
total : 5000  current step :  160
total : 5000  current step :  161
total : 5000  current step :  162
total : 5000  current step :  163
total : 5000  current step :  164
total : 5000  current step :  165
total : 5000  current step :  166
total : 5000  current step :  167
total : 5000  current step :  168
total : 5000  current step :  169
total : 5000  current step :  170
total : 5000  current step :  171
total : 5000  current step :  172
total : 5000  current step :  173
total : 5000  current step :  174
total : 5000  current step :  175
Train Iter: 176/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5136. T_Loss: 2.2735. Mask: 0.8750. :  75%|███████▌  | 75/100 [00:19<00:03,  7.15it/s]Train Iter: 176/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5136. T_Loss: 2.2735. Mask: 0.8750. :  76%|███████▌  | 76/100 [00:19<00:17,  1.35it/s]Train Iter: 177/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5156. T_Loss: 2.2770. Mask: 0.8754. :  76%|███████▌  | 76/100 [00:20<00:17,  1.35it/s]Train Iter: 177/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5156. T_Loss: 2.2770. Mask: 0.8754. :  77%|███████▋  | 77/100 [00:20<00:12,  1.81it/s]Train Iter: 178/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5150. T_Loss: 2.2805. Mask: 0.8750. :  77%|███████▋  | 77/100 [00:20<00:12,  1.81it/s]Train Iter: 178/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5150. T_Loss: 2.2805. Mask: 0.8750. :  78%|███████▊  | 78/100 [00:20<00:09,  2.35it/s]Train Iter: 179/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5134. T_Loss: 2.2835. Mask: 0.8750. :  78%|███████▊  | 78/100 [00:20<00:09,  2.35it/s]Train Iter: 179/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5134. T_Loss: 2.2835. Mask: 0.8750. :  79%|███████▉  | 79/100 [00:20<00:08,  2.52it/s]Train Iter: 180/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5134. T_Loss: 2.2855. Mask: 0.8746. :  79%|███████▉  | 79/100 [00:20<00:08,  2.52it/s]Train Iter: 180/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5134. T_Loss: 2.2855. Mask: 0.8746. :  80%|████████  | 80/100 [00:20<00:06,  3.17it/s]Train Iter: 181/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5137. T_Loss: 2.2886. Mask: 0.8738. :  80%|████████  | 80/100 [00:20<00:06,  3.17it/s]Train Iter: 181/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5137. T_Loss: 2.2886. Mask: 0.8738. :  81%|████████  | 81/100 [00:20<00:04,  3.86it/s]Train Iter: 182/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5130. T_Loss: 2.2894. Mask: 0.8742. :  81%|████████  | 81/100 [00:20<00:04,  3.86it/s]Train Iter: 182/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5130. T_Loss: 2.2894. Mask: 0.8742. :  82%|████████▏ | 82/100 [00:20<00:03,  4.52it/s]Train Iter: 183/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5131. T_Loss: 2.2907. Mask: 0.8746. :  82%|████████▏ | 82/100 [00:20<00:03,  4.52it/s]Train Iter: 183/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5131. T_Loss: 2.2907. Mask: 0.8746. :  83%|████████▎ | 83/100 [00:21<00:03,  5.21it/s]Train Iter: 184/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5127. T_Loss: 2.2984. Mask: 0.8750. :  83%|████████▎ | 83/100 [00:21<00:03,  5.21it/s]Train Iter: 184/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5127. T_Loss: 2.2984. Mask: 0.8750. :  84%|████████▍ | 84/100 [00:21<00:02,  5.75it/s]Train Iter: 185/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5129. T_Loss: 2.2964. Mask: 0.8743. :  84%|████████▍ | 84/100 [00:21<00:02,  5.75it/s]Train Iter: 185/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5129. T_Loss: 2.2964. Mask: 0.8743. :  85%|████████▌ | 85/100 [00:21<00:02,  5.27it/s]Train Iter: 186/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5124. T_Loss: 2.3126. Mask: 0.8754. :  85%|████████▌ | 85/100 [00:21<00:02,  5.27it/s]Train Iter: 186/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5124. T_Loss: 2.3126. Mask: 0.8754. :  86%|████████▌ | 86/100 [00:21<00:02,  5.97it/s]Train Iter: 187/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5117. T_Loss: 2.3117. Mask: 0.8757. :  86%|████████▌ | 86/100 [00:21<00:02,  5.97it/s]Train Iter: 187/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5117. T_Loss: 2.3117. Mask: 0.8757. :  87%|████████▋ | 87/100 [00:21<00:02,  6.38it/s]Train Iter: 188/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5117. T_Loss: 2.3229. Mask: 0.8754. :  87%|████████▋ | 87/100 [00:21<00:02,  6.38it/s]Train Iter: 188/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5117. T_Loss: 2.3229. Mask: 0.8754. :  88%|████████▊ | 88/100 [00:21<00:01,  6.74it/s]Train Iter: 189/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5116. T_Loss: 2.3244. Mask: 0.8761. :  88%|████████▊ | 88/100 [00:21<00:01,  6.74it/s]Train Iter: 189/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5116. T_Loss: 2.3244. Mask: 0.8761. :  89%|████████▉ | 89/100 [00:21<00:01,  6.81it/s]Train Iter: 190/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5107. T_Loss: 2.3278. Mask: 0.8767. :  89%|████████▉ | 89/100 [00:22<00:01,  6.81it/s]Train Iter: 190/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5107. T_Loss: 2.3278. Mask: 0.8767. :  90%|█████████ | 90/100 [00:22<00:01,  6.95it/s]Train Iter: 191/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5109. T_Loss: 2.3348. Mask: 0.8760. :  90%|█████████ | 90/100 [00:22<00:01,  6.95it/s]Train Iter: 191/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5109. T_Loss: 2.3348. Mask: 0.8760. :  91%|█████████ | 91/100 [00:22<00:01,  6.97it/s]Train Iter: 192/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5101. T_Loss: 2.3353. Mask: 0.8757. :  91%|█████████ | 91/100 [00:22<00:01,  6.97it/s]Train Iter: 192/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5101. T_Loss: 2.3353. Mask: 0.8757. :  92%|█████████▏| 92/100 [00:22<00:01,  7.08it/s]Train Iter: 193/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5109. T_Loss: 2.3415. Mask: 0.8753. :  92%|█████████▏| 92/100 [00:22<00:01,  7.08it/s]Train Iter: 193/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5109. T_Loss: 2.3415. Mask: 0.8753. :  93%|█████████▎| 93/100 [00:22<00:00,  7.33it/s]Train Iter: 194/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5113. T_Loss: 2.3453. Mask: 0.8753. :  93%|█████████▎| 93/100 [00:22<00:00,  7.33it/s]Train Iter: 194/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5113. T_Loss: 2.3453. Mask: 0.8753. :  94%|█████████▍| 94/100 [00:22<00:00,  7.79it/s]Train Iter: 195/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5115. T_Loss: 2.3485. Mask: 0.8747. :  94%|█████████▍| 94/100 [00:22<00:00,  7.79it/s]Train Iter: 195/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5115. T_Loss: 2.3485. Mask: 0.8747. :  95%|█████████▌| 95/100 [00:22<00:00,  5.35it/s]Train Iter: 196/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5121. T_Loss: 2.3533. Mask: 0.8743. :  95%|█████████▌| 95/100 [00:22<00:00,  5.35it/s]Train Iter: 196/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5121. T_Loss: 2.3533. Mask: 0.8743. :  96%|█████████▌| 96/100 [00:22<00:00,  5.77it/s]Train Iter: 197/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5124. T_Loss: 2.3567. Mask: 0.8740. :  96%|█████████▌| 96/100 [00:23<00:00,  5.77it/s]Train Iter: 197/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5124. T_Loss: 2.3567. Mask: 0.8740. :  97%|█████████▋| 97/100 [00:23<00:00,  6.52it/s]Train Iter: 198/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5134. T_Loss: 2.3601. Mask: 0.8731. :  97%|█████████▋| 97/100 [00:23<00:00,  6.52it/s]Train Iter: 198/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5134. T_Loss: 2.3601. Mask: 0.8731. :  98%|█████████▊| 98/100 [00:23<00:00,  7.13it/s]Train Iter: 199/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5137. T_Loss: 2.3658. Mask: 0.8728. :  98%|█████████▊| 98/100 [00:23<00:00,  7.13it/s]Train Iter: 199/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5137. T_Loss: 2.3658. Mask: 0.8728. :  99%|█████████▉| 99/100 [00:23<00:00,  5.15it/s]Train Iter: 200/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 2.5139. T_Loss: 2.3671. Mask: 0.8712. :  99%|█████████▉| 99/100 [00:23<00:00,  5.15it/s]Train Iter: 200/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 2.5139. T_Loss: 2.3671. Mask: 0.8712. : 100%|██████████| 100/100 [00:23<00:00,  5.92it/s]Train Iter: 200/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 2.5139. T_Loss: 2.3671. Mask: 0.8712. : 100%|██████████| 100/100 [00:23<00:00,  4.23it/s]
total : 5000  current step :  176
total : 5000  current step :  177
total : 5000  current step :  178
total : 5000  current step :  179
total : 5000  current step :  180
total : 5000  current step :  181
total : 5000  current step :  182
total : 5000  current step :  183
total : 5000  current step :  184
total : 5000  current step :  185
total : 5000  current step :  186
total : 5000  current step :  187
total : 5000  current step :  188
total : 5000  current step :  189
total : 5000  current step :  190
total : 5000  current step :  191
total : 5000  current step :  192
total : 5000  current step :  193
total : 5000  current step :  194
total : 5000  current step :  195
total : 5000  current step :  196
total : 5000  current step :  197
total : 5000  current step :  198
total : 5000  current step :  199
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.88s. Loss: 2.0969. top1: 9.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.88s. Loss: 2.0969. top1: 9.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.96s. Loss: 2.0912. top1: 9.38. top5: 98.44. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it] Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 2.0962. top1: 11.46. top5: 93.75. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.49s. Loss: 2.0852. top1: 9.38. top5: 95.31. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it] Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 2.0936. top1: 8.12. top5: 95.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 2.0891. top1: 7.81. top5: 95.83. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 2.0985. top1: 7.14. top5: 95.98. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 2.0999. top1: 6.64. top5: 96.48. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 2.0999. top1: 6.64. top5: 96.48. :  13%|█▎        | 8/63 [00:01<00:10,  5.42it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 2.1064. top1: 5.90. top5: 96.53. :  13%|█▎        | 8/63 [00:01<00:10,  5.42it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 2.1074. top1: 6.25. top5: 96.56. :  13%|█▎        | 8/63 [00:02<00:10,  5.42it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 2.1096. top1: 5.97. top5: 96.88. :  13%|█▎        | 8/63 [00:02<00:10,  5.42it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.1111. top1: 6.25. top5: 96.88. :  13%|█▎        | 8/63 [00:02<00:10,  5.42it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.1157. top1: 5.77. top5: 96.63. :  13%|█▎        | 8/63 [00:02<00:10,  5.42it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.1099. top1: 6.03. top5: 96.88. :  13%|█▎        | 8/63 [00:02<00:10,  5.42it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.1145. top1: 5.62. top5: 97.08. :  13%|█▎        | 8/63 [00:02<00:10,  5.42it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.1168. top1: 5.66. top5: 96.88. :  13%|█▎        | 8/63 [00:02<00:10,  5.42it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.1168. top1: 5.66. top5: 96.88. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.1141. top1: 5.33. top5: 96.88. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.1161. top1: 5.03. top5: 96.88. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.1183. top1: 4.77. top5: 96.71. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.1176. top1: 5.16. top5: 96.88. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1177. top1: 4.91. top5: 96.88. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1162. top1: 4.97. top5: 97.02. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1172. top1: 4.76. top5: 97.01. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1172. top1: 4.76. top5: 97.01. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1183. top1: 4.82. top5: 97.01. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1185. top1: 4.88. top5: 96.75. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1197. top1: 4.93. top5: 96.88. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1211. top1: 4.75. top5: 96.76. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1208. top1: 4.69. top5: 96.65. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1183. top1: 4.85. top5: 96.77. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1192. top1: 4.90. top5: 96.77. :  37%|███▋      | 23/63 [00:02<00:02, 18.31it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1192. top1: 4.90. top5: 96.77. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1192. top1: 5.04. top5: 96.57. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1278. top1: 4.98. top5: 96.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1360. top1: 4.83. top5: 95.64. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1451. top1: 4.69. top5: 95.13. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1513. top1: 4.55. top5: 94.64. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1605. top1: 4.43. top5: 93.84. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1681. top1: 4.31. top5: 93.67. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1752. top1: 4.19. top5: 93.50. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1820. top1: 4.09. top5: 93.43. :  48%|████▊     | 30/63 [00:02<00:01, 24.94it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1820. top1: 4.09. top5: 93.43. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1895. top1: 3.98. top5: 93.05. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1961. top1: 3.89. top5: 93.06. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2028. top1: 3.79. top5: 92.63. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2090. top1: 3.71. top5: 92.30. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2132. top1: 3.62. top5: 92.33. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2177. top1: 3.54. top5: 92.29. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2222. top1: 3.46. top5: 92.05. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2274. top1: 3.39. top5: 91.69. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2326. top1: 3.32. top5: 91.67. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2380. top1: 3.25. top5: 91.71. :  62%|██████▏   | 39/63 [00:02<00:00, 35.44it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2380. top1: 3.25. top5: 91.71. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2430. top1: 3.19. top5: 91.62. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2488. top1: 3.12. top5: 91.30. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2531. top1: 3.06. top5: 91.05. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2565. top1: 3.01. top5: 91.10. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2599. top1: 2.95. top5: 90.80. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2641. top1: 2.90. top5: 90.68. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2669. top1: 2.85. top5: 90.57. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2696. top1: 2.80. top5: 90.41. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2716. top1: 2.75. top5: 90.25. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2750. top1: 2.70. top5: 90.04. :  78%|███████▊  | 49/63 [00:02<00:00, 47.16it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2750. top1: 2.70. top5: 90.04. :  94%|█████████▎| 59/63 [00:02<00:00, 57.10it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2783. top1: 2.66. top5: 90.00. :  94%|█████████▎| 59/63 [00:02<00:00, 57.10it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2819. top1: 2.61. top5: 89.81. :  94%|█████████▎| 59/63 [00:02<00:00, 57.10it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2849. top1: 2.57. top5: 89.52. :  94%|█████████▎| 59/63 [00:02<00:00, 57.10it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2866. top1: 2.55. top5: 89.45. :  94%|█████████▎| 59/63 [00:02<00:00, 57.10it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2866. top1: 2.55. top5: 89.45. : 100%|██████████| 63/63 [00:02<00:00, 21.62it/s]
total : 5000  current step :  200
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 201/5000. LR: 0.0000. Data: 2.17s. Batch: 2.29s. S_Loss: 2.5616. T_Loss: 2.6466. Mask: 0.8750. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 201/5000. LR: 0.0000. Data: 2.17s. Batch: 2.29s. S_Loss: 2.5616. T_Loss: 2.6466. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:47,  2.29s/it]Train Iter: 202/5000. LR: 0.0000. Data: 1.09s. Batch: 1.22s. S_Loss: 2.5663. T_Loss: 2.7320. Mask: 0.8438. :   1%|          | 1/100 [00:02<03:47,  2.29s/it]Train Iter: 202/5000. LR: 0.0000. Data: 1.09s. Batch: 1.22s. S_Loss: 2.5663. T_Loss: 2.7320. Mask: 0.8438. :   2%|▏         | 2/100 [00:02<01:40,  1.03s/it]Train Iter: 203/5000. LR: 0.0000. Data: 0.73s. Batch: 0.86s. S_Loss: 2.5479. T_Loss: 2.8302. Mask: 0.8333. :   2%|▏         | 2/100 [00:02<01:40,  1.03s/it]Train Iter: 203/5000. LR: 0.0000. Data: 0.73s. Batch: 0.86s. S_Loss: 2.5479. T_Loss: 2.8302. Mask: 0.8333. :   3%|▎         | 3/100 [00:02<01:00,  1.59it/s]Train Iter: 204/5000. LR: 0.0000. Data: 0.55s. Batch: 0.68s. S_Loss: 2.5285. T_Loss: 2.8358. Mask: 0.8438. :   3%|▎         | 3/100 [00:02<01:00,  1.59it/s]Train Iter: 204/5000. LR: 0.0000. Data: 0.55s. Batch: 0.68s. S_Loss: 2.5285. T_Loss: 2.8358. Mask: 0.8438. :   4%|▍         | 4/100 [00:02<00:42,  2.27it/s]Train Iter: 205/5000. LR: 0.0000. Data: 0.44s. Batch: 0.60s. S_Loss: 2.5034. T_Loss: 2.8594. Mask: 0.8500. :   4%|▍         | 4/100 [00:03<00:42,  2.27it/s]Train Iter: 205/5000. LR: 0.0000. Data: 0.44s. Batch: 0.60s. S_Loss: 2.5034. T_Loss: 2.8594. Mask: 0.8500. :   5%|▌         | 5/100 [00:03<00:36,  2.62it/s]Train Iter: 206/5000. LR: 0.0000. Data: 0.37s. Batch: 0.52s. S_Loss: 2.5020. T_Loss: 2.8586. Mask: 0.8490. :   5%|▌         | 5/100 [00:03<00:36,  2.62it/s]Train Iter: 207/5000. LR: 0.0000. Data: 0.31s. Batch: 0.45s. S_Loss: 2.5007. T_Loss: 2.8419. Mask: 0.8482. :   6%|▌         | 6/100 [00:03<00:35,  2.62it/s]Train Iter: 207/5000. LR: 0.0000. Data: 0.31s. Batch: 0.45s. S_Loss: 2.5007. T_Loss: 2.8419. Mask: 0.8482. :   7%|▋         | 7/100 [00:03<00:21,  4.35it/s]Train Iter: 208/5000. LR: 0.0000. Data: 0.28s. Batch: 0.41s. S_Loss: 2.5027. T_Loss: 2.8261. Mask: 0.8438. :   7%|▋         | 7/100 [00:03<00:21,  4.35it/s]Train Iter: 209/5000. LR: 0.0000. Data: 0.25s. Batch: 0.40s. S_Loss: 2.4980. T_Loss: 2.7992. Mask: 0.8507. :   8%|▊         | 8/100 [00:03<00:21,  4.35it/s]Train Iter: 209/5000. LR: 0.0000. Data: 0.25s. Batch: 0.40s. S_Loss: 2.4980. T_Loss: 2.7992. Mask: 0.8507. :   9%|▉         | 9/100 [00:03<00:19,  4.68it/s]Train Iter: 210/5000. LR: 0.0000. Data: 0.22s. Batch: 0.37s. S_Loss: 2.4994. T_Loss: 2.7985. Mask: 0.8562. :   9%|▉         | 9/100 [00:03<00:19,  4.68it/s]Train Iter: 210/5000. LR: 0.0000. Data: 0.22s. Batch: 0.37s. S_Loss: 2.4994. T_Loss: 2.7985. Mask: 0.8562. :  10%|█         | 10/100 [00:03<00:17,  5.18it/s]Train Iter: 211/5000. LR: 0.0000. Data: 0.20s. Batch: 0.35s. S_Loss: 2.4950. T_Loss: 2.7768. Mask: 0.8494. :  10%|█         | 10/100 [00:03<00:17,  5.18it/s]Train Iter: 211/5000. LR: 0.0000. Data: 0.20s. Batch: 0.35s. S_Loss: 2.4950. T_Loss: 2.7768. Mask: 0.8494. :  11%|█         | 11/100 [00:03<00:15,  5.68it/s]Train Iter: 212/5000. LR: 0.0000. Data: 0.19s. Batch: 0.33s. S_Loss: 2.4911. T_Loss: 2.7555. Mask: 0.8490. :  11%|█         | 11/100 [00:03<00:15,  5.68it/s]Train Iter: 212/5000. LR: 0.0000. Data: 0.19s. Batch: 0.33s. S_Loss: 2.4911. T_Loss: 2.7555. Mask: 0.8490. :  12%|█▏        | 12/100 [00:03<00:14,  6.16it/s]Train Iter: 213/5000. LR: 0.0000. Data: 0.17s. Batch: 0.31s. S_Loss: 2.4937. T_Loss: 2.7733. Mask: 0.8606. :  12%|█▏        | 12/100 [00:04<00:14,  6.16it/s]Train Iter: 213/5000. LR: 0.0000. Data: 0.17s. Batch: 0.31s. S_Loss: 2.4937. T_Loss: 2.7733. Mask: 0.8606. :  13%|█▎        | 13/100 [00:04<00:13,  6.68it/s]Train Iter: 214/5000. LR: 0.0000. Data: 0.16s. Batch: 0.30s. S_Loss: 2.4933. T_Loss: 2.8049. Mask: 0.8683. :  13%|█▎        | 13/100 [00:04<00:13,  6.68it/s]Train Iter: 214/5000. LR: 0.0000. Data: 0.16s. Batch: 0.30s. S_Loss: 2.4933. T_Loss: 2.8049. Mask: 0.8683. :  14%|█▍        | 14/100 [00:04<00:11,  7.19it/s]Train Iter: 215/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 2.5004. T_Loss: 2.8048. Mask: 0.8688. :  14%|█▍        | 14/100 [00:04<00:11,  7.19it/s]Train Iter: 215/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 2.5004. T_Loss: 2.8048. Mask: 0.8688. :  15%|█▌        | 15/100 [00:04<00:11,  7.27it/s]Train Iter: 216/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5025. T_Loss: 2.8240. Mask: 0.8711. :  15%|█▌        | 15/100 [00:04<00:11,  7.27it/s]Train Iter: 216/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5025. T_Loss: 2.8240. Mask: 0.8711. :  16%|█▌        | 16/100 [00:04<00:11,  7.34it/s]Train Iter: 217/5000. LR: 0.0000. Data: 0.13s. Batch: 0.27s. S_Loss: 2.5078. T_Loss: 2.8159. Mask: 0.8750. :  16%|█▌        | 16/100 [00:04<00:11,  7.34it/s]Train Iter: 217/5000. LR: 0.0000. Data: 0.13s. Batch: 0.27s. S_Loss: 2.5078. T_Loss: 2.8159. Mask: 0.8750. :  17%|█▋        | 17/100 [00:04<00:12,  6.77it/s]Train Iter: 218/5000. LR: 0.0000. Data: 0.13s. Batch: 0.26s. S_Loss: 2.5093. T_Loss: 2.8219. Mask: 0.8750. :  17%|█▋        | 17/100 [00:04<00:12,  6.77it/s]Train Iter: 218/5000. LR: 0.0000. Data: 0.13s. Batch: 0.26s. S_Loss: 2.5093. T_Loss: 2.8219. Mask: 0.8750. :  18%|█▊        | 18/100 [00:04<00:11,  6.86it/s]Train Iter: 219/5000. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 2.5080. T_Loss: 2.8321. Mask: 0.8750. :  18%|█▊        | 18/100 [00:04<00:11,  6.86it/s]Train Iter: 219/5000. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 2.5080. T_Loss: 2.8321. Mask: 0.8750. :  19%|█▉        | 19/100 [00:04<00:11,  7.14it/s]Train Iter: 220/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5099. T_Loss: 2.8405. Mask: 0.8766. :  19%|█▉        | 19/100 [00:05<00:11,  7.14it/s]Train Iter: 220/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5099. T_Loss: 2.8405. Mask: 0.8766. :  20%|██        | 20/100 [00:05<00:15,  5.22it/s]Train Iter: 221/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 2.5106. T_Loss: 2.8484. Mask: 0.8765. :  20%|██        | 20/100 [00:05<00:15,  5.22it/s]Train Iter: 221/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 2.5106. T_Loss: 2.8484. Mask: 0.8765. :  21%|██        | 21/100 [00:05<00:13,  6.02it/s]Train Iter: 222/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 2.5113. T_Loss: 2.8719. Mask: 0.8807. :  21%|██        | 21/100 [00:05<00:13,  6.02it/s]Train Iter: 222/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 2.5113. T_Loss: 2.8719. Mask: 0.8807. :  22%|██▏       | 22/100 [00:05<00:11,  6.54it/s]Train Iter: 223/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 2.5123. T_Loss: 2.8931. Mask: 0.8818. :  22%|██▏       | 22/100 [00:05<00:11,  6.54it/s]Train Iter: 223/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 2.5123. T_Loss: 2.8931. Mask: 0.8818. :  23%|██▎       | 23/100 [00:05<00:11,  6.95it/s]Train Iter: 224/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5148. T_Loss: 2.8974. Mask: 0.8815. :  23%|██▎       | 23/100 [00:05<00:11,  6.95it/s]Train Iter: 224/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5148. T_Loss: 2.8974. Mask: 0.8815. :  24%|██▍       | 24/100 [00:05<00:10,  7.05it/s]Train Iter: 225/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5158. T_Loss: 2.9038. Mask: 0.8812. :  24%|██▍       | 24/100 [00:06<00:10,  7.05it/s]Train Iter: 225/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5158. T_Loss: 2.9038. Mask: 0.8812. :  25%|██▌       | 25/100 [00:06<00:15,  4.81it/s]total : 5000  current step :  201
total : 5000  current step :  202
total : 5000  current step :  203
total : 5000  current step :  204
total : 5000  current step :  205
total : 5000  current step :  206
total : 5000  current step :  207
total : 5000  current step :  208
total : 5000  current step :  209
total : 5000  current step :  210
total : 5000  current step :  211
total : 5000  current step :  212
total : 5000  current step :  213
total : 5000  current step :  214
total : 5000  current step :  215
total : 5000  current step :  216
total : 5000  current step :  217
total : 5000  current step :  218
total : 5000  current step :  219
total : 5000  current step :  220
total : 5000  current step :  221
total : 5000  current step :  222
total : 5000  current step :  223
total : 5000  current step :  224
total : 5000  current step :  225
Train Iter: 226/5000. LR: 0.0000. Data: 0.17s. Batch: 0.32s. S_Loss: 2.5190. T_Loss: 2.9211. Mask: 0.8798. :  25%|██▌       | 25/100 [00:08<00:15,  4.81it/s]Train Iter: 226/5000. LR: 0.0000. Data: 0.17s. Batch: 0.32s. S_Loss: 2.5190. T_Loss: 2.9211. Mask: 0.8798. :  26%|██▌       | 26/100 [00:08<01:02,  1.19it/s]Train Iter: 227/5000. LR: 0.0000. Data: 0.17s. Batch: 0.31s. S_Loss: 2.5181. T_Loss: 2.9131. Mask: 0.8773. :  26%|██▌       | 26/100 [00:08<01:02,  1.19it/s]Train Iter: 227/5000. LR: 0.0000. Data: 0.17s. Batch: 0.31s. S_Loss: 2.5181. T_Loss: 2.9131. Mask: 0.8773. :  27%|██▋       | 27/100 [00:08<00:45,  1.61it/s]Train Iter: 228/5000. LR: 0.0000. Data: 0.16s. Batch: 0.31s. S_Loss: 2.5169. T_Loss: 2.9200. Mask: 0.8795. :  27%|██▋       | 27/100 [00:08<00:45,  1.61it/s]Train Iter: 228/5000. LR: 0.0000. Data: 0.16s. Batch: 0.31s. S_Loss: 2.5169. T_Loss: 2.9200. Mask: 0.8795. :  28%|██▊       | 28/100 [00:08<00:34,  2.09it/s]Train Iter: 229/5000. LR: 0.0000. Data: 0.16s. Batch: 0.30s. S_Loss: 2.5178. T_Loss: 2.9154. Mask: 0.8782. :  28%|██▊       | 28/100 [00:08<00:34,  2.09it/s]Train Iter: 229/5000. LR: 0.0000. Data: 0.16s. Batch: 0.30s. S_Loss: 2.5178. T_Loss: 2.9154. Mask: 0.8782. :  29%|██▉       | 29/100 [00:08<00:26,  2.69it/s]Train Iter: 230/5000. LR: 0.0000. Data: 0.15s. Batch: 0.30s. S_Loss: 2.5160. T_Loss: 2.9109. Mask: 0.8771. :  29%|██▉       | 29/100 [00:09<00:26,  2.69it/s]Train Iter: 230/5000. LR: 0.0000. Data: 0.15s. Batch: 0.30s. S_Loss: 2.5160. T_Loss: 2.9109. Mask: 0.8771. :  30%|███       | 30/100 [00:09<00:23,  2.92it/s]Train Iter: 231/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 2.5178. T_Loss: 2.9130. Mask: 0.8750. :  30%|███       | 30/100 [00:09<00:23,  2.92it/s]Train Iter: 231/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 2.5178. T_Loss: 2.9130. Mask: 0.8750. :  31%|███       | 31/100 [00:09<00:19,  3.58it/s]Train Iter: 232/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.5169. T_Loss: 2.9162. Mask: 0.8740. :  31%|███       | 31/100 [00:09<00:19,  3.58it/s]Train Iter: 232/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.5169. T_Loss: 2.9162. Mask: 0.8740. :  32%|███▏      | 32/100 [00:09<00:16,  4.20it/s]Train Iter: 233/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5193. T_Loss: 2.9252. Mask: 0.8759. :  32%|███▏      | 32/100 [00:09<00:16,  4.20it/s]Train Iter: 233/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 2.5193. T_Loss: 2.9252. Mask: 0.8759. :  33%|███▎      | 33/100 [00:09<00:13,  4.86it/s]Train Iter: 234/5000. LR: 0.0000. Data: 0.13s. Batch: 0.29s. S_Loss: 2.5190. T_Loss: 2.9236. Mask: 0.8722. :  33%|███▎      | 33/100 [00:09<00:13,  4.86it/s]Train Iter: 234/5000. LR: 0.0000. Data: 0.13s. Batch: 0.29s. S_Loss: 2.5190. T_Loss: 2.9236. Mask: 0.8722. :  34%|███▍      | 34/100 [00:09<00:17,  3.83it/s]Train Iter: 235/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5173. T_Loss: 2.9259. Mask: 0.8679. :  34%|███▍      | 34/100 [00:09<00:17,  3.83it/s]Train Iter: 235/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5173. T_Loss: 2.9259. Mask: 0.8679. :  35%|███▌      | 35/100 [00:09<00:14,  4.39it/s]Train Iter: 236/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5173. T_Loss: 2.9354. Mask: 0.8681. :  35%|███▌      | 35/100 [00:10<00:14,  4.39it/s]Train Iter: 236/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5173. T_Loss: 2.9354. Mask: 0.8681. :  36%|███▌      | 36/100 [00:10<00:12,  5.03it/s]Train Iter: 237/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5202. T_Loss: 2.9369. Mask: 0.8708. :  36%|███▌      | 36/100 [00:10<00:12,  5.03it/s]Train Iter: 237/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5202. T_Loss: 2.9369. Mask: 0.8708. :  37%|███▋      | 37/100 [00:10<00:10,  5.80it/s]Train Iter: 238/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5165. T_Loss: 2.9322. Mask: 0.8692. :  37%|███▋      | 37/100 [00:10<00:10,  5.80it/s]Train Iter: 238/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5165. T_Loss: 2.9322. Mask: 0.8692. :  38%|███▊      | 38/100 [00:10<00:09,  6.36it/s]Train Iter: 239/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5191. T_Loss: 2.9462. Mask: 0.8710. :  38%|███▊      | 38/100 [00:10<00:09,  6.36it/s]Train Iter: 239/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5191. T_Loss: 2.9462. Mask: 0.8710. :  39%|███▉      | 39/100 [00:10<00:08,  6.88it/s]Train Iter: 240/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5195. T_Loss: 2.9449. Mask: 0.8719. :  39%|███▉      | 39/100 [00:10<00:08,  6.88it/s]Train Iter: 240/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5195. T_Loss: 2.9449. Mask: 0.8719. :  40%|████      | 40/100 [00:10<00:13,  4.45it/s]Train Iter: 241/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5186. T_Loss: 2.9417. Mask: 0.8727. :  40%|████      | 40/100 [00:10<00:13,  4.45it/s]Train Iter: 241/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5186. T_Loss: 2.9417. Mask: 0.8727. :  41%|████      | 41/100 [00:10<00:11,  4.94it/s]Train Iter: 242/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5188. T_Loss: 2.9280. Mask: 0.8728. :  41%|████      | 41/100 [00:11<00:11,  4.94it/s]Train Iter: 242/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5188. T_Loss: 2.9280. Mask: 0.8728. :  42%|████▏     | 42/100 [00:11<00:10,  5.59it/s]Train Iter: 243/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5171. T_Loss: 2.9103. Mask: 0.8706. :  42%|████▏     | 42/100 [00:11<00:10,  5.59it/s]Train Iter: 243/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5171. T_Loss: 2.9103. Mask: 0.8706. :  43%|████▎     | 43/100 [00:11<00:09,  6.16it/s]Train Iter: 244/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5170. T_Loss: 2.9305. Mask: 0.8707. :  43%|████▎     | 43/100 [00:11<00:09,  6.16it/s]Train Iter: 244/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5170. T_Loss: 2.9305. Mask: 0.8707. :  44%|████▍     | 44/100 [00:11<00:13,  4.21it/s]Train Iter: 245/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5172. T_Loss: 2.9233. Mask: 0.8708. :  44%|████▍     | 44/100 [00:11<00:13,  4.21it/s]Train Iter: 245/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5172. T_Loss: 2.9233. Mask: 0.8708. :  45%|████▌     | 45/100 [00:11<00:11,  4.85it/s]Train Iter: 246/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5183. T_Loss: 2.9220. Mask: 0.8723. :  45%|████▌     | 45/100 [00:11<00:11,  4.85it/s]Train Iter: 246/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5183. T_Loss: 2.9220. Mask: 0.8723. :  46%|████▌     | 46/100 [00:11<00:09,  5.49it/s]Train Iter: 247/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5174. T_Loss: 2.9495. Mask: 0.8730. :  46%|████▌     | 46/100 [00:12<00:09,  5.49it/s]Train Iter: 247/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5174. T_Loss: 2.9495. Mask: 0.8730. :  47%|████▋     | 47/100 [00:12<00:08,  6.05it/s]Train Iter: 248/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5181. T_Loss: 2.9585. Mask: 0.8737. :  47%|████▋     | 47/100 [00:12<00:08,  6.05it/s]Train Iter: 248/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5181. T_Loss: 2.9585. Mask: 0.8737. :  48%|████▊     | 48/100 [00:12<00:08,  6.43it/s]Train Iter: 249/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5200. T_Loss: 2.9556. Mask: 0.8724. :  48%|████▊     | 48/100 [00:12<00:08,  6.43it/s]Train Iter: 249/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5200. T_Loss: 2.9556. Mask: 0.8724. :  49%|████▉     | 49/100 [00:12<00:07,  6.79it/s]Train Iter: 250/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5200. T_Loss: 2.9657. Mask: 0.8725. :  49%|████▉     | 49/100 [00:12<00:07,  6.79it/s]Train Iter: 250/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5200. T_Loss: 2.9657. Mask: 0.8725. :  50%|█████     | 50/100 [00:12<00:07,  6.98it/s]total : 5000  current step :  226
total : 5000  current step :  227
total : 5000  current step :  228
total : 5000  current step :  229
total : 5000  current step :  230
total : 5000  current step :  231
total : 5000  current step :  232
total : 5000  current step :  233
total : 5000  current step :  234
total : 5000  current step :  235
total : 5000  current step :  236
total : 5000  current step :  237
total : 5000  current step :  238
total : 5000  current step :  239
total : 5000  current step :  240
total : 5000  current step :  241
total : 5000  current step :  242
total : 5000  current step :  243
total : 5000  current step :  244
total : 5000  current step :  245
total : 5000  current step :  246
total : 5000  current step :  247
total : 5000  current step :  248
total : 5000  current step :  249
total : 5000  current step :  250
Train Iter: 251/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5196. T_Loss: 2.9614. Mask: 0.8695. :  50%|█████     | 50/100 [00:14<00:07,  6.98it/s]Train Iter: 251/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5196. T_Loss: 2.9614. Mask: 0.8695. :  51%|█████     | 51/100 [00:14<00:34,  1.40it/s]Train Iter: 252/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5185. T_Loss: 2.9567. Mask: 0.8678. :  51%|█████     | 51/100 [00:14<00:34,  1.40it/s]Train Iter: 252/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 2.5185. T_Loss: 2.9567. Mask: 0.8678. :  52%|█████▏    | 52/100 [00:14<00:25,  1.86it/s]Train Iter: 253/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5187. T_Loss: 2.9626. Mask: 0.8679. :  52%|█████▏    | 52/100 [00:14<00:25,  1.86it/s]Train Iter: 253/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5187. T_Loss: 2.9626. Mask: 0.8679. :  53%|█████▎    | 53/100 [00:14<00:19,  2.39it/s]Train Iter: 254/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5181. T_Loss: 2.9661. Mask: 0.8698. :  53%|█████▎    | 53/100 [00:15<00:19,  2.39it/s]Train Iter: 254/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5181. T_Loss: 2.9661. Mask: 0.8698. :  54%|█████▍    | 54/100 [00:15<00:19,  2.39it/s]Train Iter: 255/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5165. T_Loss: 2.9644. Mask: 0.8710. :  54%|█████▍    | 54/100 [00:15<00:19,  2.39it/s]Train Iter: 255/5000. LR: 0.0000. Data: 0.12s. Batch: 0.28s. S_Loss: 2.5165. T_Loss: 2.9644. Mask: 0.8710. :  55%|█████▌    | 55/100 [00:15<00:14,  3.06it/s]Train Iter: 256/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5169. T_Loss: 2.9606. Mask: 0.8700. :  55%|█████▌    | 55/100 [00:15<00:14,  3.06it/s]Train Iter: 256/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 2.5169. T_Loss: 2.9606. Mask: 0.8700. :  56%|█████▌    | 56/100 [00:15<00:11,  3.85it/s]Train Iter: 257/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5169. T_Loss: 2.9621. Mask: 0.8701. :  56%|█████▌    | 56/100 [00:15<00:11,  3.85it/s]Train Iter: 258/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5156. T_Loss: 2.9626. Mask: 0.8702. :  57%|█████▋    | 57/100 [00:15<00:11,  3.85it/s]Train Iter: 258/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5156. T_Loss: 2.9626. Mask: 0.8702. :  58%|█████▊    | 58/100 [00:15<00:07,  5.32it/s]Train Iter: 259/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5158. T_Loss: 2.9705. Mask: 0.8702. :  58%|█████▊    | 58/100 [00:15<00:07,  5.32it/s]Train Iter: 259/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5158. T_Loss: 2.9705. Mask: 0.8702. :  59%|█████▉    | 59/100 [00:15<00:06,  5.99it/s]Train Iter: 260/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5150. T_Loss: 2.9782. Mask: 0.8714. :  59%|█████▉    | 59/100 [00:15<00:06,  5.99it/s]Train Iter: 260/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5150. T_Loss: 2.9782. Mask: 0.8714. :  60%|██████    | 60/100 [00:15<00:06,  5.95it/s]Train Iter: 261/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5157. T_Loss: 2.9714. Mask: 0.8719. :  60%|██████    | 60/100 [00:15<00:06,  5.95it/s]Train Iter: 261/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5157. T_Loss: 2.9714. Mask: 0.8719. :  61%|██████    | 61/100 [00:15<00:06,  6.37it/s]Train Iter: 262/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5150. T_Loss: 2.9785. Mask: 0.8730. :  61%|██████    | 61/100 [00:16<00:06,  6.37it/s]Train Iter: 262/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5150. T_Loss: 2.9785. Mask: 0.8730. :  62%|██████▏   | 62/100 [00:16<00:05,  6.91it/s]Train Iter: 263/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5160. T_Loss: 2.9809. Mask: 0.8735. :  62%|██████▏   | 62/100 [00:16<00:05,  6.91it/s]Train Iter: 263/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5160. T_Loss: 2.9809. Mask: 0.8735. :  63%|██████▎   | 63/100 [00:16<00:05,  7.12it/s]Train Iter: 264/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5148. T_Loss: 2.9882. Mask: 0.8750. :  63%|██████▎   | 63/100 [00:16<00:05,  7.12it/s]Train Iter: 264/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5148. T_Loss: 2.9882. Mask: 0.8750. :  64%|██████▍   | 64/100 [00:16<00:06,  5.41it/s]Train Iter: 265/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5168. T_Loss: 2.9955. Mask: 0.8764. :  64%|██████▍   | 64/100 [00:16<00:06,  5.41it/s]Train Iter: 265/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5168. T_Loss: 2.9955. Mask: 0.8764. :  65%|██████▌   | 65/100 [00:16<00:05,  6.07it/s]Train Iter: 266/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5172. T_Loss: 3.0043. Mask: 0.8764. :  65%|██████▌   | 65/100 [00:16<00:05,  6.07it/s]Train Iter: 266/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5172. T_Loss: 3.0043. Mask: 0.8764. :  66%|██████▌   | 66/100 [00:16<00:05,  6.59it/s]Train Iter: 267/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5170. T_Loss: 3.0020. Mask: 0.8778. :  66%|██████▌   | 66/100 [00:16<00:05,  6.59it/s]Train Iter: 267/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5170. T_Loss: 3.0020. Mask: 0.8778. :  67%|██████▋   | 67/100 [00:16<00:04,  6.97it/s]Train Iter: 268/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5178. T_Loss: 3.0083. Mask: 0.8782. :  67%|██████▋   | 67/100 [00:17<00:04,  6.97it/s]Train Iter: 268/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5178. T_Loss: 3.0083. Mask: 0.8782. :  68%|██████▊   | 68/100 [00:17<00:04,  7.29it/s]Train Iter: 269/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5189. T_Loss: 3.0228. Mask: 0.8800. :  68%|██████▊   | 68/100 [00:17<00:04,  7.29it/s]Train Iter: 269/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5189. T_Loss: 3.0228. Mask: 0.8800. :  69%|██████▉   | 69/100 [00:17<00:04,  7.44it/s]Train Iter: 270/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5186. T_Loss: 3.0272. Mask: 0.8804. :  69%|██████▉   | 69/100 [00:17<00:04,  7.44it/s]Train Iter: 270/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5186. T_Loss: 3.0272. Mask: 0.8804. :  70%|███████   | 70/100 [00:17<00:06,  4.94it/s]Train Iter: 271/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5188. T_Loss: 3.0398. Mask: 0.8812. :  70%|███████   | 70/100 [00:17<00:06,  4.94it/s]Train Iter: 271/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5188. T_Loss: 3.0398. Mask: 0.8812. :  71%|███████   | 71/100 [00:17<00:05,  5.63it/s]Train Iter: 272/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5180. T_Loss: 3.0448. Mask: 0.8811. :  71%|███████   | 71/100 [00:17<00:05,  5.63it/s]Train Iter: 272/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5180. T_Loss: 3.0448. Mask: 0.8811. :  72%|███████▏  | 72/100 [00:17<00:04,  6.20it/s]Train Iter: 273/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5185. T_Loss: 3.0450. Mask: 0.8814. :  72%|███████▏  | 72/100 [00:17<00:04,  6.20it/s]Train Iter: 273/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5185. T_Loss: 3.0450. Mask: 0.8814. :  73%|███████▎  | 73/100 [00:17<00:04,  6.67it/s]Train Iter: 274/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5179. T_Loss: 3.0515. Mask: 0.8818. :  73%|███████▎  | 73/100 [00:18<00:04,  6.67it/s]Train Iter: 274/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5179. T_Loss: 3.0515. Mask: 0.8818. :  74%|███████▍  | 74/100 [00:18<00:05,  4.82it/s]Train Iter: 275/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5170. T_Loss: 3.0562. Mask: 0.8829. :  74%|███████▍  | 74/100 [00:18<00:05,  4.82it/s]Train Iter: 275/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5170. T_Loss: 3.0562. Mask: 0.8829. :  75%|███████▌  | 75/100 [00:18<00:04,  5.41it/s]total : 5000  current step :  251
total : 5000  current step :  252
total : 5000  current step :  253
total : 5000  current step :  254
total : 5000  current step :  255
total : 5000  current step :  256
total : 5000  current step :  257
total : 5000  current step :  258
total : 5000  current step :  259
total : 5000  current step :  260
total : 5000  current step :  261
total : 5000  current step :  262
total : 5000  current step :  263
total : 5000  current step :  264
total : 5000  current step :  265
total : 5000  current step :  266
total : 5000  current step :  267
total : 5000  current step :  268
total : 5000  current step :  269
total : 5000  current step :  270
total : 5000  current step :  271
total : 5000  current step :  272
total : 5000  current step :  273
total : 5000  current step :  274
total : 5000  current step :  275
Train Iter: 276/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5157. T_Loss: 3.0601. Mask: 0.8832. :  75%|███████▌  | 75/100 [00:20<00:04,  5.41it/s]Train Iter: 276/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5157. T_Loss: 3.0601. Mask: 0.8832. :  76%|███████▌  | 76/100 [00:20<00:18,  1.28it/s]Train Iter: 277/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5143. T_Loss: 3.0646. Mask: 0.8827. :  76%|███████▌  | 76/100 [00:20<00:18,  1.28it/s]Train Iter: 277/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5143. T_Loss: 3.0646. Mask: 0.8827. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 278/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5150. T_Loss: 3.0782. Mask: 0.8830. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 278/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5150. T_Loss: 3.0782. Mask: 0.8830. :  78%|███████▊  | 78/100 [00:20<00:09,  2.22it/s]Train Iter: 279/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5139. T_Loss: 3.0811. Mask: 0.8809. :  78%|███████▊  | 78/100 [00:20<00:09,  2.22it/s]Train Iter: 279/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5139. T_Loss: 3.0811. Mask: 0.8809. :  79%|███████▉  | 79/100 [00:20<00:07,  2.79it/s]Train Iter: 280/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5136. T_Loss: 3.0828. Mask: 0.8797. :  79%|███████▉  | 79/100 [00:21<00:07,  2.79it/s]Train Iter: 280/5000. LR: 0.0000. Data: 0.11s. Batch: 0.27s. S_Loss: 2.5136. T_Loss: 3.0828. Mask: 0.8797. :  80%|████████  | 80/100 [00:21<00:07,  2.68it/s]Train Iter: 281/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5145. T_Loss: 3.0892. Mask: 0.8796. :  80%|████████  | 80/100 [00:21<00:07,  2.68it/s]Train Iter: 281/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5145. T_Loss: 3.0892. Mask: 0.8796. :  81%|████████  | 81/100 [00:21<00:05,  3.37it/s]Train Iter: 282/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5144. T_Loss: 3.0958. Mask: 0.8803. :  81%|████████  | 81/100 [00:21<00:05,  3.37it/s]Train Iter: 282/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 2.5144. T_Loss: 3.0958. Mask: 0.8803. :  82%|████████▏ | 82/100 [00:21<00:04,  4.00it/s]Train Iter: 283/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5152. T_Loss: 3.0983. Mask: 0.8803. :  82%|████████▏ | 82/100 [00:21<00:04,  4.00it/s]Train Iter: 283/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5152. T_Loss: 3.0983. Mask: 0.8803. :  83%|████████▎ | 83/100 [00:21<00:03,  4.76it/s]Train Iter: 284/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5152. T_Loss: 3.1131. Mask: 0.8813. :  83%|████████▎ | 83/100 [00:22<00:03,  4.76it/s]Train Iter: 284/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5152. T_Loss: 3.1131. Mask: 0.8813. :  84%|████████▍ | 84/100 [00:22<00:03,  4.00it/s]Train Iter: 285/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5148. T_Loss: 3.1151. Mask: 0.8812. :  84%|████████▍ | 84/100 [00:22<00:03,  4.00it/s]Train Iter: 285/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5148. T_Loss: 3.1151. Mask: 0.8812. :  85%|████████▌ | 85/100 [00:22<00:03,  4.73it/s]Train Iter: 286/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5145. T_Loss: 3.1180. Mask: 0.8808. :  85%|████████▌ | 85/100 [00:22<00:03,  4.73it/s]Train Iter: 286/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5145. T_Loss: 3.1180. Mask: 0.8808. :  86%|████████▌ | 86/100 [00:22<00:02,  5.42it/s]Train Iter: 287/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5152. T_Loss: 3.1147. Mask: 0.8793. :  86%|████████▌ | 86/100 [00:22<00:02,  5.42it/s]Train Iter: 287/5000. LR: 0.0000. Data: 0.10s. Batch: 0.26s. S_Loss: 2.5152. T_Loss: 3.1147. Mask: 0.8793. :  87%|████████▋ | 87/100 [00:22<00:02,  6.02it/s]Train Iter: 288/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5155. T_Loss: 3.1170. Mask: 0.8796. :  87%|████████▋ | 87/100 [00:22<00:02,  6.02it/s]Train Iter: 288/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5155. T_Loss: 3.1170. Mask: 0.8796. :  88%|████████▊ | 88/100 [00:22<00:01,  6.52it/s]Train Iter: 289/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5159. T_Loss: 3.1204. Mask: 0.8803. :  88%|████████▊ | 88/100 [00:22<00:01,  6.52it/s]Train Iter: 289/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5159. T_Loss: 3.1204. Mask: 0.8803. :  89%|████████▉ | 89/100 [00:22<00:01,  6.83it/s]Train Iter: 290/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5173. T_Loss: 3.1213. Mask: 0.8816. :  89%|████████▉ | 89/100 [00:22<00:01,  6.83it/s]Train Iter: 290/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5173. T_Loss: 3.1213. Mask: 0.8816. :  90%|█████████ | 90/100 [00:22<00:01,  7.00it/s]Train Iter: 291/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5182. T_Loss: 3.1154. Mask: 0.8802. :  90%|█████████ | 90/100 [00:22<00:01,  7.00it/s]Train Iter: 291/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 2.5182. T_Loss: 3.1154. Mask: 0.8802. :  91%|█████████ | 91/100 [00:22<00:01,  6.93it/s]Train Iter: 292/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5190. T_Loss: 3.1329. Mask: 0.8811. :  91%|█████████ | 91/100 [00:23<00:01,  6.93it/s]Train Iter: 292/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5190. T_Loss: 3.1329. Mask: 0.8811. :  92%|█████████▏| 92/100 [00:23<00:01,  7.06it/s]Train Iter: 293/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5194. T_Loss: 3.1422. Mask: 0.8821. :  92%|█████████▏| 92/100 [00:23<00:01,  7.06it/s]Train Iter: 293/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5194. T_Loss: 3.1422. Mask: 0.8821. :  93%|█████████▎| 93/100 [00:23<00:00,  7.36it/s]Train Iter: 294/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5188. T_Loss: 3.1457. Mask: 0.8823. :  93%|█████████▎| 93/100 [00:23<00:00,  7.36it/s]Train Iter: 294/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5188. T_Loss: 3.1457. Mask: 0.8823. :  94%|█████████▍| 94/100 [00:23<00:01,  4.69it/s]Train Iter: 295/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5183. T_Loss: 3.1488. Mask: 0.8829. :  94%|█████████▍| 94/100 [00:23<00:01,  4.69it/s]Train Iter: 295/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5183. T_Loss: 3.1488. Mask: 0.8829. :  95%|█████████▌| 95/100 [00:23<00:00,  5.51it/s]Train Iter: 296/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5197. T_Loss: 3.1533. Mask: 0.8828. :  95%|█████████▌| 95/100 [00:23<00:00,  5.51it/s]Train Iter: 296/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5197. T_Loss: 3.1533. Mask: 0.8828. :  96%|█████████▌| 96/100 [00:23<00:00,  6.13it/s]Train Iter: 297/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5187. T_Loss: 3.1517. Mask: 0.8821. :  96%|█████████▌| 96/100 [00:23<00:00,  6.13it/s]Train Iter: 297/5000. LR: 0.0000. Data: 0.09s. Batch: 0.25s. S_Loss: 2.5187. T_Loss: 3.1517. Mask: 0.8821. :  97%|█████████▋| 97/100 [00:23<00:00,  6.57it/s]Train Iter: 298/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5201. T_Loss: 3.1542. Mask: 0.8823. :  97%|█████████▋| 97/100 [00:24<00:00,  6.57it/s]Train Iter: 298/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5201. T_Loss: 3.1542. Mask: 0.8823. :  98%|█████████▊| 98/100 [00:24<00:00,  7.04it/s]Train Iter: 299/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5197. T_Loss: 3.1568. Mask: 0.8826. :  98%|█████████▊| 98/100 [00:24<00:00,  7.04it/s]Train Iter: 299/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5197. T_Loss: 3.1568. Mask: 0.8826. :  99%|█████████▉| 99/100 [00:24<00:00,  6.72it/s]Train Iter: 300/5000. LR: 0.0188. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5197. T_Loss: 3.1547. Mask: 0.8819. :  99%|█████████▉| 99/100 [00:24<00:00,  6.72it/s]Train Iter: 300/5000. LR: 0.0188. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5197. T_Loss: 3.1547. Mask: 0.8819. : 100%|██████████| 100/100 [00:24<00:00,  4.86it/s]Train Iter: 300/5000. LR: 0.0188. Data: 0.09s. Batch: 0.24s. S_Loss: 2.5197. T_Loss: 3.1547. Mask: 0.8819. : 100%|██████████| 100/100 [00:24<00:00,  4.07it/s]
total : 5000  current step :  276
total : 5000  current step :  277
total : 5000  current step :  278
total : 5000  current step :  279
total : 5000  current step :  280
total : 5000  current step :  281
total : 5000  current step :  282
total : 5000  current step :  283
total : 5000  current step :  284
total : 5000  current step :  285
total : 5000  current step :  286
total : 5000  current step :  287
total : 5000  current step :  288
total : 5000  current step :  289
total : 5000  current step :  290
total : 5000  current step :  291
total : 5000  current step :  292
total : 5000  current step :  293
total : 5000  current step :  294
total : 5000  current step :  295
total : 5000  current step :  296
total : 5000  current step :  297
total : 5000  current step :  298
total : 5000  current step :  299
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 2.1466. top1: 12.50. top5: 84.38. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 2.1466. top1: 12.50. top5: 84.38. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.88s. Loss: 2.1553. top1: 10.94. top5: 85.94. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.59s. Loss: 2.1651. top1: 13.54. top5: 83.33. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 2.1557. top1: 14.06. top5: 85.16. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 2.1656. top1: 13.12. top5: 81.88. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 2.1649. top1: 13.02. top5: 81.77. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 2.1735. top1: 11.61. top5: 83.48. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 2.1768. top1: 10.94. top5: 83.98. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.1845. top1: 10.07. top5: 83.68. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.1845. top1: 10.07. top5: 83.68. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.1857. top1: 10.00. top5: 84.38. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.1882. top1: 9.66. top5: 84.94. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s] Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.1877. top1: 9.64. top5: 84.64. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.1921. top1: 8.89. top5: 84.38. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.1883. top1: 9.15. top5: 84.60. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.1922. top1: 8.75. top5: 83.96. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.1945. top1: 8.59. top5: 83.98. :  14%|█▍        | 9/63 [00:01<00:08,  6.53it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.1945. top1: 8.59. top5: 83.98. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.1914. top1: 8.82. top5: 84.19. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.1934. top1: 8.33. top5: 84.55. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1953. top1: 7.89. top5: 84.38. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1940. top1: 7.97. top5: 84.06. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1940. top1: 7.74. top5: 84.38. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1929. top1: 7.95. top5: 84.80. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1938. top1: 7.61. top5: 84.92. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1951. top1: 7.42. top5: 85.03. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1952. top1: 7.62. top5: 85.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1961. top1: 7.57. top5: 85.10. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1973. top1: 7.41. top5: 85.07. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1973. top1: 7.41. top5: 85.07. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1968. top1: 7.48. top5: 84.93. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1947. top1: 7.97. top5: 85.24. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1957. top1: 7.92. top5: 85.21. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1954. top1: 7.96. top5: 85.28. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.2000. top1: 7.71. top5: 84.86. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2051. top1: 7.48. top5: 83.71. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2105. top1: 7.26. top5: 83.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2147. top1: 7.05. top5: 82.05. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2202. top1: 6.86. top5: 80.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2244. top1: 6.67. top5: 80.32. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2286. top1: 6.50. top5: 79.77. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2286. top1: 6.50. top5: 79.77. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2325. top1: 6.33. top5: 79.25. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2367. top1: 6.17. top5: 78.44. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2402. top1: 6.02. top5: 77.90. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2442. top1: 5.88. top5: 77.31. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2477. top1: 5.74. top5: 76.89. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2502. top1: 5.61. top5: 76.78. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2523. top1: 5.49. top5: 76.53. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2550. top1: 5.37. top5: 76.22. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2578. top1: 5.25. top5: 75.66. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2603. top1: 5.14. top5: 75.33. :  60%|██████    | 38/63 [00:02<00:00, 36.37it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2603. top1: 5.14. top5: 75.33. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2633. top1: 5.04. top5: 74.81. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2663. top1: 4.94. top5: 74.19. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2694. top1: 4.84. top5: 73.53. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2719. top1: 4.75. top5: 73.14. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2737. top1: 4.66. top5: 72.88. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2758. top1: 4.57. top5: 72.51. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2782. top1: 4.49. top5: 72.16. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2801. top1: 4.41. top5: 71.76. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2818. top1: 4.33. top5: 71.44. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2831. top1: 4.26. top5: 71.12. :  76%|███████▌  | 48/63 [00:02<00:00, 46.93it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2831. top1: 4.26. top5: 71.12. :  92%|█████████▏| 58/63 [00:02<00:00, 56.36it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2853. top1: 4.18. top5: 70.55. :  92%|█████████▏| 58/63 [00:02<00:00, 56.36it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2870. top1: 4.11. top5: 70.31. :  92%|█████████▏| 58/63 [00:02<00:00, 56.36it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2892. top1: 4.05. top5: 69.72. :  92%|█████████▏| 58/63 [00:02<00:00, 56.36it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2912. top1: 3.98. top5: 69.46. :  92%|█████████▏| 58/63 [00:02<00:00, 56.36it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2922. top1: 3.95. top5: 69.30. :  92%|█████████▏| 58/63 [00:02<00:00, 56.36it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2922. top1: 3.95. top5: 69.30. : 100%|██████████| 63/63 [00:02<00:00, 23.43it/s]
total : 5000  current step :  300
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 301/5000. LR: 0.0188. Data: 2.10s. Batch: 2.22s. S_Loss: 2.6496. T_Loss: 2.9624. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 301/5000. LR: 0.0188. Data: 2.10s. Batch: 2.22s. S_Loss: 2.6496. T_Loss: 2.9624. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:39,  2.22s/it]Train Iter: 302/5000. LR: 0.0189. Data: 1.05s. Batch: 1.17s. S_Loss: 2.1496. T_Loss: 3.1591. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:39,  2.22s/it]Train Iter: 302/5000. LR: 0.0189. Data: 1.05s. Batch: 1.17s. S_Loss: 2.1496. T_Loss: 3.1591. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 303/5000. LR: 0.0189. Data: 0.70s. Batch: 0.82s. S_Loss: 1.8874. T_Loss: 3.2113. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 303/5000. LR: 0.0189. Data: 0.70s. Batch: 0.82s. S_Loss: 1.8874. T_Loss: 3.2113. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:57,  1.68it/s]Train Iter: 304/5000. LR: 0.0190. Data: 0.53s. Batch: 0.69s. S_Loss: 1.7503. T_Loss: 3.2601. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:57,  1.68it/s]Train Iter: 304/5000. LR: 0.0190. Data: 0.53s. Batch: 0.69s. S_Loss: 1.7503. T_Loss: 3.2601. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:46,  2.08it/s]Train Iter: 305/5000. LR: 0.0191. Data: 0.42s. Batch: 0.58s. S_Loss: 1.6946. T_Loss: 3.2542. Mask: 0.9187. :   4%|▍         | 4/100 [00:02<00:46,  2.08it/s]Train Iter: 305/5000. LR: 0.0191. Data: 0.42s. Batch: 0.58s. S_Loss: 1.6946. T_Loss: 3.2542. Mask: 0.9187. :   5%|▌         | 5/100 [00:02<00:33,  2.84it/s]Train Iter: 306/5000. LR: 0.0191. Data: 0.35s. Batch: 0.50s. S_Loss: 1.6619. T_Loss: 3.2606. Mask: 0.9010. :   5%|▌         | 5/100 [00:03<00:33,  2.84it/s]Train Iter: 306/5000. LR: 0.0191. Data: 0.35s. Batch: 0.50s. S_Loss: 1.6619. T_Loss: 3.2606. Mask: 0.9010. :   6%|▌         | 6/100 [00:03<00:25,  3.64it/s]Train Iter: 307/5000. LR: 0.0192. Data: 0.30s. Batch: 0.45s. S_Loss: 1.6562. T_Loss: 3.3467. Mask: 0.9062. :   6%|▌         | 6/100 [00:03<00:25,  3.64it/s]Train Iter: 307/5000. LR: 0.0192. Data: 0.30s. Batch: 0.45s. S_Loss: 1.6562. T_Loss: 3.3467. Mask: 0.9062. :   7%|▋         | 7/100 [00:03<00:21,  4.42it/s]Train Iter: 308/5000. LR: 0.0193. Data: 0.27s. Batch: 0.41s. S_Loss: 1.6480. T_Loss: 3.3892. Mask: 0.8984. :   7%|▋         | 7/100 [00:03<00:21,  4.42it/s]Train Iter: 308/5000. LR: 0.0193. Data: 0.27s. Batch: 0.41s. S_Loss: 1.6480. T_Loss: 3.3892. Mask: 0.8984. :   8%|▊         | 8/100 [00:03<00:17,  5.17it/s]Train Iter: 309/5000. LR: 0.0193. Data: 0.24s. Batch: 0.38s. S_Loss: 1.6565. T_Loss: 3.4122. Mask: 0.8924. :   8%|▊         | 8/100 [00:03<00:17,  5.17it/s]Train Iter: 309/5000. LR: 0.0193. Data: 0.24s. Batch: 0.38s. S_Loss: 1.6565. T_Loss: 3.4122. Mask: 0.8924. :   9%|▉         | 9/100 [00:03<00:15,  5.83it/s]Train Iter: 310/5000. LR: 0.0194. Data: 0.21s. Batch: 0.35s. S_Loss: 1.6527. T_Loss: 3.4135. Mask: 0.8906. :   9%|▉         | 9/100 [00:03<00:15,  5.83it/s]Train Iter: 310/5000. LR: 0.0194. Data: 0.21s. Batch: 0.35s. S_Loss: 1.6527. T_Loss: 3.4135. Mask: 0.8906. :  10%|█         | 10/100 [00:03<00:14,  6.26it/s]Train Iter: 311/5000. LR: 0.0194. Data: 0.19s. Batch: 0.33s. S_Loss: 1.6501. T_Loss: 3.4476. Mask: 0.8920. :  10%|█         | 10/100 [00:03<00:14,  6.26it/s]Train Iter: 311/5000. LR: 0.0194. Data: 0.19s. Batch: 0.33s. S_Loss: 1.6501. T_Loss: 3.4476. Mask: 0.8920. :  11%|█         | 11/100 [00:03<00:13,  6.65it/s]Train Iter: 312/5000. LR: 0.0195. Data: 0.18s. Batch: 0.31s. S_Loss: 1.6519. T_Loss: 3.4648. Mask: 0.8932. :  11%|█         | 11/100 [00:03<00:13,  6.65it/s]Train Iter: 312/5000. LR: 0.0195. Data: 0.18s. Batch: 0.31s. S_Loss: 1.6519. T_Loss: 3.4648. Mask: 0.8932. :  12%|█▏        | 12/100 [00:03<00:12,  6.98it/s]total : 5000  current step :  301
total : 5000  current step :  302
total : 5000  current step :  303
total : 5000  current step :  304
total : 5000  current step :  305
total : 5000  current step :  306
total : 5000  current step :  307
total : 5000  current step :  308
total : 5000  current step :  309
total : 5000  current step :  310
total : 5000  current step :  311
total : 5000  current step :  312
Train Iter: 313/5000. LR: 0.0196. Data: 0.31s. Batch: 0.44s. S_Loss: 1.6492. T_Loss: 3.4582. Mask: 0.8894. :  12%|█▏        | 12/100 [00:05<00:12,  6.98it/s]Train Iter: 313/5000. LR: 0.0196. Data: 0.31s. Batch: 0.44s. S_Loss: 1.6492. T_Loss: 3.4582. Mask: 0.8894. :  13%|█▎        | 13/100 [00:05<01:01,  1.42it/s]Train Iter: 314/5000. LR: 0.0196. Data: 0.29s. Batch: 0.42s. S_Loss: 1.6582. T_Loss: 3.4350. Mask: 0.8817. :  13%|█▎        | 13/100 [00:05<01:01,  1.42it/s]Train Iter: 314/5000. LR: 0.0196. Data: 0.29s. Batch: 0.42s. S_Loss: 1.6582. T_Loss: 3.4350. Mask: 0.8817. :  14%|█▍        | 14/100 [00:05<00:45,  1.89it/s]Train Iter: 315/5000. LR: 0.0197. Data: 0.27s. Batch: 0.40s. S_Loss: 1.6585. T_Loss: 3.4516. Mask: 0.8812. :  14%|█▍        | 14/100 [00:06<00:45,  1.89it/s]Train Iter: 315/5000. LR: 0.0197. Data: 0.27s. Batch: 0.40s. S_Loss: 1.6585. T_Loss: 3.4516. Mask: 0.8812. :  15%|█▌        | 15/100 [00:06<00:35,  2.40it/s]Train Iter: 316/5000. LR: 0.0198. Data: 0.25s. Batch: 0.39s. S_Loss: 1.6655. T_Loss: 3.4806. Mask: 0.8809. :  15%|█▌        | 15/100 [00:06<00:35,  2.40it/s]Train Iter: 316/5000. LR: 0.0198. Data: 0.25s. Batch: 0.39s. S_Loss: 1.6655. T_Loss: 3.4806. Mask: 0.8809. :  16%|█▌        | 16/100 [00:06<00:28,  2.98it/s]Train Iter: 317/5000. LR: 0.0198. Data: 0.24s. Batch: 0.37s. S_Loss: 1.6654. T_Loss: 3.4579. Mask: 0.8787. :  16%|█▌        | 16/100 [00:06<00:28,  2.98it/s]Train Iter: 317/5000. LR: 0.0198. Data: 0.24s. Batch: 0.37s. S_Loss: 1.6654. T_Loss: 3.4579. Mask: 0.8787. :  17%|█▋        | 17/100 [00:06<00:22,  3.72it/s]Train Iter: 318/5000. LR: 0.0199. Data: 0.22s. Batch: 0.36s. S_Loss: 1.6560. T_Loss: 3.4475. Mask: 0.8750. :  17%|█▋        | 17/100 [00:06<00:22,  3.72it/s]Train Iter: 318/5000. LR: 0.0199. Data: 0.22s. Batch: 0.36s. S_Loss: 1.6560. T_Loss: 3.4475. Mask: 0.8750. :  18%|█▊        | 18/100 [00:06<00:18,  4.44it/s]Train Iter: 319/5000. LR: 0.0199. Data: 0.21s. Batch: 0.34s. S_Loss: 1.6605. T_Loss: 3.4354. Mask: 0.8717. :  18%|█▊        | 18/100 [00:06<00:18,  4.44it/s]Train Iter: 319/5000. LR: 0.0199. Data: 0.21s. Batch: 0.34s. S_Loss: 1.6605. T_Loss: 3.4354. Mask: 0.8717. :  19%|█▉        | 19/100 [00:06<00:15,  5.14it/s]Train Iter: 320/5000. LR: 0.0200. Data: 0.20s. Batch: 0.34s. S_Loss: 1.6686. T_Loss: 3.4901. Mask: 0.8750. :  19%|█▉        | 19/100 [00:06<00:15,  5.14it/s]Train Iter: 320/5000. LR: 0.0200. Data: 0.20s. Batch: 0.34s. S_Loss: 1.6686. T_Loss: 3.4901. Mask: 0.8750. :  20%|██        | 20/100 [00:06<00:17,  4.70it/s]Train Iter: 321/5000. LR: 0.0201. Data: 0.19s. Batch: 0.33s. S_Loss: 1.6795. T_Loss: 3.4748. Mask: 0.8735. :  20%|██        | 20/100 [00:06<00:17,  4.70it/s]Train Iter: 321/5000. LR: 0.0201. Data: 0.19s. Batch: 0.33s. S_Loss: 1.6795. T_Loss: 3.4748. Mask: 0.8735. :  21%|██        | 21/100 [00:06<00:15,  5.21it/s]Train Iter: 322/5000. LR: 0.0201. Data: 0.18s. Batch: 0.32s. S_Loss: 1.6784. T_Loss: 3.4587. Mask: 0.8707. :  21%|██        | 21/100 [00:07<00:15,  5.21it/s]Train Iter: 322/5000. LR: 0.0201. Data: 0.18s. Batch: 0.32s. S_Loss: 1.6784. T_Loss: 3.4587. Mask: 0.8707. :  22%|██▏       | 22/100 [00:07<00:13,  5.85it/s]Train Iter: 323/5000. LR: 0.0202. Data: 0.18s. Batch: 0.31s. S_Loss: 1.6706. T_Loss: 3.4507. Mask: 0.8696. :  22%|██▏       | 22/100 [00:07<00:13,  5.85it/s]Train Iter: 323/5000. LR: 0.0202. Data: 0.18s. Batch: 0.31s. S_Loss: 1.6706. T_Loss: 3.4507. Mask: 0.8696. :  23%|██▎       | 23/100 [00:07<00:12,  6.37it/s]Train Iter: 324/5000. LR: 0.0203. Data: 0.17s. Batch: 0.31s. S_Loss: 1.6599. T_Loss: 3.4503. Mask: 0.8711. :  23%|██▎       | 23/100 [00:07<00:12,  6.37it/s]Train Iter: 324/5000. LR: 0.0203. Data: 0.17s. Batch: 0.31s. S_Loss: 1.6599. T_Loss: 3.4503. Mask: 0.8711. :  24%|██▍       | 24/100 [00:07<00:14,  5.19it/s]Train Iter: 325/5000. LR: 0.0203. Data: 0.16s. Batch: 0.30s. S_Loss: 1.6462. T_Loss: 3.4457. Mask: 0.8738. :  24%|██▍       | 24/100 [00:07<00:14,  5.19it/s]Train Iter: 325/5000. LR: 0.0203. Data: 0.16s. Batch: 0.30s. S_Loss: 1.6462. T_Loss: 3.4457. Mask: 0.8738. :  25%|██▌       | 25/100 [00:07<00:12,  5.82it/s]total : 5000  current step :  313
total : 5000  current step :  314
total : 5000  current step :  315
total : 5000  current step :  316
total : 5000  current step :  317
total : 5000  current step :  318
total : 5000  current step :  319
total : 5000  current step :  320
total : 5000  current step :  321
total : 5000  current step :  322
total : 5000  current step :  323
total : 5000  current step :  324
total : 5000  current step :  325
Train Iter: 326/5000. LR: 0.0204. Data: 0.24s. Batch: 0.37s. S_Loss: 1.6453. T_Loss: 3.4650. Mask: 0.8750. :  25%|██▌       | 25/100 [00:09<00:12,  5.82it/s]Train Iter: 326/5000. LR: 0.0204. Data: 0.24s. Batch: 0.37s. S_Loss: 1.6453. T_Loss: 3.4650. Mask: 0.8750. :  26%|██▌       | 26/100 [00:09<00:57,  1.29it/s]Train Iter: 327/5000. LR: 0.0204. Data: 0.23s. Batch: 0.36s. S_Loss: 1.6476. T_Loss: 3.4537. Mask: 0.8773. :  26%|██▌       | 26/100 [00:09<00:57,  1.29it/s]Train Iter: 328/5000. LR: 0.0205. Data: 0.22s. Batch: 0.36s. S_Loss: 1.6556. T_Loss: 3.4570. Mask: 0.8750. :  27%|██▋       | 27/100 [00:10<00:56,  1.29it/s]Train Iter: 328/5000. LR: 0.0205. Data: 0.22s. Batch: 0.36s. S_Loss: 1.6556. T_Loss: 3.4570. Mask: 0.8750. :  28%|██▊       | 28/100 [00:10<00:33,  2.15it/s]Train Iter: 329/5000. LR: 0.0206. Data: 0.21s. Batch: 0.35s. S_Loss: 1.6540. T_Loss: 3.4818. Mask: 0.8772. :  28%|██▊       | 28/100 [00:10<00:33,  2.15it/s]Train Iter: 329/5000. LR: 0.0206. Data: 0.21s. Batch: 0.35s. S_Loss: 1.6540. T_Loss: 3.4818. Mask: 0.8772. :  29%|██▉       | 29/100 [00:10<00:27,  2.54it/s]Train Iter: 330/5000. LR: 0.0206. Data: 0.21s. Batch: 0.34s. S_Loss: 1.6476. T_Loss: 3.4963. Mask: 0.8792. :  29%|██▉       | 29/100 [00:10<00:27,  2.54it/s]Train Iter: 330/5000. LR: 0.0206. Data: 0.21s. Batch: 0.34s. S_Loss: 1.6476. T_Loss: 3.4963. Mask: 0.8792. :  30%|███       | 30/100 [00:10<00:24,  2.91it/s]Train Iter: 331/5000. LR: 0.0207. Data: 0.20s. Batch: 0.34s. S_Loss: 1.6416. T_Loss: 3.5093. Mask: 0.8800. :  30%|███       | 30/100 [00:10<00:24,  2.91it/s]Train Iter: 331/5000. LR: 0.0207. Data: 0.20s. Batch: 0.34s. S_Loss: 1.6416. T_Loss: 3.5093. Mask: 0.8800. :  31%|███       | 31/100 [00:10<00:19,  3.56it/s]Train Iter: 332/5000. LR: 0.0208. Data: 0.19s. Batch: 0.33s. S_Loss: 1.6325. T_Loss: 3.5250. Mask: 0.8789. :  31%|███       | 31/100 [00:10<00:19,  3.56it/s]Train Iter: 332/5000. LR: 0.0208. Data: 0.19s. Batch: 0.33s. S_Loss: 1.6325. T_Loss: 3.5250. Mask: 0.8789. :  32%|███▏      | 32/100 [00:10<00:15,  4.26it/s]Train Iter: 333/5000. LR: 0.0208. Data: 0.19s. Batch: 0.32s. S_Loss: 1.6293. T_Loss: 3.5483. Mask: 0.8778. :  32%|███▏      | 32/100 [00:10<00:15,  4.26it/s]Train Iter: 333/5000. LR: 0.0208. Data: 0.19s. Batch: 0.32s. S_Loss: 1.6293. T_Loss: 3.5483. Mask: 0.8778. :  33%|███▎      | 33/100 [00:10<00:13,  4.93it/s]Train Iter: 334/5000. LR: 0.0209. Data: 0.18s. Batch: 0.32s. S_Loss: 1.6271. T_Loss: 3.5477. Mask: 0.8741. :  33%|███▎      | 33/100 [00:11<00:13,  4.93it/s]Train Iter: 334/5000. LR: 0.0209. Data: 0.18s. Batch: 0.32s. S_Loss: 1.6271. T_Loss: 3.5477. Mask: 0.8741. :  34%|███▍      | 34/100 [00:11<00:16,  4.07it/s]Train Iter: 335/5000. LR: 0.0209. Data: 0.18s. Batch: 0.32s. S_Loss: 1.6200. T_Loss: 3.5471. Mask: 0.8732. :  34%|███▍      | 34/100 [00:11<00:16,  4.07it/s]Train Iter: 335/5000. LR: 0.0209. Data: 0.18s. Batch: 0.32s. S_Loss: 1.6200. T_Loss: 3.5471. Mask: 0.8732. :  35%|███▌      | 35/100 [00:11<00:13,  4.78it/s]Train Iter: 336/5000. LR: 0.0210. Data: 0.17s. Batch: 0.31s. S_Loss: 1.6122. T_Loss: 3.5778. Mask: 0.8741. :  35%|███▌      | 35/100 [00:11<00:13,  4.78it/s]Train Iter: 336/5000. LR: 0.0210. Data: 0.17s. Batch: 0.31s. S_Loss: 1.6122. T_Loss: 3.5778. Mask: 0.8741. :  36%|███▌      | 36/100 [00:11<00:11,  5.51it/s]Train Iter: 337/5000. LR: 0.0211. Data: 0.17s. Batch: 0.31s. S_Loss: 1.6066. T_Loss: 3.5956. Mask: 0.8758. :  36%|███▌      | 36/100 [00:11<00:11,  5.51it/s]Train Iter: 337/5000. LR: 0.0211. Data: 0.17s. Batch: 0.31s. S_Loss: 1.6066. T_Loss: 3.5956. Mask: 0.8758. :  37%|███▋      | 37/100 [00:11<00:10,  6.16it/s]Train Iter: 338/5000. LR: 0.0211. Data: 0.16s. Batch: 0.30s. S_Loss: 1.6043. T_Loss: 3.5884. Mask: 0.8750. :  37%|███▋      | 37/100 [00:11<00:10,  6.16it/s]Train Iter: 338/5000. LR: 0.0211. Data: 0.16s. Batch: 0.30s. S_Loss: 1.6043. T_Loss: 3.5884. Mask: 0.8750. :  38%|███▊      | 38/100 [00:11<00:09,  6.74it/s]Train Iter: 339/5000. LR: 0.0212. Data: 0.16s. Batch: 0.30s. S_Loss: 1.5995. T_Loss: 3.5860. Mask: 0.8782. :  38%|███▊      | 38/100 [00:11<00:09,  6.74it/s]Train Iter: 339/5000. LR: 0.0212. Data: 0.16s. Batch: 0.30s. S_Loss: 1.5995. T_Loss: 3.5860. Mask: 0.8782. :  39%|███▉      | 39/100 [00:11<00:08,  6.96it/s]Train Iter: 340/5000. LR: 0.0213. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5927. T_Loss: 3.5758. Mask: 0.8812. :  39%|███▉      | 39/100 [00:11<00:08,  6.96it/s]Train Iter: 340/5000. LR: 0.0213. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5927. T_Loss: 3.5758. Mask: 0.8812. :  40%|████      | 40/100 [00:11<00:11,  5.28it/s]Train Iter: 341/5000. LR: 0.0213. Data: 0.15s. Batch: 0.29s. S_Loss: 1.5827. T_Loss: 3.5547. Mask: 0.8841. :  40%|████      | 40/100 [00:12<00:11,  5.28it/s]Train Iter: 341/5000. LR: 0.0213. Data: 0.15s. Batch: 0.29s. S_Loss: 1.5827. T_Loss: 3.5547. Mask: 0.8841. :  41%|████      | 41/100 [00:12<00:10,  5.63it/s]Train Iter: 342/5000. LR: 0.0214. Data: 0.15s. Batch: 0.29s. S_Loss: 1.5706. T_Loss: 3.5391. Mask: 0.8869. :  41%|████      | 41/100 [00:12<00:10,  5.63it/s]Train Iter: 342/5000. LR: 0.0214. Data: 0.15s. Batch: 0.29s. S_Loss: 1.5706. T_Loss: 3.5391. Mask: 0.8869. :  42%|████▏     | 42/100 [00:12<00:09,  6.22it/s]Train Iter: 343/5000. LR: 0.0214. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5571. T_Loss: 3.5216. Mask: 0.8895. :  42%|████▏     | 42/100 [00:12<00:09,  6.22it/s]Train Iter: 343/5000. LR: 0.0214. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5571. T_Loss: 3.5216. Mask: 0.8895. :  43%|████▎     | 43/100 [00:12<00:08,  6.71it/s]Train Iter: 344/5000. LR: 0.0215. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5431. T_Loss: 3.5113. Mask: 0.8920. :  43%|████▎     | 43/100 [00:12<00:08,  6.71it/s]Train Iter: 344/5000. LR: 0.0215. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5431. T_Loss: 3.5113. Mask: 0.8920. :  44%|████▍     | 44/100 [00:12<00:11,  4.97it/s]Train Iter: 345/5000. LR: 0.0216. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5307. T_Loss: 3.5043. Mask: 0.8938. :  44%|████▍     | 44/100 [00:12<00:11,  4.97it/s]Train Iter: 345/5000. LR: 0.0216. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5307. T_Loss: 3.5043. Mask: 0.8938. :  45%|████▌     | 45/100 [00:12<00:09,  5.61it/s]Train Iter: 346/5000. LR: 0.0216. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5181. T_Loss: 3.5190. Mask: 0.8954. :  45%|████▌     | 45/100 [00:12<00:09,  5.61it/s]Train Iter: 346/5000. LR: 0.0216. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5181. T_Loss: 3.5190. Mask: 0.8954. :  46%|████▌     | 46/100 [00:12<00:08,  6.38it/s]Train Iter: 347/5000. LR: 0.0217. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5119. T_Loss: 3.5228. Mask: 0.8923. :  46%|████▌     | 46/100 [00:13<00:08,  6.38it/s]Train Iter: 347/5000. LR: 0.0217. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5119. T_Loss: 3.5228. Mask: 0.8923. :  47%|████▋     | 47/100 [00:13<00:07,  7.01it/s]Train Iter: 348/5000. LR: 0.0218. Data: 0.13s. Batch: 0.27s. S_Loss: 1.5235. T_Loss: 3.5273. Mask: 0.8887. :  47%|████▋     | 47/100 [00:13<00:07,  7.01it/s]Train Iter: 348/5000. LR: 0.0218. Data: 0.13s. Batch: 0.27s. S_Loss: 1.5235. T_Loss: 3.5273. Mask: 0.8887. :  48%|████▊     | 48/100 [00:13<00:07,  7.22it/s]Train Iter: 349/5000. LR: 0.0218. Data: 0.13s. Batch: 0.27s. S_Loss: 1.5346. T_Loss: 3.5507. Mask: 0.8903. :  48%|████▊     | 48/100 [00:13<00:07,  7.22it/s]Train Iter: 349/5000. LR: 0.0218. Data: 0.13s. Batch: 0.27s. S_Loss: 1.5346. T_Loss: 3.5507. Mask: 0.8903. :  49%|████▉     | 49/100 [00:13<00:06,  7.51it/s]Train Iter: 350/5000. LR: 0.0219. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5485. T_Loss: 3.5550. Mask: 0.8900. :  49%|████▉     | 49/100 [00:13<00:06,  7.51it/s]Train Iter: 350/5000. LR: 0.0219. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5485. T_Loss: 3.5550. Mask: 0.8900. :  50%|█████     | 50/100 [00:13<00:09,  5.44it/s]total : 5000  current step :  326
total : 5000  current step :  327
total : 5000  current step :  328
total : 5000  current step :  329
total : 5000  current step :  330
total : 5000  current step :  331
total : 5000  current step :  332
total : 5000  current step :  333
total : 5000  current step :  334
total : 5000  current step :  335
total : 5000  current step :  336
total : 5000  current step :  337
total : 5000  current step :  338
total : 5000  current step :  339
total : 5000  current step :  340
total : 5000  current step :  341
total : 5000  current step :  342
total : 5000  current step :  343
total : 5000  current step :  344
total : 5000  current step :  345
total : 5000  current step :  346
total : 5000  current step :  347
total : 5000  current step :  348
total : 5000  current step :  349
total : 5000  current step :  350
Train Iter: 351/5000. LR: 0.0219. Data: 0.16s. Batch: 0.30s. S_Loss: 1.5577. T_Loss: 3.5632. Mask: 0.8922. :  50%|█████     | 50/100 [00:15<00:09,  5.44it/s]Train Iter: 351/5000. LR: 0.0219. Data: 0.16s. Batch: 0.30s. S_Loss: 1.5577. T_Loss: 3.5632. Mask: 0.8922. :  51%|█████     | 51/100 [00:15<00:34,  1.41it/s]Train Iter: 352/5000. LR: 0.0220. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5653. T_Loss: 3.5598. Mask: 0.8936. :  51%|█████     | 51/100 [00:15<00:34,  1.41it/s]Train Iter: 352/5000. LR: 0.0220. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5653. T_Loss: 3.5598. Mask: 0.8936. :  52%|█████▏    | 52/100 [00:15<00:25,  1.86it/s]Train Iter: 353/5000. LR: 0.0221. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5661. T_Loss: 3.5476. Mask: 0.8939. :  52%|█████▏    | 52/100 [00:15<00:25,  1.86it/s]Train Iter: 353/5000. LR: 0.0221. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5661. T_Loss: 3.5476. Mask: 0.8939. :  53%|█████▎    | 53/100 [00:15<00:19,  2.42it/s]Train Iter: 354/5000. LR: 0.0221. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5666. T_Loss: 3.5806. Mask: 0.8958. :  53%|█████▎    | 53/100 [00:16<00:19,  2.42it/s]Train Iter: 354/5000. LR: 0.0221. Data: 0.15s. Batch: 0.30s. S_Loss: 1.5666. T_Loss: 3.5806. Mask: 0.8958. :  54%|█████▍    | 54/100 [00:16<00:17,  2.57it/s]Train Iter: 355/5000. LR: 0.0222. Data: 0.15s. Batch: 0.29s. S_Loss: 1.5624. T_Loss: 3.5827. Mask: 0.8938. :  54%|█████▍    | 54/100 [00:16<00:17,  2.57it/s]Train Iter: 355/5000. LR: 0.0222. Data: 0.15s. Batch: 0.29s. S_Loss: 1.5624. T_Loss: 3.5827. Mask: 0.8938. :  55%|█████▌    | 55/100 [00:16<00:13,  3.22it/s]Train Iter: 356/5000. LR: 0.0223. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5593. T_Loss: 3.6094. Mask: 0.8951. :  55%|█████▌    | 55/100 [00:16<00:13,  3.22it/s]Train Iter: 356/5000. LR: 0.0223. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5593. T_Loss: 3.6094. Mask: 0.8951. :  56%|█████▌    | 56/100 [00:16<00:11,  3.94it/s]Train Iter: 357/5000. LR: 0.0223. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5570. T_Loss: 3.6089. Mask: 0.8936. :  56%|█████▌    | 56/100 [00:16<00:11,  3.94it/s]Train Iter: 357/5000. LR: 0.0223. Data: 0.14s. Batch: 0.29s. S_Loss: 1.5570. T_Loss: 3.6089. Mask: 0.8936. :  57%|█████▋    | 57/100 [00:16<00:09,  4.62it/s]Train Iter: 358/5000. LR: 0.0224. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5535. T_Loss: 3.6266. Mask: 0.8939. :  57%|█████▋    | 57/100 [00:16<00:09,  4.62it/s]Train Iter: 358/5000. LR: 0.0224. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5535. T_Loss: 3.6266. Mask: 0.8939. :  58%|█████▊    | 58/100 [00:16<00:07,  5.39it/s]Train Iter: 359/5000. LR: 0.0224. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5527. T_Loss: 3.6283. Mask: 0.8946. :  58%|█████▊    | 58/100 [00:16<00:07,  5.39it/s]Train Iter: 359/5000. LR: 0.0224. Data: 0.14s. Batch: 0.28s. S_Loss: 1.5527. T_Loss: 3.6283. Mask: 0.8946. :  59%|█████▉    | 59/100 [00:16<00:06,  5.94it/s]Train Iter: 360/5000. LR: 0.0225. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5517. T_Loss: 3.6300. Mask: 0.8964. :  59%|█████▉    | 59/100 [00:17<00:06,  5.94it/s]Train Iter: 360/5000. LR: 0.0225. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5517. T_Loss: 3.6300. Mask: 0.8964. :  60%|██████    | 60/100 [00:17<00:08,  4.84it/s]Train Iter: 361/5000. LR: 0.0226. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5486. T_Loss: 3.6279. Mask: 0.8981. :  60%|██████    | 60/100 [00:17<00:08,  4.84it/s]Train Iter: 361/5000. LR: 0.0226. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5486. T_Loss: 3.6279. Mask: 0.8981. :  61%|██████    | 61/100 [00:17<00:07,  5.47it/s]Train Iter: 362/5000. LR: 0.0226. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5435. T_Loss: 3.6170. Mask: 0.8997. :  61%|██████    | 61/100 [00:17<00:07,  5.47it/s]Train Iter: 362/5000. LR: 0.0226. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5435. T_Loss: 3.6170. Mask: 0.8997. :  62%|██████▏   | 62/100 [00:17<00:06,  6.16it/s]Train Iter: 363/5000. LR: 0.0227. Data: 0.13s. Batch: 0.27s. S_Loss: 1.5378. T_Loss: 3.6148. Mask: 0.9013. :  62%|██████▏   | 62/100 [00:17<00:06,  6.16it/s]Train Iter: 363/5000. LR: 0.0227. Data: 0.13s. Batch: 0.27s. S_Loss: 1.5378. T_Loss: 3.6148. Mask: 0.9013. :  63%|██████▎   | 63/100 [00:17<00:05,  6.43it/s]Train Iter: 364/5000. LR: 0.0228. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5298. T_Loss: 3.6246. Mask: 0.9028. :  63%|██████▎   | 63/100 [00:17<00:05,  6.43it/s]Train Iter: 364/5000. LR: 0.0228. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5298. T_Loss: 3.6246. Mask: 0.9028. :  64%|██████▍   | 64/100 [00:17<00:07,  4.50it/s]Train Iter: 365/5000. LR: 0.0228. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5210. T_Loss: 3.6310. Mask: 0.9043. :  64%|██████▍   | 64/100 [00:17<00:07,  4.50it/s]Train Iter: 365/5000. LR: 0.0228. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5210. T_Loss: 3.6310. Mask: 0.9043. :  65%|██████▌   | 65/100 [00:17<00:06,  5.10it/s]Train Iter: 366/5000. LR: 0.0229. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5120. T_Loss: 3.6439. Mask: 0.9053. :  65%|██████▌   | 65/100 [00:18<00:06,  5.10it/s]Train Iter: 366/5000. LR: 0.0229. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5120. T_Loss: 3.6439. Mask: 0.9053. :  66%|██████▌   | 66/100 [00:18<00:06,  5.59it/s]Train Iter: 367/5000. LR: 0.0229. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5040. T_Loss: 3.6598. Mask: 0.9053. :  66%|██████▌   | 66/100 [00:18<00:06,  5.59it/s]Train Iter: 367/5000. LR: 0.0229. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5040. T_Loss: 3.6598. Mask: 0.9053. :  67%|██████▋   | 67/100 [00:18<00:05,  6.14it/s]Train Iter: 368/5000. LR: 0.0230. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5010. T_Loss: 3.6732. Mask: 0.9040. :  67%|██████▋   | 67/100 [00:18<00:05,  6.14it/s]Train Iter: 368/5000. LR: 0.0230. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5010. T_Loss: 3.6732. Mask: 0.9040. :  68%|██████▊   | 68/100 [00:18<00:04,  6.75it/s]Train Iter: 369/5000. LR: 0.0231. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5029. T_Loss: 3.6807. Mask: 0.9017. :  68%|██████▊   | 68/100 [00:18<00:04,  6.75it/s]Train Iter: 369/5000. LR: 0.0231. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5029. T_Loss: 3.6807. Mask: 0.9017. :  69%|██████▉   | 69/100 [00:18<00:04,  7.20it/s]Train Iter: 370/5000. LR: 0.0231. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5081. T_Loss: 3.6883. Mask: 0.8996. :  69%|██████▉   | 69/100 [00:18<00:04,  7.20it/s]Train Iter: 370/5000. LR: 0.0231. Data: 0.12s. Batch: 0.27s. S_Loss: 1.5081. T_Loss: 3.6883. Mask: 0.8996. :  70%|███████   | 70/100 [00:18<00:06,  4.68it/s]Train Iter: 371/5000. LR: 0.0232. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5108. T_Loss: 3.6912. Mask: 0.8979. :  70%|███████   | 70/100 [00:18<00:06,  4.68it/s]Train Iter: 371/5000. LR: 0.0232. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5108. T_Loss: 3.6912. Mask: 0.8979. :  71%|███████   | 71/100 [00:18<00:05,  5.43it/s]Train Iter: 372/5000. LR: 0.0233. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5137. T_Loss: 3.7032. Mask: 0.8984. :  71%|███████   | 71/100 [00:19<00:05,  5.43it/s]Train Iter: 372/5000. LR: 0.0233. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5137. T_Loss: 3.7032. Mask: 0.8984. :  72%|███████▏  | 72/100 [00:19<00:04,  6.02it/s]Train Iter: 373/5000. LR: 0.0233. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5148. T_Loss: 3.7088. Mask: 0.8985. :  72%|███████▏  | 72/100 [00:19<00:04,  6.02it/s]Train Iter: 373/5000. LR: 0.0233. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5148. T_Loss: 3.7088. Mask: 0.8985. :  73%|███████▎  | 73/100 [00:19<00:04,  6.28it/s]Train Iter: 374/5000. LR: 0.0234. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5149. T_Loss: 3.7210. Mask: 0.8982. :  73%|███████▎  | 73/100 [00:19<00:04,  6.28it/s]Train Iter: 374/5000. LR: 0.0234. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5149. T_Loss: 3.7210. Mask: 0.8982. :  74%|███████▍  | 74/100 [00:19<00:05,  4.77it/s]Train Iter: 375/5000. LR: 0.0234. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5123. T_Loss: 3.7225. Mask: 0.8975. :  74%|███████▍  | 74/100 [00:19<00:05,  4.77it/s]Train Iter: 375/5000. LR: 0.0234. Data: 0.11s. Batch: 0.26s. S_Loss: 1.5123. T_Loss: 3.7225. Mask: 0.8975. :  75%|███████▌  | 75/100 [00:19<00:04,  5.46it/s]total : 5000  current step :  351
total : 5000  current step :  352
total : 5000  current step :  353
total : 5000  current step :  354
total : 5000  current step :  355
total : 5000  current step :  356
total : 5000  current step :  357
total : 5000  current step :  358
total : 5000  current step :  359
total : 5000  current step :  360
total : 5000  current step :  361
total : 5000  current step :  362
total : 5000  current step :  363
total : 5000  current step :  364
total : 5000  current step :  365
total : 5000  current step :  366
total : 5000  current step :  367
total : 5000  current step :  368
total : 5000  current step :  369
total : 5000  current step :  370
total : 5000  current step :  371
total : 5000  current step :  372
total : 5000  current step :  373
total : 5000  current step :  374
total : 5000  current step :  375
Train Iter: 376/5000. LR: 0.0235. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5094. T_Loss: 3.7265. Mask: 0.8976. :  75%|███████▌  | 75/100 [00:21<00:04,  5.46it/s]Train Iter: 376/5000. LR: 0.0235. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5094. T_Loss: 3.7265. Mask: 0.8976. :  76%|███████▌  | 76/100 [00:21<00:17,  1.38it/s]Train Iter: 377/5000. LR: 0.0236. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5051. T_Loss: 3.7465. Mask: 0.8981. :  76%|███████▌  | 76/100 [00:21<00:17,  1.38it/s]Train Iter: 377/5000. LR: 0.0236. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5051. T_Loss: 3.7465. Mask: 0.8981. :  77%|███████▋  | 77/100 [00:21<00:12,  1.85it/s]Train Iter: 378/5000. LR: 0.0236. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5051. T_Loss: 3.7554. Mask: 0.8970. :  77%|███████▋  | 77/100 [00:21<00:12,  1.85it/s]Train Iter: 378/5000. LR: 0.0236. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5051. T_Loss: 3.7554. Mask: 0.8970. :  78%|███████▊  | 78/100 [00:21<00:09,  2.40it/s]Train Iter: 379/5000. LR: 0.0237. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5028. T_Loss: 3.7624. Mask: 0.8968. :  78%|███████▊  | 78/100 [00:22<00:09,  2.40it/s]Train Iter: 379/5000. LR: 0.0237. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5028. T_Loss: 3.7624. Mask: 0.8968. :  79%|███████▉  | 79/100 [00:22<00:07,  2.96it/s]Train Iter: 380/5000. LR: 0.0238. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5023. T_Loss: 3.7675. Mask: 0.8961. :  79%|███████▉  | 79/100 [00:22<00:07,  2.96it/s]Train Iter: 380/5000. LR: 0.0238. Data: 0.13s. Batch: 0.28s. S_Loss: 1.5023. T_Loss: 3.7675. Mask: 0.8961. :  80%|████████  | 80/100 [00:22<00:06,  2.86it/s]Train Iter: 381/5000. LR: 0.0238. Data: 0.12s. Batch: 0.28s. S_Loss: 1.5003. T_Loss: 3.7772. Mask: 0.8951. :  80%|████████  | 80/100 [00:22<00:06,  2.86it/s]Train Iter: 381/5000. LR: 0.0238. Data: 0.12s. Batch: 0.28s. S_Loss: 1.5003. T_Loss: 3.7772. Mask: 0.8951. :  81%|████████  | 81/100 [00:22<00:05,  3.62it/s]Train Iter: 382/5000. LR: 0.0239. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4971. T_Loss: 3.7848. Mask: 0.8952. :  81%|████████  | 81/100 [00:22<00:05,  3.62it/s]Train Iter: 382/5000. LR: 0.0239. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4971. T_Loss: 3.7848. Mask: 0.8952. :  82%|████████▏ | 82/100 [00:22<00:04,  4.30it/s]Train Iter: 383/5000. LR: 0.0239. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4946. T_Loss: 3.8044. Mask: 0.8957. :  82%|████████▏ | 82/100 [00:22<00:04,  4.30it/s]Train Iter: 383/5000. LR: 0.0239. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4946. T_Loss: 3.8044. Mask: 0.8957. :  83%|████████▎ | 83/100 [00:22<00:03,  5.00it/s]Train Iter: 384/5000. LR: 0.0240. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4923. T_Loss: 3.8121. Mask: 0.8947. :  83%|████████▎ | 83/100 [00:22<00:03,  5.00it/s]Train Iter: 384/5000. LR: 0.0240. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4923. T_Loss: 3.8121. Mask: 0.8947. :  84%|████████▍ | 84/100 [00:22<00:03,  4.84it/s]Train Iter: 385/5000. LR: 0.0241. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4896. T_Loss: 3.8214. Mask: 0.8941. :  84%|████████▍ | 84/100 [00:23<00:03,  4.84it/s]Train Iter: 385/5000. LR: 0.0241. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4896. T_Loss: 3.8214. Mask: 0.8941. :  85%|████████▌ | 85/100 [00:23<00:02,  5.33it/s]Train Iter: 386/5000. LR: 0.0241. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4867. T_Loss: 3.8140. Mask: 0.8921. :  85%|████████▌ | 85/100 [00:23<00:02,  5.33it/s]Train Iter: 386/5000. LR: 0.0241. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4867. T_Loss: 3.8140. Mask: 0.8921. :  86%|████████▌ | 86/100 [00:23<00:02,  5.90it/s]Train Iter: 387/5000. LR: 0.0242. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4846. T_Loss: 3.8265. Mask: 0.8912. :  86%|████████▌ | 86/100 [00:23<00:02,  5.90it/s]Train Iter: 387/5000. LR: 0.0242. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4846. T_Loss: 3.8265. Mask: 0.8912. :  87%|████████▋ | 87/100 [00:23<00:02,  6.49it/s]Train Iter: 388/5000. LR: 0.0243. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4816. T_Loss: 3.8389. Mask: 0.8913. :  87%|████████▋ | 87/100 [00:23<00:02,  6.49it/s]Train Iter: 388/5000. LR: 0.0243. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4816. T_Loss: 3.8389. Mask: 0.8913. :  88%|████████▊ | 88/100 [00:23<00:01,  6.93it/s]Train Iter: 389/5000. LR: 0.0243. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4783. T_Loss: 3.8408. Mask: 0.8897. :  88%|████████▊ | 88/100 [00:23<00:01,  6.93it/s]Train Iter: 389/5000. LR: 0.0243. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4783. T_Loss: 3.8408. Mask: 0.8897. :  89%|████████▉ | 89/100 [00:23<00:01,  7.38it/s]Train Iter: 390/5000. LR: 0.0244. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4758. T_Loss: 3.8435. Mask: 0.8896. :  89%|████████▉ | 89/100 [00:23<00:01,  7.38it/s]Train Iter: 390/5000. LR: 0.0244. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4758. T_Loss: 3.8435. Mask: 0.8896. :  90%|█████████ | 90/100 [00:23<00:01,  5.71it/s]Train Iter: 391/5000. LR: 0.0244. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4739. T_Loss: 3.8431. Mask: 0.8884. :  90%|█████████ | 90/100 [00:23<00:01,  5.71it/s]Train Iter: 391/5000. LR: 0.0244. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4739. T_Loss: 3.8431. Mask: 0.8884. :  91%|█████████ | 91/100 [00:23<00:01,  6.46it/s]Train Iter: 392/5000. LR: 0.0245. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4705. T_Loss: 3.8406. Mask: 0.8872. :  91%|█████████ | 91/100 [00:24<00:01,  6.46it/s]Train Iter: 392/5000. LR: 0.0245. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4705. T_Loss: 3.8406. Mask: 0.8872. :  92%|█████████▏| 92/100 [00:24<00:01,  6.96it/s]Train Iter: 393/5000. LR: 0.0246. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4668. T_Loss: 3.8442. Mask: 0.8871. :  92%|█████████▏| 92/100 [00:24<00:01,  6.96it/s]Train Iter: 393/5000. LR: 0.0246. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4668. T_Loss: 3.8442. Mask: 0.8871. :  93%|█████████▎| 93/100 [00:24<00:00,  7.61it/s]Train Iter: 394/5000. LR: 0.0246. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4632. T_Loss: 3.8511. Mask: 0.8876. :  93%|█████████▎| 93/100 [00:24<00:00,  7.61it/s]Train Iter: 394/5000. LR: 0.0246. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4632. T_Loss: 3.8511. Mask: 0.8876. :  94%|█████████▍| 94/100 [00:24<00:01,  5.47it/s]Train Iter: 395/5000. LR: 0.0247. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4601. T_Loss: 3.8501. Mask: 0.8872. :  94%|█████████▍| 94/100 [00:24<00:01,  5.47it/s]Train Iter: 396/5000. LR: 0.0248. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4563. T_Loss: 3.8561. Mask: 0.8877. :  95%|█████████▌| 95/100 [00:24<00:00,  5.47it/s]Train Iter: 396/5000. LR: 0.0248. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4563. T_Loss: 3.8561. Mask: 0.8877. :  96%|█████████▌| 96/100 [00:24<00:00,  7.38it/s]Train Iter: 397/5000. LR: 0.0248. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4523. T_Loss: 3.8600. Mask: 0.8879. :  96%|█████████▌| 96/100 [00:24<00:00,  7.38it/s]Train Iter: 397/5000. LR: 0.0248. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4523. T_Loss: 3.8600. Mask: 0.8879. :  97%|█████████▋| 97/100 [00:24<00:00,  7.16it/s]Train Iter: 398/5000. LR: 0.0249. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4473. T_Loss: 3.8619. Mask: 0.8890. :  97%|█████████▋| 97/100 [00:24<00:00,  7.16it/s]Train Iter: 398/5000. LR: 0.0249. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4473. T_Loss: 3.8619. Mask: 0.8890. :  98%|█████████▊| 98/100 [00:24<00:00,  7.24it/s]Train Iter: 399/5000. LR: 0.0249. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4434. T_Loss: 3.8616. Mask: 0.8892. :  98%|█████████▊| 98/100 [00:25<00:00,  7.24it/s]Train Iter: 399/5000. LR: 0.0249. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4434. T_Loss: 3.8616. Mask: 0.8892. :  99%|█████████▉| 99/100 [00:25<00:00,  7.26it/s]Train Iter: 400/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4380. T_Loss: 3.8588. Mask: 0.8897. :  99%|█████████▉| 99/100 [00:25<00:00,  7.26it/s]Train Iter: 400/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4380. T_Loss: 3.8588. Mask: 0.8897. : 100%|██████████| 100/100 [00:25<00:00,  6.69it/s]Train Iter: 400/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4380. T_Loss: 3.8588. Mask: 0.8897. : 100%|██████████| 100/100 [00:25<00:00,  3.96it/s]
total : 5000  current step :  376
total : 5000  current step :  377
total : 5000  current step :  378
total : 5000  current step :  379
total : 5000  current step :  380
total : 5000  current step :  381
total : 5000  current step :  382
total : 5000  current step :  383
total : 5000  current step :  384
total : 5000  current step :  385
total : 5000  current step :  386
total : 5000  current step :  387
total : 5000  current step :  388
total : 5000  current step :  389
total : 5000  current step :  390
total : 5000  current step :  391
total : 5000  current step :  392
total : 5000  current step :  393
total : 5000  current step :  394
total : 5000  current step :  395
total : 5000  current step :  396
total : 5000  current step :  397
total : 5000  current step :  398
total : 5000  current step :  399
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.5106. top1: 78.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.5106. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 1.5077. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 1.4647. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.4847. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 1.4707. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 1.4780. top1: 85.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.4739. top1: 86.16. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.4730. top1: 86.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.4559. top1: 87.15. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.4559. top1: 87.15. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.4578. top1: 87.19. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.4496. top1: 87.78. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.4503. top1: 87.24. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.4455. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4514. top1: 87.28. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4460. top1: 87.92. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4396. top1: 88.09. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.79it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4396. top1: 88.09. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4406. top1: 87.87. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4391. top1: 88.54. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4364. top1: 88.32. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4394. top1: 87.66. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4415. top1: 88.10. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4413. top1: 87.78. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4401. top1: 88.04. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4375. top1: 88.15. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4362. top1: 88.00. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.95it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4362. top1: 88.00. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 22.38it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4379. top1: 87.74. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4365. top1: 88.08. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4380. top1: 87.83. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4389. top1: 87.72. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4370. top1: 87.60. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4370. top1: 87.50. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4431. top1: 86.33. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4509. top1: 85.32. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4579. top1: 84.01. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 22.38it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4579. top1: 84.01. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4646. top1: 82.77. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4715. top1: 81.08. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4771. top1: 79.90. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4823. top1: 78.87. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4883. top1: 77.72. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4938. top1: 77.11. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4986. top1: 76.60. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5039. top1: 75.74. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.38it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5039. top1: 75.74. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5080. top1: 74.93. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5119. top1: 74.29. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5159. top1: 73.40. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5200. top1: 72.62. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5237. top1: 71.94. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5268. top1: 71.29. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5299. top1: 70.47. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5333. top1: 69.94. top5: 100.00. :  67%|██████▋   | 42/63 [00:02<00:00, 40.71it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5333. top1: 69.94. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.5367. top1: 69.24. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5398. top1: 68.51. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5435. top1: 68.16. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5463. top1: 67.48. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5492. top1: 67.10. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5521. top1: 66.69. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5547. top1: 65.95. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5570. top1: 65.52. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5592. top1: 64.94. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5613. top1: 64.84. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 48.44it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5613. top1: 64.84. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 58.51it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5636. top1: 64.40. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 58.51it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5661. top1: 63.76. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 58.51it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5669. top1: 63.50. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 58.51it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.5669. top1: 63.50. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 23.61it/s]
total : 5000  current step :  400
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 401/5000. LR: 0.0251. Data: 2.11s. Batch: 2.24s. S_Loss: 0.8499. T_Loss: 3.5289. Mask: 1.0000. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 401/5000. LR: 0.0251. Data: 2.11s. Batch: 2.24s. S_Loss: 0.8499. T_Loss: 3.5289. Mask: 1.0000. :   1%|          | 1/100 [00:02<03:42,  2.25s/it]Train Iter: 402/5000. LR: 0.0251. Data: 1.06s. Batch: 1.19s. S_Loss: 0.8366. T_Loss: 3.3861. Mask: 1.0000. :   1%|          | 1/100 [00:02<03:42,  2.25s/it]Train Iter: 402/5000. LR: 0.0251. Data: 1.06s. Batch: 1.19s. S_Loss: 0.8366. T_Loss: 3.3861. Mask: 1.0000. :   2%|▏         | 2/100 [00:02<01:38,  1.00s/it]Train Iter: 403/5000. LR: 0.0252. Data: 0.71s. Batch: 0.83s. S_Loss: 0.8294. T_Loss: 3.3317. Mask: 0.9896. :   2%|▏         | 2/100 [00:02<01:38,  1.00s/it]Train Iter: 403/5000. LR: 0.0252. Data: 0.71s. Batch: 0.83s. S_Loss: 0.8294. T_Loss: 3.3317. Mask: 0.9896. :   3%|▎         | 3/100 [00:02<00:58,  1.66it/s]Train Iter: 404/5000. LR: 0.0253. Data: 0.53s. Batch: 0.71s. S_Loss: 0.8195. T_Loss: 3.4791. Mask: 0.9922. :   3%|▎         | 3/100 [00:02<00:58,  1.66it/s]Train Iter: 404/5000. LR: 0.0253. Data: 0.53s. Batch: 0.71s. S_Loss: 0.8195. T_Loss: 3.4791. Mask: 0.9922. :   4%|▍         | 4/100 [00:02<00:48,  1.97it/s]Train Iter: 405/5000. LR: 0.0253. Data: 0.43s. Batch: 0.60s. S_Loss: 0.8092. T_Loss: 3.6117. Mask: 0.9875. :   4%|▍         | 4/100 [00:03<00:48,  1.97it/s]Train Iter: 405/5000. LR: 0.0253. Data: 0.43s. Batch: 0.60s. S_Loss: 0.8092. T_Loss: 3.6117. Mask: 0.9875. :   5%|▌         | 5/100 [00:03<00:35,  2.66it/s]Train Iter: 406/5000. LR: 0.0254. Data: 0.36s. Batch: 0.52s. S_Loss: 0.8084. T_Loss: 3.7887. Mask: 0.9688. :   5%|▌         | 5/100 [00:03<00:35,  2.66it/s]Train Iter: 406/5000. LR: 0.0254. Data: 0.36s. Batch: 0.52s. S_Loss: 0.8084. T_Loss: 3.7887. Mask: 0.9688. :   6%|▌         | 6/100 [00:03<00:27,  3.39it/s]Train Iter: 407/5000. LR: 0.0254. Data: 0.31s. Batch: 0.47s. S_Loss: 0.8575. T_Loss: 4.0246. Mask: 0.9554. :   6%|▌         | 6/100 [00:03<00:27,  3.39it/s]Train Iter: 407/5000. LR: 0.0254. Data: 0.31s. Batch: 0.47s. S_Loss: 0.8575. T_Loss: 4.0246. Mask: 0.9554. :   7%|▋         | 7/100 [00:03<00:22,  4.15it/s]Train Iter: 408/5000. LR: 0.0255. Data: 0.27s. Batch: 0.42s. S_Loss: 0.9711. T_Loss: 4.1752. Mask: 0.9297. :   7%|▋         | 7/100 [00:03<00:22,  4.15it/s]Train Iter: 409/5000. LR: 0.0256. Data: 0.24s. Batch: 0.39s. S_Loss: 1.1196. T_Loss: 4.1638. Mask: 0.8993. :   8%|▊         | 8/100 [00:03<00:22,  4.15it/s]Train Iter: 409/5000. LR: 0.0256. Data: 0.24s. Batch: 0.39s. S_Loss: 1.1196. T_Loss: 4.1638. Mask: 0.8993. :   9%|▉         | 9/100 [00:03<00:16,  5.66it/s]Train Iter: 410/5000. LR: 0.0256. Data: 0.22s. Batch: 0.39s. S_Loss: 1.2281. T_Loss: 4.1790. Mask: 0.8938. :   9%|▉         | 9/100 [00:03<00:16,  5.66it/s]Train Iter: 410/5000. LR: 0.0256. Data: 0.22s. Batch: 0.39s. S_Loss: 1.2281. T_Loss: 4.1790. Mask: 0.8938. :  10%|█         | 10/100 [00:03<00:20,  4.33it/s]Train Iter: 411/5000. LR: 0.0257. Data: 0.20s. Batch: 0.36s. S_Loss: 1.3050. T_Loss: 4.1586. Mask: 0.8892. :  10%|█         | 10/100 [00:04<00:20,  4.33it/s]Train Iter: 411/5000. LR: 0.0257. Data: 0.20s. Batch: 0.36s. S_Loss: 1.3050. T_Loss: 4.1586. Mask: 0.8892. :  11%|█         | 11/100 [00:04<00:18,  4.84it/s]Train Iter: 412/5000. LR: 0.0258. Data: 0.18s. Batch: 0.34s. S_Loss: 1.3441. T_Loss: 4.1874. Mask: 0.8932. :  11%|█         | 11/100 [00:04<00:18,  4.84it/s]Train Iter: 412/5000. LR: 0.0258. Data: 0.18s. Batch: 0.34s. S_Loss: 1.3441. T_Loss: 4.1874. Mask: 0.8932. :  12%|█▏        | 12/100 [00:04<00:16,  5.41it/s]Train Iter: 413/5000. LR: 0.0258. Data: 0.17s. Batch: 0.33s. S_Loss: 1.3609. T_Loss: 4.1162. Mask: 0.8942. :  12%|█▏        | 12/100 [00:04<00:16,  5.41it/s]Train Iter: 413/5000. LR: 0.0258. Data: 0.17s. Batch: 0.33s. S_Loss: 1.3609. T_Loss: 4.1162. Mask: 0.8942. :  13%|█▎        | 13/100 [00:04<00:14,  5.85it/s]Train Iter: 414/5000. LR: 0.0259. Data: 0.16s. Batch: 0.33s. S_Loss: 1.3634. T_Loss: 4.1242. Mask: 0.8973. :  13%|█▎        | 13/100 [00:04<00:14,  5.85it/s]Train Iter: 414/5000. LR: 0.0259. Data: 0.16s. Batch: 0.33s. S_Loss: 1.3634. T_Loss: 4.1242. Mask: 0.8973. :  14%|█▍        | 14/100 [00:04<00:19,  4.51it/s]Train Iter: 415/5000. LR: 0.0259. Data: 0.15s. Batch: 0.32s. S_Loss: 1.3565. T_Loss: 4.1883. Mask: 0.9021. :  14%|█▍        | 14/100 [00:04<00:19,  4.51it/s]Train Iter: 415/5000. LR: 0.0259. Data: 0.15s. Batch: 0.32s. S_Loss: 1.3565. T_Loss: 4.1883. Mask: 0.9021. :  15%|█▌        | 15/100 [00:04<00:17,  4.98it/s]Train Iter: 416/5000. LR: 0.0260. Data: 0.14s. Batch: 0.30s. S_Loss: 1.3543. T_Loss: 4.2396. Mask: 0.9023. :  15%|█▌        | 15/100 [00:04<00:17,  4.98it/s]Train Iter: 416/5000. LR: 0.0260. Data: 0.14s. Batch: 0.30s. S_Loss: 1.3543. T_Loss: 4.2396. Mask: 0.9023. :  16%|█▌        | 16/100 [00:04<00:14,  5.64it/s]Train Iter: 417/5000. LR: 0.0261. Data: 0.13s. Batch: 0.29s. S_Loss: 1.3598. T_Loss: 4.2757. Mask: 0.9026. :  16%|█▌        | 16/100 [00:05<00:14,  5.64it/s]Train Iter: 417/5000. LR: 0.0261. Data: 0.13s. Batch: 0.29s. S_Loss: 1.3598. T_Loss: 4.2757. Mask: 0.9026. :  17%|█▋        | 17/100 [00:05<00:13,  6.22it/s]Train Iter: 418/5000. LR: 0.0261. Data: 0.12s. Batch: 0.29s. S_Loss: 1.3658. T_Loss: 4.2979. Mask: 0.9062. :  17%|█▋        | 17/100 [00:05<00:13,  6.22it/s]Train Iter: 418/5000. LR: 0.0261. Data: 0.12s. Batch: 0.29s. S_Loss: 1.3658. T_Loss: 4.2979. Mask: 0.9062. :  18%|█▊        | 18/100 [00:05<00:12,  6.42it/s]Train Iter: 419/5000. LR: 0.0262. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3804. T_Loss: 4.2572. Mask: 0.8997. :  18%|█▊        | 18/100 [00:05<00:12,  6.42it/s]Train Iter: 419/5000. LR: 0.0262. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3804. T_Loss: 4.2572. Mask: 0.8997. :  19%|█▉        | 19/100 [00:05<00:12,  6.58it/s]Train Iter: 420/5000. LR: 0.0263. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4074. T_Loss: 4.2294. Mask: 0.9031. :  19%|█▉        | 19/100 [00:05<00:12,  6.58it/s]Train Iter: 420/5000. LR: 0.0263. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4074. T_Loss: 4.2294. Mask: 0.9031. :  20%|██        | 20/100 [00:05<00:11,  6.86it/s]Train Iter: 421/5000. LR: 0.0263. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4313. T_Loss: 4.1635. Mask: 0.9062. :  20%|██        | 20/100 [00:05<00:11,  6.86it/s]Train Iter: 421/5000. LR: 0.0263. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4313. T_Loss: 4.1635. Mask: 0.9062. :  21%|██        | 21/100 [00:05<00:11,  7.05it/s]Train Iter: 422/5000. LR: 0.0264. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4442. T_Loss: 4.0812. Mask: 0.9091. :  21%|██        | 21/100 [00:05<00:11,  7.05it/s]Train Iter: 422/5000. LR: 0.0264. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4442. T_Loss: 4.0812. Mask: 0.9091. :  22%|██▏       | 22/100 [00:05<00:10,  7.27it/s]Train Iter: 423/5000. LR: 0.0264. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4498. T_Loss: 4.0428. Mask: 0.9130. :  22%|██▏       | 22/100 [00:05<00:10,  7.27it/s]Train Iter: 423/5000. LR: 0.0264. Data: 0.10s. Batch: 0.25s. S_Loss: 1.4498. T_Loss: 4.0428. Mask: 0.9130. :  23%|██▎       | 23/100 [00:05<00:10,  7.48it/s]Train Iter: 424/5000. LR: 0.0265. Data: 0.09s. Batch: 0.25s. S_Loss: 1.4484. T_Loss: 4.0120. Mask: 0.9167. :  23%|██▎       | 23/100 [00:06<00:10,  7.48it/s]Train Iter: 424/5000. LR: 0.0265. Data: 0.09s. Batch: 0.25s. S_Loss: 1.4484. T_Loss: 4.0120. Mask: 0.9167. :  24%|██▍       | 24/100 [00:06<00:14,  5.37it/s]Train Iter: 425/5000. LR: 0.0266. Data: 0.09s. Batch: 0.25s. S_Loss: 1.4363. T_Loss: 4.0079. Mask: 0.9200. :  24%|██▍       | 24/100 [00:06<00:14,  5.37it/s]total : 5000  current step :  401
total : 5000  current step :  402
total : 5000  current step :  403
total : 5000  current step :  404
total : 5000  current step :  405
total : 5000  current step :  406
total : 5000  current step :  407
total : 5000  current step :  408
total : 5000  current step :  409
total : 5000  current step :  410
total : 5000  current step :  411
total : 5000  current step :  412
total : 5000  current step :  413
total : 5000  current step :  414
total : 5000  current step :  415
total : 5000  current step :  416
total : 5000  current step :  417
total : 5000  current step :  418
total : 5000  current step :  419
total : 5000  current step :  420
total : 5000  current step :  421
total : 5000  current step :  422
total : 5000  current step :  423
total : 5000  current step :  424
total : 5000  current step :  425
Train Iter: 426/5000. LR: 0.0266. Data: 0.16s. Batch: 0.32s. S_Loss: 1.4249. T_Loss: 3.9947. Mask: 0.9219. :  25%|██▌       | 25/100 [00:08<00:13,  5.37it/s]Train Iter: 426/5000. LR: 0.0266. Data: 0.16s. Batch: 0.32s. S_Loss: 1.4249. T_Loss: 3.9947. Mask: 0.9219. :  26%|██▌       | 26/100 [00:08<00:46,  1.60it/s]Train Iter: 427/5000. LR: 0.0267. Data: 0.16s. Batch: 0.32s. S_Loss: 1.4151. T_Loss: 4.0042. Mask: 0.9236. :  26%|██▌       | 26/100 [00:08<00:46,  1.60it/s]Train Iter: 427/5000. LR: 0.0267. Data: 0.16s. Batch: 0.32s. S_Loss: 1.4151. T_Loss: 4.0042. Mask: 0.9236. :  27%|██▋       | 27/100 [00:08<00:37,  1.97it/s]Train Iter: 428/5000. LR: 0.0268. Data: 0.15s. Batch: 0.31s. S_Loss: 1.4107. T_Loss: 4.0531. Mask: 0.9230. :  27%|██▋       | 27/100 [00:08<00:37,  1.97it/s]Train Iter: 428/5000. LR: 0.0268. Data: 0.15s. Batch: 0.31s. S_Loss: 1.4107. T_Loss: 4.0531. Mask: 0.9230. :  28%|██▊       | 28/100 [00:08<00:29,  2.43it/s]Train Iter: 429/5000. LR: 0.0268. Data: 0.15s. Batch: 0.30s. S_Loss: 1.4147. T_Loss: 4.1264. Mask: 0.9213. :  28%|██▊       | 28/100 [00:08<00:29,  2.43it/s]Train Iter: 429/5000. LR: 0.0268. Data: 0.15s. Batch: 0.30s. S_Loss: 1.4147. T_Loss: 4.1264. Mask: 0.9213. :  29%|██▉       | 29/100 [00:08<00:23,  3.00it/s]Train Iter: 430/5000. LR: 0.0269. Data: 0.14s. Batch: 0.30s. S_Loss: 1.4186. T_Loss: 4.1446. Mask: 0.9229. :  29%|██▉       | 29/100 [00:08<00:23,  3.00it/s]Train Iter: 430/5000. LR: 0.0269. Data: 0.14s. Batch: 0.30s. S_Loss: 1.4186. T_Loss: 4.1446. Mask: 0.9229. :  30%|███       | 30/100 [00:08<00:19,  3.66it/s]Train Iter: 431/5000. LR: 0.0269. Data: 0.14s. Batch: 0.29s. S_Loss: 1.4246. T_Loss: 4.1390. Mask: 0.9214. :  30%|███       | 30/100 [00:09<00:19,  3.66it/s]Train Iter: 431/5000. LR: 0.0269. Data: 0.14s. Batch: 0.29s. S_Loss: 1.4246. T_Loss: 4.1390. Mask: 0.9214. :  31%|███       | 31/100 [00:09<00:16,  4.19it/s]Train Iter: 432/5000. LR: 0.0270. Data: 0.13s. Batch: 0.29s. S_Loss: 1.4308. T_Loss: 4.1254. Mask: 0.9199. :  31%|███       | 31/100 [00:09<00:16,  4.19it/s]Train Iter: 432/5000. LR: 0.0270. Data: 0.13s. Batch: 0.29s. S_Loss: 1.4308. T_Loss: 4.1254. Mask: 0.9199. :  32%|███▏      | 32/100 [00:09<00:13,  4.89it/s]Train Iter: 433/5000. LR: 0.0271. Data: 0.13s. Batch: 0.28s. S_Loss: 1.4310. T_Loss: 4.1678. Mask: 0.9214. :  32%|███▏      | 32/100 [00:09<00:13,  4.89it/s]Train Iter: 433/5000. LR: 0.0271. Data: 0.13s. Batch: 0.28s. S_Loss: 1.4310. T_Loss: 4.1678. Mask: 0.9214. :  33%|███▎      | 33/100 [00:09<00:12,  5.56it/s]Train Iter: 434/5000. LR: 0.0271. Data: 0.13s. Batch: 0.29s. S_Loss: 1.4313. T_Loss: 4.1820. Mask: 0.9219. :  33%|███▎      | 33/100 [00:09<00:12,  5.56it/s]Train Iter: 434/5000. LR: 0.0271. Data: 0.13s. Batch: 0.29s. S_Loss: 1.4313. T_Loss: 4.1820. Mask: 0.9219. :  34%|███▍      | 34/100 [00:09<00:16,  3.94it/s]Train Iter: 435/5000. LR: 0.0272. Data: 0.12s. Batch: 0.28s. S_Loss: 1.4303. T_Loss: 4.1809. Mask: 0.9223. :  34%|███▍      | 34/100 [00:09<00:16,  3.94it/s]Train Iter: 435/5000. LR: 0.0272. Data: 0.12s. Batch: 0.28s. S_Loss: 1.4303. T_Loss: 4.1809. Mask: 0.9223. :  35%|███▌      | 35/100 [00:09<00:14,  4.62it/s]Train Iter: 436/5000. LR: 0.0273. Data: 0.12s. Batch: 0.28s. S_Loss: 1.4254. T_Loss: 4.2013. Mask: 0.9219. :  35%|███▌      | 35/100 [00:10<00:14,  4.62it/s]Train Iter: 436/5000. LR: 0.0273. Data: 0.12s. Batch: 0.28s. S_Loss: 1.4254. T_Loss: 4.2013. Mask: 0.9219. :  36%|███▌      | 36/100 [00:10<00:12,  5.22it/s]Train Iter: 437/5000. LR: 0.0273. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4202. T_Loss: 4.2414. Mask: 0.9206. :  36%|███▌      | 36/100 [00:10<00:12,  5.22it/s]Train Iter: 437/5000. LR: 0.0273. Data: 0.12s. Batch: 0.27s. S_Loss: 1.4202. T_Loss: 4.2414. Mask: 0.9206. :  37%|███▋      | 37/100 [00:10<00:10,  5.84it/s]Train Iter: 438/5000. LR: 0.0274. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4158. T_Loss: 4.2633. Mask: 0.9194. :  37%|███▋      | 37/100 [00:10<00:10,  5.84it/s]Train Iter: 438/5000. LR: 0.0274. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4158. T_Loss: 4.2633. Mask: 0.9194. :  38%|███▊      | 38/100 [00:10<00:09,  6.28it/s]Train Iter: 439/5000. LR: 0.0274. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4142. T_Loss: 4.2982. Mask: 0.9199. :  38%|███▊      | 38/100 [00:10<00:09,  6.28it/s]Train Iter: 439/5000. LR: 0.0274. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4142. T_Loss: 4.2982. Mask: 0.9199. :  39%|███▉      | 39/100 [00:10<00:09,  6.72it/s]Train Iter: 440/5000. LR: 0.0275. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4125. T_Loss: 4.2969. Mask: 0.9172. :  39%|███▉      | 39/100 [00:10<00:09,  6.72it/s]Train Iter: 440/5000. LR: 0.0275. Data: 0.11s. Batch: 0.27s. S_Loss: 1.4125. T_Loss: 4.2969. Mask: 0.9172. :  40%|████      | 40/100 [00:10<00:13,  4.61it/s]Train Iter: 441/5000. LR: 0.0276. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4108. T_Loss: 4.3081. Mask: 0.9162. :  40%|████      | 40/100 [00:10<00:13,  4.61it/s]Train Iter: 441/5000. LR: 0.0276. Data: 0.11s. Batch: 0.26s. S_Loss: 1.4108. T_Loss: 4.3081. Mask: 0.9162. :  41%|████      | 41/100 [00:10<00:11,  5.15it/s]Train Iter: 442/5000. LR: 0.0276. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4103. T_Loss: 4.3060. Mask: 0.9152. :  41%|████      | 41/100 [00:11<00:11,  5.15it/s]Train Iter: 442/5000. LR: 0.0276. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4103. T_Loss: 4.3060. Mask: 0.9152. :  42%|████▏     | 42/100 [00:11<00:09,  5.81it/s]Train Iter: 443/5000. LR: 0.0277. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4079. T_Loss: 4.2857. Mask: 0.9157. :  42%|████▏     | 42/100 [00:11<00:09,  5.81it/s]Train Iter: 443/5000. LR: 0.0277. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4079. T_Loss: 4.2857. Mask: 0.9157. :  43%|████▎     | 43/100 [00:11<00:08,  6.36it/s]Train Iter: 444/5000. LR: 0.0278. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4047. T_Loss: 4.2648. Mask: 0.9169. :  43%|████▎     | 43/100 [00:11<00:08,  6.36it/s]Train Iter: 444/5000. LR: 0.0278. Data: 0.10s. Batch: 0.26s. S_Loss: 1.4047. T_Loss: 4.2648. Mask: 0.9169. :  44%|████▍     | 44/100 [00:11<00:12,  4.56it/s]Train Iter: 445/5000. LR: 0.0278. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3987. T_Loss: 4.2451. Mask: 0.9181. :  44%|████▍     | 44/100 [00:11<00:12,  4.56it/s]Train Iter: 445/5000. LR: 0.0278. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3987. T_Loss: 4.2451. Mask: 0.9181. :  45%|████▌     | 45/100 [00:11<00:10,  5.25it/s]Train Iter: 446/5000. LR: 0.0279. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3917. T_Loss: 4.2300. Mask: 0.9198. :  45%|████▌     | 45/100 [00:11<00:10,  5.25it/s]Train Iter: 446/5000. LR: 0.0279. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3917. T_Loss: 4.2300. Mask: 0.9198. :  46%|████▌     | 46/100 [00:11<00:09,  5.90it/s]Train Iter: 447/5000. LR: 0.0279. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3829. T_Loss: 4.2191. Mask: 0.9215. :  46%|████▌     | 46/100 [00:11<00:09,  5.90it/s]Train Iter: 447/5000. LR: 0.0279. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3829. T_Loss: 4.2191. Mask: 0.9215. :  47%|████▋     | 47/100 [00:11<00:08,  6.44it/s]Train Iter: 448/5000. LR: 0.0280. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3739. T_Loss: 4.2070. Mask: 0.9219. :  47%|████▋     | 47/100 [00:12<00:08,  6.44it/s]Train Iter: 448/5000. LR: 0.0280. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3739. T_Loss: 4.2070. Mask: 0.9219. :  48%|████▊     | 48/100 [00:12<00:07,  6.86it/s]Train Iter: 449/5000. LR: 0.0281. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3632. T_Loss: 4.2078. Mask: 0.9222. :  48%|████▊     | 48/100 [00:12<00:07,  6.86it/s]Train Iter: 449/5000. LR: 0.0281. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3632. T_Loss: 4.2078. Mask: 0.9222. :  49%|████▉     | 49/100 [00:12<00:07,  7.21it/s]Train Iter: 450/5000. LR: 0.0281. Data: 0.09s. Batch: 0.24s. S_Loss: 1.3560. T_Loss: 4.2020. Mask: 0.9219. :  49%|████▉     | 49/100 [00:12<00:07,  7.21it/s]Train Iter: 450/5000. LR: 0.0281. Data: 0.09s. Batch: 0.24s. S_Loss: 1.3560. T_Loss: 4.2020. Mask: 0.9219. :  50%|█████     | 50/100 [00:12<00:06,  7.34it/s]total : 5000  current step :  426
total : 5000  current step :  427
total : 5000  current step :  428
total : 5000  current step :  429
total : 5000  current step :  430
total : 5000  current step :  431
total : 5000  current step :  432
total : 5000  current step :  433
total : 5000  current step :  434
total : 5000  current step :  435
total : 5000  current step :  436
total : 5000  current step :  437
total : 5000  current step :  438
total : 5000  current step :  439
total : 5000  current step :  440
total : 5000  current step :  441
total : 5000  current step :  442
total : 5000  current step :  443
total : 5000  current step :  444
total : 5000  current step :  445
total : 5000  current step :  446
total : 5000  current step :  447
total : 5000  current step :  448
total : 5000  current step :  449
total : 5000  current step :  450
Train Iter: 451/5000. LR: 0.0282. Data: 0.13s. Batch: 0.28s. S_Loss: 1.3501. T_Loss: 4.2183. Mask: 0.9222. :  50%|█████     | 50/100 [00:14<00:06,  7.34it/s]Train Iter: 451/5000. LR: 0.0282. Data: 0.13s. Batch: 0.28s. S_Loss: 1.3501. T_Loss: 4.2183. Mask: 0.9222. :  51%|█████     | 51/100 [00:14<00:35,  1.37it/s]Train Iter: 452/5000. LR: 0.0282. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3485. T_Loss: 4.2387. Mask: 0.9219. :  51%|█████     | 51/100 [00:14<00:35,  1.37it/s]Train Iter: 452/5000. LR: 0.0282. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3485. T_Loss: 4.2387. Mask: 0.9219. :  52%|█████▏    | 52/100 [00:14<00:26,  1.81it/s]Train Iter: 453/5000. LR: 0.0283. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3487. T_Loss: 4.2577. Mask: 0.9216. :  52%|█████▏    | 52/100 [00:14<00:26,  1.81it/s]Train Iter: 453/5000. LR: 0.0283. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3487. T_Loss: 4.2577. Mask: 0.9216. :  53%|█████▎    | 53/100 [00:14<00:20,  2.30it/s]Train Iter: 454/5000. LR: 0.0284. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3529. T_Loss: 4.2630. Mask: 0.9190. :  53%|█████▎    | 53/100 [00:15<00:20,  2.30it/s]Train Iter: 454/5000. LR: 0.0284. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3529. T_Loss: 4.2630. Mask: 0.9190. :  54%|█████▍    | 54/100 [00:15<00:19,  2.41it/s]Train Iter: 455/5000. LR: 0.0284. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3593. T_Loss: 4.2760. Mask: 0.9170. :  54%|█████▍    | 54/100 [00:15<00:19,  2.41it/s]Train Iter: 455/5000. LR: 0.0284. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3593. T_Loss: 4.2760. Mask: 0.9170. :  55%|█████▌    | 55/100 [00:15<00:15,  2.96it/s]Train Iter: 456/5000. LR: 0.0285. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3685. T_Loss: 4.2959. Mask: 0.9146. :  55%|█████▌    | 55/100 [00:15<00:15,  2.96it/s]Train Iter: 456/5000. LR: 0.0285. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3685. T_Loss: 4.2959. Mask: 0.9146. :  56%|█████▌    | 56/100 [00:15<00:12,  3.65it/s]Train Iter: 457/5000. LR: 0.0286. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3727. T_Loss: 4.3089. Mask: 0.9128. :  56%|█████▌    | 56/100 [00:15<00:12,  3.65it/s]Train Iter: 457/5000. LR: 0.0286. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3727. T_Loss: 4.3089. Mask: 0.9128. :  57%|█████▋    | 57/100 [00:15<00:09,  4.34it/s]Train Iter: 458/5000. LR: 0.0286. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3737. T_Loss: 4.3084. Mask: 0.9116. :  57%|█████▋    | 57/100 [00:15<00:09,  4.34it/s]Train Iter: 458/5000. LR: 0.0286. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3737. T_Loss: 4.3084. Mask: 0.9116. :  58%|█████▊    | 58/100 [00:15<00:08,  4.98it/s]Train Iter: 459/5000. LR: 0.0287. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3733. T_Loss: 4.3158. Mask: 0.9110. :  58%|█████▊    | 58/100 [00:15<00:08,  4.98it/s]Train Iter: 459/5000. LR: 0.0287. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3733. T_Loss: 4.3158. Mask: 0.9110. :  59%|█████▉    | 59/100 [00:15<00:07,  5.60it/s]Train Iter: 460/5000. LR: 0.0287. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3743. T_Loss: 4.3320. Mask: 0.9104. :  59%|█████▉    | 59/100 [00:16<00:07,  5.60it/s]Train Iter: 460/5000. LR: 0.0287. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3743. T_Loss: 4.3320. Mask: 0.9104. :  60%|██████    | 60/100 [00:16<00:09,  4.07it/s]Train Iter: 461/5000. LR: 0.0288. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3724. T_Loss: 4.3206. Mask: 0.9083. :  60%|██████    | 60/100 [00:16<00:09,  4.07it/s]Train Iter: 461/5000. LR: 0.0288. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3724. T_Loss: 4.3206. Mask: 0.9083. :  61%|██████    | 61/100 [00:16<00:08,  4.79it/s]Train Iter: 462/5000. LR: 0.0289. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3706. T_Loss: 4.3332. Mask: 0.9083. :  61%|██████    | 61/100 [00:16<00:08,  4.79it/s]Train Iter: 462/5000. LR: 0.0289. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3706. T_Loss: 4.3332. Mask: 0.9083. :  62%|██████▏   | 62/100 [00:16<00:07,  5.42it/s]Train Iter: 463/5000. LR: 0.0289. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3692. T_Loss: 4.3439. Mask: 0.9082. :  62%|██████▏   | 62/100 [00:16<00:07,  5.42it/s]Train Iter: 463/5000. LR: 0.0289. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3692. T_Loss: 4.3439. Mask: 0.9082. :  63%|██████▎   | 63/100 [00:16<00:06,  6.01it/s]Train Iter: 464/5000. LR: 0.0290. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3687. T_Loss: 4.3593. Mask: 0.9092. :  63%|██████▎   | 63/100 [00:16<00:06,  6.01it/s]Train Iter: 464/5000. LR: 0.0290. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3687. T_Loss: 4.3593. Mask: 0.9092. :  64%|██████▍   | 64/100 [00:16<00:07,  4.68it/s]Train Iter: 465/5000. LR: 0.0291. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3678. T_Loss: 4.3569. Mask: 0.9091. :  64%|██████▍   | 64/100 [00:16<00:07,  4.68it/s]Train Iter: 465/5000. LR: 0.0291. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3678. T_Loss: 4.3569. Mask: 0.9091. :  65%|██████▌   | 65/100 [00:16<00:06,  5.26it/s]Train Iter: 466/5000. LR: 0.0291. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3657. T_Loss: 4.3811. Mask: 0.9086. :  65%|██████▌   | 65/100 [00:17<00:06,  5.26it/s]Train Iter: 466/5000. LR: 0.0291. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3657. T_Loss: 4.3811. Mask: 0.9086. :  66%|██████▌   | 66/100 [00:17<00:05,  5.91it/s]Train Iter: 467/5000. LR: 0.0292. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3650. T_Loss: 4.3936. Mask: 0.9086. :  66%|██████▌   | 66/100 [00:17<00:05,  5.91it/s]Train Iter: 467/5000. LR: 0.0292. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3650. T_Loss: 4.3936. Mask: 0.9086. :  67%|██████▋   | 67/100 [00:17<00:05,  6.44it/s]Train Iter: 468/5000. LR: 0.0292. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3630. T_Loss: 4.4003. Mask: 0.9076. :  67%|██████▋   | 67/100 [00:17<00:05,  6.44it/s]Train Iter: 468/5000. LR: 0.0292. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3630. T_Loss: 4.4003. Mask: 0.9076. :  68%|██████▊   | 68/100 [00:17<00:04,  6.90it/s]Train Iter: 469/5000. LR: 0.0293. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3608. T_Loss: 4.3999. Mask: 0.9062. :  68%|██████▊   | 68/100 [00:17<00:04,  6.90it/s]Train Iter: 469/5000. LR: 0.0293. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3608. T_Loss: 4.3999. Mask: 0.9062. :  69%|██████▉   | 69/100 [00:17<00:04,  7.18it/s]Train Iter: 470/5000. LR: 0.0294. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3576. T_Loss: 4.4072. Mask: 0.9062. :  69%|██████▉   | 69/100 [00:17<00:04,  7.18it/s]Train Iter: 470/5000. LR: 0.0294. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3576. T_Loss: 4.4072. Mask: 0.9062. :  70%|███████   | 70/100 [00:17<00:04,  7.48it/s]Train Iter: 471/5000. LR: 0.0294. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3546. T_Loss: 4.3958. Mask: 0.9040. :  70%|███████   | 70/100 [00:17<00:04,  7.48it/s]Train Iter: 471/5000. LR: 0.0294. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3546. T_Loss: 4.3958. Mask: 0.9040. :  71%|███████   | 71/100 [00:17<00:03,  7.76it/s]Train Iter: 472/5000. LR: 0.0295. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3512. T_Loss: 4.3853. Mask: 0.9028. :  71%|███████   | 71/100 [00:17<00:03,  7.76it/s]Train Iter: 472/5000. LR: 0.0295. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3512. T_Loss: 4.3853. Mask: 0.9028. :  72%|███████▏  | 72/100 [00:17<00:03,  7.89it/s]Train Iter: 473/5000. LR: 0.0296. Data: 0.09s. Batch: 0.24s. S_Loss: 1.3474. T_Loss: 4.3876. Mask: 0.9028. :  72%|███████▏  | 72/100 [00:17<00:03,  7.89it/s]Train Iter: 473/5000. LR: 0.0296. Data: 0.09s. Batch: 0.24s. S_Loss: 1.3474. T_Loss: 4.3876. Mask: 0.9028. :  73%|███████▎  | 73/100 [00:17<00:03,  7.93it/s]Train Iter: 474/5000. LR: 0.0296. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3436. T_Loss: 4.3777. Mask: 0.9024. :  73%|███████▎  | 73/100 [00:18<00:03,  7.93it/s]Train Iter: 474/5000. LR: 0.0296. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3436. T_Loss: 4.3777. Mask: 0.9024. :  74%|███████▍  | 74/100 [00:18<00:05,  4.91it/s]Train Iter: 475/5000. LR: 0.0297. Data: 0.09s. Batch: 0.24s. S_Loss: 1.3387. T_Loss: 4.3663. Mask: 0.9021. :  74%|███████▍  | 74/100 [00:18<00:05,  4.91it/s]Train Iter: 475/5000. LR: 0.0297. Data: 0.09s. Batch: 0.24s. S_Loss: 1.3387. T_Loss: 4.3663. Mask: 0.9021. :  75%|███████▌  | 75/100 [00:18<00:04,  5.66it/s]total : 5000  current step :  451
total : 5000  current step :  452
total : 5000  current step :  453
total : 5000  current step :  454
total : 5000  current step :  455
total : 5000  current step :  456
total : 5000  current step :  457
total : 5000  current step :  458
total : 5000  current step :  459
total : 5000  current step :  460
total : 5000  current step :  461
total : 5000  current step :  462
total : 5000  current step :  463
total : 5000  current step :  464
total : 5000  current step :  465
total : 5000  current step :  466
total : 5000  current step :  467
total : 5000  current step :  468
total : 5000  current step :  469
total : 5000  current step :  470
total : 5000  current step :  471
total : 5000  current step :  472
total : 5000  current step :  473
total : 5000  current step :  474
total : 5000  current step :  475
Train Iter: 476/5000. LR: 0.0297. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3341. T_Loss: 4.3748. Mask: 0.9025. :  75%|███████▌  | 75/100 [00:20<00:04,  5.66it/s]Train Iter: 476/5000. LR: 0.0297. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3341. T_Loss: 4.3748. Mask: 0.9025. :  76%|███████▌  | 76/100 [00:20<00:18,  1.33it/s]Train Iter: 477/5000. LR: 0.0298. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3315. T_Loss: 4.3718. Mask: 0.9010. :  76%|███████▌  | 76/100 [00:20<00:18,  1.33it/s]Train Iter: 477/5000. LR: 0.0298. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3315. T_Loss: 4.3718. Mask: 0.9010. :  77%|███████▋  | 77/100 [00:20<00:13,  1.75it/s]Train Iter: 478/5000. LR: 0.0299. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3305. T_Loss: 4.3956. Mask: 0.9018. :  77%|███████▋  | 77/100 [00:20<00:13,  1.75it/s]Train Iter: 478/5000. LR: 0.0299. Data: 0.11s. Batch: 0.27s. S_Loss: 1.3305. T_Loss: 4.3956. Mask: 0.9018. :  78%|███████▊  | 78/100 [00:20<00:09,  2.27it/s]Train Iter: 479/5000. LR: 0.0299. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3297. T_Loss: 4.4133. Mask: 0.9011. :  78%|███████▊  | 78/100 [00:20<00:09,  2.27it/s]Train Iter: 479/5000. LR: 0.0299. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3297. T_Loss: 4.4133. Mask: 0.9011. :  79%|███████▉  | 79/100 [00:20<00:07,  2.87it/s]Train Iter: 480/5000. LR: 0.0300. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3283. T_Loss: 4.4279. Mask: 0.9004. :  79%|███████▉  | 79/100 [00:21<00:07,  2.87it/s]Train Iter: 480/5000. LR: 0.0300. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3283. T_Loss: 4.4279. Mask: 0.9004. :  80%|████████  | 80/100 [00:21<00:06,  3.06it/s]Train Iter: 481/5000. LR: 0.0301. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3295. T_Loss: 4.4331. Mask: 0.8989. :  80%|████████  | 80/100 [00:21<00:06,  3.06it/s]Train Iter: 481/5000. LR: 0.0301. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3295. T_Loss: 4.4331. Mask: 0.8989. :  81%|████████  | 81/100 [00:21<00:04,  3.85it/s]Train Iter: 482/5000. LR: 0.0301. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3295. T_Loss: 4.4389. Mask: 0.8982. :  81%|████████  | 81/100 [00:21<00:04,  3.85it/s]Train Iter: 482/5000. LR: 0.0301. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3295. T_Loss: 4.4389. Mask: 0.8982. :  82%|████████▏ | 82/100 [00:21<00:03,  4.70it/s]Train Iter: 483/5000. LR: 0.0302. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3271. T_Loss: 4.4500. Mask: 0.8987. :  82%|████████▏ | 82/100 [00:21<00:03,  4.70it/s]Train Iter: 483/5000. LR: 0.0302. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3271. T_Loss: 4.4500. Mask: 0.8987. :  83%|████████▎ | 83/100 [00:21<00:03,  5.41it/s]Train Iter: 484/5000. LR: 0.0302. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3259. T_Loss: 4.4585. Mask: 0.8988. :  83%|████████▎ | 83/100 [00:21<00:03,  5.41it/s]Train Iter: 484/5000. LR: 0.0302. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3259. T_Loss: 4.4585. Mask: 0.8988. :  84%|████████▍ | 84/100 [00:21<00:03,  4.32it/s]Train Iter: 485/5000. LR: 0.0303. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3253. T_Loss: 4.4611. Mask: 0.8974. :  84%|████████▍ | 84/100 [00:22<00:03,  4.32it/s]Train Iter: 485/5000. LR: 0.0303. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3253. T_Loss: 4.4611. Mask: 0.8974. :  85%|████████▌ | 85/100 [00:22<00:02,  5.08it/s]Train Iter: 486/5000. LR: 0.0304. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3223. T_Loss: 4.4620. Mask: 0.8968. :  85%|████████▌ | 85/100 [00:22<00:02,  5.08it/s]Train Iter: 486/5000. LR: 0.0304. Data: 0.10s. Batch: 0.26s. S_Loss: 1.3223. T_Loss: 4.4620. Mask: 0.8968. :  86%|████████▌ | 86/100 [00:22<00:02,  5.69it/s]Train Iter: 487/5000. LR: 0.0304. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3193. T_Loss: 4.4548. Mask: 0.8966. :  86%|████████▌ | 86/100 [00:22<00:02,  5.69it/s]Train Iter: 487/5000. LR: 0.0304. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3193. T_Loss: 4.4548. Mask: 0.8966. :  87%|████████▋ | 87/100 [00:22<00:02,  6.40it/s]Train Iter: 488/5000. LR: 0.0305. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3169. T_Loss: 4.4507. Mask: 0.8967. :  87%|████████▋ | 87/100 [00:22<00:02,  6.40it/s]Train Iter: 488/5000. LR: 0.0305. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3169. T_Loss: 4.4507. Mask: 0.8967. :  88%|████████▊ | 88/100 [00:22<00:01,  6.82it/s]Train Iter: 489/5000. LR: 0.0306. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3142. T_Loss: 4.4495. Mask: 0.8968. :  88%|████████▊ | 88/100 [00:22<00:01,  6.82it/s]Train Iter: 489/5000. LR: 0.0306. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3142. T_Loss: 4.4495. Mask: 0.8968. :  89%|████████▉ | 89/100 [00:22<00:01,  7.31it/s]Train Iter: 490/5000. LR: 0.0306. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3122. T_Loss: 4.4630. Mask: 0.8976. :  89%|████████▉ | 89/100 [00:22<00:01,  7.31it/s]Train Iter: 490/5000. LR: 0.0306. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3122. T_Loss: 4.4630. Mask: 0.8976. :  90%|█████████ | 90/100 [00:22<00:01,  5.71it/s]Train Iter: 491/5000. LR: 0.0307. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3092. T_Loss: 4.4491. Mask: 0.8977. :  90%|█████████ | 90/100 [00:22<00:01,  5.71it/s]Train Iter: 491/5000. LR: 0.0307. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3092. T_Loss: 4.4491. Mask: 0.8977. :  91%|█████████ | 91/100 [00:22<00:01,  6.17it/s]Train Iter: 492/5000. LR: 0.0307. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3059. T_Loss: 4.4316. Mask: 0.8971. :  91%|█████████ | 91/100 [00:23<00:01,  6.17it/s]Train Iter: 492/5000. LR: 0.0307. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3059. T_Loss: 4.4316. Mask: 0.8971. :  92%|█████████▏| 92/100 [00:23<00:01,  6.48it/s]Train Iter: 493/5000. LR: 0.0308. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3028. T_Loss: 4.4344. Mask: 0.8975. :  92%|█████████▏| 92/100 [00:23<00:01,  6.48it/s]Train Iter: 493/5000. LR: 0.0308. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3028. T_Loss: 4.4344. Mask: 0.8975. :  93%|█████████▎| 93/100 [00:23<00:01,  6.89it/s]Train Iter: 494/5000. LR: 0.0309. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3005. T_Loss: 4.4321. Mask: 0.8983. :  93%|█████████▎| 93/100 [00:23<00:01,  6.89it/s]Train Iter: 494/5000. LR: 0.0309. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3005. T_Loss: 4.4321. Mask: 0.8983. :  94%|█████████▍| 94/100 [00:23<00:00,  7.17it/s]Train Iter: 495/5000. LR: 0.0309. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2978. T_Loss: 4.4239. Mask: 0.8990. :  94%|█████████▍| 94/100 [00:23<00:00,  7.17it/s]Train Iter: 495/5000. LR: 0.0309. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2978. T_Loss: 4.4239. Mask: 0.8990. :  95%|█████████▌| 95/100 [00:23<00:00,  7.42it/s]Train Iter: 496/5000. LR: 0.0310. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2962. T_Loss: 4.4232. Mask: 0.8994. :  95%|█████████▌| 95/100 [00:23<00:00,  7.42it/s]Train Iter: 496/5000. LR: 0.0310. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2962. T_Loss: 4.4232. Mask: 0.8994. :  96%|█████████▌| 96/100 [00:23<00:00,  7.63it/s]Train Iter: 497/5000. LR: 0.0311. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2960. T_Loss: 4.4253. Mask: 0.8998. :  96%|█████████▌| 96/100 [00:23<00:00,  7.63it/s]Train Iter: 497/5000. LR: 0.0311. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2960. T_Loss: 4.4253. Mask: 0.8998. :  97%|█████████▋| 97/100 [00:23<00:00,  7.75it/s]Train Iter: 498/5000. LR: 0.0311. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2948. T_Loss: 4.4314. Mask: 0.9002. :  97%|█████████▋| 97/100 [00:23<00:00,  7.75it/s]Train Iter: 498/5000. LR: 0.0311. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2948. T_Loss: 4.4314. Mask: 0.9002. :  98%|█████████▊| 98/100 [00:23<00:00,  7.95it/s]Train Iter: 499/5000. LR: 0.0312. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2954. T_Loss: 4.4430. Mask: 0.9006. :  98%|█████████▊| 98/100 [00:23<00:00,  7.95it/s]Train Iter: 499/5000. LR: 0.0312. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2954. T_Loss: 4.4430. Mask: 0.9006. :  99%|█████████▉| 99/100 [00:23<00:00,  8.00it/s]Train Iter: 500/5000. LR: 0.0312. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2950. T_Loss: 4.4492. Mask: 0.9006. :  99%|█████████▉| 99/100 [00:24<00:00,  8.00it/s]Train Iter: 500/5000. LR: 0.0312. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2950. T_Loss: 4.4492. Mask: 0.9006. : 100%|██████████| 100/100 [00:24<00:00,  5.23it/s]Train Iter: 500/5000. LR: 0.0312. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2950. T_Loss: 4.4492. Mask: 0.9006. : 100%|██████████| 100/100 [00:24<00:00,  4.13it/s]
total : 5000  current step :  476
total : 5000  current step :  477
total : 5000  current step :  478
total : 5000  current step :  479
total : 5000  current step :  480
total : 5000  current step :  481
total : 5000  current step :  482
total : 5000  current step :  483
total : 5000  current step :  484
total : 5000  current step :  485
total : 5000  current step :  486
total : 5000  current step :  487
total : 5000  current step :  488
total : 5000  current step :  489
total : 5000  current step :  490
total : 5000  current step :  491
total : 5000  current step :  492
total : 5000  current step :  493
total : 5000  current step :  494
total : 5000  current step :  495
total : 5000  current step :  496
total : 5000  current step :  497
total : 5000  current step :  498
total : 5000  current step :  499
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.2093. top1: 96.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.2093. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.89s. Loss: 1.1796. top1: 98.44. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 1.1600. top1: 97.92. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 1.1774. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.1680. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.1793. top1: 97.40. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.1772. top1: 97.77. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 1.1730. top1: 98.05. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.1628. top1: 98.26. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.1628. top1: 98.26. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.1642. top1: 98.44. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.1570. top1: 98.58. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.1593. top1: 98.18. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.1560. top1: 98.32. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.1607. top1: 98.44. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1562. top1: 98.54. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1532. top1: 98.63. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1532. top1: 98.63. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.51it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1526. top1: 98.53. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.51it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1512. top1: 98.61. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.51it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1512. top1: 98.52. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.51it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1528. top1: 98.59. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.51it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1528. top1: 98.66. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.51it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1519. top1: 98.72. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.51it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1494. top1: 98.78. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.51it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1486. top1: 98.83. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.51it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1486. top1: 98.83. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1486. top1: 98.62. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1488. top1: 98.68. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1494. top1: 98.73. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1516. top1: 98.66. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1535. top1: 98.71. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1528. top1: 98.75. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1529. top1: 98.59. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1668. top1: 96.58. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1850. top1: 94.03. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2030. top1: 91.54. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.61it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2030. top1: 91.54. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2167. top1: 89.11. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2375. top1: 86.72. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2505. top1: 84.71. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2624. top1: 82.57. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2789. top1: 80.61. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2897. top1: 78.83. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3018. top1: 77.06. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3116. top1: 75.52. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3204. top1: 73.84. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3293. top1: 72.30. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3397. top1: 70.97. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 32.13it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3397. top1: 70.97. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3490. top1: 69.57. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3598. top1: 68.28. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3695. top1: 66.99. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3781. top1: 65.69. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3859. top1: 64.69. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3965. top1: 63.48. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4030. top1: 62.50. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4094. top1: 61.56. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4158. top1: 60.53. top5: 100.00. :  71%|███████▏  | 45/63 [00:02<00:00, 44.74it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4158. top1: 60.53. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4234. top1: 59.55. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4283. top1: 58.71. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4373. top1: 57.79. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4426. top1: 56.84. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4489. top1: 55.99. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4544. top1: 55.21. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4600. top1: 54.51. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4688. top1: 53.78. top5: 100.00. :  86%|████████▌ | 54/63 [00:02<00:00, 50.21it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4688. top1: 53.78. top5: 100.00. :  98%|█████████▊| 62/63 [00:02<00:00, 55.92it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4726. top1: 53.40. top5: 100.00. :  98%|█████████▊| 62/63 [00:02<00:00, 55.92it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.4726. top1: 53.40. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 22.92it/s]
total : 5000  current step :  500
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 501/5000. LR: 0.0313. Data: 1.87s. Batch: 2.00s. S_Loss: 1.2236. T_Loss: 4.9487. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 501/5000. LR: 0.0313. Data: 1.87s. Batch: 2.00s. S_Loss: 1.2236. T_Loss: 4.9487. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:18,  2.00s/it]Train Iter: 502/5000. LR: 0.0314. Data: 0.94s. Batch: 1.05s. S_Loss: 1.1923. T_Loss: 4.8161. Mask: 0.8906. :   1%|          | 1/100 [00:02<03:18,  2.00s/it]Train Iter: 502/5000. LR: 0.0314. Data: 0.94s. Batch: 1.05s. S_Loss: 1.1923. T_Loss: 4.8161. Mask: 0.8906. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 503/5000. LR: 0.0314. Data: 0.63s. Batch: 0.75s. S_Loss: 1.1840. T_Loss: 5.0937. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 503/5000. LR: 0.0314. Data: 0.63s. Batch: 0.75s. S_Loss: 1.1840. T_Loss: 5.0937. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<00:52,  1.84it/s]Train Iter: 504/5000. LR: 0.0315. Data: 0.47s. Batch: 0.64s. S_Loss: 1.1844. T_Loss: 4.8530. Mask: 0.9141. :   3%|▎         | 3/100 [00:02<00:52,  1.84it/s]Train Iter: 504/5000. LR: 0.0315. Data: 0.47s. Batch: 0.64s. S_Loss: 1.1844. T_Loss: 4.8530. Mask: 0.9141. :   4%|▍         | 4/100 [00:02<00:43,  2.22it/s]Train Iter: 505/5000. LR: 0.0316. Data: 0.38s. Batch: 0.53s. S_Loss: 1.1897. T_Loss: 4.8468. Mask: 0.9000. :   4%|▍         | 4/100 [00:02<00:43,  2.22it/s]Train Iter: 505/5000. LR: 0.0316. Data: 0.38s. Batch: 0.53s. S_Loss: 1.1897. T_Loss: 4.8468. Mask: 0.9000. :   5%|▌         | 5/100 [00:02<00:31,  3.01it/s]Train Iter: 506/5000. LR: 0.0316. Data: 0.32s. Batch: 0.46s. S_Loss: 1.1838. T_Loss: 5.0026. Mask: 0.9010. :   5%|▌         | 5/100 [00:02<00:31,  3.01it/s]Train Iter: 506/5000. LR: 0.0316. Data: 0.32s. Batch: 0.46s. S_Loss: 1.1838. T_Loss: 5.0026. Mask: 0.9010. :   6%|▌         | 6/100 [00:02<00:24,  3.84it/s]Train Iter: 507/5000. LR: 0.0317. Data: 0.27s. Batch: 0.42s. S_Loss: 1.1777. T_Loss: 5.0087. Mask: 0.8929. :   6%|▌         | 6/100 [00:02<00:24,  3.84it/s]Train Iter: 507/5000. LR: 0.0317. Data: 0.27s. Batch: 0.42s. S_Loss: 1.1777. T_Loss: 5.0087. Mask: 0.8929. :   7%|▋         | 7/100 [00:02<00:20,  4.64it/s]Train Iter: 508/5000. LR: 0.0318. Data: 0.24s. Batch: 0.38s. S_Loss: 1.1648. T_Loss: 4.9693. Mask: 0.8945. :   7%|▋         | 7/100 [00:03<00:20,  4.64it/s]Train Iter: 508/5000. LR: 0.0318. Data: 0.24s. Batch: 0.38s. S_Loss: 1.1648. T_Loss: 4.9693. Mask: 0.8945. :   8%|▊         | 8/100 [00:03<00:17,  5.41it/s]Train Iter: 509/5000. LR: 0.0318. Data: 0.21s. Batch: 0.35s. S_Loss: 1.1690. T_Loss: 4.9781. Mask: 0.9028. :   8%|▊         | 8/100 [00:03<00:17,  5.41it/s]Train Iter: 509/5000. LR: 0.0318. Data: 0.21s. Batch: 0.35s. S_Loss: 1.1690. T_Loss: 4.9781. Mask: 0.9028. :   9%|▉         | 9/100 [00:03<00:15,  6.05it/s]Train Iter: 510/5000. LR: 0.0319. Data: 0.19s. Batch: 0.35s. S_Loss: 1.1687. T_Loss: 4.8890. Mask: 0.9031. :   9%|▉         | 9/100 [00:03<00:15,  6.05it/s]Train Iter: 510/5000. LR: 0.0319. Data: 0.19s. Batch: 0.35s. S_Loss: 1.1687. T_Loss: 4.8890. Mask: 0.9031. :  10%|█         | 10/100 [00:03<00:18,  4.74it/s]Train Iter: 511/5000. LR: 0.0319. Data: 0.17s. Batch: 0.33s. S_Loss: 1.1656. T_Loss: 4.7912. Mask: 0.9034. :  10%|█         | 10/100 [00:03<00:18,  4.74it/s]Train Iter: 511/5000. LR: 0.0319. Data: 0.17s. Batch: 0.33s. S_Loss: 1.1656. T_Loss: 4.7912. Mask: 0.9034. :  11%|█         | 11/100 [00:03<00:16,  5.44it/s]Train Iter: 512/5000. LR: 0.0320. Data: 0.16s. Batch: 0.31s. S_Loss: 1.1697. T_Loss: 4.7162. Mask: 0.9036. :  11%|█         | 11/100 [00:03<00:16,  5.44it/s]Train Iter: 512/5000. LR: 0.0320. Data: 0.16s. Batch: 0.31s. S_Loss: 1.1697. T_Loss: 4.7162. Mask: 0.9036. :  12%|█▏        | 12/100 [00:03<00:14,  5.99it/s]Train Iter: 513/5000. LR: 0.0321. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1627. T_Loss: 4.6221. Mask: 0.9111. :  12%|█▏        | 12/100 [00:03<00:14,  5.99it/s]Train Iter: 513/5000. LR: 0.0321. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1627. T_Loss: 4.6221. Mask: 0.9111. :  13%|█▎        | 13/100 [00:03<00:13,  6.66it/s]Train Iter: 514/5000. LR: 0.0321. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1517. T_Loss: 4.5249. Mask: 0.9152. :  13%|█▎        | 13/100 [00:04<00:13,  6.66it/s]Train Iter: 514/5000. LR: 0.0321. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1517. T_Loss: 4.5249. Mask: 0.9152. :  14%|█▍        | 14/100 [00:04<00:17,  4.84it/s]Train Iter: 515/5000. LR: 0.0322. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1381. T_Loss: 4.4514. Mask: 0.9208. :  14%|█▍        | 14/100 [00:04<00:17,  4.84it/s]Train Iter: 515/5000. LR: 0.0322. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1381. T_Loss: 4.4514. Mask: 0.9208. :  15%|█▌        | 15/100 [00:04<00:15,  5.40it/s]Train Iter: 516/5000. LR: 0.0323. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1241. T_Loss: 4.4017. Mask: 0.9238. :  15%|█▌        | 15/100 [00:04<00:15,  5.40it/s]Train Iter: 516/5000. LR: 0.0323. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1241. T_Loss: 4.4017. Mask: 0.9238. :  16%|█▌        | 16/100 [00:04<00:14,  5.76it/s]Train Iter: 517/5000. LR: 0.0323. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1067. T_Loss: 4.3725. Mask: 0.9283. :  16%|█▌        | 16/100 [00:04<00:14,  5.76it/s]Train Iter: 517/5000. LR: 0.0323. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1067. T_Loss: 4.3725. Mask: 0.9283. :  17%|█▋        | 17/100 [00:04<00:13,  6.32it/s]Train Iter: 518/5000. LR: 0.0324. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0906. T_Loss: 4.3476. Mask: 0.9323. :  17%|█▋        | 17/100 [00:04<00:13,  6.32it/s]Train Iter: 518/5000. LR: 0.0324. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0906. T_Loss: 4.3476. Mask: 0.9323. :  18%|█▊        | 18/100 [00:04<00:11,  6.84it/s]Train Iter: 519/5000. LR: 0.0324. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0737. T_Loss: 4.3386. Mask: 0.9359. :  18%|█▊        | 18/100 [00:04<00:11,  6.84it/s]Train Iter: 519/5000. LR: 0.0324. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0737. T_Loss: 4.3386. Mask: 0.9359. :  19%|█▉        | 19/100 [00:04<00:11,  7.31it/s]Train Iter: 520/5000. LR: 0.0325. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0619. T_Loss: 4.3609. Mask: 0.9328. :  19%|█▉        | 19/100 [00:05<00:11,  7.31it/s]Train Iter: 520/5000. LR: 0.0325. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0619. T_Loss: 4.3609. Mask: 0.9328. :  20%|██        | 20/100 [00:05<00:15,  5.25it/s]Train Iter: 521/5000. LR: 0.0326. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0601. T_Loss: 4.4283. Mask: 0.9301. :  20%|██        | 20/100 [00:05<00:15,  5.25it/s]Train Iter: 521/5000. LR: 0.0326. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0601. T_Loss: 4.4283. Mask: 0.9301. :  21%|██        | 21/100 [00:05<00:13,  5.87it/s]Train Iter: 522/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0697. T_Loss: 4.4880. Mask: 0.9247. :  21%|██        | 21/100 [00:05<00:13,  5.87it/s]Train Iter: 522/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0697. T_Loss: 4.4880. Mask: 0.9247. :  22%|██▏       | 22/100 [00:05<00:12,  6.24it/s]Train Iter: 523/5000. LR: 0.0327. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0873. T_Loss: 4.5860. Mask: 0.9226. :  22%|██▏       | 22/100 [00:05<00:12,  6.24it/s]Train Iter: 523/5000. LR: 0.0327. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0873. T_Loss: 4.5860. Mask: 0.9226. :  23%|██▎       | 23/100 [00:05<00:11,  6.77it/s]Train Iter: 524/5000. LR: 0.0328. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1123. T_Loss: 4.6297. Mask: 0.9141. :  23%|██▎       | 23/100 [00:05<00:11,  6.77it/s]Train Iter: 524/5000. LR: 0.0328. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1123. T_Loss: 4.6297. Mask: 0.9141. :  24%|██▍       | 24/100 [00:05<00:16,  4.64it/s]Train Iter: 525/5000. LR: 0.0328. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1461. T_Loss: 4.6448. Mask: 0.9025. :  24%|██▍       | 24/100 [00:05<00:16,  4.64it/s]Train Iter: 525/5000. LR: 0.0328. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1461. T_Loss: 4.6448. Mask: 0.9025. :  25%|██▌       | 25/100 [00:05<00:13,  5.40it/s]total : 5000  current step :  501
total : 5000  current step :  502
total : 5000  current step :  503
total : 5000  current step :  504
total : 5000  current step :  505
total : 5000  current step :  506
total : 5000  current step :  507
total : 5000  current step :  508
total : 5000  current step :  509
total : 5000  current step :  510
total : 5000  current step :  511
total : 5000  current step :  512
total : 5000  current step :  513
total : 5000  current step :  514
total : 5000  current step :  515
total : 5000  current step :  516
total : 5000  current step :  517
total : 5000  current step :  518
total : 5000  current step :  519
total : 5000  current step :  520
total : 5000  current step :  521
total : 5000  current step :  522
total : 5000  current step :  523
total : 5000  current step :  524
total : 5000  current step :  525
Train Iter: 526/5000. LR: 0.0329. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1750. T_Loss: 4.6789. Mask: 0.8990. :  25%|██▌       | 25/100 [00:07<00:13,  5.40it/s]Train Iter: 526/5000. LR: 0.0329. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1750. T_Loss: 4.6789. Mask: 0.8990. :  26%|██▌       | 26/100 [00:07<00:51,  1.45it/s]Train Iter: 527/5000. LR: 0.0329. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1941. T_Loss: 4.6873. Mask: 0.8935. :  26%|██▌       | 26/100 [00:07<00:51,  1.45it/s]Train Iter: 527/5000. LR: 0.0329. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1941. T_Loss: 4.6873. Mask: 0.8935. :  27%|██▋       | 27/100 [00:07<00:37,  1.93it/s]Train Iter: 528/5000. LR: 0.0330. Data: 0.13s. Batch: 0.29s. S_Loss: 1.2147. T_Loss: 4.6751. Mask: 0.8895. :  27%|██▋       | 27/100 [00:08<00:37,  1.93it/s]Train Iter: 528/5000. LR: 0.0330. Data: 0.13s. Batch: 0.29s. S_Loss: 1.2147. T_Loss: 4.6751. Mask: 0.8895. :  28%|██▊       | 28/100 [00:08<00:28,  2.50it/s]Train Iter: 529/5000. LR: 0.0331. Data: 0.13s. Batch: 0.28s. S_Loss: 1.2302. T_Loss: 4.6777. Mask: 0.8901. :  28%|██▊       | 28/100 [00:08<00:28,  2.50it/s]Train Iter: 529/5000. LR: 0.0331. Data: 0.13s. Batch: 0.28s. S_Loss: 1.2302. T_Loss: 4.6777. Mask: 0.8901. :  29%|██▉       | 29/100 [00:08<00:22,  3.18it/s]Train Iter: 530/5000. LR: 0.0331. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2388. T_Loss: 4.6765. Mask: 0.8906. :  29%|██▉       | 29/100 [00:08<00:22,  3.18it/s]Train Iter: 530/5000. LR: 0.0331. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2388. T_Loss: 4.6765. Mask: 0.8906. :  30%|███       | 30/100 [00:08<00:21,  3.22it/s]Train Iter: 531/5000. LR: 0.0332. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2427. T_Loss: 4.7231. Mask: 0.8911. :  30%|███       | 30/100 [00:08<00:21,  3.22it/s]Train Iter: 531/5000. LR: 0.0332. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2427. T_Loss: 4.7231. Mask: 0.8911. :  31%|███       | 31/100 [00:08<00:18,  3.81it/s]Train Iter: 532/5000. LR: 0.0333. Data: 0.12s. Batch: 0.27s. S_Loss: 1.2441. T_Loss: 4.7058. Mask: 0.8926. :  31%|███       | 31/100 [00:08<00:18,  3.81it/s]Train Iter: 532/5000. LR: 0.0333. Data: 0.12s. Batch: 0.27s. S_Loss: 1.2441. T_Loss: 4.7058. Mask: 0.8926. :  32%|███▏      | 32/100 [00:08<00:15,  4.48it/s]Train Iter: 533/5000. LR: 0.0333. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2432. T_Loss: 4.7256. Mask: 0.8949. :  32%|███▏      | 32/100 [00:08<00:15,  4.48it/s]Train Iter: 533/5000. LR: 0.0333. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2432. T_Loss: 4.7256. Mask: 0.8949. :  33%|███▎      | 33/100 [00:08<00:12,  5.18it/s]Train Iter: 534/5000. LR: 0.0334. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2469. T_Loss: 4.7941. Mask: 0.8971. :  33%|███▎      | 33/100 [00:09<00:12,  5.18it/s]Train Iter: 534/5000. LR: 0.0334. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2469. T_Loss: 4.7941. Mask: 0.8971. :  34%|███▍      | 34/100 [00:09<00:16,  4.05it/s]Train Iter: 535/5000. LR: 0.0334. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2462. T_Loss: 4.7885. Mask: 0.8964. :  34%|███▍      | 34/100 [00:09<00:16,  4.05it/s]Train Iter: 535/5000. LR: 0.0334. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2462. T_Loss: 4.7885. Mask: 0.8964. :  35%|███▌      | 35/100 [00:09<00:13,  4.76it/s]Train Iter: 536/5000. LR: 0.0335. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2446. T_Loss: 4.7928. Mask: 0.8958. :  35%|███▌      | 35/100 [00:09<00:13,  4.76it/s]Train Iter: 536/5000. LR: 0.0335. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2446. T_Loss: 4.7928. Mask: 0.8958. :  36%|███▌      | 36/100 [00:09<00:12,  5.22it/s]Train Iter: 537/5000. LR: 0.0336. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2477. T_Loss: 4.7774. Mask: 0.8910. :  36%|███▌      | 36/100 [00:09<00:12,  5.22it/s]Train Iter: 537/5000. LR: 0.0336. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2477. T_Loss: 4.7774. Mask: 0.8910. :  37%|███▋      | 37/100 [00:09<00:10,  6.00it/s]Train Iter: 538/5000. LR: 0.0336. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2467. T_Loss: 4.7915. Mask: 0.8914. :  37%|███▋      | 37/100 [00:09<00:10,  6.00it/s]Train Iter: 538/5000. LR: 0.0336. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2467. T_Loss: 4.7915. Mask: 0.8914. :  38%|███▊      | 38/100 [00:09<00:09,  6.70it/s]Train Iter: 539/5000. LR: 0.0337. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2456. T_Loss: 4.7650. Mask: 0.8870. :  38%|███▊      | 38/100 [00:09<00:09,  6.70it/s]Train Iter: 539/5000. LR: 0.0337. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2456. T_Loss: 4.7650. Mask: 0.8870. :  39%|███▉      | 39/100 [00:09<00:08,  7.34it/s]Train Iter: 540/5000. LR: 0.0338. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2472. T_Loss: 4.7789. Mask: 0.8875. :  39%|███▉      | 39/100 [00:10<00:08,  7.34it/s]Train Iter: 540/5000. LR: 0.0338. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2472. T_Loss: 4.7789. Mask: 0.8875. :  40%|████      | 40/100 [00:10<00:10,  5.69it/s]Train Iter: 541/5000. LR: 0.0338. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2501. T_Loss: 4.8091. Mask: 0.8880. :  40%|████      | 40/100 [00:10<00:10,  5.69it/s]Train Iter: 541/5000. LR: 0.0338. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2501. T_Loss: 4.8091. Mask: 0.8880. :  41%|████      | 41/100 [00:10<00:09,  6.35it/s]Train Iter: 542/5000. LR: 0.0339. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2544. T_Loss: 4.8112. Mask: 0.8884. :  41%|████      | 41/100 [00:10<00:09,  6.35it/s]Train Iter: 542/5000. LR: 0.0339. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2544. T_Loss: 4.8112. Mask: 0.8884. :  42%|████▏     | 42/100 [00:10<00:08,  6.79it/s]Train Iter: 543/5000. LR: 0.0339. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2564. T_Loss: 4.8058. Mask: 0.8844. :  42%|████▏     | 42/100 [00:10<00:08,  6.79it/s]Train Iter: 543/5000. LR: 0.0339. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2564. T_Loss: 4.8058. Mask: 0.8844. :  43%|████▎     | 43/100 [00:10<00:07,  7.16it/s]Train Iter: 544/5000. LR: 0.0340. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2582. T_Loss: 4.8159. Mask: 0.8842. :  43%|████▎     | 43/100 [00:10<00:07,  7.16it/s]Train Iter: 544/5000. LR: 0.0340. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2582. T_Loss: 4.8159. Mask: 0.8842. :  44%|████▍     | 44/100 [00:10<00:10,  5.52it/s]Train Iter: 545/5000. LR: 0.0341. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2626. T_Loss: 4.8211. Mask: 0.8826. :  44%|████▍     | 44/100 [00:10<00:10,  5.52it/s]Train Iter: 545/5000. LR: 0.0341. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2626. T_Loss: 4.8211. Mask: 0.8826. :  45%|████▌     | 45/100 [00:10<00:09,  5.92it/s]Train Iter: 546/5000. LR: 0.0341. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2637. T_Loss: 4.8286. Mask: 0.8811. :  45%|████▌     | 45/100 [00:11<00:09,  5.92it/s]Train Iter: 546/5000. LR: 0.0341. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2637. T_Loss: 4.8286. Mask: 0.8811. :  46%|████▌     | 46/100 [00:11<00:08,  6.42it/s]Train Iter: 547/5000. LR: 0.0342. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2640. T_Loss: 4.8294. Mask: 0.8810. :  46%|████▌     | 46/100 [00:11<00:08,  6.42it/s]Train Iter: 547/5000. LR: 0.0342. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2640. T_Loss: 4.8294. Mask: 0.8810. :  47%|████▋     | 47/100 [00:11<00:07,  6.88it/s]Train Iter: 548/5000. LR: 0.0343. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2632. T_Loss: 4.8274. Mask: 0.8802. :  47%|████▋     | 47/100 [00:11<00:07,  6.88it/s]Train Iter: 548/5000. LR: 0.0343. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2632. T_Loss: 4.8274. Mask: 0.8802. :  48%|████▊     | 48/100 [00:11<00:07,  7.40it/s]Train Iter: 549/5000. LR: 0.0343. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2626. T_Loss: 4.8424. Mask: 0.8820. :  48%|████▊     | 48/100 [00:11<00:07,  7.40it/s]Train Iter: 549/5000. LR: 0.0343. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2626. T_Loss: 4.8424. Mask: 0.8820. :  49%|████▉     | 49/100 [00:11<00:06,  7.65it/s]Train Iter: 550/5000. LR: 0.0344. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2610. T_Loss: 4.8325. Mask: 0.8800. :  49%|████▉     | 49/100 [00:11<00:06,  7.65it/s]Train Iter: 550/5000. LR: 0.0344. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2610. T_Loss: 4.8325. Mask: 0.8800. :  50%|█████     | 50/100 [00:11<00:09,  5.35it/s]total : 5000  current step :  526
total : 5000  current step :  527
total : 5000  current step :  528
total : 5000  current step :  529
total : 5000  current step :  530
total : 5000  current step :  531
total : 5000  current step :  532
total : 5000  current step :  533
total : 5000  current step :  534
total : 5000  current step :  535
total : 5000  current step :  536
total : 5000  current step :  537
total : 5000  current step :  538
total : 5000  current step :  539
total : 5000  current step :  540
total : 5000  current step :  541
total : 5000  current step :  542
total : 5000  current step :  543
total : 5000  current step :  544
total : 5000  current step :  545
total : 5000  current step :  546
total : 5000  current step :  547
total : 5000  current step :  548
total : 5000  current step :  549
total : 5000  current step :  550
Train Iter: 551/5000. LR: 0.0344. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2577. T_Loss: 4.8377. Mask: 0.8811. :  50%|█████     | 50/100 [00:13<00:09,  5.35it/s]Train Iter: 551/5000. LR: 0.0344. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2577. T_Loss: 4.8377. Mask: 0.8811. :  51%|█████     | 51/100 [00:13<00:38,  1.29it/s]Train Iter: 552/5000. LR: 0.0345. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2550. T_Loss: 4.8322. Mask: 0.8816. :  51%|█████     | 51/100 [00:14<00:38,  1.29it/s]Train Iter: 552/5000. LR: 0.0345. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2550. T_Loss: 4.8322. Mask: 0.8816. :  52%|█████▏    | 52/100 [00:14<00:27,  1.72it/s]Train Iter: 553/5000. LR: 0.0346. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2519. T_Loss: 4.8139. Mask: 0.8821. :  52%|█████▏    | 52/100 [00:14<00:27,  1.72it/s]Train Iter: 553/5000. LR: 0.0346. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2519. T_Loss: 4.8139. Mask: 0.8821. :  53%|█████▎    | 53/100 [00:14<00:20,  2.24it/s]Train Iter: 554/5000. LR: 0.0346. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2460. T_Loss: 4.8076. Mask: 0.8831. :  53%|█████▎    | 53/100 [00:14<00:20,  2.24it/s]Train Iter: 554/5000. LR: 0.0346. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2460. T_Loss: 4.8076. Mask: 0.8831. :  54%|█████▍    | 54/100 [00:14<00:18,  2.52it/s]Train Iter: 555/5000. LR: 0.0347. Data: 0.11s. Batch: 0.26s. S_Loss: 1.2410. T_Loss: 4.7941. Mask: 0.8830. :  54%|█████▍    | 54/100 [00:14<00:18,  2.52it/s]Train Iter: 555/5000. LR: 0.0347. Data: 0.11s. Batch: 0.26s. S_Loss: 1.2410. T_Loss: 4.7941. Mask: 0.8830. :  55%|█████▌    | 55/100 [00:14<00:14,  3.16it/s]Train Iter: 556/5000. LR: 0.0347. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2357. T_Loss: 4.7848. Mask: 0.8845. :  55%|█████▌    | 55/100 [00:14<00:14,  3.16it/s]Train Iter: 556/5000. LR: 0.0347. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2357. T_Loss: 4.7848. Mask: 0.8845. :  56%|█████▌    | 56/100 [00:14<00:11,  3.88it/s]Train Iter: 557/5000. LR: 0.0348. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2304. T_Loss: 4.7776. Mask: 0.8854. :  56%|█████▌    | 56/100 [00:14<00:11,  3.88it/s]Train Iter: 557/5000. LR: 0.0348. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2304. T_Loss: 4.7776. Mask: 0.8854. :  57%|█████▋    | 57/100 [00:14<00:09,  4.52it/s]Train Iter: 558/5000. LR: 0.0349. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2265. T_Loss: 4.7727. Mask: 0.8863. :  57%|█████▋    | 57/100 [00:14<00:09,  4.52it/s]Train Iter: 558/5000. LR: 0.0349. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2265. T_Loss: 4.7727. Mask: 0.8863. :  58%|█████▊    | 58/100 [00:14<00:08,  5.08it/s]Train Iter: 559/5000. LR: 0.0349. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2240. T_Loss: 4.7851. Mask: 0.8861. :  58%|█████▊    | 58/100 [00:15<00:08,  5.08it/s]Train Iter: 559/5000. LR: 0.0349. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2240. T_Loss: 4.7851. Mask: 0.8861. :  59%|█████▉    | 59/100 [00:15<00:07,  5.73it/s]Train Iter: 560/5000. LR: 0.0350. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2208. T_Loss: 4.7898. Mask: 0.8865. :  59%|█████▉    | 59/100 [00:15<00:07,  5.73it/s]Train Iter: 560/5000. LR: 0.0350. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2208. T_Loss: 4.7898. Mask: 0.8865. :  60%|██████    | 60/100 [00:15<00:08,  4.61it/s]Train Iter: 561/5000. LR: 0.0351. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2226. T_Loss: 4.8062. Mask: 0.8863. :  60%|██████    | 60/100 [00:15<00:08,  4.61it/s]Train Iter: 561/5000. LR: 0.0351. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2226. T_Loss: 4.8062. Mask: 0.8863. :  61%|██████    | 61/100 [00:15<00:07,  5.31it/s]Train Iter: 562/5000. LR: 0.0351. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2242. T_Loss: 4.8252. Mask: 0.8871. :  61%|██████    | 61/100 [00:15<00:07,  5.31it/s]Train Iter: 562/5000. LR: 0.0351. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2242. T_Loss: 4.8252. Mask: 0.8871. :  62%|██████▏   | 62/100 [00:15<00:06,  5.91it/s]Train Iter: 563/5000. LR: 0.0352. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2264. T_Loss: 4.8250. Mask: 0.8839. :  62%|██████▏   | 62/100 [00:15<00:06,  5.91it/s]Train Iter: 563/5000. LR: 0.0352. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2264. T_Loss: 4.8250. Mask: 0.8839. :  63%|██████▎   | 63/100 [00:15<00:05,  6.47it/s]Train Iter: 564/5000. LR: 0.0352. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2289. T_Loss: 4.8307. Mask: 0.8848. :  63%|██████▎   | 63/100 [00:16<00:05,  6.47it/s]Train Iter: 564/5000. LR: 0.0352. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2289. T_Loss: 4.8307. Mask: 0.8848. :  64%|██████▍   | 64/100 [00:16<00:08,  4.34it/s]Train Iter: 565/5000. LR: 0.0353. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2325. T_Loss: 4.8432. Mask: 0.8846. :  64%|██████▍   | 64/100 [00:16<00:08,  4.34it/s]Train Iter: 565/5000. LR: 0.0353. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2325. T_Loss: 4.8432. Mask: 0.8846. :  65%|██████▌   | 65/100 [00:16<00:06,  5.06it/s]Train Iter: 566/5000. LR: 0.0354. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2359. T_Loss: 4.8537. Mask: 0.8859. :  65%|██████▌   | 65/100 [00:16<00:06,  5.06it/s]Train Iter: 566/5000. LR: 0.0354. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2359. T_Loss: 4.8537. Mask: 0.8859. :  66%|██████▌   | 66/100 [00:16<00:06,  5.50it/s]Train Iter: 567/5000. LR: 0.0354. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2382. T_Loss: 4.8562. Mask: 0.8857. :  66%|██████▌   | 66/100 [00:16<00:06,  5.50it/s]Train Iter: 567/5000. LR: 0.0354. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2382. T_Loss: 4.8562. Mask: 0.8857. :  67%|██████▋   | 67/100 [00:16<00:05,  6.10it/s]Train Iter: 568/5000. LR: 0.0355. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2388. T_Loss: 4.8655. Mask: 0.8851. :  67%|██████▋   | 67/100 [00:16<00:05,  6.10it/s]Train Iter: 568/5000. LR: 0.0355. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2388. T_Loss: 4.8655. Mask: 0.8851. :  68%|██████▊   | 68/100 [00:16<00:04,  6.83it/s]Train Iter: 569/5000. LR: 0.0356. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2385. T_Loss: 4.8694. Mask: 0.8841. :  68%|██████▊   | 68/100 [00:16<00:04,  6.83it/s]Train Iter: 569/5000. LR: 0.0356. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2385. T_Loss: 4.8694. Mask: 0.8841. :  69%|██████▉   | 69/100 [00:16<00:04,  7.54it/s]Train Iter: 570/5000. LR: 0.0356. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2382. T_Loss: 4.8784. Mask: 0.8853. :  69%|██████▉   | 69/100 [00:16<00:04,  7.54it/s]Train Iter: 570/5000. LR: 0.0356. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2382. T_Loss: 4.8784. Mask: 0.8853. :  70%|███████   | 70/100 [00:16<00:03,  7.86it/s]Train Iter: 571/5000. LR: 0.0357. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2379. T_Loss: 4.8938. Mask: 0.8834. :  70%|███████   | 70/100 [00:16<00:03,  7.86it/s]Train Iter: 572/5000. LR: 0.0357. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2364. T_Loss: 4.8863. Mask: 0.8841. :  71%|███████   | 71/100 [00:17<00:03,  7.86it/s]Train Iter: 572/5000. LR: 0.0357. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2364. T_Loss: 4.8863. Mask: 0.8841. :  72%|███████▏  | 72/100 [00:17<00:03,  8.88it/s]Train Iter: 573/5000. LR: 0.0358. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2348. T_Loss: 4.8809. Mask: 0.8844. :  72%|███████▏  | 72/100 [00:17<00:03,  8.88it/s]Train Iter: 573/5000. LR: 0.0358. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2348. T_Loss: 4.8809. Mask: 0.8844. :  73%|███████▎  | 73/100 [00:17<00:03,  8.68it/s]Train Iter: 574/5000. LR: 0.0359. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2340. T_Loss: 4.8873. Mask: 0.8856. :  73%|███████▎  | 73/100 [00:17<00:03,  8.68it/s]Train Iter: 574/5000. LR: 0.0359. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2340. T_Loss: 4.8873. Mask: 0.8856. :  74%|███████▍  | 74/100 [00:17<00:04,  6.39it/s]Train Iter: 575/5000. LR: 0.0359. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2327. T_Loss: 4.8754. Mask: 0.8846. :  74%|███████▍  | 74/100 [00:17<00:04,  6.39it/s]Train Iter: 575/5000. LR: 0.0359. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2327. T_Loss: 4.8754. Mask: 0.8846. :  75%|███████▌  | 75/100 [00:17<00:03,  6.90it/s]total : 5000  current step :  551
total : 5000  current step :  552
total : 5000  current step :  553
total : 5000  current step :  554
total : 5000  current step :  555
total : 5000  current step :  556
total : 5000  current step :  557
total : 5000  current step :  558
total : 5000  current step :  559
total : 5000  current step :  560
total : 5000  current step :  561
total : 5000  current step :  562
total : 5000  current step :  563
total : 5000  current step :  564
total : 5000  current step :  565
total : 5000  current step :  566
total : 5000  current step :  567
total : 5000  current step :  568
total : 5000  current step :  569
total : 5000  current step :  570
total : 5000  current step :  571
total : 5000  current step :  572
total : 5000  current step :  573
total : 5000  current step :  574
total : 5000  current step :  575
Train Iter: 576/5000. LR: 0.0360. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2313. T_Loss: 4.8911. Mask: 0.8857. :  75%|███████▌  | 75/100 [00:19<00:03,  6.90it/s]Train Iter: 576/5000. LR: 0.0360. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2313. T_Loss: 4.8911. Mask: 0.8857. :  76%|███████▌  | 76/100 [00:19<00:16,  1.46it/s]Train Iter: 577/5000. LR: 0.0361. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2292. T_Loss: 4.8827. Mask: 0.8856. :  76%|███████▌  | 76/100 [00:19<00:16,  1.46it/s]Train Iter: 577/5000. LR: 0.0361. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2292. T_Loss: 4.8827. Mask: 0.8856. :  77%|███████▋  | 77/100 [00:19<00:12,  1.91it/s]Train Iter: 578/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2277. T_Loss: 4.8771. Mask: 0.8862. :  77%|███████▋  | 77/100 [00:19<00:12,  1.91it/s]Train Iter: 578/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2277. T_Loss: 4.8771. Mask: 0.8862. :  78%|███████▊  | 78/100 [00:19<00:09,  2.44it/s]Train Iter: 579/5000. LR: 0.0362. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2288. T_Loss: 4.8830. Mask: 0.8853. :  78%|███████▊  | 78/100 [00:20<00:09,  2.44it/s]Train Iter: 579/5000. LR: 0.0362. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2288. T_Loss: 4.8830. Mask: 0.8853. :  79%|███████▉  | 79/100 [00:20<00:06,  3.04it/s]Train Iter: 580/5000. LR: 0.0362. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2272. T_Loss: 4.8866. Mask: 0.8852. :  79%|███████▉  | 79/100 [00:20<00:06,  3.04it/s]Train Iter: 580/5000. LR: 0.0362. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2272. T_Loss: 4.8866. Mask: 0.8852. :  80%|████████  | 80/100 [00:20<00:05,  3.45it/s]Train Iter: 581/5000. LR: 0.0363. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2255. T_Loss: 4.8728. Mask: 0.8835. :  80%|████████  | 80/100 [00:20<00:05,  3.45it/s]Train Iter: 581/5000. LR: 0.0363. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2255. T_Loss: 4.8728. Mask: 0.8835. :  81%|████████  | 81/100 [00:20<00:04,  4.14it/s]Train Iter: 582/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2233. T_Loss: 4.8825. Mask: 0.8849. :  81%|████████  | 81/100 [00:20<00:04,  4.14it/s]Train Iter: 582/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2233. T_Loss: 4.8825. Mask: 0.8849. :  82%|████████▏ | 82/100 [00:20<00:03,  4.80it/s]Train Iter: 583/5000. LR: 0.0364. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2230. T_Loss: 4.8655. Mask: 0.8840. :  82%|████████▏ | 82/100 [00:20<00:03,  4.80it/s]Train Iter: 583/5000. LR: 0.0364. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2230. T_Loss: 4.8655. Mask: 0.8840. :  83%|████████▎ | 83/100 [00:20<00:03,  5.46it/s]Train Iter: 584/5000. LR: 0.0365. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2218. T_Loss: 4.8524. Mask: 0.8847. :  83%|████████▎ | 83/100 [00:20<00:03,  5.46it/s]Train Iter: 584/5000. LR: 0.0365. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2218. T_Loss: 4.8524. Mask: 0.8847. :  84%|████████▍ | 84/100 [00:20<00:03,  4.70it/s]Train Iter: 585/5000. LR: 0.0366. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2211. T_Loss: 4.8573. Mask: 0.8853. :  84%|████████▍ | 84/100 [00:21<00:03,  4.70it/s]Train Iter: 585/5000. LR: 0.0366. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2211. T_Loss: 4.8573. Mask: 0.8853. :  85%|████████▌ | 85/100 [00:21<00:02,  5.06it/s]Train Iter: 586/5000. LR: 0.0366. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2210. T_Loss: 4.8603. Mask: 0.8863. :  85%|████████▌ | 85/100 [00:21<00:02,  5.06it/s]Train Iter: 586/5000. LR: 0.0366. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2210. T_Loss: 4.8603. Mask: 0.8863. :  86%|████████▌ | 86/100 [00:21<00:02,  5.70it/s]Train Iter: 587/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2196. T_Loss: 4.8537. Mask: 0.8861. :  86%|████████▌ | 86/100 [00:21<00:02,  5.70it/s]Train Iter: 587/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2196. T_Loss: 4.8537. Mask: 0.8861. :  87%|████████▋ | 87/100 [00:21<00:02,  6.29it/s]Train Iter: 588/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2188. T_Loss: 4.8641. Mask: 0.8867. :  87%|████████▋ | 87/100 [00:21<00:02,  6.29it/s]Train Iter: 588/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2188. T_Loss: 4.8641. Mask: 0.8867. :  88%|████████▊ | 88/100 [00:21<00:01,  6.39it/s]Train Iter: 589/5000. LR: 0.0368. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2179. T_Loss: 4.8634. Mask: 0.8869. :  88%|████████▊ | 88/100 [00:21<00:01,  6.39it/s]Train Iter: 589/5000. LR: 0.0368. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2179. T_Loss: 4.8634. Mask: 0.8869. :  89%|████████▉ | 89/100 [00:21<00:01,  6.62it/s]Train Iter: 590/5000. LR: 0.0369. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2170. T_Loss: 4.8619. Mask: 0.8878. :  89%|████████▉ | 89/100 [00:21<00:01,  6.62it/s]Train Iter: 590/5000. LR: 0.0369. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2170. T_Loss: 4.8619. Mask: 0.8878. :  90%|█████████ | 90/100 [00:21<00:02,  4.99it/s]Train Iter: 591/5000. LR: 0.0369. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2150. T_Loss: 4.8565. Mask: 0.8880. :  90%|█████████ | 90/100 [00:22<00:02,  4.99it/s]Train Iter: 591/5000. LR: 0.0369. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2150. T_Loss: 4.8565. Mask: 0.8880. :  91%|█████████ | 91/100 [00:22<00:01,  5.50it/s]Train Iter: 592/5000. LR: 0.0370. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2137. T_Loss: 4.8481. Mask: 0.8879. :  91%|█████████ | 91/100 [00:22<00:01,  5.50it/s]Train Iter: 592/5000. LR: 0.0370. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2137. T_Loss: 4.8481. Mask: 0.8879. :  92%|█████████▏| 92/100 [00:22<00:01,  5.94it/s]Train Iter: 593/5000. LR: 0.0371. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2135. T_Loss: 4.8581. Mask: 0.8884. :  92%|█████████▏| 92/100 [00:22<00:01,  5.94it/s]Train Iter: 593/5000. LR: 0.0371. Data: 0.09s. Batch: 0.24s. S_Loss: 1.2135. T_Loss: 4.8581. Mask: 0.8884. :  93%|█████████▎| 93/100 [00:22<00:01,  6.39it/s]Train Iter: 594/5000. LR: 0.0371. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2123. T_Loss: 4.8497. Mask: 0.8880. :  93%|█████████▎| 93/100 [00:22<00:01,  6.39it/s]Train Iter: 594/5000. LR: 0.0371. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2123. T_Loss: 4.8497. Mask: 0.8880. :  94%|█████████▍| 94/100 [00:22<00:00,  6.57it/s]Train Iter: 595/5000. LR: 0.0372. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2116. T_Loss: 4.8529. Mask: 0.8885. :  94%|█████████▍| 94/100 [00:22<00:00,  6.57it/s]Train Iter: 595/5000. LR: 0.0372. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2116. T_Loss: 4.8529. Mask: 0.8885. :  95%|█████████▌| 95/100 [00:22<00:00,  6.81it/s]Train Iter: 596/5000. LR: 0.0372. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2108. T_Loss: 4.8600. Mask: 0.8890. :  95%|█████████▌| 95/100 [00:22<00:00,  6.81it/s]Train Iter: 596/5000. LR: 0.0372. Data: 0.08s. Batch: 0.24s. S_Loss: 1.2108. T_Loss: 4.8600. Mask: 0.8890. :  96%|█████████▌| 96/100 [00:22<00:00,  7.07it/s]Train Iter: 597/5000. LR: 0.0373. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2092. T_Loss: 4.8650. Mask: 0.8892. :  96%|█████████▌| 96/100 [00:22<00:00,  7.07it/s]Train Iter: 597/5000. LR: 0.0373. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2092. T_Loss: 4.8650. Mask: 0.8892. :  97%|█████████▋| 97/100 [00:22<00:00,  7.17it/s]Train Iter: 598/5000. LR: 0.0374. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2088. T_Loss: 4.8688. Mask: 0.8893. :  97%|█████████▋| 97/100 [00:22<00:00,  7.17it/s]Train Iter: 598/5000. LR: 0.0374. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2088. T_Loss: 4.8688. Mask: 0.8893. :  98%|█████████▊| 98/100 [00:22<00:00,  7.34it/s]Train Iter: 599/5000. LR: 0.0374. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2079. T_Loss: 4.8665. Mask: 0.8892. :  98%|█████████▊| 98/100 [00:23<00:00,  7.34it/s]Train Iter: 599/5000. LR: 0.0374. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2079. T_Loss: 4.8665. Mask: 0.8892. :  99%|█████████▉| 99/100 [00:23<00:00,  7.40it/s]Train Iter: 600/5000. LR: 0.0375. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2085. T_Loss: 4.8677. Mask: 0.8884. :  99%|█████████▉| 99/100 [00:23<00:00,  7.40it/s]Train Iter: 600/5000. LR: 0.0375. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2085. T_Loss: 4.8677. Mask: 0.8884. : 100%|██████████| 100/100 [00:23<00:00,  5.84it/s]Train Iter: 600/5000. LR: 0.0375. Data: 0.08s. Batch: 0.23s. S_Loss: 1.2085. T_Loss: 4.8677. Mask: 0.8884. : 100%|██████████| 100/100 [00:23<00:00,  4.28it/s]
total : 5000  current step :  576
total : 5000  current step :  577
total : 5000  current step :  578
total : 5000  current step :  579
total : 5000  current step :  580
total : 5000  current step :  581
total : 5000  current step :  582
total : 5000  current step :  583
total : 5000  current step :  584
total : 5000  current step :  585
total : 5000  current step :  586
total : 5000  current step :  587
total : 5000  current step :  588
total : 5000  current step :  589
total : 5000  current step :  590
total : 5000  current step :  591
total : 5000  current step :  592
total : 5000  current step :  593
total : 5000  current step :  594
total : 5000  current step :  595
total : 5000  current step :  596
total : 5000  current step :  597
total : 5000  current step :  598
total : 5000  current step :  599
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.07s. Loss: 1.1146. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.07s. Loss: 1.1146. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.07s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.04s. Loss: 1.0808. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.07s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.71s. Loss: 1.0736. top1: 97.92. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.07s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.54s. Loss: 1.0915. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.07s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.0804. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.07s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.0878. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.07s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.0878. top1: 96.88. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.0867. top1: 96.88. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.0862. top1: 97.27. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.0759. top1: 97.57. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.0792. top1: 97.81. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.0757. top1: 98.01. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.0798. top1: 97.92. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.0781. top1: 98.08. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.0793. top1: 98.21. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:15,  3.68it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.0793. top1: 98.21. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0747. top1: 98.33. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0717. top1: 98.44. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0705. top1: 98.53. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0711. top1: 98.61. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0712. top1: 98.68. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0710. top1: 98.75. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0709. top1: 98.81. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.04it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0709. top1: 98.81. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0716. top1: 98.86. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0716. top1: 98.91. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0713. top1: 98.96. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0714. top1: 98.75. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0720. top1: 98.80. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0738. top1: 98.84. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0748. top1: 98.77. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0767. top1: 98.81. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0771. top1: 98.75. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0782. top1: 98.79. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.30it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0782. top1: 98.79. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0948. top1: 96.97. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1148. top1: 94.32. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1363. top1: 91.64. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1514. top1: 89.29. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1766. top1: 86.81. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1910. top1: 84.80. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2053. top1: 82.57. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2235. top1: 80.69. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 27.17it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2235. top1: 80.69. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2345. top1: 78.83. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2481. top1: 77.13. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2589. top1: 75.45. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2690. top1: 73.84. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2787. top1: 72.37. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2913. top1: 70.83. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3020. top1: 69.36. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3135. top1: 68.02. top5: 100.00. :  62%|██████▏   | 39/63 [00:02<00:00, 35.32it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3135. top1: 68.02. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3262. top1: 66.67. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3375. top1: 65.37. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3467. top1: 64.25. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3607. top1: 63.11. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3682. top1: 62.08. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3740. top1: 61.14. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3823. top1: 60.07. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3905. top1: 59.03. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.01it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3905. top1: 59.03. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3941. top1: 58.26. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4056. top1: 57.35. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4122. top1: 56.36. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4200. top1: 55.51. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4261. top1: 54.79. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4338. top1: 53.89. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4444. top1: 53.07. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4495. top1: 52.65. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 49.34it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4495. top1: 52.65. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 53.71it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.4495. top1: 52.65. top5: 100.00. : 100%|██████████| 63/63 [00:03<00:00, 20.11it/s]
total : 5000  current step :  600
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 601/5000. LR: 0.0376. Data: 1.90s. Batch: 2.01s. S_Loss: 1.2894. T_Loss: 5.1163. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 601/5000. LR: 0.0376. Data: 1.90s. Batch: 2.01s. S_Loss: 1.2894. T_Loss: 5.1163. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:19,  2.02s/it]Train Iter: 602/5000. LR: 0.0376. Data: 0.95s. Batch: 1.07s. S_Loss: 1.2478. T_Loss: 5.3181. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:19,  2.02s/it]Train Iter: 602/5000. LR: 0.0376. Data: 0.95s. Batch: 1.07s. S_Loss: 1.2478. T_Loss: 5.3181. Mask: 0.9688. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 603/5000. LR: 0.0377. Data: 0.63s. Batch: 0.76s. S_Loss: 1.2409. T_Loss: 5.1070. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 603/5000. LR: 0.0377. Data: 0.63s. Batch: 0.76s. S_Loss: 1.2409. T_Loss: 5.1070. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<00:53,  1.82it/s]Train Iter: 604/5000. LR: 0.0378. Data: 0.48s. Batch: 0.65s. S_Loss: 1.2335. T_Loss: 4.9175. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:53,  1.82it/s]Train Iter: 604/5000. LR: 0.0378. Data: 0.48s. Batch: 0.65s. S_Loss: 1.2335. T_Loss: 4.9175. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:44,  2.15it/s]Train Iter: 605/5000. LR: 0.0378. Data: 0.38s. Batch: 0.54s. S_Loss: 1.2161. T_Loss: 4.8969. Mask: 0.9250. :   4%|▍         | 4/100 [00:02<00:44,  2.15it/s]Train Iter: 605/5000. LR: 0.0378. Data: 0.38s. Batch: 0.54s. S_Loss: 1.2161. T_Loss: 4.8969. Mask: 0.9250. :   5%|▌         | 5/100 [00:02<00:32,  2.92it/s]Train Iter: 606/5000. LR: 0.0379. Data: 0.32s. Batch: 0.48s. S_Loss: 1.1914. T_Loss: 4.7351. Mask: 0.9323. :   5%|▌         | 5/100 [00:02<00:32,  2.92it/s]Train Iter: 606/5000. LR: 0.0379. Data: 0.32s. Batch: 0.48s. S_Loss: 1.1914. T_Loss: 4.7351. Mask: 0.9323. :   6%|▌         | 6/100 [00:02<00:26,  3.57it/s]Train Iter: 607/5000. LR: 0.0379. Data: 0.27s. Batch: 0.43s. S_Loss: 1.1658. T_Loss: 4.7204. Mask: 0.9286. :   6%|▌         | 6/100 [00:03<00:26,  3.57it/s]Train Iter: 607/5000. LR: 0.0379. Data: 0.27s. Batch: 0.43s. S_Loss: 1.1658. T_Loss: 4.7204. Mask: 0.9286. :   7%|▋         | 7/100 [00:03<00:21,  4.33it/s]Train Iter: 608/5000. LR: 0.0380. Data: 0.24s. Batch: 0.39s. S_Loss: 1.1435. T_Loss: 4.6925. Mask: 0.9336. :   7%|▋         | 7/100 [00:03<00:21,  4.33it/s]Train Iter: 608/5000. LR: 0.0380. Data: 0.24s. Batch: 0.39s. S_Loss: 1.1435. T_Loss: 4.6925. Mask: 0.9336. :   8%|▊         | 8/100 [00:03<00:18,  4.97it/s]Train Iter: 609/5000. LR: 0.0381. Data: 0.21s. Batch: 0.36s. S_Loss: 1.1306. T_Loss: 4.6575. Mask: 0.9271. :   8%|▊         | 8/100 [00:03<00:18,  4.97it/s]Train Iter: 609/5000. LR: 0.0381. Data: 0.21s. Batch: 0.36s. S_Loss: 1.1306. T_Loss: 4.6575. Mask: 0.9271. :   9%|▉         | 9/100 [00:03<00:16,  5.63it/s]Train Iter: 610/5000. LR: 0.0381. Data: 0.19s. Batch: 0.36s. S_Loss: 1.1223. T_Loss: 4.5499. Mask: 0.9250. :   9%|▉         | 9/100 [00:03<00:16,  5.63it/s]Train Iter: 610/5000. LR: 0.0381. Data: 0.19s. Batch: 0.36s. S_Loss: 1.1223. T_Loss: 4.5499. Mask: 0.9250. :  10%|█         | 10/100 [00:03<00:21,  4.27it/s]Train Iter: 611/5000. LR: 0.0382. Data: 0.18s. Batch: 0.34s. S_Loss: 1.1235. T_Loss: 4.5945. Mask: 0.9233. :  10%|█         | 10/100 [00:03<00:21,  4.27it/s]Train Iter: 611/5000. LR: 0.0382. Data: 0.18s. Batch: 0.34s. S_Loss: 1.1235. T_Loss: 4.5945. Mask: 0.9233. :  11%|█         | 11/100 [00:03<00:17,  4.95it/s]Train Iter: 612/5000. LR: 0.0383. Data: 0.16s. Batch: 0.32s. S_Loss: 1.1436. T_Loss: 4.6459. Mask: 0.9297. :  11%|█         | 11/100 [00:03<00:17,  4.95it/s]Train Iter: 612/5000. LR: 0.0383. Data: 0.16s. Batch: 0.32s. S_Loss: 1.1436. T_Loss: 4.6459. Mask: 0.9297. :  12%|█▏        | 12/100 [00:03<00:15,  5.53it/s]Train Iter: 613/5000. LR: 0.0383. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1505. T_Loss: 4.6490. Mask: 0.9327. :  12%|█▏        | 12/100 [00:04<00:15,  5.53it/s]Train Iter: 613/5000. LR: 0.0383. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1505. T_Loss: 4.6490. Mask: 0.9327. :  13%|█▎        | 13/100 [00:04<00:14,  6.10it/s]Train Iter: 614/5000. LR: 0.0384. Data: 0.14s. Batch: 0.31s. S_Loss: 1.1494. T_Loss: 4.5761. Mask: 0.9219. :  13%|█▎        | 13/100 [00:04<00:14,  6.10it/s]Train Iter: 614/5000. LR: 0.0384. Data: 0.14s. Batch: 0.31s. S_Loss: 1.1494. T_Loss: 4.5761. Mask: 0.9219. :  14%|█▍        | 14/100 [00:04<00:18,  4.77it/s]Train Iter: 615/5000. LR: 0.0384. Data: 0.13s. Batch: 0.30s. S_Loss: 1.1678. T_Loss: 4.6898. Mask: 0.9229. :  14%|█▍        | 14/100 [00:04<00:18,  4.77it/s]Train Iter: 615/5000. LR: 0.0384. Data: 0.13s. Batch: 0.30s. S_Loss: 1.1678. T_Loss: 4.6898. Mask: 0.9229. :  15%|█▌        | 15/100 [00:04<00:15,  5.37it/s]Train Iter: 616/5000. LR: 0.0385. Data: 0.12s. Batch: 0.29s. S_Loss: 1.1832. T_Loss: 4.6342. Mask: 0.9219. :  15%|█▌        | 15/100 [00:04<00:15,  5.37it/s]Train Iter: 616/5000. LR: 0.0385. Data: 0.12s. Batch: 0.29s. S_Loss: 1.1832. T_Loss: 4.6342. Mask: 0.9219. :  16%|█▌        | 16/100 [00:04<00:14,  5.88it/s]Train Iter: 617/5000. LR: 0.0386. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1917. T_Loss: 4.6536. Mask: 0.9246. :  16%|█▌        | 16/100 [00:04<00:14,  5.88it/s]Train Iter: 617/5000. LR: 0.0386. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1917. T_Loss: 4.6536. Mask: 0.9246. :  17%|█▋        | 17/100 [00:04<00:12,  6.43it/s]Train Iter: 618/5000. LR: 0.0386. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1934. T_Loss: 4.6495. Mask: 0.9184. :  17%|█▋        | 17/100 [00:04<00:12,  6.43it/s]Train Iter: 618/5000. LR: 0.0386. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1934. T_Loss: 4.6495. Mask: 0.9184. :  18%|█▊        | 18/100 [00:04<00:12,  6.82it/s]Train Iter: 619/5000. LR: 0.0387. Data: 0.10s. Batch: 0.26s. S_Loss: 1.1914. T_Loss: 4.6248. Mask: 0.9194. :  18%|█▊        | 18/100 [00:04<00:12,  6.82it/s]Train Iter: 619/5000. LR: 0.0387. Data: 0.10s. Batch: 0.26s. S_Loss: 1.1914. T_Loss: 4.6248. Mask: 0.9194. :  19%|█▉        | 19/100 [00:04<00:10,  7.37it/s]Train Iter: 620/5000. LR: 0.0388. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1867. T_Loss: 4.6199. Mask: 0.9141. :  19%|█▉        | 19/100 [00:05<00:10,  7.37it/s]Train Iter: 620/5000. LR: 0.0388. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1867. T_Loss: 4.6199. Mask: 0.9141. :  20%|██        | 20/100 [00:05<00:10,  7.84it/s]Train Iter: 621/5000. LR: 0.0388. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1829. T_Loss: 4.6222. Mask: 0.9107. :  20%|██        | 20/100 [00:05<00:10,  7.84it/s]Train Iter: 622/5000. LR: 0.0389. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1774. T_Loss: 4.6293. Mask: 0.9134. :  21%|██        | 21/100 [00:05<00:10,  7.84it/s]Train Iter: 622/5000. LR: 0.0389. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1774. T_Loss: 4.6293. Mask: 0.9134. :  22%|██▏       | 22/100 [00:05<00:09,  8.18it/s]Train Iter: 623/5000. LR: 0.0389. Data: 0.09s. Batch: 0.23s. S_Loss: 1.1705. T_Loss: 4.6199. Mask: 0.9144. :  22%|██▏       | 22/100 [00:05<00:09,  8.18it/s]Train Iter: 623/5000. LR: 0.0389. Data: 0.09s. Batch: 0.23s. S_Loss: 1.1705. T_Loss: 4.6199. Mask: 0.9144. :  23%|██▎       | 23/100 [00:05<00:09,  8.27it/s]Train Iter: 624/5000. LR: 0.0390. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1628. T_Loss: 4.6360. Mask: 0.9167. :  23%|██▎       | 23/100 [00:05<00:09,  8.27it/s]Train Iter: 624/5000. LR: 0.0390. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1628. T_Loss: 4.6360. Mask: 0.9167. :  24%|██▍       | 24/100 [00:05<00:13,  5.50it/s]Train Iter: 625/5000. LR: 0.0391. Data: 0.08s. Batch: 0.23s. S_Loss: 1.1717. T_Loss: 4.6952. Mask: 0.9150. :  24%|██▍       | 24/100 [00:05<00:13,  5.50it/s]Train Iter: 625/5000. LR: 0.0391. Data: 0.08s. Batch: 0.23s. S_Loss: 1.1717. T_Loss: 4.6952. Mask: 0.9150. :  25%|██▌       | 25/100 [00:05<00:12,  6.02it/s]total : 5000  current step :  601
total : 5000  current step :  602
total : 5000  current step :  603
total : 5000  current step :  604
total : 5000  current step :  605
total : 5000  current step :  606
total : 5000  current step :  607
total : 5000  current step :  608
total : 5000  current step :  609
total : 5000  current step :  610
total : 5000  current step :  611
total : 5000  current step :  612
total : 5000  current step :  613
total : 5000  current step :  614
total : 5000  current step :  615
total : 5000  current step :  616
total : 5000  current step :  617
total : 5000  current step :  618
total : 5000  current step :  619
total : 5000  current step :  620
total : 5000  current step :  621
total : 5000  current step :  622
total : 5000  current step :  623
total : 5000  current step :  624
total : 5000  current step :  625
Train Iter: 626/5000. LR: 0.0391. Data: 0.22s. Batch: 0.37s. S_Loss: 1.1796. T_Loss: 4.7470. Mask: 0.9147. :  25%|██▌       | 25/100 [00:09<00:12,  6.02it/s]Train Iter: 626/5000. LR: 0.0391. Data: 0.22s. Batch: 0.37s. S_Loss: 1.1796. T_Loss: 4.7470. Mask: 0.9147. :  26%|██▌       | 26/100 [00:09<01:28,  1.20s/it]Train Iter: 627/5000. LR: 0.0392. Data: 0.21s. Batch: 0.37s. S_Loss: 1.1782. T_Loss: 4.7702. Mask: 0.9155. :  26%|██▌       | 26/100 [00:09<01:28,  1.20s/it]Train Iter: 627/5000. LR: 0.0392. Data: 0.21s. Batch: 0.37s. S_Loss: 1.1782. T_Loss: 4.7702. Mask: 0.9155. :  27%|██▋       | 27/100 [00:09<01:05,  1.11it/s]Train Iter: 628/5000. LR: 0.0393. Data: 0.20s. Batch: 0.36s. S_Loss: 1.1817. T_Loss: 4.7660. Mask: 0.9141. :  27%|██▋       | 27/100 [00:10<01:05,  1.11it/s]Train Iter: 628/5000. LR: 0.0393. Data: 0.20s. Batch: 0.36s. S_Loss: 1.1817. T_Loss: 4.7660. Mask: 0.9141. :  28%|██▊       | 28/100 [00:10<00:48,  1.47it/s]Train Iter: 629/5000. LR: 0.0393. Data: 0.20s. Batch: 0.35s. S_Loss: 1.1841. T_Loss: 4.7673. Mask: 0.9138. :  28%|██▊       | 28/100 [00:10<00:48,  1.47it/s]Train Iter: 629/5000. LR: 0.0393. Data: 0.20s. Batch: 0.35s. S_Loss: 1.1841. T_Loss: 4.7673. Mask: 0.9138. :  29%|██▉       | 29/100 [00:10<00:37,  1.90it/s]Train Iter: 630/5000. LR: 0.0394. Data: 0.19s. Batch: 0.35s. S_Loss: 1.1822. T_Loss: 4.7790. Mask: 0.9146. :  29%|██▉       | 29/100 [00:10<00:37,  1.90it/s]Train Iter: 630/5000. LR: 0.0394. Data: 0.19s. Batch: 0.35s. S_Loss: 1.1822. T_Loss: 4.7790. Mask: 0.9146. :  30%|███       | 30/100 [00:10<00:33,  2.08it/s]Train Iter: 631/5000. LR: 0.0394. Data: 0.19s. Batch: 0.34s. S_Loss: 1.1798. T_Loss: 4.7940. Mask: 0.9133. :  30%|███       | 30/100 [00:10<00:33,  2.08it/s]Train Iter: 631/5000. LR: 0.0394. Data: 0.19s. Batch: 0.34s. S_Loss: 1.1798. T_Loss: 4.7940. Mask: 0.9133. :  31%|███       | 31/100 [00:10<00:25,  2.70it/s]Train Iter: 632/5000. LR: 0.0395. Data: 0.18s. Batch: 0.34s. S_Loss: 1.1783. T_Loss: 4.8158. Mask: 0.9141. :  31%|███       | 31/100 [00:10<00:25,  2.70it/s]Train Iter: 632/5000. LR: 0.0395. Data: 0.18s. Batch: 0.34s. S_Loss: 1.1783. T_Loss: 4.8158. Mask: 0.9141. :  32%|███▏      | 32/100 [00:10<00:20,  3.40it/s]Train Iter: 633/5000. LR: 0.0396. Data: 0.17s. Batch: 0.33s. S_Loss: 1.1779. T_Loss: 4.8626. Mask: 0.9138. :  32%|███▏      | 32/100 [00:10<00:20,  3.40it/s]Train Iter: 633/5000. LR: 0.0396. Data: 0.17s. Batch: 0.33s. S_Loss: 1.1779. T_Loss: 4.8626. Mask: 0.9138. :  33%|███▎      | 33/100 [00:10<00:16,  4.16it/s]Train Iter: 634/5000. LR: 0.0396. Data: 0.17s. Batch: 0.32s. S_Loss: 1.1733. T_Loss: 4.8614. Mask: 0.9118. :  33%|███▎      | 33/100 [00:11<00:16,  4.16it/s]Train Iter: 634/5000. LR: 0.0396. Data: 0.17s. Batch: 0.32s. S_Loss: 1.1733. T_Loss: 4.8614. Mask: 0.9118. :  34%|███▍      | 34/100 [00:11<00:13,  4.87it/s]Train Iter: 635/5000. LR: 0.0397. Data: 0.16s. Batch: 0.32s. S_Loss: 1.1715. T_Loss: 4.8657. Mask: 0.9089. :  34%|███▍      | 34/100 [00:11<00:13,  4.87it/s]Train Iter: 635/5000. LR: 0.0397. Data: 0.16s. Batch: 0.32s. S_Loss: 1.1715. T_Loss: 4.8657. Mask: 0.9089. :  35%|███▌      | 35/100 [00:11<00:11,  5.61it/s]Train Iter: 636/5000. LR: 0.0398. Data: 0.16s. Batch: 0.31s. S_Loss: 1.1674. T_Loss: 4.8839. Mask: 0.9106. :  35%|███▌      | 35/100 [00:11<00:11,  5.61it/s]Train Iter: 636/5000. LR: 0.0398. Data: 0.16s. Batch: 0.31s. S_Loss: 1.1674. T_Loss: 4.8839. Mask: 0.9106. :  36%|███▌      | 36/100 [00:11<00:10,  6.15it/s]Train Iter: 637/5000. LR: 0.0398. Data: 0.16s. Batch: 0.31s. S_Loss: 1.1681. T_Loss: 4.8929. Mask: 0.9088. :  36%|███▌      | 36/100 [00:11<00:10,  6.15it/s]Train Iter: 638/5000. LR: 0.0399. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1685. T_Loss: 4.9004. Mask: 0.9079. :  37%|███▋      | 37/100 [00:11<00:10,  6.15it/s]Train Iter: 638/5000. LR: 0.0399. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1685. T_Loss: 4.9004. Mask: 0.9079. :  38%|███▊      | 38/100 [00:11<00:08,  7.30it/s]Train Iter: 639/5000. LR: 0.0399. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1652. T_Loss: 4.8952. Mask: 0.9046. :  38%|███▊      | 38/100 [00:11<00:08,  7.30it/s]Train Iter: 639/5000. LR: 0.0399. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1652. T_Loss: 4.8952. Mask: 0.9046. :  39%|███▉      | 39/100 [00:11<00:08,  7.27it/s]Train Iter: 640/5000. LR: 0.0400. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1683. T_Loss: 4.8933. Mask: 0.9023. :  39%|███▉      | 39/100 [00:11<00:08,  7.27it/s]Train Iter: 640/5000. LR: 0.0400. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1683. T_Loss: 4.8933. Mask: 0.9023. :  40%|████      | 40/100 [00:11<00:09,  6.30it/s]Train Iter: 641/5000. LR: 0.0401. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1715. T_Loss: 4.8833. Mask: 0.9009. :  40%|████      | 40/100 [00:11<00:09,  6.30it/s]Train Iter: 641/5000. LR: 0.0401. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1715. T_Loss: 4.8833. Mask: 0.9009. :  41%|████      | 41/100 [00:11<00:09,  6.46it/s]Train Iter: 642/5000. LR: 0.0401. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1725. T_Loss: 4.8757. Mask: 0.9010. :  41%|████      | 41/100 [00:12<00:09,  6.46it/s]Train Iter: 642/5000. LR: 0.0401. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1725. T_Loss: 4.8757. Mask: 0.9010. :  42%|████▏     | 42/100 [00:12<00:08,  6.50it/s]Train Iter: 643/5000. LR: 0.0402. Data: 0.14s. Batch: 0.28s. S_Loss: 1.1735. T_Loss: 4.8649. Mask: 0.9012. :  42%|████▏     | 42/100 [00:12<00:08,  6.50it/s]Train Iter: 643/5000. LR: 0.0402. Data: 0.14s. Batch: 0.28s. S_Loss: 1.1735. T_Loss: 4.8649. Mask: 0.9012. :  43%|████▎     | 43/100 [00:12<00:08,  6.91it/s]Train Iter: 644/5000. LR: 0.0403. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1714. T_Loss: 4.8259. Mask: 0.8999. :  43%|████▎     | 43/100 [00:12<00:08,  6.91it/s]Train Iter: 644/5000. LR: 0.0403. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1714. T_Loss: 4.8259. Mask: 0.8999. :  44%|████▍     | 44/100 [00:12<00:11,  4.80it/s]Train Iter: 645/5000. LR: 0.0403. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1687. T_Loss: 4.7930. Mask: 0.9000. :  44%|████▍     | 44/100 [00:12<00:11,  4.80it/s]Train Iter: 645/5000. LR: 0.0403. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1687. T_Loss: 4.7930. Mask: 0.9000. :  45%|████▌     | 45/100 [00:12<00:10,  5.48it/s]Train Iter: 646/5000. LR: 0.0404. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1628. T_Loss: 4.7677. Mask: 0.9022. :  45%|████▌     | 45/100 [00:12<00:10,  5.48it/s]Train Iter: 646/5000. LR: 0.0404. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1628. T_Loss: 4.7677. Mask: 0.9022. :  46%|████▌     | 46/100 [00:12<00:08,  6.07it/s]Train Iter: 647/5000. LR: 0.0404. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1564. T_Loss: 4.7601. Mask: 0.9043. :  46%|████▌     | 46/100 [00:12<00:08,  6.07it/s]Train Iter: 647/5000. LR: 0.0404. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1564. T_Loss: 4.7601. Mask: 0.9043. :  47%|████▋     | 47/100 [00:12<00:07,  6.64it/s]Train Iter: 648/5000. LR: 0.0405. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1505. T_Loss: 4.7387. Mask: 0.9056. :  47%|████▋     | 47/100 [00:13<00:07,  6.64it/s]Train Iter: 648/5000. LR: 0.0405. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1505. T_Loss: 4.7387. Mask: 0.9056. :  48%|████▊     | 48/100 [00:13<00:07,  7.03it/s]Train Iter: 649/5000. LR: 0.0406. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1444. T_Loss: 4.7158. Mask: 0.9062. :  48%|████▊     | 48/100 [00:13<00:07,  7.03it/s]Train Iter: 649/5000. LR: 0.0406. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1444. T_Loss: 4.7158. Mask: 0.9062. :  49%|████▉     | 49/100 [00:13<00:06,  7.45it/s]Train Iter: 650/5000. LR: 0.0406. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1386. T_Loss: 4.7116. Mask: 0.9069. :  49%|████▉     | 49/100 [00:13<00:06,  7.45it/s]Train Iter: 650/5000. LR: 0.0406. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1386. T_Loss: 4.7116. Mask: 0.9069. :  50%|█████     | 50/100 [00:13<00:06,  7.47it/s]total : 5000  current step :  626
total : 5000  current step :  627
total : 5000  current step :  628
total : 5000  current step :  629
total : 5000  current step :  630
total : 5000  current step :  631
total : 5000  current step :  632
total : 5000  current step :  633
total : 5000  current step :  634
total : 5000  current step :  635
total : 5000  current step :  636
total : 5000  current step :  637
total : 5000  current step :  638
total : 5000  current step :  639
total : 5000  current step :  640
total : 5000  current step :  641
total : 5000  current step :  642
total : 5000  current step :  643
total : 5000  current step :  644
total : 5000  current step :  645
total : 5000  current step :  646
total : 5000  current step :  647
total : 5000  current step :  648
total : 5000  current step :  649
total : 5000  current step :  650
Train Iter: 651/5000. LR: 0.0407. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1393. T_Loss: 4.7060. Mask: 0.9075. :  50%|█████     | 50/100 [00:15<00:06,  7.47it/s]Train Iter: 651/5000. LR: 0.0407. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1393. T_Loss: 4.7060. Mask: 0.9075. :  51%|█████     | 51/100 [00:15<00:33,  1.47it/s]Train Iter: 652/5000. LR: 0.0408. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1406. T_Loss: 4.7148. Mask: 0.9087. :  51%|█████     | 51/100 [00:15<00:33,  1.47it/s]Train Iter: 652/5000. LR: 0.0408. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1406. T_Loss: 4.7148. Mask: 0.9087. :  52%|█████▏    | 52/100 [00:15<00:24,  1.96it/s]Train Iter: 653/5000. LR: 0.0408. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1406. T_Loss: 4.7057. Mask: 0.9068. :  52%|█████▏    | 52/100 [00:15<00:24,  1.96it/s]Train Iter: 653/5000. LR: 0.0408. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1406. T_Loss: 4.7057. Mask: 0.9068. :  53%|█████▎    | 53/100 [00:15<00:18,  2.54it/s]Train Iter: 654/5000. LR: 0.0409. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1468. T_Loss: 4.7139. Mask: 0.9074. :  53%|█████▎    | 53/100 [00:15<00:18,  2.54it/s]Train Iter: 654/5000. LR: 0.0409. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1468. T_Loss: 4.7139. Mask: 0.9074. :  54%|█████▍    | 54/100 [00:15<00:14,  3.15it/s]Train Iter: 655/5000. LR: 0.0409. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1535. T_Loss: 4.7198. Mask: 0.9068. :  54%|█████▍    | 54/100 [00:16<00:14,  3.15it/s]Train Iter: 655/5000. LR: 0.0409. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1535. T_Loss: 4.7198. Mask: 0.9068. :  55%|█████▌    | 55/100 [00:16<00:15,  2.82it/s]Train Iter: 656/5000. LR: 0.0410. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1581. T_Loss: 4.7504. Mask: 0.9068. :  55%|█████▌    | 55/100 [00:16<00:15,  2.82it/s]Train Iter: 656/5000. LR: 0.0410. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1581. T_Loss: 4.7504. Mask: 0.9068. :  56%|█████▌    | 56/100 [00:16<00:12,  3.47it/s]Train Iter: 657/5000. LR: 0.0411. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1703. T_Loss: 4.7644. Mask: 0.9068. :  56%|█████▌    | 56/100 [00:16<00:12,  3.47it/s]Train Iter: 657/5000. LR: 0.0411. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1703. T_Loss: 4.7644. Mask: 0.9068. :  57%|█████▋    | 57/100 [00:16<00:10,  4.19it/s]Train Iter: 658/5000. LR: 0.0411. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1784. T_Loss: 4.7760. Mask: 0.9062. :  57%|█████▋    | 57/100 [00:16<00:10,  4.19it/s]Train Iter: 658/5000. LR: 0.0411. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1784. T_Loss: 4.7760. Mask: 0.9062. :  58%|█████▊    | 58/100 [00:16<00:08,  5.05it/s]Train Iter: 659/5000. LR: 0.0412. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1829. T_Loss: 4.7672. Mask: 0.9062. :  58%|█████▊    | 58/100 [00:16<00:08,  5.05it/s]Train Iter: 659/5000. LR: 0.0412. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1829. T_Loss: 4.7672. Mask: 0.9062. :  59%|█████▉    | 59/100 [00:16<00:07,  5.58it/s]Train Iter: 660/5000. LR: 0.0413. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1861. T_Loss: 4.7981. Mask: 0.9068. :  59%|█████▉    | 59/100 [00:16<00:07,  5.58it/s]Train Iter: 660/5000. LR: 0.0413. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1861. T_Loss: 4.7981. Mask: 0.9068. :  60%|██████    | 60/100 [00:16<00:06,  6.13it/s]Train Iter: 661/5000. LR: 0.0413. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1881. T_Loss: 4.7805. Mask: 0.9073. :  60%|██████    | 60/100 [00:16<00:06,  6.13it/s]Train Iter: 661/5000. LR: 0.0413. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1881. T_Loss: 4.7805. Mask: 0.9073. :  61%|██████    | 61/100 [00:16<00:05,  6.80it/s]Train Iter: 662/5000. LR: 0.0414. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1909. T_Loss: 4.7843. Mask: 0.9068. :  61%|██████    | 61/100 [00:16<00:05,  6.80it/s]Train Iter: 662/5000. LR: 0.0414. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1909. T_Loss: 4.7843. Mask: 0.9068. :  62%|██████▏   | 62/100 [00:16<00:05,  7.28it/s]Train Iter: 663/5000. LR: 0.0414. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1916. T_Loss: 4.7680. Mask: 0.9067. :  62%|██████▏   | 62/100 [00:17<00:05,  7.28it/s]Train Iter: 663/5000. LR: 0.0414. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1916. T_Loss: 4.7680. Mask: 0.9067. :  63%|██████▎   | 63/100 [00:17<00:04,  7.70it/s]Train Iter: 664/5000. LR: 0.0415. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1928. T_Loss: 4.7754. Mask: 0.9072. :  63%|██████▎   | 63/100 [00:17<00:04,  7.70it/s]Train Iter: 664/5000. LR: 0.0415. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1928. T_Loss: 4.7754. Mask: 0.9072. :  64%|██████▍   | 64/100 [00:17<00:04,  8.14it/s]Train Iter: 665/5000. LR: 0.0416. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1933. T_Loss: 4.7839. Mask: 0.9087. :  64%|██████▍   | 64/100 [00:17<00:04,  8.14it/s]Train Iter: 665/5000. LR: 0.0416. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1933. T_Loss: 4.7839. Mask: 0.9087. :  65%|██████▌   | 65/100 [00:17<00:06,  5.63it/s]Train Iter: 666/5000. LR: 0.0416. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1932. T_Loss: 4.7681. Mask: 0.9081. :  65%|██████▌   | 65/100 [00:17<00:06,  5.63it/s]Train Iter: 666/5000. LR: 0.0416. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1932. T_Loss: 4.7681. Mask: 0.9081. :  66%|██████▌   | 66/100 [00:17<00:05,  6.23it/s]Train Iter: 667/5000. LR: 0.0417. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1927. T_Loss: 4.7706. Mask: 0.9090. :  66%|██████▌   | 66/100 [00:17<00:05,  6.23it/s]Train Iter: 667/5000. LR: 0.0417. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1927. T_Loss: 4.7706. Mask: 0.9090. :  67%|██████▋   | 67/100 [00:17<00:04,  6.89it/s]Train Iter: 668/5000. LR: 0.0418. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1918. T_Loss: 4.7710. Mask: 0.9095. :  67%|██████▋   | 67/100 [00:17<00:04,  6.89it/s]Train Iter: 668/5000. LR: 0.0418. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1918. T_Loss: 4.7710. Mask: 0.9095. :  68%|██████▊   | 68/100 [00:17<00:04,  7.34it/s]Train Iter: 669/5000. LR: 0.0418. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1910. T_Loss: 4.7710. Mask: 0.9085. :  68%|██████▊   | 68/100 [00:18<00:04,  7.34it/s]Train Iter: 669/5000. LR: 0.0418. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1910. T_Loss: 4.7710. Mask: 0.9085. :  69%|██████▉   | 69/100 [00:18<00:06,  4.74it/s]Train Iter: 670/5000. LR: 0.0419. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1916. T_Loss: 4.7610. Mask: 0.9080. :  69%|██████▉   | 69/100 [00:18<00:06,  4.74it/s]Train Iter: 670/5000. LR: 0.0419. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1916. T_Loss: 4.7610. Mask: 0.9080. :  70%|███████   | 70/100 [00:18<00:05,  5.54it/s]Train Iter: 671/5000. LR: 0.0419. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1901. T_Loss: 4.7692. Mask: 0.9085. :  70%|███████   | 70/100 [00:18<00:05,  5.54it/s]Train Iter: 671/5000. LR: 0.0419. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1901. T_Loss: 4.7692. Mask: 0.9085. :  71%|███████   | 71/100 [00:18<00:04,  6.12it/s]Train Iter: 672/5000. LR: 0.0420. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1898. T_Loss: 4.7779. Mask: 0.9084. :  71%|███████   | 71/100 [00:18<00:04,  6.12it/s]Train Iter: 672/5000. LR: 0.0420. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1898. T_Loss: 4.7779. Mask: 0.9084. :  72%|███████▏  | 72/100 [00:18<00:04,  6.54it/s]Train Iter: 673/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1886. T_Loss: 4.7805. Mask: 0.9084. :  72%|███████▏  | 72/100 [00:18<00:04,  6.54it/s]Train Iter: 673/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1886. T_Loss: 4.7805. Mask: 0.9084. :  73%|███████▎  | 73/100 [00:18<00:03,  7.11it/s]Train Iter: 674/5000. LR: 0.0421. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1886. T_Loss: 4.7757. Mask: 0.9084. :  73%|███████▎  | 73/100 [00:18<00:03,  7.11it/s]Train Iter: 674/5000. LR: 0.0421. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1886. T_Loss: 4.7757. Mask: 0.9084. :  74%|███████▍  | 74/100 [00:18<00:03,  7.59it/s]Train Iter: 675/5000. LR: 0.0422. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1883. T_Loss: 4.7864. Mask: 0.9087. :  74%|███████▍  | 74/100 [00:18<00:03,  7.59it/s]Train Iter: 675/5000. LR: 0.0422. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1883. T_Loss: 4.7864. Mask: 0.9087. :  75%|███████▌  | 75/100 [00:18<00:03,  7.85it/s]total : 5000  current step :  651
total : 5000  current step :  652
total : 5000  current step :  653
total : 5000  current step :  654
total : 5000  current step :  655
total : 5000  current step :  656
total : 5000  current step :  657
total : 5000  current step :  658
total : 5000  current step :  659
total : 5000  current step :  660
total : 5000  current step :  661
total : 5000  current step :  662
total : 5000  current step :  663
total : 5000  current step :  664
total : 5000  current step :  665
total : 5000  current step :  666
total : 5000  current step :  667
total : 5000  current step :  668
total : 5000  current step :  669
total : 5000  current step :  670
total : 5000  current step :  671
total : 5000  current step :  672
total : 5000  current step :  673
total : 5000  current step :  674
total : 5000  current step :  675
Train Iter: 676/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1862. T_Loss: 4.7855. Mask: 0.9075. :  75%|███████▌  | 75/100 [00:20<00:03,  7.85it/s]Train Iter: 676/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1862. T_Loss: 4.7855. Mask: 0.9075. :  76%|███████▌  | 76/100 [00:20<00:15,  1.52it/s]Train Iter: 677/5000. LR: 0.0423. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1853. T_Loss: 4.7831. Mask: 0.9067. :  76%|███████▌  | 76/100 [00:20<00:15,  1.52it/s]Train Iter: 677/5000. LR: 0.0423. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1853. T_Loss: 4.7831. Mask: 0.9067. :  77%|███████▋  | 77/100 [00:20<00:11,  2.03it/s]Train Iter: 678/5000. LR: 0.0424. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1839. T_Loss: 4.7808. Mask: 0.9058. :  77%|███████▋  | 77/100 [00:21<00:11,  2.03it/s]Train Iter: 678/5000. LR: 0.0424. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1839. T_Loss: 4.7808. Mask: 0.9058. :  78%|███████▊  | 78/100 [00:21<00:08,  2.65it/s]Train Iter: 679/5000. LR: 0.0424. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1830. T_Loss: 4.7801. Mask: 0.9055. :  78%|███████▊  | 78/100 [00:21<00:08,  2.65it/s]Train Iter: 679/5000. LR: 0.0424. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1830. T_Loss: 4.7801. Mask: 0.9055. :  79%|███████▉  | 79/100 [00:21<00:06,  3.28it/s]Train Iter: 680/5000. LR: 0.0425. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1811. T_Loss: 4.7826. Mask: 0.9055. :  79%|███████▉  | 79/100 [00:21<00:06,  3.28it/s]Train Iter: 680/5000. LR: 0.0425. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1811. T_Loss: 4.7826. Mask: 0.9055. :  80%|████████  | 80/100 [00:21<00:04,  4.09it/s]Train Iter: 681/5000. LR: 0.0426. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1797. T_Loss: 4.7770. Mask: 0.9055. :  80%|████████  | 80/100 [00:21<00:04,  4.09it/s]Train Iter: 682/5000. LR: 0.0426. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1791. T_Loss: 4.7854. Mask: 0.9062. :  81%|████████  | 81/100 [00:21<00:04,  4.09it/s]Train Iter: 682/5000. LR: 0.0426. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1791. T_Loss: 4.7854. Mask: 0.9062. :  82%|████████▏ | 82/100 [00:21<00:03,  5.55it/s]Train Iter: 683/5000. LR: 0.0427. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1775. T_Loss: 4.7857. Mask: 0.9070. :  82%|████████▏ | 82/100 [00:21<00:03,  5.55it/s]Train Iter: 683/5000. LR: 0.0427. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1775. T_Loss: 4.7857. Mask: 0.9070. :  83%|████████▎ | 83/100 [00:21<00:02,  6.10it/s]Train Iter: 684/5000. LR: 0.0428. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1772. T_Loss: 4.7905. Mask: 0.9077. :  83%|████████▎ | 83/100 [00:21<00:02,  6.10it/s]Train Iter: 684/5000. LR: 0.0428. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1772. T_Loss: 4.7905. Mask: 0.9077. :  84%|████████▍ | 84/100 [00:21<00:02,  6.44it/s]Train Iter: 685/5000. LR: 0.0428. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1766. T_Loss: 4.7857. Mask: 0.9081. :  84%|████████▍ | 84/100 [00:22<00:02,  6.44it/s]Train Iter: 685/5000. LR: 0.0428. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1766. T_Loss: 4.7857. Mask: 0.9081. :  85%|████████▌ | 85/100 [00:22<00:02,  5.08it/s]Train Iter: 686/5000. LR: 0.0429. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1749. T_Loss: 4.7821. Mask: 0.9088. :  85%|████████▌ | 85/100 [00:22<00:02,  5.08it/s]Train Iter: 686/5000. LR: 0.0429. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1749. T_Loss: 4.7821. Mask: 0.9088. :  86%|████████▌ | 86/100 [00:22<00:02,  5.54it/s]Train Iter: 687/5000. LR: 0.0429. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1735. T_Loss: 4.7767. Mask: 0.9095. :  86%|████████▌ | 86/100 [00:22<00:02,  5.54it/s]Train Iter: 687/5000. LR: 0.0429. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1735. T_Loss: 4.7767. Mask: 0.9095. :  87%|████████▋ | 87/100 [00:22<00:02,  5.96it/s]Train Iter: 688/5000. LR: 0.0430. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1721. T_Loss: 4.7651. Mask: 0.9087. :  87%|████████▋ | 87/100 [00:22<00:02,  5.96it/s]Train Iter: 688/5000. LR: 0.0430. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1721. T_Loss: 4.7651. Mask: 0.9087. :  88%|████████▊ | 88/100 [00:22<00:01,  6.48it/s]Train Iter: 689/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1715. T_Loss: 4.7589. Mask: 0.9080. :  88%|████████▊ | 88/100 [00:22<00:01,  6.48it/s]Train Iter: 689/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1715. T_Loss: 4.7589. Mask: 0.9080. :  89%|████████▉ | 89/100 [00:22<00:02,  4.86it/s]Train Iter: 690/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1702. T_Loss: 4.7545. Mask: 0.9083. :  89%|████████▉ | 89/100 [00:22<00:02,  4.86it/s]Train Iter: 690/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1702. T_Loss: 4.7545. Mask: 0.9083. :  90%|█████████ | 90/100 [00:22<00:01,  5.53it/s]Train Iter: 691/5000. LR: 0.0432. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1688. T_Loss: 4.7465. Mask: 0.9090. :  90%|█████████ | 90/100 [00:23<00:01,  5.53it/s]Train Iter: 691/5000. LR: 0.0432. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1688. T_Loss: 4.7465. Mask: 0.9090. :  91%|█████████ | 91/100 [00:23<00:01,  5.92it/s]Train Iter: 692/5000. LR: 0.0433. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1674. T_Loss: 4.7378. Mask: 0.9096. :  91%|█████████ | 91/100 [00:23<00:01,  5.92it/s]Train Iter: 692/5000. LR: 0.0433. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1674. T_Loss: 4.7378. Mask: 0.9096. :  92%|█████████▏| 92/100 [00:23<00:01,  6.35it/s]Train Iter: 693/5000. LR: 0.0433. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1658. T_Loss: 4.7297. Mask: 0.9096. :  92%|█████████▏| 92/100 [00:23<00:01,  6.35it/s]Train Iter: 693/5000. LR: 0.0433. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1658. T_Loss: 4.7297. Mask: 0.9096. :  93%|█████████▎| 93/100 [00:23<00:01,  6.71it/s]Train Iter: 694/5000. LR: 0.0434. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1637. T_Loss: 4.7229. Mask: 0.9099. :  93%|█████████▎| 93/100 [00:23<00:01,  6.71it/s]Train Iter: 694/5000. LR: 0.0434. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1637. T_Loss: 4.7229. Mask: 0.9099. :  94%|█████████▍| 94/100 [00:23<00:00,  7.01it/s]Train Iter: 695/5000. LR: 0.0434. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1618. T_Loss: 4.7251. Mask: 0.9099. :  94%|█████████▍| 94/100 [00:23<00:00,  7.01it/s]Train Iter: 695/5000. LR: 0.0434. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1618. T_Loss: 4.7251. Mask: 0.9099. :  95%|█████████▌| 95/100 [00:23<00:00,  7.19it/s]Train Iter: 696/5000. LR: 0.0435. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1623. T_Loss: 4.7403. Mask: 0.9105. :  95%|█████████▌| 95/100 [00:23<00:00,  7.19it/s]Train Iter: 696/5000. LR: 0.0435. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1623. T_Loss: 4.7403. Mask: 0.9105. :  96%|█████████▌| 96/100 [00:23<00:00,  7.48it/s]Train Iter: 697/5000. LR: 0.0436. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1611. T_Loss: 4.7394. Mask: 0.9098. :  96%|█████████▌| 96/100 [00:23<00:00,  7.48it/s]Train Iter: 697/5000. LR: 0.0436. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1611. T_Loss: 4.7394. Mask: 0.9098. :  97%|█████████▋| 97/100 [00:23<00:00,  7.58it/s]Train Iter: 698/5000. LR: 0.0436. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1595. T_Loss: 4.7412. Mask: 0.9101. :  97%|█████████▋| 97/100 [00:23<00:00,  7.58it/s]Train Iter: 698/5000. LR: 0.0436. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1595. T_Loss: 4.7412. Mask: 0.9101. :  98%|█████████▊| 98/100 [00:23<00:00,  7.65it/s]Train Iter: 699/5000. LR: 0.0437. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1584. T_Loss: 4.7438. Mask: 0.9097. :  98%|█████████▊| 98/100 [00:24<00:00,  7.65it/s]Train Iter: 699/5000. LR: 0.0437. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1584. T_Loss: 4.7438. Mask: 0.9097. :  99%|█████████▉| 99/100 [00:24<00:00,  5.51it/s]Train Iter: 700/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1566. T_Loss: 4.7427. Mask: 0.9094. :  99%|█████████▉| 99/100 [00:24<00:00,  5.51it/s]Train Iter: 700/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1566. T_Loss: 4.7427. Mask: 0.9094. : 100%|██████████| 100/100 [00:24<00:00,  5.97it/s]Train Iter: 700/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1566. T_Loss: 4.7427. Mask: 0.9094. : 100%|██████████| 100/100 [00:24<00:00,  4.10it/s]
total : 5000  current step :  676
total : 5000  current step :  677
total : 5000  current step :  678
total : 5000  current step :  679
total : 5000  current step :  680
total : 5000  current step :  681
total : 5000  current step :  682
total : 5000  current step :  683
total : 5000  current step :  684
total : 5000  current step :  685
total : 5000  current step :  686
total : 5000  current step :  687
total : 5000  current step :  688
total : 5000  current step :  689
total : 5000  current step :  690
total : 5000  current step :  691
total : 5000  current step :  692
total : 5000  current step :  693
total : 5000  current step :  694
total : 5000  current step :  695
total : 5000  current step :  696
total : 5000  current step :  697
total : 5000  current step :  698
total : 5000  current step :  699
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.87s. Loss: 1.0611. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.87s. Loss: 1.0611. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 1.0330. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 1.0106. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 1.0317. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 1.0205. top1: 88.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 1.0266. top1: 88.02. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 1.0278. top1: 88.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.0291. top1: 88.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.0210. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.0245. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.0196. top1: 90.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.0196. top1: 90.06. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.58it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.0239. top1: 89.58. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.58it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0208. top1: 89.42. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.58it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0222. top1: 89.29. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.58it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0156. top1: 89.79. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.58it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0121. top1: 90.04. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.58it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0112. top1: 90.07. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.58it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0112. top1: 90.07. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0113. top1: 90.45. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0117. top1: 90.46. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0127. top1: 90.47. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0143. top1: 90.62. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0140. top1: 90.77. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0134. top1: 91.03. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0122. top1: 91.02. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0121. top1: 90.88. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0130. top1: 90.50. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0129. top1: 90.86. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0141. top1: 90.74. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0157. top1: 90.52. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.33it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0157. top1: 90.52. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0155. top1: 90.42. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0162. top1: 90.02. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0332. top1: 88.38. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0519. top1: 86.84. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0747. top1: 85.11. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0893. top1: 84.02. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1164. top1: 82.20. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1295. top1: 80.83. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1445. top1: 79.36. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1636. top1: 78.12. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1742. top1: 77.03. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1870. top1: 76.07. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.68it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1870. top1: 76.07. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1977. top1: 75.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2075. top1: 73.84. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2159. top1: 72.87. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2285. top1: 71.88. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2388. top1: 71.20. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2496. top1: 70.28. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2623. top1: 69.47. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2733. top1: 68.49. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2828. top1: 67.56. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2982. top1: 66.48. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.69it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2982. top1: 66.48. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3057. top1: 65.50. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3116. top1: 65.39. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3195. top1: 64.64. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3274. top1: 64.09. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3306. top1: 63.73. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3422. top1: 62.99. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3492. top1: 62.50. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3568. top1: 61.92. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3625. top1: 61.51. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3713. top1: 60.96. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3818. top1: 60.28. top5: 100.00. :  81%|████████  | 51/63 [00:02<00:00, 46.57it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3818. top1: 60.28. top5: 100.00. :  98%|█████████▊| 62/63 [00:02<00:00, 56.25it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3870. top1: 60.05. top5: 100.00. :  98%|█████████▊| 62/63 [00:02<00:00, 56.25it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.3870. top1: 60.05. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 22.96it/s]
total : 5000  current step :  700
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 701/5000. LR: 0.0438. Data: 2.02s. Batch: 2.17s. S_Loss: 1.0497. T_Loss: 4.1699. Mask: 0.8438. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 701/5000. LR: 0.0438. Data: 2.02s. Batch: 2.17s. S_Loss: 1.0497. T_Loss: 4.1699. Mask: 0.8438. :   1%|          | 1/100 [00:02<03:34,  2.17s/it]Train Iter: 702/5000. LR: 0.0439. Data: 1.01s. Batch: 1.15s. S_Loss: 1.0051. T_Loss: 4.7987. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:34,  2.17s/it]Train Iter: 702/5000. LR: 0.0439. Data: 1.01s. Batch: 1.15s. S_Loss: 1.0051. T_Loss: 4.7987. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:35,  1.03it/s]Train Iter: 703/5000. LR: 0.0439. Data: 0.68s. Batch: 0.81s. S_Loss: 1.0379. T_Loss: 4.4712. Mask: 0.8854. :   2%|▏         | 2/100 [00:02<01:35,  1.03it/s]Train Iter: 703/5000. LR: 0.0439. Data: 0.68s. Batch: 0.81s. S_Loss: 1.0379. T_Loss: 4.4712. Mask: 0.8854. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 704/5000. LR: 0.0440. Data: 0.51s. Batch: 0.64s. S_Loss: 1.0177. T_Loss: 4.4785. Mask: 0.8906. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 704/5000. LR: 0.0440. Data: 0.51s. Batch: 0.64s. S_Loss: 1.0177. T_Loss: 4.4785. Mask: 0.8906. :   4%|▍         | 4/100 [00:02<00:39,  2.46it/s]Train Iter: 705/5000. LR: 0.0441. Data: 0.41s. Batch: 0.57s. S_Loss: 0.9978. T_Loss: 4.5645. Mask: 0.8938. :   4%|▍         | 4/100 [00:02<00:39,  2.46it/s]Train Iter: 705/5000. LR: 0.0441. Data: 0.41s. Batch: 0.57s. S_Loss: 0.9978. T_Loss: 4.5645. Mask: 0.8938. :   5%|▌         | 5/100 [00:02<00:34,  2.73it/s]Train Iter: 706/5000. LR: 0.0441. Data: 0.34s. Batch: 0.49s. S_Loss: 1.0114. T_Loss: 4.8181. Mask: 0.9010. :   5%|▌         | 5/100 [00:02<00:34,  2.73it/s]Train Iter: 707/5000. LR: 0.0442. Data: 0.29s. Batch: 0.43s. S_Loss: 1.0210. T_Loss: 4.8803. Mask: 0.9062. :   6%|▌         | 6/100 [00:03<00:34,  2.73it/s]Train Iter: 707/5000. LR: 0.0442. Data: 0.29s. Batch: 0.43s. S_Loss: 1.0210. T_Loss: 4.8803. Mask: 0.9062. :   7%|▋         | 7/100 [00:03<00:20,  4.43it/s]Train Iter: 708/5000. LR: 0.0443. Data: 0.26s. Batch: 0.39s. S_Loss: 1.0411. T_Loss: 4.9109. Mask: 0.8984. :   7%|▋         | 7/100 [00:03<00:20,  4.43it/s]Train Iter: 709/5000. LR: 0.0443. Data: 0.23s. Batch: 0.38s. S_Loss: 1.0392. T_Loss: 4.9057. Mask: 0.8993. :   8%|▊         | 8/100 [00:03<00:20,  4.43it/s]Train Iter: 709/5000. LR: 0.0443. Data: 0.23s. Batch: 0.38s. S_Loss: 1.0392. T_Loss: 4.9057. Mask: 0.8993. :   9%|▉         | 9/100 [00:03<00:18,  4.80it/s]Train Iter: 710/5000. LR: 0.0444. Data: 0.21s. Batch: 0.35s. S_Loss: 1.0456. T_Loss: 4.9655. Mask: 0.8938. :   9%|▉         | 9/100 [00:03<00:18,  4.80it/s]Train Iter: 710/5000. LR: 0.0444. Data: 0.21s. Batch: 0.35s. S_Loss: 1.0456. T_Loss: 4.9655. Mask: 0.8938. :  10%|█         | 10/100 [00:03<00:17,  5.26it/s]Train Iter: 711/5000. LR: 0.0444. Data: 0.19s. Batch: 0.33s. S_Loss: 1.0516. T_Loss: 4.8709. Mask: 0.8864. :  10%|█         | 10/100 [00:03<00:17,  5.26it/s]Train Iter: 711/5000. LR: 0.0444. Data: 0.19s. Batch: 0.33s. S_Loss: 1.0516. T_Loss: 4.8709. Mask: 0.8864. :  11%|█         | 11/100 [00:03<00:15,  5.64it/s]Train Iter: 712/5000. LR: 0.0445. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0567. T_Loss: 4.9118. Mask: 0.8880. :  11%|█         | 11/100 [00:03<00:15,  5.64it/s]Train Iter: 712/5000. LR: 0.0445. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0567. T_Loss: 4.9118. Mask: 0.8880. :  12%|█▏        | 12/100 [00:03<00:14,  6.07it/s]Train Iter: 713/5000. LR: 0.0446. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0597. T_Loss: 4.8963. Mask: 0.8846. :  12%|█▏        | 12/100 [00:03<00:14,  6.07it/s]Train Iter: 713/5000. LR: 0.0446. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0597. T_Loss: 4.8963. Mask: 0.8846. :  13%|█▎        | 13/100 [00:03<00:13,  6.40it/s]Train Iter: 714/5000. LR: 0.0446. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0539. T_Loss: 4.9250. Mask: 0.8884. :  13%|█▎        | 13/100 [00:04<00:13,  6.40it/s]Train Iter: 714/5000. LR: 0.0446. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0539. T_Loss: 4.9250. Mask: 0.8884. :  14%|█▍        | 14/100 [00:04<00:13,  6.54it/s]Train Iter: 715/5000. LR: 0.0447. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0565. T_Loss: 4.9227. Mask: 0.8917. :  14%|█▍        | 14/100 [00:04<00:13,  6.54it/s]Train Iter: 715/5000. LR: 0.0447. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0565. T_Loss: 4.9227. Mask: 0.8917. :  15%|█▌        | 15/100 [00:04<00:18,  4.68it/s]Train Iter: 716/5000. LR: 0.0448. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0551. T_Loss: 4.9069. Mask: 0.8887. :  15%|█▌        | 15/100 [00:04<00:18,  4.68it/s]Train Iter: 716/5000. LR: 0.0448. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0551. T_Loss: 4.9069. Mask: 0.8887. :  16%|█▌        | 16/100 [00:04<00:16,  5.20it/s]Train Iter: 717/5000. LR: 0.0448. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0520. T_Loss: 4.9257. Mask: 0.8915. :  16%|█▌        | 16/100 [00:04<00:16,  5.20it/s]Train Iter: 717/5000. LR: 0.0448. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0520. T_Loss: 4.9257. Mask: 0.8915. :  17%|█▋        | 17/100 [00:04<00:14,  5.64it/s]Train Iter: 718/5000. LR: 0.0449. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0512. T_Loss: 4.8514. Mask: 0.8872. :  17%|█▋        | 17/100 [00:04<00:14,  5.64it/s]Train Iter: 718/5000. LR: 0.0449. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0512. T_Loss: 4.8514. Mask: 0.8872. :  18%|█▊        | 18/100 [00:04<00:13,  6.11it/s]Train Iter: 719/5000. LR: 0.0449. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0474. T_Loss: 4.8139. Mask: 0.8849. :  18%|█▊        | 18/100 [00:05<00:13,  6.11it/s]Train Iter: 719/5000. LR: 0.0449. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0474. T_Loss: 4.8139. Mask: 0.8849. :  19%|█▉        | 19/100 [00:05<00:17,  4.68it/s]Train Iter: 720/5000. LR: 0.0450. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0405. T_Loss: 4.7725. Mask: 0.8859. :  19%|█▉        | 19/100 [00:05<00:17,  4.68it/s]Train Iter: 720/5000. LR: 0.0450. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0405. T_Loss: 4.7725. Mask: 0.8859. :  20%|██        | 20/100 [00:05<00:15,  5.28it/s]Train Iter: 721/5000. LR: 0.0451. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0372. T_Loss: 4.7473. Mask: 0.8869. :  20%|██        | 20/100 [00:05<00:15,  5.28it/s]Train Iter: 721/5000. LR: 0.0451. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0372. T_Loss: 4.7473. Mask: 0.8869. :  21%|██        | 21/100 [00:05<00:13,  5.81it/s]Train Iter: 722/5000. LR: 0.0451. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0303. T_Loss: 4.7031. Mask: 0.8906. :  21%|██        | 21/100 [00:05<00:13,  5.81it/s]Train Iter: 722/5000. LR: 0.0451. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0303. T_Loss: 4.7031. Mask: 0.8906. :  22%|██▏       | 22/100 [00:05<00:12,  6.27it/s]Train Iter: 723/5000. LR: 0.0452. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0269. T_Loss: 4.6814. Mask: 0.8913. :  22%|██▏       | 22/100 [00:05<00:12,  6.27it/s]Train Iter: 723/5000. LR: 0.0452. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0269. T_Loss: 4.6814. Mask: 0.8913. :  23%|██▎       | 23/100 [00:05<00:11,  6.73it/s]Train Iter: 724/5000. LR: 0.0453. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0284. T_Loss: 4.6602. Mask: 0.8932. :  23%|██▎       | 23/100 [00:05<00:11,  6.73it/s]Train Iter: 724/5000. LR: 0.0453. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0284. T_Loss: 4.6602. Mask: 0.8932. :  24%|██▍       | 24/100 [00:05<00:10,  7.04it/s]Train Iter: 725/5000. LR: 0.0453. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0289. T_Loss: 4.6573. Mask: 0.8950. :  24%|██▍       | 24/100 [00:06<00:10,  7.04it/s]Train Iter: 725/5000. LR: 0.0453. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0289. T_Loss: 4.6573. Mask: 0.8950. :  25%|██▌       | 25/100 [00:06<00:13,  5.73it/s]total : 5000  current step :  701
total : 5000  current step :  702
total : 5000  current step :  703
total : 5000  current step :  704
total : 5000  current step :  705
total : 5000  current step :  706
total : 5000  current step :  707
total : 5000  current step :  708
total : 5000  current step :  709
total : 5000  current step :  710
total : 5000  current step :  711
total : 5000  current step :  712
total : 5000  current step :  713
total : 5000  current step :  714
total : 5000  current step :  715
total : 5000  current step :  716
total : 5000  current step :  717
total : 5000  current step :  718
total : 5000  current step :  719
total : 5000  current step :  720
total : 5000  current step :  721
total : 5000  current step :  722
total : 5000  current step :  723
total : 5000  current step :  724
total : 5000  current step :  725
Train Iter: 726/5000. LR: 0.0454. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0262. T_Loss: 4.6340. Mask: 0.8978. :  25%|██▌       | 25/100 [00:08<00:13,  5.73it/s]Train Iter: 726/5000. LR: 0.0454. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0262. T_Loss: 4.6340. Mask: 0.8978. :  26%|██▌       | 26/100 [00:08<00:57,  1.29it/s]Train Iter: 727/5000. LR: 0.0454. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0295. T_Loss: 4.6446. Mask: 0.8970. :  26%|██▌       | 26/100 [00:08<00:57,  1.29it/s]Train Iter: 727/5000. LR: 0.0454. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0295. T_Loss: 4.6446. Mask: 0.8970. :  27%|██▋       | 27/100 [00:08<00:42,  1.71it/s]Train Iter: 728/5000. LR: 0.0455. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0257. T_Loss: 4.6056. Mask: 0.8973. :  27%|██▋       | 27/100 [00:08<00:42,  1.71it/s]Train Iter: 728/5000. LR: 0.0455. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0257. T_Loss: 4.6056. Mask: 0.8973. :  28%|██▊       | 28/100 [00:08<00:32,  2.23it/s]Train Iter: 729/5000. LR: 0.0456. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0275. T_Loss: 4.5910. Mask: 0.8955. :  28%|██▊       | 28/100 [00:08<00:32,  2.23it/s]Train Iter: 729/5000. LR: 0.0456. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0275. T_Loss: 4.5910. Mask: 0.8955. :  29%|██▉       | 29/100 [00:08<00:26,  2.64it/s]Train Iter: 730/5000. LR: 0.0456. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0251. T_Loss: 4.5505. Mask: 0.8969. :  29%|██▉       | 29/100 [00:08<00:26,  2.64it/s]Train Iter: 730/5000. LR: 0.0456. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0251. T_Loss: 4.5505. Mask: 0.8969. :  30%|███       | 30/100 [00:08<00:21,  3.30it/s]Train Iter: 731/5000. LR: 0.0457. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0292. T_Loss: 4.5767. Mask: 0.8992. :  30%|███       | 30/100 [00:09<00:21,  3.30it/s]Train Iter: 731/5000. LR: 0.0457. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0292. T_Loss: 4.5767. Mask: 0.8992. :  31%|███       | 31/100 [00:09<00:17,  3.97it/s]Train Iter: 732/5000. LR: 0.0458. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0330. T_Loss: 4.5857. Mask: 0.8994. :  31%|███       | 31/100 [00:09<00:17,  3.97it/s]Train Iter: 732/5000. LR: 0.0458. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0330. T_Loss: 4.5857. Mask: 0.8994. :  32%|███▏      | 32/100 [00:09<00:15,  4.45it/s]Train Iter: 733/5000. LR: 0.0458. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0295. T_Loss: 4.5626. Mask: 0.9006. :  32%|███▏      | 32/100 [00:09<00:15,  4.45it/s]Train Iter: 733/5000. LR: 0.0458. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0295. T_Loss: 4.5626. Mask: 0.9006. :  33%|███▎      | 33/100 [00:09<00:12,  5.16it/s]Train Iter: 734/5000. LR: 0.0459. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0286. T_Loss: 4.5518. Mask: 0.9026. :  33%|███▎      | 33/100 [00:09<00:12,  5.16it/s]Train Iter: 734/5000. LR: 0.0459. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0286. T_Loss: 4.5518. Mask: 0.9026. :  34%|███▍      | 34/100 [00:09<00:11,  5.87it/s]Train Iter: 735/5000. LR: 0.0459. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0269. T_Loss: 4.5503. Mask: 0.9018. :  34%|███▍      | 34/100 [00:09<00:11,  5.87it/s]Train Iter: 735/5000. LR: 0.0459. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0269. T_Loss: 4.5503. Mask: 0.9018. :  35%|███▌      | 35/100 [00:09<00:13,  4.83it/s]Train Iter: 736/5000. LR: 0.0460. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0244. T_Loss: 4.5691. Mask: 0.9045. :  35%|███▌      | 35/100 [00:09<00:13,  4.83it/s]Train Iter: 736/5000. LR: 0.0460. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0244. T_Loss: 4.5691. Mask: 0.9045. :  36%|███▌      | 36/100 [00:09<00:11,  5.50it/s]Train Iter: 737/5000. LR: 0.0461. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0218. T_Loss: 4.5482. Mask: 0.9029. :  36%|███▌      | 36/100 [00:09<00:11,  5.50it/s]Train Iter: 737/5000. LR: 0.0461. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0218. T_Loss: 4.5482. Mask: 0.9029. :  37%|███▋      | 37/100 [00:09<00:10,  6.05it/s]Train Iter: 738/5000. LR: 0.0461. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0223. T_Loss: 4.5594. Mask: 0.9046. :  37%|███▋      | 37/100 [00:10<00:10,  6.05it/s]Train Iter: 738/5000. LR: 0.0461. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0223. T_Loss: 4.5594. Mask: 0.9046. :  38%|███▊      | 38/100 [00:10<00:09,  6.58it/s]Train Iter: 739/5000. LR: 0.0462. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0214. T_Loss: 4.5714. Mask: 0.9046. :  38%|███▊      | 38/100 [00:10<00:09,  6.58it/s]Train Iter: 739/5000. LR: 0.0462. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0214. T_Loss: 4.5714. Mask: 0.9046. :  39%|███▉      | 39/100 [00:10<00:13,  4.57it/s]Train Iter: 740/5000. LR: 0.0463. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0212. T_Loss: 4.5767. Mask: 0.9055. :  39%|███▉      | 39/100 [00:10<00:13,  4.57it/s]Train Iter: 740/5000. LR: 0.0463. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0212. T_Loss: 4.5767. Mask: 0.9055. :  40%|████      | 40/100 [00:10<00:11,  5.24it/s]Train Iter: 741/5000. LR: 0.0463. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0219. T_Loss: 4.5751. Mask: 0.9040. :  40%|████      | 40/100 [00:10<00:11,  5.24it/s]Train Iter: 741/5000. LR: 0.0463. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0219. T_Loss: 4.5751. Mask: 0.9040. :  41%|████      | 41/100 [00:10<00:10,  5.56it/s]Train Iter: 742/5000. LR: 0.0464. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0202. T_Loss: 4.5690. Mask: 0.9048. :  41%|████      | 41/100 [00:10<00:10,  5.56it/s]Train Iter: 742/5000. LR: 0.0464. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0202. T_Loss: 4.5690. Mask: 0.9048. :  42%|████▏     | 42/100 [00:10<00:09,  6.19it/s]Train Iter: 743/5000. LR: 0.0464. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0200. T_Loss: 4.5608. Mask: 0.9062. :  42%|████▏     | 42/100 [00:10<00:09,  6.19it/s]Train Iter: 743/5000. LR: 0.0464. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0200. T_Loss: 4.5608. Mask: 0.9062. :  43%|████▎     | 43/100 [00:10<00:08,  6.78it/s]Train Iter: 744/5000. LR: 0.0465. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0213. T_Loss: 4.5413. Mask: 0.9048. :  43%|████▎     | 43/100 [00:11<00:08,  6.78it/s]Train Iter: 744/5000. LR: 0.0465. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0213. T_Loss: 4.5413. Mask: 0.9048. :  44%|████▍     | 44/100 [00:11<00:07,  7.24it/s]Train Iter: 745/5000. LR: 0.0466. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0204. T_Loss: 4.5353. Mask: 0.9042. :  44%|████▍     | 44/100 [00:11<00:07,  7.24it/s]Train Iter: 745/5000. LR: 0.0466. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0204. T_Loss: 4.5353. Mask: 0.9042. :  45%|████▌     | 45/100 [00:11<00:10,  5.11it/s]Train Iter: 746/5000. LR: 0.0466. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0180. T_Loss: 4.5308. Mask: 0.9056. :  45%|████▌     | 45/100 [00:11<00:10,  5.11it/s]Train Iter: 746/5000. LR: 0.0466. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0180. T_Loss: 4.5308. Mask: 0.9056. :  46%|████▌     | 46/100 [00:11<00:09,  5.76it/s]Train Iter: 747/5000. LR: 0.0467. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0189. T_Loss: 4.5218. Mask: 0.9049. :  46%|████▌     | 46/100 [00:11<00:09,  5.76it/s]Train Iter: 747/5000. LR: 0.0467. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0189. T_Loss: 4.5218. Mask: 0.9049. :  47%|████▋     | 47/100 [00:11<00:08,  6.42it/s]Train Iter: 748/5000. LR: 0.0468. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0169. T_Loss: 4.5200. Mask: 0.9043. :  47%|████▋     | 47/100 [00:11<00:08,  6.42it/s]Train Iter: 749/5000. LR: 0.0468. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0178. T_Loss: 4.5283. Mask: 0.9043. :  48%|████▊     | 48/100 [00:11<00:08,  6.42it/s]Train Iter: 749/5000. LR: 0.0468. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0178. T_Loss: 4.5283. Mask: 0.9043. :  49%|████▉     | 49/100 [00:11<00:08,  6.10it/s]Train Iter: 750/5000. LR: 0.0469. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0191. T_Loss: 4.5520. Mask: 0.9062. :  49%|████▉     | 49/100 [00:12<00:08,  6.10it/s]Train Iter: 750/5000. LR: 0.0469. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0191. T_Loss: 4.5520. Mask: 0.9062. :  50%|█████     | 50/100 [00:12<00:07,  6.42it/s]total : 5000  current step :  726
total : 5000  current step :  727
total : 5000  current step :  728
total : 5000  current step :  729
total : 5000  current step :  730
total : 5000  current step :  731
total : 5000  current step :  732
total : 5000  current step :  733
total : 5000  current step :  734
total : 5000  current step :  735
total : 5000  current step :  736
total : 5000  current step :  737
total : 5000  current step :  738
total : 5000  current step :  739
total : 5000  current step :  740
total : 5000  current step :  741
total : 5000  current step :  742
total : 5000  current step :  743
total : 5000  current step :  744
total : 5000  current step :  745
total : 5000  current step :  746
total : 5000  current step :  747
total : 5000  current step :  748
total : 5000  current step :  749
total : 5000  current step :  750
Train Iter: 751/5000. LR: 0.0469. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0176. T_Loss: 4.5464. Mask: 0.9069. :  50%|█████     | 50/100 [00:14<00:07,  6.42it/s]Train Iter: 751/5000. LR: 0.0469. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0176. T_Loss: 4.5464. Mask: 0.9069. :  51%|█████     | 51/100 [00:14<00:31,  1.55it/s]Train Iter: 752/5000. LR: 0.0470. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0189. T_Loss: 4.5517. Mask: 0.9069. :  51%|█████     | 51/100 [00:14<00:31,  1.55it/s]Train Iter: 752/5000. LR: 0.0470. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0189. T_Loss: 4.5517. Mask: 0.9069. :  52%|█████▏    | 52/100 [00:14<00:24,  1.99it/s]Train Iter: 753/5000. LR: 0.0471. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0197. T_Loss: 4.5561. Mask: 0.9068. :  52%|█████▏    | 52/100 [00:14<00:24,  1.99it/s]Train Iter: 753/5000. LR: 0.0471. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0197. T_Loss: 4.5561. Mask: 0.9068. :  53%|█████▎    | 53/100 [00:14<00:18,  2.54it/s]Train Iter: 754/5000. LR: 0.0471. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0211. T_Loss: 4.5442. Mask: 0.9074. :  53%|█████▎    | 53/100 [00:14<00:18,  2.54it/s]Train Iter: 755/5000. LR: 0.0472. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0220. T_Loss: 4.5478. Mask: 0.9080. :  54%|█████▍    | 54/100 [00:14<00:18,  2.54it/s]Train Iter: 755/5000. LR: 0.0472. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0220. T_Loss: 4.5478. Mask: 0.9080. :  55%|█████▌    | 55/100 [00:14<00:14,  3.07it/s]Train Iter: 756/5000. LR: 0.0473. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0207. T_Loss: 4.5423. Mask: 0.9068. :  55%|█████▌    | 55/100 [00:15<00:14,  3.07it/s]Train Iter: 756/5000. LR: 0.0473. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0207. T_Loss: 4.5423. Mask: 0.9068. :  56%|█████▌    | 56/100 [00:15<00:12,  3.53it/s]Train Iter: 757/5000. LR: 0.0473. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0213. T_Loss: 4.5641. Mask: 0.9084. :  56%|█████▌    | 56/100 [00:15<00:12,  3.53it/s]Train Iter: 757/5000. LR: 0.0473. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0213. T_Loss: 4.5641. Mask: 0.9084. :  57%|█████▋    | 57/100 [00:15<00:10,  4.13it/s]Train Iter: 758/5000. LR: 0.0474. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0224. T_Loss: 4.5711. Mask: 0.9089. :  57%|█████▋    | 57/100 [00:15<00:10,  4.13it/s]Train Iter: 758/5000. LR: 0.0474. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0224. T_Loss: 4.5711. Mask: 0.9089. :  58%|█████▊    | 58/100 [00:15<00:08,  4.78it/s]Train Iter: 759/5000. LR: 0.0474. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0243. T_Loss: 4.5660. Mask: 0.9078. :  58%|█████▊    | 58/100 [00:15<00:08,  4.78it/s]Train Iter: 759/5000. LR: 0.0474. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0243. T_Loss: 4.5660. Mask: 0.9078. :  59%|█████▉    | 59/100 [00:15<00:09,  4.20it/s]Train Iter: 760/5000. LR: 0.0475. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0258. T_Loss: 4.5699. Mask: 0.9073. :  59%|█████▉    | 59/100 [00:15<00:09,  4.20it/s]Train Iter: 760/5000. LR: 0.0475. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0258. T_Loss: 4.5699. Mask: 0.9073. :  60%|██████    | 60/100 [00:15<00:08,  4.86it/s]Train Iter: 761/5000. LR: 0.0476. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0312. T_Loss: 4.5891. Mask: 0.9068. :  60%|██████    | 60/100 [00:15<00:08,  4.86it/s]Train Iter: 761/5000. LR: 0.0476. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0312. T_Loss: 4.5891. Mask: 0.9068. :  61%|██████    | 61/100 [00:15<00:07,  5.53it/s]Train Iter: 762/5000. LR: 0.0476. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0338. T_Loss: 4.6097. Mask: 0.9078. :  61%|██████    | 61/100 [00:15<00:07,  5.53it/s]Train Iter: 762/5000. LR: 0.0476. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0338. T_Loss: 4.6097. Mask: 0.9078. :  62%|██████▏   | 62/100 [00:15<00:06,  6.19it/s]Train Iter: 763/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0346. T_Loss: 4.5993. Mask: 0.9058. :  62%|██████▏   | 62/100 [00:16<00:06,  6.19it/s]Train Iter: 763/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0346. T_Loss: 4.5993. Mask: 0.9058. :  63%|██████▎   | 63/100 [00:16<00:05,  6.57it/s]Train Iter: 764/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0348. T_Loss: 4.6020. Mask: 0.9048. :  63%|██████▎   | 63/100 [00:16<00:05,  6.57it/s]Train Iter: 764/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0348. T_Loss: 4.6020. Mask: 0.9048. :  64%|██████▍   | 64/100 [00:16<00:05,  7.09it/s]Train Iter: 765/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0342. T_Loss: 4.6218. Mask: 0.9058. :  64%|██████▍   | 64/100 [00:16<00:05,  7.09it/s]Train Iter: 765/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0342. T_Loss: 4.6218. Mask: 0.9058. :  65%|██████▌   | 65/100 [00:16<00:06,  5.18it/s]Train Iter: 766/5000. LR: 0.0479. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0342. T_Loss: 4.6140. Mask: 0.9044. :  65%|██████▌   | 65/100 [00:16<00:06,  5.18it/s]Train Iter: 766/5000. LR: 0.0479. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0342. T_Loss: 4.6140. Mask: 0.9044. :  66%|██████▌   | 66/100 [00:16<00:05,  5.79it/s]Train Iter: 767/5000. LR: 0.0479. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0332. T_Loss: 4.6104. Mask: 0.9039. :  66%|██████▌   | 66/100 [00:16<00:05,  5.79it/s]Train Iter: 767/5000. LR: 0.0479. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0332. T_Loss: 4.6104. Mask: 0.9039. :  67%|██████▋   | 67/100 [00:16<00:05,  6.48it/s]Train Iter: 768/5000. LR: 0.0480. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0308. T_Loss: 4.6082. Mask: 0.9035. :  67%|██████▋   | 67/100 [00:16<00:05,  6.48it/s]Train Iter: 768/5000. LR: 0.0480. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0308. T_Loss: 4.6082. Mask: 0.9035. :  68%|██████▊   | 68/100 [00:16<00:04,  6.85it/s]Train Iter: 769/5000. LR: 0.0481. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0290. T_Loss: 4.5885. Mask: 0.9013. :  68%|██████▊   | 68/100 [00:17<00:04,  6.85it/s]Train Iter: 769/5000. LR: 0.0481. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0290. T_Loss: 4.5885. Mask: 0.9013. :  69%|██████▉   | 69/100 [00:17<00:06,  4.69it/s]Train Iter: 770/5000. LR: 0.0481. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0273. T_Loss: 4.5891. Mask: 0.9018. :  69%|██████▉   | 69/100 [00:17<00:06,  4.69it/s]Train Iter: 770/5000. LR: 0.0481. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0273. T_Loss: 4.5891. Mask: 0.9018. :  70%|███████   | 70/100 [00:17<00:05,  5.37it/s]Train Iter: 771/5000. LR: 0.0482. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0255. T_Loss: 4.6048. Mask: 0.9023. :  70%|███████   | 70/100 [00:17<00:05,  5.37it/s]Train Iter: 771/5000. LR: 0.0482. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0255. T_Loss: 4.6048. Mask: 0.9023. :  71%|███████   | 71/100 [00:17<00:04,  5.97it/s]Train Iter: 772/5000. LR: 0.0483. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0235. T_Loss: 4.6171. Mask: 0.9032. :  71%|███████   | 71/100 [00:17<00:04,  5.97it/s]Train Iter: 772/5000. LR: 0.0483. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0235. T_Loss: 4.6171. Mask: 0.9032. :  72%|███████▏  | 72/100 [00:17<00:04,  6.38it/s]Train Iter: 773/5000. LR: 0.0483. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0226. T_Loss: 4.6176. Mask: 0.9028. :  72%|███████▏  | 72/100 [00:17<00:04,  6.38it/s]Train Iter: 773/5000. LR: 0.0483. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0226. T_Loss: 4.6176. Mask: 0.9028. :  73%|███████▎  | 73/100 [00:17<00:03,  6.79it/s]Train Iter: 774/5000. LR: 0.0484. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0244. T_Loss: 4.6285. Mask: 0.9029. :  73%|███████▎  | 73/100 [00:17<00:03,  6.79it/s]Train Iter: 774/5000. LR: 0.0484. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0244. T_Loss: 4.6285. Mask: 0.9029. :  74%|███████▍  | 74/100 [00:17<00:03,  7.22it/s]Train Iter: 775/5000. LR: 0.0484. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0267. T_Loss: 4.6312. Mask: 0.9021. :  74%|███████▍  | 74/100 [00:18<00:03,  7.22it/s]Train Iter: 775/5000. LR: 0.0484. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0267. T_Loss: 4.6312. Mask: 0.9021. :  75%|███████▌  | 75/100 [00:18<00:05,  4.61it/s]total : 5000  current step :  751
total : 5000  current step :  752
total : 5000  current step :  753
total : 5000  current step :  754
total : 5000  current step :  755
total : 5000  current step :  756
total : 5000  current step :  757
total : 5000  current step :  758
total : 5000  current step :  759
total : 5000  current step :  760
total : 5000  current step :  761
total : 5000  current step :  762
total : 5000  current step :  763
total : 5000  current step :  764
total : 5000  current step :  765
total : 5000  current step :  766
total : 5000  current step :  767
total : 5000  current step :  768
total : 5000  current step :  769
total : 5000  current step :  770
total : 5000  current step :  771
total : 5000  current step :  772
total : 5000  current step :  773
total : 5000  current step :  774
total : 5000  current step :  775
Train Iter: 776/5000. LR: 0.0485. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0300. T_Loss: 4.6485. Mask: 0.9030. :  75%|███████▌  | 75/100 [00:20<00:05,  4.61it/s]Train Iter: 776/5000. LR: 0.0485. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0300. T_Loss: 4.6485. Mask: 0.9030. :  76%|███████▌  | 76/100 [00:20<00:17,  1.39it/s]Train Iter: 777/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0341. T_Loss: 4.6543. Mask: 0.9014. :  76%|███████▌  | 76/100 [00:20<00:17,  1.39it/s]Train Iter: 777/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0341. T_Loss: 4.6543. Mask: 0.9014. :  77%|███████▋  | 77/100 [00:20<00:12,  1.85it/s]Train Iter: 778/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0369. T_Loss: 4.6651. Mask: 0.9014. :  77%|███████▋  | 77/100 [00:20<00:12,  1.85it/s]Train Iter: 778/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0369. T_Loss: 4.6651. Mask: 0.9014. :  78%|███████▊  | 78/100 [00:20<00:09,  2.38it/s]Train Iter: 779/5000. LR: 0.0487. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0426. T_Loss: 4.6737. Mask: 0.8999. :  78%|███████▊  | 78/100 [00:20<00:09,  2.38it/s]Train Iter: 779/5000. LR: 0.0487. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0426. T_Loss: 4.6737. Mask: 0.8999. :  79%|███████▉  | 79/100 [00:20<00:08,  2.55it/s]Train Iter: 780/5000. LR: 0.0488. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0448. T_Loss: 4.6826. Mask: 0.9004. :  79%|███████▉  | 79/100 [00:20<00:08,  2.55it/s]Train Iter: 780/5000. LR: 0.0488. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0448. T_Loss: 4.6826. Mask: 0.9004. :  80%|████████  | 80/100 [00:20<00:06,  3.21it/s]Train Iter: 781/5000. LR: 0.0488. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0473. T_Loss: 4.6849. Mask: 0.9008. :  80%|████████  | 80/100 [00:20<00:06,  3.21it/s]Train Iter: 781/5000. LR: 0.0488. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0473. T_Loss: 4.6849. Mask: 0.9008. :  81%|████████  | 81/100 [00:20<00:04,  3.93it/s]Train Iter: 782/5000. LR: 0.0489. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0497. T_Loss: 4.6794. Mask: 0.9013. :  81%|████████  | 81/100 [00:21<00:04,  3.93it/s]Train Iter: 782/5000. LR: 0.0489. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0497. T_Loss: 4.6794. Mask: 0.9013. :  82%|████████▏ | 82/100 [00:21<00:03,  4.67it/s]Train Iter: 783/5000. LR: 0.0489. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0511. T_Loss: 4.6701. Mask: 0.9014. :  82%|████████▏ | 82/100 [00:21<00:03,  4.67it/s]Train Iter: 783/5000. LR: 0.0489. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0511. T_Loss: 4.6701. Mask: 0.9014. :  83%|████████▎ | 83/100 [00:21<00:03,  5.36it/s]Train Iter: 784/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0528. T_Loss: 4.6771. Mask: 0.9025. :  83%|████████▎ | 83/100 [00:21<00:03,  5.36it/s]Train Iter: 784/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0528. T_Loss: 4.6771. Mask: 0.9025. :  84%|████████▍ | 84/100 [00:21<00:02,  5.93it/s]Train Iter: 785/5000. LR: 0.0491. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0535. T_Loss: 4.6759. Mask: 0.9022. :  84%|████████▍ | 84/100 [00:21<00:02,  5.93it/s]Train Iter: 785/5000. LR: 0.0491. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0535. T_Loss: 4.6759. Mask: 0.9022. :  85%|████████▌ | 85/100 [00:21<00:03,  4.74it/s]Train Iter: 786/5000. LR: 0.0491. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0539. T_Loss: 4.6773. Mask: 0.9030. :  85%|████████▌ | 85/100 [00:21<00:03,  4.74it/s]Train Iter: 786/5000. LR: 0.0491. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0539. T_Loss: 4.6773. Mask: 0.9030. :  86%|████████▌ | 86/100 [00:21<00:02,  5.43it/s]Train Iter: 787/5000. LR: 0.0492. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0539. T_Loss: 4.6699. Mask: 0.9034. :  86%|████████▌ | 86/100 [00:21<00:02,  5.43it/s]Train Iter: 787/5000. LR: 0.0492. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0539. T_Loss: 4.6699. Mask: 0.9034. :  87%|████████▋ | 87/100 [00:21<00:02,  5.99it/s]Train Iter: 788/5000. LR: 0.0493. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0556. T_Loss: 4.6622. Mask: 0.9034. :  87%|████████▋ | 87/100 [00:21<00:02,  5.99it/s]Train Iter: 789/5000. LR: 0.0493. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0560. T_Loss: 4.6623. Mask: 0.9031. :  88%|████████▊ | 88/100 [00:22<00:02,  5.99it/s]Train Iter: 789/5000. LR: 0.0493. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0560. T_Loss: 4.6623. Mask: 0.9031. :  89%|████████▉ | 89/100 [00:22<00:01,  6.05it/s]Train Iter: 790/5000. LR: 0.0494. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0567. T_Loss: 4.6728. Mask: 0.9031. :  89%|████████▉ | 89/100 [00:22<00:01,  6.05it/s]Train Iter: 790/5000. LR: 0.0494. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0567. T_Loss: 4.6728. Mask: 0.9031. :  90%|█████████ | 90/100 [00:22<00:01,  6.43it/s]Train Iter: 791/5000. LR: 0.0494. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0572. T_Loss: 4.6749. Mask: 0.9035. :  90%|█████████ | 90/100 [00:22<00:01,  6.43it/s]Train Iter: 791/5000. LR: 0.0494. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0572. T_Loss: 4.6749. Mask: 0.9035. :  91%|█████████ | 91/100 [00:22<00:01,  6.68it/s]Train Iter: 792/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0571. T_Loss: 4.6691. Mask: 0.9035. :  91%|█████████ | 91/100 [00:22<00:01,  6.68it/s]Train Iter: 792/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0571. T_Loss: 4.6691. Mask: 0.9035. :  92%|█████████▏| 92/100 [00:22<00:01,  7.03it/s]Train Iter: 793/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0599. T_Loss: 4.6773. Mask: 0.9039. :  92%|█████████▏| 92/100 [00:22<00:01,  7.03it/s]Train Iter: 793/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0599. T_Loss: 4.6773. Mask: 0.9039. :  93%|█████████▎| 93/100 [00:22<00:00,  7.32it/s]Train Iter: 794/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0616. T_Loss: 4.6817. Mask: 0.9039. :  93%|█████████▎| 93/100 [00:22<00:00,  7.32it/s]Train Iter: 794/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0616. T_Loss: 4.6817. Mask: 0.9039. :  94%|█████████▍| 94/100 [00:22<00:00,  7.57it/s]Train Iter: 795/5000. LR: 0.0497. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0622. T_Loss: 4.6913. Mask: 0.9039. :  94%|█████████▍| 94/100 [00:23<00:00,  7.57it/s]Train Iter: 795/5000. LR: 0.0497. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0622. T_Loss: 4.6913. Mask: 0.9039. :  95%|█████████▌| 95/100 [00:23<00:00,  5.79it/s]Train Iter: 796/5000. LR: 0.0498. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0636. T_Loss: 4.6942. Mask: 0.9046. :  95%|█████████▌| 95/100 [00:23<00:00,  5.79it/s]Train Iter: 796/5000. LR: 0.0498. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0636. T_Loss: 4.6942. Mask: 0.9046. :  96%|█████████▌| 96/100 [00:23<00:00,  6.33it/s]Train Iter: 797/5000. LR: 0.0498. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0649. T_Loss: 4.6992. Mask: 0.9050. :  96%|█████████▌| 96/100 [00:23<00:00,  6.33it/s]Train Iter: 797/5000. LR: 0.0498. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0649. T_Loss: 4.6992. Mask: 0.9050. :  97%|█████████▋| 97/100 [00:23<00:00,  6.80it/s]Train Iter: 798/5000. LR: 0.0499. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0661. T_Loss: 4.7125. Mask: 0.9050. :  97%|█████████▋| 97/100 [00:23<00:00,  6.80it/s]Train Iter: 798/5000. LR: 0.0499. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0661. T_Loss: 4.7125. Mask: 0.9050. :  98%|█████████▊| 98/100 [00:23<00:00,  7.17it/s]Train Iter: 799/5000. LR: 0.0499. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0674. T_Loss: 4.7196. Mask: 0.9053. :  98%|█████████▊| 98/100 [00:23<00:00,  7.17it/s]Train Iter: 799/5000. LR: 0.0499. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0674. T_Loss: 4.7196. Mask: 0.9053. :  99%|█████████▉| 99/100 [00:23<00:00,  5.46it/s]Train Iter: 800/5000. LR: 0.0500. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0690. T_Loss: 4.7296. Mask: 0.9050. :  99%|█████████▉| 99/100 [00:23<00:00,  5.46it/s]Train Iter: 800/5000. LR: 0.0500. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0690. T_Loss: 4.7296. Mask: 0.9050. : 100%|██████████| 100/100 [00:23<00:00,  6.16it/s]Train Iter: 800/5000. LR: 0.0500. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0690. T_Loss: 4.7296. Mask: 0.9050. : 100%|██████████| 100/100 [00:23<00:00,  4.19it/s]
total : 5000  current step :  776
total : 5000  current step :  777
total : 5000  current step :  778
total : 5000  current step :  779
total : 5000  current step :  780
total : 5000  current step :  781
total : 5000  current step :  782
total : 5000  current step :  783
total : 5000  current step :  784
total : 5000  current step :  785
total : 5000  current step :  786
total : 5000  current step :  787
total : 5000  current step :  788
total : 5000  current step :  789
total : 5000  current step :  790
total : 5000  current step :  791
total : 5000  current step :  792
total : 5000  current step :  793
total : 5000  current step :  794
total : 5000  current step :  795
total : 5000  current step :  796
total : 5000  current step :  797
total : 5000  current step :  798
total : 5000  current step :  799
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0469. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0469. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.90s. Loss: 1.0116. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 0.9761. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 1.0038. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9911. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9976. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9976. top1: 82.81. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9999. top1: 82.14. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.0065. top1: 80.47. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9982. top1: 81.60. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.0030. top1: 81.25. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9944. top1: 82.67. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9979. top1: 82.29. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9942. top1: 82.21. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9962. top1: 82.37. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9875. top1: 83.12. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.25it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9845. top1: 83.20. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:13,  4.25it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9845. top1: 83.20. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9825. top1: 83.27. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9824. top1: 83.51. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9829. top1: 83.39. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9834. top1: 83.44. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9863. top1: 83.18. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9844. top1: 83.52. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9832. top1: 83.70. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9819. top1: 83.72. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9824. top1: 83.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.01it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9824. top1: 83.62. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9849. top1: 83.29. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9826. top1: 83.56. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9834. top1: 83.59. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9848. top1: 83.51. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9848. top1: 83.44. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9853. top1: 83.37. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0006. top1: 82.23. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0145. top1: 81.63. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0344. top1: 80.61. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0459. top1: 80.09. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0712. top1: 78.73. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 21.90it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0712. top1: 78.73. top5: 100.00. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0808. top1: 78.12. top5: 100.00. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0918. top1: 77.06. top5: 100.00. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1101. top1: 76.20. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s] Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1193. top1: 75.47. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1281. top1: 75.00. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1380. top1: 74.33. top5: 99.93. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1452. top1: 73.76. top5: 99.93. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1507. top1: 73.30. top5: 99.93. :  57%|█████▋    | 36/63 [00:02<00:00, 34.08it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1507. top1: 73.30. top5: 99.93. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1602. top1: 72.64. top5: 99.93. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1689. top1: 72.08. top5: 99.93. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1783. top1: 71.54. top5: 99.93. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1873. top1: 71.16. top5: 99.93. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1961. top1: 70.66. top5: 99.94. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2037. top1: 70.00. top5: 99.94. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2187. top1: 69.06. top5: 99.94. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2247. top1: 68.57. top5: 99.94. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2305. top1: 68.57. top5: 99.88. :  70%|██████▉   | 44/63 [00:02<00:00, 41.07it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2305. top1: 68.57. top5: 99.88. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2374. top1: 67.88. top5: 99.88. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2437. top1: 67.73. top5: 99.89. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2461. top1: 67.69. top5: 99.89. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2555. top1: 67.27. top5: 99.89. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2614. top1: 66.97. top5: 99.89. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2678. top1: 66.53. top5: 99.89. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2707. top1: 66.46. top5: 99.90. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2786. top1: 65.98. top5: 99.90. :  84%|████████▍ | 53/63 [00:02<00:00, 49.38it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2786. top1: 65.98. top5: 99.90. :  97%|█████████▋| 61/63 [00:02<00:00, 54.80it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2878. top1: 65.37. top5: 99.90. :  97%|█████████▋| 61/63 [00:02<00:00, 54.80it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2915. top1: 65.25. top5: 99.90. :  97%|█████████▋| 61/63 [00:02<00:00, 54.80it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2915. top1: 65.25. top5: 99.90. : 100%|██████████| 63/63 [00:02<00:00, 22.32it/s]
total : 5000  current step :  800
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 801/5000. LR: 0.0500. Data: 2.11s. Batch: 2.24s. S_Loss: 1.0945. T_Loss: 5.0319. Mask: 0.8125. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 801/5000. LR: 0.0500. Data: 2.11s. Batch: 2.24s. S_Loss: 1.0945. T_Loss: 5.0319. Mask: 0.8125. :   1%|          | 1/100 [00:02<03:41,  2.24s/it]Train Iter: 802/5000. LR: 0.0500. Data: 1.06s. Batch: 1.17s. S_Loss: 1.1152. T_Loss: 4.9468. Mask: 0.7969. :   1%|          | 1/100 [00:02<03:41,  2.24s/it]Train Iter: 802/5000. LR: 0.0500. Data: 1.06s. Batch: 1.17s. S_Loss: 1.1152. T_Loss: 4.9468. Mask: 0.7969. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 803/5000. LR: 0.0500. Data: 0.71s. Batch: 0.82s. S_Loss: 1.1205. T_Loss: 4.9015. Mask: 0.8021. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 803/5000. LR: 0.0500. Data: 0.71s. Batch: 0.82s. S_Loss: 1.1205. T_Loss: 4.9015. Mask: 0.8021. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 804/5000. LR: 0.0500. Data: 0.53s. Batch: 0.64s. S_Loss: 1.0995. T_Loss: 4.9913. Mask: 0.8203. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 804/5000. LR: 0.0500. Data: 0.53s. Batch: 0.64s. S_Loss: 1.0995. T_Loss: 4.9913. Mask: 0.8203. :   4%|▍         | 4/100 [00:02<00:38,  2.51it/s]Train Iter: 805/5000. LR: 0.0500. Data: 0.43s. Batch: 0.57s. S_Loss: 1.1015. T_Loss: 5.0115. Mask: 0.8000. :   4%|▍         | 4/100 [00:02<00:38,  2.51it/s]Train Iter: 805/5000. LR: 0.0500. Data: 0.43s. Batch: 0.57s. S_Loss: 1.1015. T_Loss: 5.0115. Mask: 0.8000. :   5%|▌         | 5/100 [00:02<00:34,  2.77it/s]Train Iter: 806/5000. LR: 0.0500. Data: 0.36s. Batch: 0.50s. S_Loss: 1.1120. T_Loss: 5.0749. Mask: 0.8021. :   5%|▌         | 5/100 [00:03<00:34,  2.77it/s]Train Iter: 806/5000. LR: 0.0500. Data: 0.36s. Batch: 0.50s. S_Loss: 1.1120. T_Loss: 5.0749. Mask: 0.8021. :   6%|▌         | 6/100 [00:03<00:27,  3.48it/s]Train Iter: 807/5000. LR: 0.0500. Data: 0.30s. Batch: 0.45s. S_Loss: 1.1040. T_Loss: 5.1127. Mask: 0.8036. :   6%|▌         | 6/100 [00:03<00:27,  3.48it/s]Train Iter: 807/5000. LR: 0.0500. Data: 0.30s. Batch: 0.45s. S_Loss: 1.1040. T_Loss: 5.1127. Mask: 0.8036. :   7%|▋         | 7/100 [00:03<00:21,  4.25it/s]Train Iter: 808/5000. LR: 0.0500. Data: 0.27s. Batch: 0.41s. S_Loss: 1.1071. T_Loss: 5.1813. Mask: 0.8125. :   7%|▋         | 7/100 [00:03<00:21,  4.25it/s]Train Iter: 808/5000. LR: 0.0500. Data: 0.27s. Batch: 0.41s. S_Loss: 1.1071. T_Loss: 5.1813. Mask: 0.8125. :   8%|▊         | 8/100 [00:03<00:18,  4.97it/s]Train Iter: 809/5000. LR: 0.0500. Data: 0.24s. Batch: 0.39s. S_Loss: 1.1161. T_Loss: 5.1034. Mask: 0.7951. :   8%|▊         | 8/100 [00:03<00:18,  4.97it/s]Train Iter: 809/5000. LR: 0.0500. Data: 0.24s. Batch: 0.39s. S_Loss: 1.1161. T_Loss: 5.1034. Mask: 0.7951. :   9%|▉         | 9/100 [00:03<00:19,  4.62it/s]Train Iter: 810/5000. LR: 0.0500. Data: 0.21s. Batch: 0.36s. S_Loss: 1.1172. T_Loss: 5.2154. Mask: 0.8031. :   9%|▉         | 9/100 [00:03<00:19,  4.62it/s]Train Iter: 810/5000. LR: 0.0500. Data: 0.21s. Batch: 0.36s. S_Loss: 1.1172. T_Loss: 5.2154. Mask: 0.8031. :  10%|█         | 10/100 [00:03<00:17,  5.25it/s]Train Iter: 811/5000. LR: 0.0500. Data: 0.20s. Batch: 0.34s. S_Loss: 1.1196. T_Loss: 5.2117. Mask: 0.8040. :  10%|█         | 10/100 [00:03<00:17,  5.25it/s]Train Iter: 811/5000. LR: 0.0500. Data: 0.20s. Batch: 0.34s. S_Loss: 1.1196. T_Loss: 5.2117. Mask: 0.8040. :  11%|█         | 11/100 [00:03<00:14,  6.04it/s]Train Iter: 812/5000. LR: 0.0500. Data: 0.18s. Batch: 0.32s. S_Loss: 1.1135. T_Loss: 5.2057. Mask: 0.8099. :  11%|█         | 11/100 [00:03<00:14,  6.04it/s]Train Iter: 812/5000. LR: 0.0500. Data: 0.18s. Batch: 0.32s. S_Loss: 1.1135. T_Loss: 5.2057. Mask: 0.8099. :  12%|█▏        | 12/100 [00:03<00:13,  6.58it/s]Train Iter: 813/5000. LR: 0.0500. Data: 0.17s. Batch: 0.31s. S_Loss: 1.1151. T_Loss: 5.2115. Mask: 0.8173. :  12%|█▏        | 12/100 [00:04<00:13,  6.58it/s]Train Iter: 813/5000. LR: 0.0500. Data: 0.17s. Batch: 0.31s. S_Loss: 1.1151. T_Loss: 5.2115. Mask: 0.8173. :  13%|█▎        | 13/100 [00:04<00:13,  6.61it/s]Train Iter: 814/5000. LR: 0.0500. Data: 0.16s. Batch: 0.29s. S_Loss: 1.1194. T_Loss: 5.2427. Mask: 0.8192. :  13%|█▎        | 13/100 [00:04<00:13,  6.61it/s]Train Iter: 814/5000. LR: 0.0500. Data: 0.16s. Batch: 0.29s. S_Loss: 1.1194. T_Loss: 5.2427. Mask: 0.8192. :  14%|█▍        | 14/100 [00:04<00:12,  7.10it/s]Train Iter: 815/5000. LR: 0.0500. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1177. T_Loss: 5.2207. Mask: 0.8208. :  14%|█▍        | 14/100 [00:04<00:12,  7.10it/s]Train Iter: 815/5000. LR: 0.0500. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1177. T_Loss: 5.2207. Mask: 0.8208. :  15%|█▌        | 15/100 [00:04<00:16,  5.16it/s]Train Iter: 816/5000. LR: 0.0500. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1168. T_Loss: 5.1985. Mask: 0.8262. :  15%|█▌        | 15/100 [00:04<00:16,  5.16it/s]Train Iter: 816/5000. LR: 0.0500. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1168. T_Loss: 5.1985. Mask: 0.8262. :  16%|█▌        | 16/100 [00:04<00:14,  5.80it/s]Train Iter: 817/5000. LR: 0.0500. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1144. T_Loss: 5.1573. Mask: 0.8364. :  16%|█▌        | 16/100 [00:04<00:14,  5.80it/s]Train Iter: 818/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1091. T_Loss: 5.0628. Mask: 0.8351. :  17%|█▋        | 17/100 [00:04<00:14,  5.80it/s]Train Iter: 818/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1091. T_Loss: 5.0628. Mask: 0.8351. :  18%|█▊        | 18/100 [00:04<00:11,  7.33it/s]Train Iter: 819/5000. LR: 0.0500. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1054. T_Loss: 5.0080. Mask: 0.8355. :  18%|█▊        | 18/100 [00:05<00:11,  7.33it/s]Train Iter: 819/5000. LR: 0.0500. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1054. T_Loss: 5.0080. Mask: 0.8355. :  19%|█▉        | 19/100 [00:05<00:14,  5.53it/s]Train Iter: 820/5000. LR: 0.0500. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1052. T_Loss: 4.9818. Mask: 0.8422. :  19%|█▉        | 19/100 [00:05<00:14,  5.53it/s]Train Iter: 820/5000. LR: 0.0500. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1052. T_Loss: 4.9818. Mask: 0.8422. :  20%|██        | 20/100 [00:05<00:12,  6.22it/s]Train Iter: 821/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1037. T_Loss: 4.9532. Mask: 0.8438. :  20%|██        | 20/100 [00:05<00:12,  6.22it/s]Train Iter: 821/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1037. T_Loss: 4.9532. Mask: 0.8438. :  21%|██        | 21/100 [00:05<00:11,  6.62it/s]Train Iter: 822/5000. LR: 0.0500. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1037. T_Loss: 4.9340. Mask: 0.8452. :  21%|██        | 21/100 [00:05<00:11,  6.62it/s]Train Iter: 822/5000. LR: 0.0500. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1037. T_Loss: 4.9340. Mask: 0.8452. :  22%|██▏       | 22/100 [00:05<00:11,  6.92it/s]Train Iter: 823/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1034. T_Loss: 4.8945. Mask: 0.8478. :  22%|██▏       | 22/100 [00:05<00:11,  6.92it/s]Train Iter: 823/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1034. T_Loss: 4.8945. Mask: 0.8478. :  23%|██▎       | 23/100 [00:05<00:10,  7.25it/s]Train Iter: 824/5000. LR: 0.0500. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1021. T_Loss: 4.8357. Mask: 0.8503. :  23%|██▎       | 23/100 [00:05<00:10,  7.25it/s]Train Iter: 824/5000. LR: 0.0500. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1021. T_Loss: 4.8357. Mask: 0.8503. :  24%|██▍       | 24/100 [00:05<00:10,  7.49it/s]Train Iter: 825/5000. LR: 0.0500. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0983. T_Loss: 4.7860. Mask: 0.8550. :  24%|██▍       | 24/100 [00:05<00:10,  7.49it/s]Train Iter: 825/5000. LR: 0.0500. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0983. T_Loss: 4.7860. Mask: 0.8550. :  25%|██▌       | 25/100 [00:05<00:12,  6.07it/s]total : 5000  current step :  801
total : 5000  current step :  802
total : 5000  current step :  803
total : 5000  current step :  804
total : 5000  current step :  805
total : 5000  current step :  806
total : 5000  current step :  807
total : 5000  current step :  808
total : 5000  current step :  809
total : 5000  current step :  810
total : 5000  current step :  811
total : 5000  current step :  812
total : 5000  current step :  813
total : 5000  current step :  814
total : 5000  current step :  815
total : 5000  current step :  816
total : 5000  current step :  817
total : 5000  current step :  818
total : 5000  current step :  819
total : 5000  current step :  820
total : 5000  current step :  821
total : 5000  current step :  822
total : 5000  current step :  823
total : 5000  current step :  824
total : 5000  current step :  825
Train Iter: 826/5000. LR: 0.0500. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0989. T_Loss: 4.8405. Mask: 0.8546. :  25%|██▌       | 25/100 [00:08<00:12,  6.07it/s]Train Iter: 826/5000. LR: 0.0500. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0989. T_Loss: 4.8405. Mask: 0.8546. :  26%|██▌       | 26/100 [00:08<00:54,  1.36it/s]Train Iter: 827/5000. LR: 0.0500. Data: 0.16s. Batch: 0.30s. S_Loss: 1.1001. T_Loss: 4.8989. Mask: 0.8588. :  26%|██▌       | 26/100 [00:08<00:54,  1.36it/s]Train Iter: 827/5000. LR: 0.0500. Data: 0.16s. Batch: 0.30s. S_Loss: 1.1001. T_Loss: 4.8989. Mask: 0.8588. :  27%|██▋       | 27/100 [00:08<00:40,  1.81it/s]Train Iter: 828/5000. LR: 0.0500. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1000. T_Loss: 4.8734. Mask: 0.8616. :  27%|██▋       | 27/100 [00:08<00:40,  1.81it/s]Train Iter: 828/5000. LR: 0.0500. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1000. T_Loss: 4.8734. Mask: 0.8616. :  28%|██▊       | 28/100 [00:08<00:30,  2.34it/s]Train Iter: 829/5000. LR: 0.0500. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1023. T_Loss: 4.8988. Mask: 0.8653. :  28%|██▊       | 28/100 [00:08<00:30,  2.34it/s]Train Iter: 829/5000. LR: 0.0500. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1023. T_Loss: 4.8988. Mask: 0.8653. :  29%|██▉       | 29/100 [00:08<00:23,  2.97it/s]Train Iter: 830/5000. LR: 0.0500. Data: 0.14s. Batch: 0.28s. S_Loss: 1.1016. T_Loss: 4.8967. Mask: 0.8688. :  29%|██▉       | 29/100 [00:08<00:23,  2.97it/s]Train Iter: 830/5000. LR: 0.0500. Data: 0.14s. Batch: 0.28s. S_Loss: 1.1016. T_Loss: 4.8967. Mask: 0.8688. :  30%|███       | 30/100 [00:08<00:19,  3.67it/s]Train Iter: 831/5000. LR: 0.0500. Data: 0.14s. Batch: 0.28s. S_Loss: 1.1005. T_Loss: 4.8885. Mask: 0.8679. :  30%|███       | 30/100 [00:08<00:19,  3.67it/s]Train Iter: 831/5000. LR: 0.0500. Data: 0.14s. Batch: 0.28s. S_Loss: 1.1005. T_Loss: 4.8885. Mask: 0.8679. :  31%|███       | 31/100 [00:08<00:16,  4.29it/s]Train Iter: 832/5000. LR: 0.0500. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1031. T_Loss: 4.8918. Mask: 0.8672. :  31%|███       | 31/100 [00:08<00:16,  4.29it/s]Train Iter: 833/5000. LR: 0.0500. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1025. T_Loss: 4.9006. Mask: 0.8703. :  32%|███▏      | 32/100 [00:08<00:15,  4.29it/s]Train Iter: 833/5000. LR: 0.0500. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1025. T_Loss: 4.9006. Mask: 0.8703. :  33%|███▎      | 33/100 [00:08<00:11,  5.66it/s]Train Iter: 834/5000. LR: 0.0500. Data: 0.13s. Batch: 0.26s. S_Loss: 1.1005. T_Loss: 4.8976. Mask: 0.8704. :  33%|███▎      | 33/100 [00:09<00:11,  5.66it/s]Train Iter: 834/5000. LR: 0.0500. Data: 0.13s. Batch: 0.26s. S_Loss: 1.1005. T_Loss: 4.8976. Mask: 0.8704. :  34%|███▍      | 34/100 [00:09<00:10,  6.12it/s]Train Iter: 835/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0996. T_Loss: 4.8914. Mask: 0.8705. :  34%|███▍      | 34/100 [00:09<00:10,  6.12it/s]Train Iter: 835/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0996. T_Loss: 4.8914. Mask: 0.8705. :  35%|███▌      | 35/100 [00:09<00:12,  5.16it/s]Train Iter: 836/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0970. T_Loss: 4.8929. Mask: 0.8715. :  35%|███▌      | 35/100 [00:09<00:12,  5.16it/s]Train Iter: 836/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0970. T_Loss: 4.8929. Mask: 0.8715. :  36%|███▌      | 36/100 [00:09<00:11,  5.76it/s]Train Iter: 837/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0966. T_Loss: 4.8789. Mask: 0.8708. :  36%|███▌      | 36/100 [00:09<00:11,  5.76it/s]Train Iter: 837/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0966. T_Loss: 4.8789. Mask: 0.8708. :  37%|███▋      | 37/100 [00:09<00:10,  6.18it/s]Train Iter: 838/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0944. T_Loss: 4.8662. Mask: 0.8709. :  37%|███▋      | 37/100 [00:09<00:10,  6.18it/s]Train Iter: 838/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0944. T_Loss: 4.8662. Mask: 0.8709. :  38%|███▊      | 38/100 [00:09<00:09,  6.61it/s]Train Iter: 839/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0952. T_Loss: 4.8745. Mask: 0.8726. :  38%|███▊      | 38/100 [00:09<00:09,  6.61it/s]Train Iter: 839/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0952. T_Loss: 4.8745. Mask: 0.8726. :  39%|███▉      | 39/100 [00:09<00:10,  6.00it/s]Train Iter: 840/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0939. T_Loss: 4.8549. Mask: 0.8727. :  39%|███▉      | 39/100 [00:09<00:10,  6.00it/s]Train Iter: 841/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0924. T_Loss: 4.8571. Mask: 0.8758. :  40%|████      | 40/100 [00:10<00:09,  6.00it/s]Train Iter: 841/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0924. T_Loss: 4.8571. Mask: 0.8758. :  41%|████      | 41/100 [00:10<00:08,  7.24it/s]Train Iter: 842/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0916. T_Loss: 4.8307. Mask: 0.8750. :  41%|████      | 41/100 [00:10<00:08,  7.24it/s]Train Iter: 842/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0916. T_Loss: 4.8307. Mask: 0.8750. :  42%|████▏     | 42/100 [00:10<00:07,  7.34it/s]Train Iter: 843/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0905. T_Loss: 4.8281. Mask: 0.8757. :  42%|████▏     | 42/100 [00:10<00:07,  7.34it/s]Train Iter: 843/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0905. T_Loss: 4.8281. Mask: 0.8757. :  43%|████▎     | 43/100 [00:10<00:07,  7.44it/s]Train Iter: 844/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0891. T_Loss: 4.8181. Mask: 0.8764. :  43%|████▎     | 43/100 [00:10<00:07,  7.44it/s]Train Iter: 844/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0891. T_Loss: 4.8181. Mask: 0.8764. :  44%|████▍     | 44/100 [00:10<00:07,  7.54it/s]Train Iter: 845/5000. LR: 0.0500. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0876. T_Loss: 4.8153. Mask: 0.8785. :  44%|████▍     | 44/100 [00:10<00:07,  7.54it/s]Train Iter: 845/5000. LR: 0.0500. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0876. T_Loss: 4.8153. Mask: 0.8785. :  45%|████▌     | 45/100 [00:10<00:07,  7.58it/s]Train Iter: 846/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0864. T_Loss: 4.8167. Mask: 0.8804. :  45%|████▌     | 45/100 [00:10<00:07,  7.58it/s]Train Iter: 846/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0864. T_Loss: 4.8167. Mask: 0.8804. :  46%|████▌     | 46/100 [00:10<00:07,  7.58it/s]Train Iter: 847/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0866. T_Loss: 4.8193. Mask: 0.8816. :  46%|████▌     | 46/100 [00:10<00:07,  7.58it/s]Train Iter: 847/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0866. T_Loss: 4.8193. Mask: 0.8816. :  47%|████▋     | 47/100 [00:10<00:06,  7.63it/s]Train Iter: 848/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0851. T_Loss: 4.8252. Mask: 0.8828. :  47%|████▋     | 47/100 [00:10<00:06,  7.63it/s]Train Iter: 848/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0851. T_Loss: 4.8252. Mask: 0.8828. :  48%|████▊     | 48/100 [00:10<00:06,  7.76it/s]Train Iter: 849/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0836. T_Loss: 4.8120. Mask: 0.8814. :  48%|████▊     | 48/100 [00:11<00:06,  7.76it/s]Train Iter: 849/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0836. T_Loss: 4.8120. Mask: 0.8814. :  49%|████▉     | 49/100 [00:11<00:08,  5.91it/s]Train Iter: 850/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0843. T_Loss: 4.8226. Mask: 0.8825. :  49%|████▉     | 49/100 [00:11<00:08,  5.91it/s]Train Iter: 850/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0843. T_Loss: 4.8226. Mask: 0.8825. :  50%|█████     | 50/100 [00:11<00:07,  6.34it/s]total : 5000  current step :  826
total : 5000  current step :  827
total : 5000  current step :  828
total : 5000  current step :  829
total : 5000  current step :  830
total : 5000  current step :  831
total : 5000  current step :  832
total : 5000  current step :  833
total : 5000  current step :  834
total : 5000  current step :  835
total : 5000  current step :  836
total : 5000  current step :  837
total : 5000  current step :  838
total : 5000  current step :  839
total : 5000  current step :  840
total : 5000  current step :  841
total : 5000  current step :  842
total : 5000  current step :  843
total : 5000  current step :  844
total : 5000  current step :  845
total : 5000  current step :  846
total : 5000  current step :  847
total : 5000  current step :  848
total : 5000  current step :  849
total : 5000  current step :  850
Train Iter: 851/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0841. T_Loss: 4.8246. Mask: 0.8824. :  50%|█████     | 50/100 [00:13<00:07,  6.34it/s]Train Iter: 851/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0841. T_Loss: 4.8246. Mask: 0.8824. :  51%|█████     | 51/100 [00:13<00:33,  1.45it/s]Train Iter: 852/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0850. T_Loss: 4.8343. Mask: 0.8840. :  51%|█████     | 51/100 [00:13<00:33,  1.45it/s]Train Iter: 852/5000. LR: 0.0500. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0850. T_Loss: 4.8343. Mask: 0.8840. :  52%|█████▏    | 52/100 [00:13<00:25,  1.92it/s]Train Iter: 853/5000. LR: 0.0500. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0848. T_Loss: 4.8290. Mask: 0.8838. :  52%|█████▏    | 52/100 [00:13<00:25,  1.92it/s]Train Iter: 853/5000. LR: 0.0500. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0848. T_Loss: 4.8290. Mask: 0.8838. :  53%|█████▎    | 53/100 [00:13<00:18,  2.48it/s]Train Iter: 854/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0839. T_Loss: 4.8267. Mask: 0.8837. :  53%|█████▎    | 53/100 [00:13<00:18,  2.48it/s]Train Iter: 854/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0839. T_Loss: 4.8267. Mask: 0.8837. :  54%|█████▍    | 54/100 [00:13<00:14,  3.14it/s]Train Iter: 855/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0822. T_Loss: 4.8273. Mask: 0.8852. :  54%|█████▍    | 54/100 [00:13<00:14,  3.14it/s]Train Iter: 855/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0822. T_Loss: 4.8273. Mask: 0.8852. :  55%|█████▌    | 55/100 [00:13<00:12,  3.68it/s]Train Iter: 856/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0820. T_Loss: 4.8105. Mask: 0.8850. :  55%|█████▌    | 55/100 [00:13<00:12,  3.68it/s]Train Iter: 856/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0820. T_Loss: 4.8105. Mask: 0.8850. :  56%|█████▌    | 56/100 [00:13<00:09,  4.40it/s]Train Iter: 857/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0818. T_Loss: 4.8168. Mask: 0.8860. :  56%|█████▌    | 56/100 [00:14<00:09,  4.40it/s]Train Iter: 857/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0818. T_Loss: 4.8168. Mask: 0.8860. :  57%|█████▋    | 57/100 [00:14<00:08,  5.11it/s]Train Iter: 858/5000. LR: 0.0500. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0790. T_Loss: 4.8175. Mask: 0.8874. :  57%|█████▋    | 57/100 [00:14<00:08,  5.11it/s]Train Iter: 858/5000. LR: 0.0500. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0790. T_Loss: 4.8175. Mask: 0.8874. :  58%|█████▊    | 58/100 [00:14<00:07,  5.78it/s]Train Iter: 859/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0777. T_Loss: 4.8147. Mask: 0.8882. :  58%|█████▊    | 58/100 [00:14<00:07,  5.78it/s]Train Iter: 859/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0777. T_Loss: 4.8147. Mask: 0.8882. :  59%|█████▉    | 59/100 [00:14<00:08,  4.88it/s]Train Iter: 860/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0771. T_Loss: 4.8104. Mask: 0.8885. :  59%|█████▉    | 59/100 [00:14<00:08,  4.88it/s]Train Iter: 860/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0771. T_Loss: 4.8104. Mask: 0.8885. :  60%|██████    | 60/100 [00:14<00:07,  5.59it/s]Train Iter: 861/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0746. T_Loss: 4.7979. Mask: 0.8878. :  60%|██████    | 60/100 [00:14<00:07,  5.59it/s]Train Iter: 861/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0746. T_Loss: 4.7979. Mask: 0.8878. :  61%|██████    | 61/100 [00:14<00:06,  6.11it/s]Train Iter: 862/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0741. T_Loss: 4.7984. Mask: 0.8886. :  61%|██████    | 61/100 [00:14<00:06,  6.11it/s]Train Iter: 863/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0731. T_Loss: 4.7791. Mask: 0.8884. :  62%|██████▏   | 62/100 [00:14<00:06,  6.11it/s]Train Iter: 863/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0731. T_Loss: 4.7791. Mask: 0.8884. :  63%|██████▎   | 63/100 [00:14<00:04,  7.95it/s]Train Iter: 864/5000. LR: 0.0500. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0719. T_Loss: 4.7745. Mask: 0.8901. :  63%|██████▎   | 63/100 [00:14<00:04,  7.95it/s]Train Iter: 865/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0704. T_Loss: 4.7606. Mask: 0.8904. :  64%|██████▍   | 64/100 [00:15<00:04,  7.95it/s]Train Iter: 865/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0704. T_Loss: 4.7606. Mask: 0.8904. :  65%|██████▌   | 65/100 [00:15<00:05,  6.71it/s]Train Iter: 866/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0708. T_Loss: 4.7612. Mask: 0.8902. :  65%|██████▌   | 65/100 [00:15<00:05,  6.71it/s]Train Iter: 866/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0708. T_Loss: 4.7612. Mask: 0.8902. :  66%|██████▌   | 66/100 [00:15<00:04,  6.88it/s]Train Iter: 867/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0702. T_Loss: 4.7564. Mask: 0.8899. :  66%|██████▌   | 66/100 [00:15<00:04,  6.88it/s]Train Iter: 867/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0702. T_Loss: 4.7564. Mask: 0.8899. :  67%|██████▋   | 67/100 [00:15<00:04,  7.03it/s]Train Iter: 868/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0707. T_Loss: 4.7444. Mask: 0.8902. :  67%|██████▋   | 67/100 [00:15<00:04,  7.03it/s]Train Iter: 868/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0707. T_Loss: 4.7444. Mask: 0.8902. :  68%|██████▊   | 68/100 [00:15<00:04,  7.09it/s]Train Iter: 869/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0699. T_Loss: 4.7467. Mask: 0.8904. :  68%|██████▊   | 68/100 [00:15<00:04,  7.09it/s]Train Iter: 869/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0699. T_Loss: 4.7467. Mask: 0.8904. :  69%|██████▉   | 69/100 [00:15<00:05,  5.90it/s]Train Iter: 870/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0697. T_Loss: 4.7483. Mask: 0.8906. :  69%|██████▉   | 69/100 [00:16<00:05,  5.90it/s]Train Iter: 870/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0697. T_Loss: 4.7483. Mask: 0.8906. :  70%|███████   | 70/100 [00:16<00:04,  6.28it/s]Train Iter: 871/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0707. T_Loss: 4.7505. Mask: 0.8904. :  70%|███████   | 70/100 [00:16<00:04,  6.28it/s]Train Iter: 871/5000. LR: 0.0500. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0707. T_Loss: 4.7505. Mask: 0.8904. :  71%|███████   | 71/100 [00:16<00:04,  6.68it/s]Train Iter: 872/5000. LR: 0.0500. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0709. T_Loss: 4.7673. Mask: 0.8911. :  71%|███████   | 71/100 [00:16<00:04,  6.68it/s]Train Iter: 872/5000. LR: 0.0500. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0709. T_Loss: 4.7673. Mask: 0.8911. :  72%|███████▏  | 72/100 [00:16<00:03,  7.37it/s]Train Iter: 873/5000. LR: 0.0500. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0698. T_Loss: 4.7724. Mask: 0.8917. :  72%|███████▏  | 72/100 [00:16<00:03,  7.37it/s]Train Iter: 873/5000. LR: 0.0500. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0698. T_Loss: 4.7724. Mask: 0.8917. :  73%|███████▎  | 73/100 [00:16<00:03,  7.67it/s]Train Iter: 874/5000. LR: 0.0500. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0691. T_Loss: 4.7674. Mask: 0.8915. :  73%|███████▎  | 73/100 [00:16<00:03,  7.67it/s]Train Iter: 874/5000. LR: 0.0500. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0691. T_Loss: 4.7674. Mask: 0.8915. :  74%|███████▍  | 74/100 [00:16<00:03,  7.60it/s]Train Iter: 875/5000. LR: 0.0500. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0707. T_Loss: 4.7749. Mask: 0.8912. :  74%|███████▍  | 74/100 [00:16<00:03,  7.60it/s]Train Iter: 875/5000. LR: 0.0500. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0707. T_Loss: 4.7749. Mask: 0.8912. :  75%|███████▌  | 75/100 [00:16<00:04,  5.89it/s]total : 5000  current step :  851
total : 5000  current step :  852
total : 5000  current step :  853
total : 5000  current step :  854
total : 5000  current step :  855
total : 5000  current step :  856
total : 5000  current step :  857
total : 5000  current step :  858
total : 5000  current step :  859
total : 5000  current step :  860
total : 5000  current step :  861
total : 5000  current step :  862
total : 5000  current step :  863
total : 5000  current step :  864
total : 5000  current step :  865
total : 5000  current step :  866
total : 5000  current step :  867
total : 5000  current step :  868
total : 5000  current step :  869
total : 5000  current step :  870
total : 5000  current step :  871
total : 5000  current step :  872
total : 5000  current step :  873
total : 5000  current step :  874
total : 5000  current step :  875
Train Iter: 876/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0686. T_Loss: 4.7724. Mask: 0.8919. :  75%|███████▌  | 75/100 [00:18<00:04,  5.89it/s]Train Iter: 876/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0686. T_Loss: 4.7724. Mask: 0.8919. :  76%|███████▌  | 76/100 [00:18<00:17,  1.35it/s]Train Iter: 877/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0684. T_Loss: 4.7786. Mask: 0.8920. :  76%|███████▌  | 76/100 [00:19<00:17,  1.35it/s]Train Iter: 877/5000. LR: 0.0500. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0684. T_Loss: 4.7786. Mask: 0.8920. :  77%|███████▋  | 77/100 [00:19<00:12,  1.79it/s]Train Iter: 878/5000. LR: 0.0500. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0679. T_Loss: 4.7776. Mask: 0.8926. :  77%|███████▋  | 77/100 [00:19<00:12,  1.79it/s]Train Iter: 879/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0668. T_Loss: 4.7935. Mask: 0.8940. :  78%|███████▊  | 78/100 [00:19<00:12,  1.79it/s]Train Iter: 879/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0668. T_Loss: 4.7935. Mask: 0.8940. :  79%|███████▉  | 79/100 [00:19<00:08,  2.62it/s]Train Iter: 880/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0671. T_Loss: 4.7938. Mask: 0.8949. :  79%|███████▉  | 79/100 [00:19<00:08,  2.62it/s]Train Iter: 880/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0671. T_Loss: 4.7938. Mask: 0.8949. :  80%|████████  | 80/100 [00:19<00:06,  3.17it/s]Train Iter: 881/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0677. T_Loss: 4.7918. Mask: 0.8947. :  80%|████████  | 80/100 [00:19<00:06,  3.17it/s]Train Iter: 881/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0677. T_Loss: 4.7918. Mask: 0.8947. :  81%|████████  | 81/100 [00:19<00:04,  3.81it/s]Train Iter: 882/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0675. T_Loss: 4.7945. Mask: 0.8952. :  81%|████████  | 81/100 [00:19<00:04,  3.81it/s]Train Iter: 882/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0675. T_Loss: 4.7945. Mask: 0.8952. :  82%|████████▏ | 82/100 [00:19<00:03,  4.52it/s]Train Iter: 883/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0669. T_Loss: 4.7938. Mask: 0.8946. :  82%|████████▏ | 82/100 [00:19<00:03,  4.52it/s]Train Iter: 883/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0669. T_Loss: 4.7938. Mask: 0.8946. :  83%|████████▎ | 83/100 [00:19<00:03,  5.17it/s]Train Iter: 884/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0660. T_Loss: 4.7925. Mask: 0.8943. :  83%|████████▎ | 83/100 [00:19<00:03,  5.17it/s]Train Iter: 884/5000. LR: 0.0500. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0660. T_Loss: 4.7925. Mask: 0.8943. :  84%|████████▍ | 84/100 [00:19<00:02,  5.78it/s]Train Iter: 885/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0643. T_Loss: 4.7922. Mask: 0.8945. :  84%|████████▍ | 84/100 [00:20<00:02,  5.78it/s]Train Iter: 885/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0643. T_Loss: 4.7922. Mask: 0.8945. :  85%|████████▌ | 85/100 [00:20<00:03,  4.80it/s]Train Iter: 886/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0644. T_Loss: 4.7919. Mask: 0.8935. :  85%|████████▌ | 85/100 [00:20<00:03,  4.80it/s]Train Iter: 886/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0644. T_Loss: 4.7919. Mask: 0.8935. :  86%|████████▌ | 86/100 [00:20<00:02,  5.49it/s]Train Iter: 887/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0652. T_Loss: 4.7836. Mask: 0.8926. :  86%|████████▌ | 86/100 [00:20<00:02,  5.49it/s]Train Iter: 887/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0652. T_Loss: 4.7836. Mask: 0.8926. :  87%|████████▋ | 87/100 [00:20<00:02,  6.13it/s]Train Iter: 888/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0662. T_Loss: 4.7775. Mask: 0.8920. :  87%|████████▋ | 87/100 [00:20<00:02,  6.13it/s]Train Iter: 888/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0662. T_Loss: 4.7775. Mask: 0.8920. :  88%|████████▊ | 88/100 [00:20<00:01,  6.73it/s]Train Iter: 889/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0676. T_Loss: 4.7792. Mask: 0.8919. :  88%|████████▊ | 88/100 [00:20<00:01,  6.73it/s]Train Iter: 889/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0676. T_Loss: 4.7792. Mask: 0.8919. :  89%|████████▉ | 89/100 [00:20<00:02,  5.26it/s]Train Iter: 890/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0687. T_Loss: 4.7887. Mask: 0.8917. :  89%|████████▉ | 89/100 [00:21<00:02,  5.26it/s]Train Iter: 890/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0687. T_Loss: 4.7887. Mask: 0.8917. :  90%|█████████ | 90/100 [00:21<00:01,  5.80it/s]Train Iter: 891/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0671. T_Loss: 4.7859. Mask: 0.8922. :  90%|█████████ | 90/100 [00:21<00:01,  5.80it/s]Train Iter: 891/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0671. T_Loss: 4.7859. Mask: 0.8922. :  91%|█████████ | 91/100 [00:21<00:01,  6.04it/s]Train Iter: 892/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0677. T_Loss: 4.7864. Mask: 0.8920. :  91%|█████████ | 91/100 [00:21<00:01,  6.04it/s]Train Iter: 892/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0677. T_Loss: 4.7864. Mask: 0.8920. :  92%|█████████▏| 92/100 [00:21<00:01,  6.52it/s]Train Iter: 893/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0674. T_Loss: 4.7858. Mask: 0.8915. :  92%|█████████▏| 92/100 [00:21<00:01,  6.52it/s]Train Iter: 893/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0674. T_Loss: 4.7858. Mask: 0.8915. :  93%|█████████▎| 93/100 [00:21<00:00,  7.18it/s]Train Iter: 894/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0665. T_Loss: 4.7800. Mask: 0.8916. :  93%|█████████▎| 93/100 [00:21<00:00,  7.18it/s]Train Iter: 894/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0665. T_Loss: 4.7800. Mask: 0.8916. :  94%|█████████▍| 94/100 [00:21<00:00,  7.60it/s]Train Iter: 895/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0661. T_Loss: 4.7747. Mask: 0.8918. :  94%|█████████▍| 94/100 [00:21<00:00,  7.60it/s]Train Iter: 895/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0661. T_Loss: 4.7747. Mask: 0.8918. :  95%|█████████▌| 95/100 [00:21<00:00,  7.76it/s]Train Iter: 896/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0658. T_Loss: 4.7733. Mask: 0.8929. :  95%|█████████▌| 95/100 [00:21<00:00,  7.76it/s]Train Iter: 896/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0658. T_Loss: 4.7733. Mask: 0.8929. :  96%|█████████▌| 96/100 [00:21<00:00,  7.85it/s]Train Iter: 897/5000. LR: 0.0499. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0655. T_Loss: 4.7669. Mask: 0.8927. :  96%|█████████▌| 96/100 [00:21<00:00,  7.85it/s]Train Iter: 897/5000. LR: 0.0499. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0655. T_Loss: 4.7669. Mask: 0.8927. :  97%|█████████▋| 97/100 [00:21<00:00,  7.81it/s]Train Iter: 898/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0648. T_Loss: 4.7630. Mask: 0.8929. :  97%|█████████▋| 97/100 [00:22<00:00,  7.81it/s]Train Iter: 898/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0648. T_Loss: 4.7630. Mask: 0.8929. :  98%|█████████▊| 98/100 [00:22<00:00,  7.64it/s]Train Iter: 899/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0638. T_Loss: 4.7638. Mask: 0.8936. :  98%|█████████▊| 98/100 [00:22<00:00,  7.64it/s]Train Iter: 899/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0638. T_Loss: 4.7638. Mask: 0.8936. :  99%|█████████▉| 99/100 [00:22<00:00,  5.12it/s]Train Iter: 900/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0634. T_Loss: 4.7587. Mask: 0.8938. :  99%|█████████▉| 99/100 [00:22<00:00,  5.12it/s]Train Iter: 900/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0634. T_Loss: 4.7587. Mask: 0.8938. : 100%|██████████| 100/100 [00:22<00:00,  5.85it/s]Train Iter: 900/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0634. T_Loss: 4.7587. Mask: 0.8938. : 100%|██████████| 100/100 [00:22<00:00,  4.45it/s]
total : 5000  current step :  876
total : 5000  current step :  877
total : 5000  current step :  878
total : 5000  current step :  879
total : 5000  current step :  880
total : 5000  current step :  881
total : 5000  current step :  882
total : 5000  current step :  883
total : 5000  current step :  884
total : 5000  current step :  885
total : 5000  current step :  886
total : 5000  current step :  887
total : 5000  current step :  888
total : 5000  current step :  889
total : 5000  current step :  890
total : 5000  current step :  891
total : 5000  current step :  892
total : 5000  current step :  893
total : 5000  current step :  894
total : 5000  current step :  895
total : 5000  current step :  896
total : 5000  current step :  897
total : 5000  current step :  898
total : 5000  current step :  899
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.63s. Loss: 1.1380. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.63s. Loss: 1.1380. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.82s. Loss: 1.0949. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 1.0440. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 1.0799. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 1.0628. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 1.0707. top1: 77.08. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.0729. top1: 76.79. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.0825. top1: 75.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.0726. top1: 76.04. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.0783. top1: 74.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.0652. top1: 75.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0687. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0687. top1: 75.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0631. top1: 75.24. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0672. top1: 74.55. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0543. top1: 75.83. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0506. top1: 75.98. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0478. top1: 76.47. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0472. top1: 76.22. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0471. top1: 76.15. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0469. top1: 76.41. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0504. top1: 76.19. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  9.35it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0504. top1: 76.19. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0469. top1: 76.42. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0442. top1: 76.63. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0421. top1: 76.69. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0425. top1: 76.88. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0463. top1: 76.44. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0423. top1: 76.74. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0441. top1: 76.56. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0454. top1: 76.40. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0452. top1: 76.56. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0459. top1: 76.51. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0563. top1: 75.68. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0563. top1: 75.68. top5: 100.00. :  51%|█████     | 32/63 [00:01<00:01, 29.09it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0627. top1: 75.47. top5: 100.00. :  51%|█████     | 32/63 [00:01<00:01, 29.09it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0776. top1: 74.82. top5: 99.91. :  51%|█████     | 32/63 [00:01<00:01, 29.09it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0823. top1: 74.91. top5: 99.91. :  51%|█████     | 32/63 [00:01<00:01, 29.09it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1035. top1: 73.96. top5: 99.83. :  51%|█████     | 32/63 [00:01<00:01, 29.09it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1068. top1: 73.90. top5: 99.83. :  51%|█████     | 32/63 [00:02<00:01, 29.09it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1113. top1: 73.60. top5: 99.84. :  51%|█████     | 32/63 [00:02<00:01, 29.09it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1267. top1: 73.16. top5: 99.76. :  51%|█████     | 32/63 [00:02<00:01, 29.09it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1316. top1: 72.73. top5: 99.77. :  51%|█████     | 32/63 [00:02<00:01, 29.09it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1356. top1: 72.71. top5: 99.77. :  51%|█████     | 32/63 [00:02<00:01, 29.09it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1410. top1: 72.40. top5: 99.78. :  51%|█████     | 32/63 [00:02<00:01, 29.09it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1410. top1: 72.40. top5: 99.78. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1429. top1: 72.46. top5: 99.78. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1440. top1: 72.66. top5: 99.79. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1484. top1: 72.22. top5: 99.79. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1525. top1: 71.81. top5: 99.80. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1593. top1: 71.54. top5: 99.73. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1642. top1: 71.35. top5: 99.74. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1698. top1: 71.30. top5: 99.74. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1746. top1: 71.06. top5: 99.75. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1877. top1: 70.53. top5: 99.69. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1903. top1: 70.49. top5: 99.70. :  67%|██████▋   | 42/63 [00:02<00:00, 39.41it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1903. top1: 70.49. top5: 99.70. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1940. top1: 70.52. top5: 99.59. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1987. top1: 70.20. top5: 99.59. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2026. top1: 70.17. top5: 99.60. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2028. top1: 70.37. top5: 99.61. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2109. top1: 70.12. top5: 99.62. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2142. top1: 70.04. top5: 99.62. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2191. top1: 69.86. top5: 99.63. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2195. top1: 69.90. top5: 99.64. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2256. top1: 69.57. top5: 99.64. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2342. top1: 69.20. top5: 99.65. :  83%|████████▎ | 52/63 [00:02<00:00, 49.29it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2342. top1: 69.20. top5: 99.65. :  98%|█████████▊| 62/63 [00:02<00:00, 58.17it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2367. top1: 69.10. top5: 99.65. :  98%|█████████▊| 62/63 [00:02<00:00, 58.17it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2367. top1: 69.10. top5: 99.65. : 100%|██████████| 63/63 [00:02<00:00, 25.53it/s]
total : 5000  current step :  900
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 901/5000. LR: 0.0499. Data: 1.79s. Batch: 1.89s. S_Loss: 1.0088. T_Loss: 5.3165. Mask: 1.0000. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 901/5000. LR: 0.0499. Data: 1.79s. Batch: 1.89s. S_Loss: 1.0088. T_Loss: 5.3165. Mask: 1.0000. :   1%|          | 1/100 [00:01<03:07,  1.89s/it]Train Iter: 902/5000. LR: 0.0499. Data: 0.90s. Batch: 0.99s. S_Loss: 1.0191. T_Loss: 5.2313. Mask: 1.0000. :   1%|          | 1/100 [00:01<03:07,  1.89s/it]Train Iter: 903/5000. LR: 0.0499. Data: 0.60s. Batch: 0.69s. S_Loss: 1.0159. T_Loss: 4.8937. Mask: 0.9792. :   2%|▏         | 2/100 [00:02<03:05,  1.89s/it]Train Iter: 903/5000. LR: 0.0499. Data: 0.60s. Batch: 0.69s. S_Loss: 1.0159. T_Loss: 4.8937. Mask: 0.9792. :   3%|▎         | 3/100 [00:02<00:53,  1.80it/s]Train Iter: 904/5000. LR: 0.0499. Data: 0.45s. Batch: 0.54s. S_Loss: 0.9916. T_Loss: 4.6977. Mask: 0.9844. :   3%|▎         | 3/100 [00:02<00:53,  1.80it/s]Train Iter: 905/5000. LR: 0.0499. Data: 0.36s. Batch: 0.46s. S_Loss: 0.9899. T_Loss: 4.5824. Mask: 0.9688. :   4%|▍         | 4/100 [00:02<00:53,  1.80it/s]Train Iter: 905/5000. LR: 0.0499. Data: 0.36s. Batch: 0.46s. S_Loss: 0.9899. T_Loss: 4.5824. Mask: 0.9688. :   5%|▌         | 5/100 [00:02<00:31,  3.03it/s]Train Iter: 906/5000. LR: 0.0499. Data: 0.30s. Batch: 0.40s. S_Loss: 0.9954. T_Loss: 4.6193. Mask: 0.9583. :   5%|▌         | 5/100 [00:02<00:31,  3.03it/s]Train Iter: 906/5000. LR: 0.0499. Data: 0.30s. Batch: 0.40s. S_Loss: 0.9954. T_Loss: 4.6193. Mask: 0.9583. :   6%|▌         | 6/100 [00:02<00:25,  3.63it/s]Train Iter: 907/5000. LR: 0.0499. Data: 0.26s. Batch: 0.37s. S_Loss: 0.9819. T_Loss: 4.5020. Mask: 0.9643. :   6%|▌         | 6/100 [00:02<00:25,  3.63it/s]Train Iter: 907/5000. LR: 0.0499. Data: 0.26s. Batch: 0.37s. S_Loss: 0.9819. T_Loss: 4.5020. Mask: 0.9643. :   7%|▋         | 7/100 [00:02<00:22,  4.22it/s]Train Iter: 908/5000. LR: 0.0499. Data: 0.23s. Batch: 0.34s. S_Loss: 0.9941. T_Loss: 4.5953. Mask: 0.9648. :   7%|▋         | 7/100 [00:02<00:22,  4.22it/s]Train Iter: 908/5000. LR: 0.0499. Data: 0.23s. Batch: 0.34s. S_Loss: 0.9941. T_Loss: 4.5953. Mask: 0.9648. :   8%|▊         | 8/100 [00:02<00:19,  4.68it/s]Train Iter: 909/5000. LR: 0.0499. Data: 0.21s. Batch: 0.33s. S_Loss: 0.9887. T_Loss: 4.6052. Mask: 0.9618. :   8%|▊         | 8/100 [00:02<00:19,  4.68it/s]Train Iter: 909/5000. LR: 0.0499. Data: 0.21s. Batch: 0.33s. S_Loss: 0.9887. T_Loss: 4.6052. Mask: 0.9618. :   9%|▉         | 9/100 [00:02<00:20,  4.34it/s]Train Iter: 910/5000. LR: 0.0499. Data: 0.18s. Batch: 0.31s. S_Loss: 1.0054. T_Loss: 4.6015. Mask: 0.9531. :   9%|▉         | 9/100 [00:03<00:20,  4.34it/s]Train Iter: 910/5000. LR: 0.0499. Data: 0.18s. Batch: 0.31s. S_Loss: 1.0054. T_Loss: 4.6015. Mask: 0.9531. :  10%|█         | 10/100 [00:03<00:18,  4.94it/s]Train Iter: 911/5000. LR: 0.0499. Data: 0.17s. Batch: 0.30s. S_Loss: 1.0117. T_Loss: 4.6462. Mask: 0.9574. :  10%|█         | 10/100 [00:03<00:18,  4.94it/s]Train Iter: 911/5000. LR: 0.0499. Data: 0.17s. Batch: 0.30s. S_Loss: 1.0117. T_Loss: 4.6462. Mask: 0.9574. :  11%|█         | 11/100 [00:03<00:16,  5.47it/s]Train Iter: 912/5000. LR: 0.0499. Data: 0.15s. Batch: 0.28s. S_Loss: 1.0248. T_Loss: 4.8284. Mask: 0.9583. :  11%|█         | 11/100 [00:03<00:16,  5.47it/s]Train Iter: 912/5000. LR: 0.0499. Data: 0.15s. Batch: 0.28s. S_Loss: 1.0248. T_Loss: 4.8284. Mask: 0.9583. :  12%|█▏        | 12/100 [00:03<00:14,  5.92it/s]Train Iter: 913/5000. LR: 0.0499. Data: 0.14s. Batch: 0.27s. S_Loss: 1.0324. T_Loss: 4.9007. Mask: 0.9567. :  12%|█▏        | 12/100 [00:03<00:14,  5.92it/s]Train Iter: 913/5000. LR: 0.0499. Data: 0.14s. Batch: 0.27s. S_Loss: 1.0324. T_Loss: 4.9007. Mask: 0.9567. :  13%|█▎        | 13/100 [00:03<00:13,  6.27it/s]Train Iter: 914/5000. LR: 0.0499. Data: 0.13s. Batch: 0.26s. S_Loss: 1.0262. T_Loss: 4.8910. Mask: 0.9576. :  13%|█▎        | 13/100 [00:03<00:13,  6.27it/s]Train Iter: 914/5000. LR: 0.0499. Data: 0.13s. Batch: 0.26s. S_Loss: 1.0262. T_Loss: 4.8910. Mask: 0.9576. :  14%|█▍        | 14/100 [00:03<00:12,  6.67it/s]Train Iter: 915/5000. LR: 0.0499. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0211. T_Loss: 4.8797. Mask: 0.9521. :  14%|█▍        | 14/100 [00:03<00:12,  6.67it/s]Train Iter: 915/5000. LR: 0.0499. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0211. T_Loss: 4.8797. Mask: 0.9521. :  15%|█▌        | 15/100 [00:03<00:17,  4.99it/s]Train Iter: 916/5000. LR: 0.0499. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0218. T_Loss: 4.8427. Mask: 0.9473. :  15%|█▌        | 15/100 [00:04<00:17,  4.99it/s]Train Iter: 916/5000. LR: 0.0499. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0218. T_Loss: 4.8427. Mask: 0.9473. :  16%|█▌        | 16/100 [00:04<00:15,  5.32it/s]Train Iter: 917/5000. LR: 0.0499. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0214. T_Loss: 4.8475. Mask: 0.9449. :  16%|█▌        | 16/100 [00:04<00:15,  5.32it/s]Train Iter: 917/5000. LR: 0.0499. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0214. T_Loss: 4.8475. Mask: 0.9449. :  17%|█▋        | 17/100 [00:04<00:13,  6.01it/s]Train Iter: 918/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0221. T_Loss: 4.8829. Mask: 0.9462. :  17%|█▋        | 17/100 [00:04<00:13,  6.01it/s]Train Iter: 918/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0221. T_Loss: 4.8829. Mask: 0.9462. :  18%|█▊        | 18/100 [00:04<00:12,  6.50it/s]Train Iter: 919/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0159. T_Loss: 4.8910. Mask: 0.9474. :  18%|█▊        | 18/100 [00:04<00:12,  6.50it/s]Train Iter: 919/5000. LR: 0.0499. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0159. T_Loss: 4.8910. Mask: 0.9474. :  19%|█▉        | 19/100 [00:04<00:12,  6.68it/s]Train Iter: 920/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0148. T_Loss: 4.8918. Mask: 0.9484. :  19%|█▉        | 19/100 [00:04<00:12,  6.68it/s]Train Iter: 920/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0148. T_Loss: 4.8918. Mask: 0.9484. :  20%|██        | 20/100 [00:04<00:11,  6.99it/s]Train Iter: 921/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0208. T_Loss: 4.8991. Mask: 0.9449. :  20%|██        | 20/100 [00:04<00:11,  6.99it/s]Train Iter: 921/5000. LR: 0.0499. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0208. T_Loss: 4.8991. Mask: 0.9449. :  21%|██        | 21/100 [00:04<00:10,  7.30it/s]Train Iter: 922/5000. LR: 0.0499. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0149. T_Loss: 4.8874. Mask: 0.9446. :  21%|██        | 21/100 [00:04<00:10,  7.30it/s]Train Iter: 922/5000. LR: 0.0499. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0149. T_Loss: 4.8874. Mask: 0.9446. :  22%|██▏       | 22/100 [00:04<00:10,  7.53it/s]Train Iter: 923/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0190. T_Loss: 4.9019. Mask: 0.9389. :  22%|██▏       | 22/100 [00:05<00:10,  7.53it/s]Train Iter: 923/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0190. T_Loss: 4.9019. Mask: 0.9389. :  23%|██▎       | 23/100 [00:05<00:10,  7.65it/s]Train Iter: 924/5000. LR: 0.0499. Data: 0.08s. Batch: 0.21s. S_Loss: 1.0212. T_Loss: 4.9273. Mask: 0.9388. :  23%|██▎       | 23/100 [00:05<00:10,  7.65it/s]Train Iter: 924/5000. LR: 0.0499. Data: 0.08s. Batch: 0.21s. S_Loss: 1.0212. T_Loss: 4.9273. Mask: 0.9388. :  24%|██▍       | 24/100 [00:05<00:09,  7.68it/s]Train Iter: 925/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0193. T_Loss: 4.9452. Mask: 0.9375. :  24%|██▍       | 24/100 [00:05<00:09,  7.68it/s]Train Iter: 925/5000. LR: 0.0499. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0193. T_Loss: 4.9452. Mask: 0.9375. :  25%|██▌       | 25/100 [00:05<00:14,  5.14it/s]total : 5000  current step :  901
total : 5000  current step :  902
total : 5000  current step :  903
total : 5000  current step :  904
total : 5000  current step :  905
total : 5000  current step :  906
total : 5000  current step :  907
total : 5000  current step :  908
total : 5000  current step :  909
total : 5000  current step :  910
total : 5000  current step :  911
total : 5000  current step :  912
total : 5000  current step :  913
total : 5000  current step :  914
total : 5000  current step :  915
total : 5000  current step :  916
total : 5000  current step :  917
total : 5000  current step :  918
total : 5000  current step :  919
total : 5000  current step :  920
total : 5000  current step :  921
total : 5000  current step :  922
total : 5000  current step :  923
total : 5000  current step :  924
total : 5000  current step :  925
Train Iter: 926/5000. LR: 0.0499. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0149. T_Loss: 4.9301. Mask: 0.9351. :  25%|██▌       | 25/100 [00:07<00:14,  5.14it/s]Train Iter: 926/5000. LR: 0.0499. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0149. T_Loss: 4.9301. Mask: 0.9351. :  26%|██▌       | 26/100 [00:07<01:00,  1.22it/s]Train Iter: 927/5000. LR: 0.0499. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0241. T_Loss: 4.9455. Mask: 0.9329. :  26%|██▌       | 26/100 [00:07<01:00,  1.22it/s]Train Iter: 927/5000. LR: 0.0499. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0241. T_Loss: 4.9455. Mask: 0.9329. :  27%|██▋       | 27/100 [00:07<00:44,  1.63it/s]Train Iter: 928/5000. LR: 0.0499. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0216. T_Loss: 4.9354. Mask: 0.9330. :  27%|██▋       | 27/100 [00:08<00:44,  1.63it/s]Train Iter: 928/5000. LR: 0.0499. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0216. T_Loss: 4.9354. Mask: 0.9330. :  28%|██▊       | 28/100 [00:08<00:34,  2.11it/s]Train Iter: 929/5000. LR: 0.0499. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0227. T_Loss: 4.9205. Mask: 0.9278. :  28%|██▊       | 28/100 [00:08<00:34,  2.11it/s]Train Iter: 929/5000. LR: 0.0499. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0227. T_Loss: 4.9205. Mask: 0.9278. :  29%|██▉       | 29/100 [00:08<00:30,  2.36it/s]Train Iter: 930/5000. LR: 0.0499. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0212. T_Loss: 4.9336. Mask: 0.9271. :  29%|██▉       | 29/100 [00:08<00:30,  2.36it/s]Train Iter: 930/5000. LR: 0.0499. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0212. T_Loss: 4.9336. Mask: 0.9271. :  30%|███       | 30/100 [00:08<00:23,  2.97it/s]Train Iter: 931/5000. LR: 0.0499. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0191. T_Loss: 4.9134. Mask: 0.9254. :  30%|███       | 30/100 [00:08<00:23,  2.97it/s]Train Iter: 931/5000. LR: 0.0499. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0191. T_Loss: 4.9134. Mask: 0.9254. :  31%|███       | 31/100 [00:08<00:18,  3.66it/s]Train Iter: 932/5000. LR: 0.0499. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0179. T_Loss: 4.9082. Mask: 0.9238. :  31%|███       | 31/100 [00:08<00:18,  3.66it/s]Train Iter: 932/5000. LR: 0.0499. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0179. T_Loss: 4.9082. Mask: 0.9238. :  32%|███▏      | 32/100 [00:08<00:15,  4.31it/s]Train Iter: 933/5000. LR: 0.0499. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0141. T_Loss: 4.9033. Mask: 0.9242. :  32%|███▏      | 32/100 [00:08<00:15,  4.31it/s]Train Iter: 933/5000. LR: 0.0499. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0141. T_Loss: 4.9033. Mask: 0.9242. :  33%|███▎      | 33/100 [00:08<00:14,  4.78it/s]Train Iter: 934/5000. LR: 0.0499. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0137. T_Loss: 4.9021. Mask: 0.9256. :  33%|███▎      | 33/100 [00:09<00:14,  4.78it/s]Train Iter: 934/5000. LR: 0.0499. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0137. T_Loss: 4.9021. Mask: 0.9256. :  34%|███▍      | 34/100 [00:09<00:12,  5.29it/s]Train Iter: 935/5000. LR: 0.0499. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0116. T_Loss: 4.8771. Mask: 0.9259. :  34%|███▍      | 34/100 [00:09<00:12,  5.29it/s]Train Iter: 935/5000. LR: 0.0499. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0116. T_Loss: 4.8771. Mask: 0.9259. :  35%|███▌      | 35/100 [00:09<00:14,  4.53it/s]Train Iter: 936/5000. LR: 0.0499. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0108. T_Loss: 4.8569. Mask: 0.9245. :  35%|███▌      | 35/100 [00:09<00:14,  4.53it/s]Train Iter: 936/5000. LR: 0.0499. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0108. T_Loss: 4.8569. Mask: 0.9245. :  36%|███▌      | 36/100 [00:09<00:11,  5.37it/s]Train Iter: 937/5000. LR: 0.0499. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0109. T_Loss: 4.8577. Mask: 0.9231. :  36%|███▌      | 36/100 [00:09<00:11,  5.37it/s]Train Iter: 937/5000. LR: 0.0499. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0109. T_Loss: 4.8577. Mask: 0.9231. :  37%|███▋      | 37/100 [00:09<00:10,  6.04it/s]Train Iter: 938/5000. LR: 0.0499. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0087. T_Loss: 4.8647. Mask: 0.9227. :  37%|███▋      | 37/100 [00:09<00:10,  6.04it/s]Train Iter: 938/5000. LR: 0.0499. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0087. T_Loss: 4.8647. Mask: 0.9227. :  38%|███▊      | 38/100 [00:09<00:09,  6.68it/s]total : 5000  current step :  926
total : 5000  current step :  927
total : 5000  current step :  928
total : 5000  current step :  929
total : 5000  current step :  930
total : 5000  current step :  931
total : 5000  current step :  932
total : 5000  current step :  933
total : 5000  current step :  934
total : 5000  current step :  935
total : 5000  current step :  936
total : 5000  current step :  937
total : 5000  current step :  938
Train Iter: 939/5000. LR: 0.0499. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0072. T_Loss: 4.8658. Mask: 0.9231. :  38%|███▊      | 38/100 [00:12<00:09,  6.68it/s]Train Iter: 939/5000. LR: 0.0499. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0072. T_Loss: 4.8658. Mask: 0.9231. :  39%|███▉      | 39/100 [00:12<00:58,  1.05it/s]Train Iter: 940/5000. LR: 0.0499. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0046. T_Loss: 4.8505. Mask: 0.9234. :  39%|███▉      | 39/100 [00:12<00:58,  1.05it/s]Train Iter: 940/5000. LR: 0.0499. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0046. T_Loss: 4.8505. Mask: 0.9234. :  40%|████      | 40/100 [00:12<00:42,  1.41it/s]Train Iter: 941/5000. LR: 0.0499. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0051. T_Loss: 4.8329. Mask: 0.9215. :  40%|████      | 40/100 [00:12<00:42,  1.41it/s]Train Iter: 941/5000. LR: 0.0499. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0051. T_Loss: 4.8329. Mask: 0.9215. :  41%|████      | 41/100 [00:12<00:32,  1.83it/s]Train Iter: 942/5000. LR: 0.0499. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0059. T_Loss: 4.8068. Mask: 0.9204. :  41%|████      | 41/100 [00:12<00:32,  1.83it/s]Train Iter: 942/5000. LR: 0.0499. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0059. T_Loss: 4.8068. Mask: 0.9204. :  42%|████▏     | 42/100 [00:12<00:24,  2.42it/s]Train Iter: 943/5000. LR: 0.0499. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0064. T_Loss: 4.8118. Mask: 0.9208. :  42%|████▏     | 42/100 [00:13<00:24,  2.42it/s]Train Iter: 943/5000. LR: 0.0499. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0064. T_Loss: 4.8118. Mask: 0.9208. :  43%|████▎     | 43/100 [00:13<00:18,  3.07it/s]Train Iter: 944/5000. LR: 0.0499. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0065. T_Loss: 4.7966. Mask: 0.9205. :  43%|████▎     | 43/100 [00:13<00:18,  3.07it/s]Train Iter: 944/5000. LR: 0.0499. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0065. T_Loss: 4.7966. Mask: 0.9205. :  44%|████▍     | 44/100 [00:13<00:14,  3.77it/s]Train Iter: 945/5000. LR: 0.0499. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0054. T_Loss: 4.7937. Mask: 0.9222. :  44%|████▍     | 44/100 [00:13<00:14,  3.77it/s]Train Iter: 945/5000. LR: 0.0499. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0054. T_Loss: 4.7937. Mask: 0.9222. :  45%|████▌     | 45/100 [00:13<00:14,  3.73it/s]Train Iter: 946/5000. LR: 0.0499. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0062. T_Loss: 4.7997. Mask: 0.9198. :  45%|████▌     | 45/100 [00:13<00:14,  3.73it/s]Train Iter: 946/5000. LR: 0.0499. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0062. T_Loss: 4.7997. Mask: 0.9198. :  46%|████▌     | 46/100 [00:13<00:12,  4.48it/s]Train Iter: 947/5000. LR: 0.0498. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0087. T_Loss: 4.7941. Mask: 0.9182. :  46%|████▌     | 46/100 [00:13<00:12,  4.48it/s]Train Iter: 947/5000. LR: 0.0498. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0087. T_Loss: 4.7941. Mask: 0.9182. :  47%|████▋     | 47/100 [00:13<00:09,  5.31it/s]Train Iter: 948/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0093. T_Loss: 4.8012. Mask: 0.9180. :  47%|████▋     | 47/100 [00:13<00:09,  5.31it/s]Train Iter: 948/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0093. T_Loss: 4.8012. Mask: 0.9180. :  48%|████▊     | 48/100 [00:13<00:08,  6.17it/s]Train Iter: 949/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0069. T_Loss: 4.7902. Mask: 0.9184. :  48%|████▊     | 48/100 [00:14<00:08,  6.17it/s]Train Iter: 949/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0069. T_Loss: 4.7902. Mask: 0.9184. :  49%|████▉     | 49/100 [00:14<00:11,  4.26it/s]Train Iter: 950/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0088. T_Loss: 4.7996. Mask: 0.9163. :  49%|████▉     | 49/100 [00:14<00:11,  4.26it/s]Train Iter: 950/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0088. T_Loss: 4.7996. Mask: 0.9163. :  50%|█████     | 50/100 [00:14<00:10,  4.75it/s]total : 5000  current step :  939
total : 5000  current step :  940
total : 5000  current step :  941
total : 5000  current step :  942
total : 5000  current step :  943
total : 5000  current step :  944
total : 5000  current step :  945
total : 5000  current step :  946
total : 5000  current step :  947
total : 5000  current step :  948
total : 5000  current step :  949
total : 5000  current step :  950
Train Iter: 951/5000. LR: 0.0498. Data: 0.18s. Batch: 0.32s. S_Loss: 1.0133. T_Loss: 4.8155. Mask: 0.9161. :  50%|█████     | 50/100 [00:16<00:10,  4.75it/s]Train Iter: 951/5000. LR: 0.0498. Data: 0.18s. Batch: 0.32s. S_Loss: 1.0133. T_Loss: 4.8155. Mask: 0.9161. :  51%|█████     | 51/100 [00:16<00:40,  1.21it/s]Train Iter: 952/5000. LR: 0.0498. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0121. T_Loss: 4.8200. Mask: 0.9153. :  51%|█████     | 51/100 [00:16<00:40,  1.21it/s]Train Iter: 952/5000. LR: 0.0498. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0121. T_Loss: 4.8200. Mask: 0.9153. :  52%|█████▏    | 52/100 [00:16<00:30,  1.59it/s]Train Iter: 953/5000. LR: 0.0498. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0113. T_Loss: 4.8259. Mask: 0.9157. :  52%|█████▏    | 52/100 [00:16<00:30,  1.59it/s]Train Iter: 953/5000. LR: 0.0498. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0113. T_Loss: 4.8259. Mask: 0.9157. :  53%|█████▎    | 53/100 [00:16<00:22,  2.10it/s]Train Iter: 954/5000. LR: 0.0498. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0118. T_Loss: 4.8290. Mask: 0.9161. :  53%|█████▎    | 53/100 [00:16<00:22,  2.10it/s]Train Iter: 954/5000. LR: 0.0498. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0118. T_Loss: 4.8290. Mask: 0.9161. :  54%|█████▍    | 54/100 [00:16<00:17,  2.69it/s]Train Iter: 955/5000. LR: 0.0498. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0119. T_Loss: 4.8259. Mask: 0.9159. :  54%|█████▍    | 54/100 [00:17<00:17,  2.69it/s]Train Iter: 955/5000. LR: 0.0498. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0119. T_Loss: 4.8259. Mask: 0.9159. :  55%|█████▌    | 55/100 [00:17<00:13,  3.32it/s]Train Iter: 956/5000. LR: 0.0498. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0133. T_Loss: 4.8215. Mask: 0.9157. :  55%|█████▌    | 55/100 [00:17<00:13,  3.32it/s]Train Iter: 956/5000. LR: 0.0498. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0133. T_Loss: 4.8215. Mask: 0.9157. :  56%|█████▌    | 56/100 [00:17<00:10,  4.05it/s]Train Iter: 957/5000. LR: 0.0498. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0162. T_Loss: 4.8174. Mask: 0.9134. :  56%|█████▌    | 56/100 [00:17<00:10,  4.05it/s]Train Iter: 957/5000. LR: 0.0498. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0162. T_Loss: 4.8174. Mask: 0.9134. :  57%|█████▋    | 57/100 [00:17<00:09,  4.74it/s]Train Iter: 958/5000. LR: 0.0498. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0215. T_Loss: 4.8108. Mask: 0.9122. :  57%|█████▋    | 57/100 [00:17<00:09,  4.74it/s]Train Iter: 958/5000. LR: 0.0498. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0215. T_Loss: 4.8108. Mask: 0.9122. :  58%|█████▊    | 58/100 [00:17<00:07,  5.30it/s]Train Iter: 959/5000. LR: 0.0498. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0233. T_Loss: 4.8155. Mask: 0.9126. :  58%|█████▊    | 58/100 [00:17<00:07,  5.30it/s]Train Iter: 959/5000. LR: 0.0498. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0233. T_Loss: 4.8155. Mask: 0.9126. :  59%|█████▉    | 59/100 [00:17<00:09,  4.21it/s]Train Iter: 960/5000. LR: 0.0498. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0258. T_Loss: 4.8089. Mask: 0.9115. :  59%|█████▉    | 59/100 [00:17<00:09,  4.21it/s]Train Iter: 960/5000. LR: 0.0498. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0258. T_Loss: 4.8089. Mask: 0.9115. :  60%|██████    | 60/100 [00:17<00:07,  5.06it/s]Train Iter: 961/5000. LR: 0.0498. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0265. T_Loss: 4.8032. Mask: 0.9103. :  60%|██████    | 60/100 [00:18<00:07,  5.06it/s]Train Iter: 961/5000. LR: 0.0498. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0265. T_Loss: 4.8032. Mask: 0.9103. :  61%|██████    | 61/100 [00:18<00:07,  5.53it/s]Train Iter: 962/5000. LR: 0.0498. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0249. T_Loss: 4.7877. Mask: 0.9098. :  61%|██████    | 61/100 [00:18<00:07,  5.53it/s]Train Iter: 962/5000. LR: 0.0498. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0249. T_Loss: 4.7877. Mask: 0.9098. :  62%|██████▏   | 62/100 [00:18<00:06,  6.10it/s]Train Iter: 963/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0251. T_Loss: 4.7849. Mask: 0.9097. :  62%|██████▏   | 62/100 [00:18<00:06,  6.10it/s]Train Iter: 963/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0251. T_Loss: 4.7849. Mask: 0.9097. :  63%|██████▎   | 63/100 [00:18<00:05,  6.67it/s]Train Iter: 964/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0249. T_Loss: 4.7896. Mask: 0.9097. :  63%|██████▎   | 63/100 [00:18<00:05,  6.67it/s]Train Iter: 964/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0249. T_Loss: 4.7896. Mask: 0.9097. :  64%|██████▍   | 64/100 [00:18<00:05,  7.07it/s]Train Iter: 965/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0239. T_Loss: 4.7935. Mask: 0.9096. :  64%|██████▍   | 64/100 [00:18<00:05,  7.07it/s]Train Iter: 965/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0239. T_Loss: 4.7935. Mask: 0.9096. :  65%|██████▌   | 65/100 [00:18<00:07,  4.66it/s]Train Iter: 966/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0227. T_Loss: 4.7895. Mask: 0.9105. :  65%|██████▌   | 65/100 [00:19<00:07,  4.66it/s]Train Iter: 966/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0227. T_Loss: 4.7895. Mask: 0.9105. :  66%|██████▌   | 66/100 [00:19<00:06,  5.04it/s]Train Iter: 967/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0258. T_Loss: 4.7889. Mask: 0.9109. :  66%|██████▌   | 66/100 [00:19<00:06,  5.04it/s]Train Iter: 967/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0258. T_Loss: 4.7889. Mask: 0.9109. :  67%|██████▋   | 67/100 [00:19<00:05,  5.68it/s]Train Iter: 968/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0272. T_Loss: 4.7827. Mask: 0.9099. :  67%|██████▋   | 67/100 [00:19<00:05,  5.68it/s]Train Iter: 968/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0272. T_Loss: 4.7827. Mask: 0.9099. :  68%|██████▊   | 68/100 [00:19<00:05,  6.26it/s]Train Iter: 969/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0303. T_Loss: 4.7902. Mask: 0.9099. :  68%|██████▊   | 68/100 [00:19<00:05,  6.26it/s]Train Iter: 969/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0303. T_Loss: 4.7902. Mask: 0.9099. :  69%|██████▉   | 69/100 [00:19<00:04,  6.86it/s]Train Iter: 970/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0340. T_Loss: 4.7929. Mask: 0.9094. :  69%|██████▉   | 69/100 [00:19<00:04,  6.86it/s]Train Iter: 970/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0340. T_Loss: 4.7929. Mask: 0.9094. :  70%|███████   | 70/100 [00:19<00:04,  7.01it/s]Train Iter: 971/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0368. T_Loss: 4.8014. Mask: 0.9107. :  70%|███████   | 70/100 [00:19<00:04,  7.01it/s]Train Iter: 971/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0368. T_Loss: 4.8014. Mask: 0.9107. :  71%|███████   | 71/100 [00:19<00:03,  7.38it/s]Train Iter: 972/5000. LR: 0.0498. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0397. T_Loss: 4.8029. Mask: 0.9102. :  71%|███████   | 71/100 [00:19<00:03,  7.38it/s]Train Iter: 972/5000. LR: 0.0498. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0397. T_Loss: 4.8029. Mask: 0.9102. :  72%|███████▏  | 72/100 [00:19<00:03,  7.40it/s]Train Iter: 973/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0428. T_Loss: 4.8089. Mask: 0.9101. :  72%|███████▏  | 72/100 [00:19<00:03,  7.40it/s]Train Iter: 973/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0428. T_Loss: 4.8089. Mask: 0.9101. :  73%|███████▎  | 73/100 [00:19<00:03,  7.48it/s]Train Iter: 974/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0421. T_Loss: 4.7968. Mask: 0.9101. :  73%|███████▎  | 73/100 [00:20<00:03,  7.48it/s]Train Iter: 974/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0421. T_Loss: 4.7968. Mask: 0.9101. :  74%|███████▍  | 74/100 [00:20<00:03,  7.87it/s]Train Iter: 975/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0410. T_Loss: 4.7948. Mask: 0.9104. :  74%|███████▍  | 74/100 [00:20<00:03,  7.87it/s]Train Iter: 975/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0410. T_Loss: 4.7948. Mask: 0.9104. :  75%|███████▌  | 75/100 [00:20<00:04,  6.09it/s]total : 5000  current step :  951
total : 5000  current step :  952
total : 5000  current step :  953
total : 5000  current step :  954
total : 5000  current step :  955
total : 5000  current step :  956
total : 5000  current step :  957
total : 5000  current step :  958
total : 5000  current step :  959
total : 5000  current step :  960
total : 5000  current step :  961
total : 5000  current step :  962
total : 5000  current step :  963
total : 5000  current step :  964
total : 5000  current step :  965
total : 5000  current step :  966
total : 5000  current step :  967
total : 5000  current step :  968
total : 5000  current step :  969
total : 5000  current step :  970
total : 5000  current step :  971
total : 5000  current step :  972
total : 5000  current step :  973
total : 5000  current step :  974
total : 5000  current step :  975
Train Iter: 976/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0407. T_Loss: 4.7847. Mask: 0.9100. :  75%|███████▌  | 75/100 [00:22<00:04,  6.09it/s]Train Iter: 976/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0407. T_Loss: 4.7847. Mask: 0.9100. :  76%|███████▌  | 76/100 [00:22<00:17,  1.39it/s]Train Iter: 977/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0396. T_Loss: 4.7718. Mask: 0.9095. :  76%|███████▌  | 76/100 [00:22<00:17,  1.39it/s]Train Iter: 977/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0396. T_Loss: 4.7718. Mask: 0.9095. :  77%|███████▋  | 77/100 [00:22<00:12,  1.86it/s]Train Iter: 978/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0402. T_Loss: 4.7756. Mask: 0.9099. :  77%|███████▋  | 77/100 [00:22<00:12,  1.86it/s]Train Iter: 978/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0402. T_Loss: 4.7756. Mask: 0.9099. :  78%|███████▊  | 78/100 [00:22<00:09,  2.38it/s]Train Iter: 979/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0396. T_Loss: 4.7781. Mask: 0.9102. :  78%|███████▊  | 78/100 [00:22<00:09,  2.38it/s]Train Iter: 979/5000. LR: 0.0498. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0396. T_Loss: 4.7781. Mask: 0.9102. :  79%|███████▉  | 79/100 [00:22<00:07,  2.75it/s]Train Iter: 980/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0384. T_Loss: 4.7777. Mask: 0.9105. :  79%|███████▉  | 79/100 [00:22<00:07,  2.75it/s]Train Iter: 980/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0384. T_Loss: 4.7777. Mask: 0.9105. :  80%|████████  | 80/100 [00:22<00:05,  3.38it/s]Train Iter: 981/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0383. T_Loss: 4.7784. Mask: 0.9101. :  80%|████████  | 80/100 [00:23<00:05,  3.38it/s]Train Iter: 981/5000. LR: 0.0498. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0383. T_Loss: 4.7784. Mask: 0.9101. :  81%|████████  | 81/100 [00:23<00:04,  4.08it/s]Train Iter: 982/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0378. T_Loss: 4.7775. Mask: 0.9108. :  81%|████████  | 81/100 [00:23<00:04,  4.08it/s]Train Iter: 982/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0378. T_Loss: 4.7775. Mask: 0.9108. :  82%|████████▏ | 82/100 [00:23<00:03,  4.71it/s]Train Iter: 983/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0388. T_Loss: 4.7825. Mask: 0.9111. :  82%|████████▏ | 82/100 [00:23<00:03,  4.71it/s]Train Iter: 983/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0388. T_Loss: 4.7825. Mask: 0.9111. :  83%|████████▎ | 83/100 [00:23<00:03,  5.39it/s]Train Iter: 984/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0412. T_Loss: 4.7836. Mask: 0.9118. :  83%|████████▎ | 83/100 [00:23<00:03,  5.39it/s]Train Iter: 984/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0412. T_Loss: 4.7836. Mask: 0.9118. :  84%|████████▍ | 84/100 [00:23<00:02,  6.05it/s]Train Iter: 985/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0437. T_Loss: 4.7857. Mask: 0.9110. :  84%|████████▍ | 84/100 [00:23<00:02,  6.05it/s]Train Iter: 985/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0437. T_Loss: 4.7857. Mask: 0.9110. :  85%|████████▌ | 85/100 [00:23<00:03,  4.99it/s]Train Iter: 986/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0475. T_Loss: 4.8001. Mask: 0.9110. :  85%|████████▌ | 85/100 [00:23<00:03,  4.99it/s]Train Iter: 986/5000. LR: 0.0498. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0475. T_Loss: 4.8001. Mask: 0.9110. :  86%|████████▌ | 86/100 [00:23<00:02,  5.56it/s]Train Iter: 987/5000. LR: 0.0498. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0512. T_Loss: 4.7984. Mask: 0.9106. :  86%|████████▌ | 86/100 [00:23<00:02,  5.56it/s]Train Iter: 987/5000. LR: 0.0498. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0512. T_Loss: 4.7984. Mask: 0.9106. :  87%|████████▋ | 87/100 [00:23<00:02,  6.12it/s]Train Iter: 988/5000. LR: 0.0498. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0534. T_Loss: 4.8062. Mask: 0.9112. :  87%|████████▋ | 87/100 [00:24<00:02,  6.12it/s]Train Iter: 988/5000. LR: 0.0498. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0534. T_Loss: 4.8062. Mask: 0.9112. :  88%|████████▊ | 88/100 [00:24<00:01,  6.42it/s]Train Iter: 989/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0549. T_Loss: 4.7997. Mask: 0.9115. :  88%|████████▊ | 88/100 [00:24<00:01,  6.42it/s]Train Iter: 989/5000. LR: 0.0498. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0549. T_Loss: 4.7997. Mask: 0.9115. :  89%|████████▉ | 89/100 [00:24<00:02,  4.43it/s]Train Iter: 990/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0560. T_Loss: 4.7979. Mask: 0.9118. :  89%|████████▉ | 89/100 [00:24<00:02,  4.43it/s]Train Iter: 990/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0560. T_Loss: 4.7979. Mask: 0.9118. :  90%|█████████ | 90/100 [00:24<00:01,  5.31it/s]Train Iter: 991/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0575. T_Loss: 4.8008. Mask: 0.9114. :  90%|█████████ | 90/100 [00:24<00:01,  5.31it/s]Train Iter: 991/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0575. T_Loss: 4.8008. Mask: 0.9114. :  91%|█████████ | 91/100 [00:24<00:01,  5.73it/s]Train Iter: 992/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0586. T_Loss: 4.7968. Mask: 0.9107. :  91%|█████████ | 91/100 [00:24<00:01,  5.73it/s]Train Iter: 992/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0586. T_Loss: 4.7968. Mask: 0.9107. :  92%|█████████▏| 92/100 [00:24<00:01,  6.24it/s]Train Iter: 993/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0595. T_Loss: 4.7921. Mask: 0.9106. :  92%|█████████▏| 92/100 [00:24<00:01,  6.24it/s]Train Iter: 993/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0595. T_Loss: 4.7921. Mask: 0.9106. :  93%|█████████▎| 93/100 [00:24<00:01,  6.63it/s]Train Iter: 994/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0589. T_Loss: 4.7919. Mask: 0.9109. :  93%|█████████▎| 93/100 [00:25<00:01,  6.63it/s]Train Iter: 994/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0589. T_Loss: 4.7919. Mask: 0.9109. :  94%|█████████▍| 94/100 [00:25<00:00,  6.97it/s]Train Iter: 995/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0608. T_Loss: 4.8003. Mask: 0.9109. :  94%|█████████▍| 94/100 [00:25<00:00,  6.97it/s]Train Iter: 995/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0608. T_Loss: 4.8003. Mask: 0.9109. :  95%|█████████▌| 95/100 [00:25<00:01,  4.66it/s]Train Iter: 996/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0609. T_Loss: 4.8006. Mask: 0.9111. :  95%|█████████▌| 95/100 [00:25<00:01,  4.66it/s]Train Iter: 996/5000. LR: 0.0497. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0609. T_Loss: 4.8006. Mask: 0.9111. :  96%|█████████▌| 96/100 [00:25<00:00,  5.39it/s]Train Iter: 997/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0599. T_Loss: 4.7958. Mask: 0.9120. :  96%|█████████▌| 96/100 [00:25<00:00,  5.39it/s]Train Iter: 997/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0599. T_Loss: 4.7958. Mask: 0.9120. :  97%|█████████▋| 97/100 [00:25<00:00,  5.94it/s]Train Iter: 998/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0583. T_Loss: 4.7888. Mask: 0.9123. :  97%|█████████▋| 97/100 [00:25<00:00,  5.94it/s]Train Iter: 998/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0583. T_Loss: 4.7888. Mask: 0.9123. :  98%|█████████▊| 98/100 [00:25<00:00,  6.44it/s]Train Iter: 999/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0586. T_Loss: 4.7866. Mask: 0.9122. :  98%|█████████▊| 98/100 [00:26<00:00,  6.44it/s]Train Iter: 999/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0586. T_Loss: 4.7866. Mask: 0.9122. :  99%|█████████▉| 99/100 [00:26<00:00,  4.87it/s]Train Iter: 1000/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0580. T_Loss: 4.7807. Mask: 0.9125. :  99%|█████████▉| 99/100 [00:26<00:00,  4.87it/s]Train Iter: 1000/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0580. T_Loss: 4.7807. Mask: 0.9125. : 100%|██████████| 100/100 [00:26<00:00,  5.51it/s]Train Iter: 1000/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0580. T_Loss: 4.7807. Mask: 0.9125. : 100%|██████████| 100/100 [00:26<00:00,  3.80it/s]
total : 5000  current step :  976
total : 5000  current step :  977
total : 5000  current step :  978
total : 5000  current step :  979
total : 5000  current step :  980
total : 5000  current step :  981
total : 5000  current step :  982
total : 5000  current step :  983
total : 5000  current step :  984
total : 5000  current step :  985
total : 5000  current step :  986
total : 5000  current step :  987
total : 5000  current step :  988
total : 5000  current step :  989
total : 5000  current step :  990
total : 5000  current step :  991
total : 5000  current step :  992
total : 5000  current step :  993
total : 5000  current step :  994
total : 5000  current step :  995
total : 5000  current step :  996
total : 5000  current step :  997
total : 5000  current step :  998
total : 5000  current step :  999
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.77s. Loss: 1.3659. top1: 56.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.77s. Loss: 1.3659. top1: 56.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.89s. Loss: 1.2996. top1: 67.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 1.2181. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 1.2679. top1: 67.97. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.2440. top1: 69.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.2581. top1: 68.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.2625. top1: 68.30. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 1.2796. top1: 66.80. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.2660. top1: 67.36. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.2660. top1: 67.36. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.44it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.2761. top1: 66.56. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.44it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.2536. top1: 67.33. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.44it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.2571. top1: 66.41. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.44it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.2479. top1: 66.59. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.44it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.2549. top1: 66.29. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.44it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2361. top1: 67.71. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.44it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2361. top1: 67.71. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:04, 11.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2320. top1: 67.77. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.2263. top1: 67.83. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.2262. top1: 67.36. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.2251. top1: 67.60. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.2235. top1: 67.97. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.2315. top1: 67.56. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2250. top1: 67.90. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2192. top1: 68.21. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2157. top1: 68.23. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.52it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2157. top1: 68.23. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2154. top1: 68.25. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2222. top1: 67.91. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2155. top1: 68.52. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2183. top1: 68.30. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2191. top1: 68.21. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2185. top1: 68.44. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2199. top1: 68.35. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2213. top1: 68.46. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2145. top1: 69.13. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2168. top1: 69.12. top5: 99.91. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2109. top1: 69.55. top5: 99.91. :  38%|███▊      | 24/63 [00:02<00:01, 20.90it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2109. top1: 69.55. top5: 99.91. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2206. top1: 69.18. top5: 99.65. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2143. top1: 69.59. top5: 99.66. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2079. top1: 70.07. top5: 99.67. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2151. top1: 70.03. top5: 99.44. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2123. top1: 70.31. top5: 99.38. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2089. top1: 70.66. top5: 99.39. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2074. top1: 70.68. top5: 99.40. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2025. top1: 71.00. top5: 99.42. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1970. top1: 71.52. top5: 99.43. :  56%|█████▌    | 35/63 [00:02<00:00, 33.69it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1970. top1: 71.52. top5: 99.43. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1927. top1: 71.67. top5: 99.44. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1897. top1: 71.74. top5: 99.46. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1910. top1: 71.81. top5: 99.40. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1880. top1: 72.07. top5: 99.41. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1873. top1: 72.13. top5: 99.43. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1863. top1: 72.25. top5: 99.44. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1929. top1: 72.06. top5: 99.33. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1899. top1: 72.30. top5: 99.34. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1904. top1: 72.41. top5: 99.23. :  70%|██████▉   | 44/63 [00:02<00:00, 43.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1904. top1: 72.41. top5: 99.23. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1901. top1: 72.51. top5: 99.25. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1893. top1: 72.56. top5: 99.26. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1866. top1: 72.71. top5: 99.27. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1897. top1: 72.81. top5: 99.29. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1884. top1: 72.90. top5: 99.30. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1893. top1: 72.83. top5: 99.31. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1856. top1: 73.02. top5: 99.32. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1871. top1: 72.85. top5: 99.33. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1920. top1: 72.73. top5: 99.34. :  84%|████████▍ | 53/63 [00:02<00:00, 51.24it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1920. top1: 72.73. top5: 99.34. :  98%|█████████▊| 62/63 [00:02<00:00, 57.24it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1919. top1: 72.75. top5: 99.30. :  98%|█████████▊| 62/63 [00:02<00:00, 57.24it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1919. top1: 72.75. top5: 99.30. : 100%|██████████| 63/63 [00:02<00:00, 22.68it/s]
total : 5000  current step :  1000
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1001/5000. LR: 0.0497. Data: 1.86s. Batch: 1.98s. S_Loss: 1.0461. T_Loss: 4.7969. Mask: 0.9688. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 1001/5000. LR: 0.0497. Data: 1.86s. Batch: 1.98s. S_Loss: 1.0461. T_Loss: 4.7969. Mask: 0.9688. :   1%|          | 1/100 [00:01<03:16,  1.98s/it]Train Iter: 1002/5000. LR: 0.0497. Data: 0.93s. Batch: 1.05s. S_Loss: 1.0969. T_Loss: 4.4954. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:16,  1.98s/it]Train Iter: 1002/5000. LR: 0.0497. Data: 0.93s. Batch: 1.05s. S_Loss: 1.0969. T_Loss: 4.4954. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:26,  1.13it/s]Train Iter: 1003/5000. LR: 0.0497. Data: 0.62s. Batch: 0.74s. S_Loss: 1.1217. T_Loss: 4.3160. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:26,  1.13it/s]Train Iter: 1003/5000. LR: 0.0497. Data: 0.62s. Batch: 0.74s. S_Loss: 1.1217. T_Loss: 4.3160. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:51,  1.87it/s]Train Iter: 1004/5000. LR: 0.0497. Data: 0.47s. Batch: 0.59s. S_Loss: 1.1406. T_Loss: 4.5244. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:51,  1.87it/s]Train Iter: 1004/5000. LR: 0.0497. Data: 0.47s. Batch: 0.59s. S_Loss: 1.1406. T_Loss: 4.5244. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:36,  2.63it/s]Train Iter: 1005/5000. LR: 0.0497. Data: 0.38s. Batch: 0.53s. S_Loss: 1.1337. T_Loss: 4.6580. Mask: 0.9375. :   4%|▍         | 4/100 [00:02<00:36,  2.63it/s]Train Iter: 1005/5000. LR: 0.0497. Data: 0.38s. Batch: 0.53s. S_Loss: 1.1337. T_Loss: 4.6580. Mask: 0.9375. :   5%|▌         | 5/100 [00:02<00:32,  2.90it/s]Train Iter: 1006/5000. LR: 0.0497. Data: 0.32s. Batch: 0.46s. S_Loss: 1.1219. T_Loss: 4.6823. Mask: 0.9271. :   5%|▌         | 5/100 [00:02<00:32,  2.90it/s]Train Iter: 1006/5000. LR: 0.0497. Data: 0.32s. Batch: 0.46s. S_Loss: 1.1219. T_Loss: 4.6823. Mask: 0.9271. :   6%|▌         | 6/100 [00:02<00:24,  3.82it/s]Train Iter: 1007/5000. LR: 0.0497. Data: 0.27s. Batch: 0.41s. S_Loss: 1.1046. T_Loss: 4.7395. Mask: 0.9241. :   6%|▌         | 6/100 [00:02<00:24,  3.82it/s]Train Iter: 1007/5000. LR: 0.0497. Data: 0.27s. Batch: 0.41s. S_Loss: 1.1046. T_Loss: 4.7395. Mask: 0.9241. :   7%|▋         | 7/100 [00:02<00:19,  4.71it/s]Train Iter: 1008/5000. LR: 0.0497. Data: 0.24s. Batch: 0.37s. S_Loss: 1.0986. T_Loss: 4.7556. Mask: 0.9336. :   7%|▋         | 7/100 [00:02<00:19,  4.71it/s]Train Iter: 1008/5000. LR: 0.0497. Data: 0.24s. Batch: 0.37s. S_Loss: 1.0986. T_Loss: 4.7556. Mask: 0.9336. :   8%|▊         | 8/100 [00:02<00:17,  5.38it/s]Train Iter: 1009/5000. LR: 0.0497. Data: 0.21s. Batch: 0.37s. S_Loss: 1.0950. T_Loss: 4.7576. Mask: 0.9271. :   8%|▊         | 8/100 [00:03<00:17,  5.38it/s]Train Iter: 1009/5000. LR: 0.0497. Data: 0.21s. Batch: 0.37s. S_Loss: 1.0950. T_Loss: 4.7576. Mask: 0.9271. :   9%|▉         | 9/100 [00:03<00:22,  4.03it/s]Train Iter: 1010/5000. LR: 0.0497. Data: 0.19s. Batch: 0.35s. S_Loss: 1.0874. T_Loss: 4.7547. Mask: 0.9219. :   9%|▉         | 9/100 [00:03<00:22,  4.03it/s]Train Iter: 1010/5000. LR: 0.0497. Data: 0.19s. Batch: 0.35s. S_Loss: 1.0874. T_Loss: 4.7547. Mask: 0.9219. :  10%|█         | 10/100 [00:03<00:18,  4.89it/s]Train Iter: 1011/5000. LR: 0.0497. Data: 0.17s. Batch: 0.33s. S_Loss: 1.0815. T_Loss: 4.6807. Mask: 0.9148. :  10%|█         | 10/100 [00:03<00:18,  4.89it/s]Train Iter: 1011/5000. LR: 0.0497. Data: 0.17s. Batch: 0.33s. S_Loss: 1.0815. T_Loss: 4.6807. Mask: 0.9148. :  11%|█         | 11/100 [00:03<00:15,  5.58it/s]Train Iter: 1012/5000. LR: 0.0497. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0839. T_Loss: 4.7045. Mask: 0.9115. :  11%|█         | 11/100 [00:03<00:15,  5.58it/s]Train Iter: 1012/5000. LR: 0.0497. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0839. T_Loss: 4.7045. Mask: 0.9115. :  12%|█▏        | 12/100 [00:03<00:14,  5.92it/s]Train Iter: 1013/5000. LR: 0.0497. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0836. T_Loss: 4.6753. Mask: 0.9038. :  12%|█▏        | 12/100 [00:03<00:14,  5.92it/s]Train Iter: 1013/5000. LR: 0.0497. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0836. T_Loss: 4.6753. Mask: 0.9038. :  13%|█▎        | 13/100 [00:03<00:13,  6.25it/s]Train Iter: 1014/5000. LR: 0.0497. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0776. T_Loss: 4.7265. Mask: 0.9062. :  13%|█▎        | 13/100 [00:03<00:13,  6.25it/s]Train Iter: 1014/5000. LR: 0.0497. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0776. T_Loss: 4.7265. Mask: 0.9062. :  14%|█▍        | 14/100 [00:03<00:12,  6.80it/s]Train Iter: 1015/5000. LR: 0.0497. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0792. T_Loss: 4.6932. Mask: 0.9042. :  14%|█▍        | 14/100 [00:04<00:12,  6.80it/s]Train Iter: 1015/5000. LR: 0.0497. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0792. T_Loss: 4.6932. Mask: 0.9042. :  15%|█▌        | 15/100 [00:04<00:16,  5.14it/s]Train Iter: 1016/5000. LR: 0.0497. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0745. T_Loss: 4.6485. Mask: 0.9062. :  15%|█▌        | 15/100 [00:04<00:16,  5.14it/s]Train Iter: 1016/5000. LR: 0.0497. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0745. T_Loss: 4.6485. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:15,  5.43it/s]Train Iter: 1017/5000. LR: 0.0497. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0756. T_Loss: 4.6843. Mask: 0.9099. :  16%|█▌        | 16/100 [00:04<00:15,  5.43it/s]Train Iter: 1017/5000. LR: 0.0497. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0756. T_Loss: 4.6843. Mask: 0.9099. :  17%|█▋        | 17/100 [00:04<00:14,  5.84it/s]Train Iter: 1018/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0779. T_Loss: 4.7151. Mask: 0.9132. :  17%|█▋        | 17/100 [00:04<00:14,  5.84it/s]Train Iter: 1018/5000. LR: 0.0497. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0779. T_Loss: 4.7151. Mask: 0.9132. :  18%|█▊        | 18/100 [00:04<00:13,  6.13it/s]Train Iter: 1019/5000. LR: 0.0497. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0738. T_Loss: 4.6906. Mask: 0.9161. :  18%|█▊        | 18/100 [00:04<00:13,  6.13it/s]Train Iter: 1019/5000. LR: 0.0497. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0738. T_Loss: 4.6906. Mask: 0.9161. :  19%|█▉        | 19/100 [00:04<00:15,  5.33it/s]Train Iter: 1020/5000. LR: 0.0497. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0678. T_Loss: 4.6799. Mask: 0.9141. :  19%|█▉        | 19/100 [00:05<00:15,  5.33it/s]Train Iter: 1020/5000. LR: 0.0497. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0678. T_Loss: 4.6799. Mask: 0.9141. :  20%|██        | 20/100 [00:05<00:13,  5.88it/s]Train Iter: 1021/5000. LR: 0.0497. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0658. T_Loss: 4.6952. Mask: 0.9137. :  20%|██        | 20/100 [00:05<00:13,  5.88it/s]Train Iter: 1021/5000. LR: 0.0497. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0658. T_Loss: 4.6952. Mask: 0.9137. :  21%|██        | 21/100 [00:05<00:12,  6.28it/s]Train Iter: 1022/5000. LR: 0.0497. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0659. T_Loss: 4.7061. Mask: 0.9162. :  21%|██        | 21/100 [00:05<00:12,  6.28it/s]Train Iter: 1022/5000. LR: 0.0497. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0659. T_Loss: 4.7061. Mask: 0.9162. :  22%|██▏       | 22/100 [00:05<00:11,  6.60it/s]Train Iter: 1023/5000. LR: 0.0497. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0635. T_Loss: 4.7277. Mask: 0.9158. :  22%|██▏       | 22/100 [00:05<00:11,  6.60it/s]Train Iter: 1023/5000. LR: 0.0497. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0635. T_Loss: 4.7277. Mask: 0.9158. :  23%|██▎       | 23/100 [00:05<00:11,  6.98it/s]Train Iter: 1024/5000. LR: 0.0496. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0636. T_Loss: 4.7140. Mask: 0.9115. :  23%|██▎       | 23/100 [00:05<00:11,  6.98it/s]Train Iter: 1024/5000. LR: 0.0496. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0636. T_Loss: 4.7140. Mask: 0.9115. :  24%|██▍       | 24/100 [00:05<00:10,  7.27it/s]Train Iter: 1025/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0633. T_Loss: 4.7331. Mask: 0.9100. :  24%|██▍       | 24/100 [00:05<00:10,  7.27it/s]Train Iter: 1025/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0633. T_Loss: 4.7331. Mask: 0.9100. :  25%|██▌       | 25/100 [00:05<00:13,  5.39it/s]total : 5000  current step :  1001
total : 5000  current step :  1002
total : 5000  current step :  1003
total : 5000  current step :  1004
total : 5000  current step :  1005
total : 5000  current step :  1006
total : 5000  current step :  1007
total : 5000  current step :  1008
total : 5000  current step :  1009
total : 5000  current step :  1010
total : 5000  current step :  1011
total : 5000  current step :  1012
total : 5000  current step :  1013
total : 5000  current step :  1014
total : 5000  current step :  1015
total : 5000  current step :  1016
total : 5000  current step :  1017
total : 5000  current step :  1018
total : 5000  current step :  1019
total : 5000  current step :  1020
total : 5000  current step :  1021
total : 5000  current step :  1022
total : 5000  current step :  1023
total : 5000  current step :  1024
total : 5000  current step :  1025
Train Iter: 1026/5000. LR: 0.0496. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0610. T_Loss: 4.7529. Mask: 0.9135. :  25%|██▌       | 25/100 [00:08<00:13,  5.39it/s]Train Iter: 1026/5000. LR: 0.0496. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0610. T_Loss: 4.7529. Mask: 0.9135. :  26%|██▌       | 26/100 [00:08<00:56,  1.32it/s]Train Iter: 1027/5000. LR: 0.0496. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0562. T_Loss: 4.7818. Mask: 0.9155. :  26%|██▌       | 26/100 [00:08<00:56,  1.32it/s]Train Iter: 1027/5000. LR: 0.0496. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0562. T_Loss: 4.7818. Mask: 0.9155. :  27%|██▋       | 27/100 [00:08<00:41,  1.75it/s]Train Iter: 1028/5000. LR: 0.0496. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0564. T_Loss: 4.7884. Mask: 0.9141. :  27%|██▋       | 27/100 [00:08<00:41,  1.75it/s]Train Iter: 1028/5000. LR: 0.0496. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0564. T_Loss: 4.7884. Mask: 0.9141. :  28%|██▊       | 28/100 [00:08<00:32,  2.22it/s]Train Iter: 1029/5000. LR: 0.0496. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0541. T_Loss: 4.7944. Mask: 0.9149. :  28%|██▊       | 28/100 [00:08<00:32,  2.22it/s]Train Iter: 1029/5000. LR: 0.0496. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0541. T_Loss: 4.7944. Mask: 0.9149. :  29%|██▉       | 29/100 [00:08<00:25,  2.84it/s]Train Iter: 1030/5000. LR: 0.0496. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0529. T_Loss: 4.8099. Mask: 0.9156. :  29%|██▉       | 29/100 [00:08<00:25,  2.84it/s]Train Iter: 1030/5000. LR: 0.0496. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0529. T_Loss: 4.8099. Mask: 0.9156. :  30%|███       | 30/100 [00:08<00:19,  3.52it/s]Train Iter: 1031/5000. LR: 0.0496. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0488. T_Loss: 4.8108. Mask: 0.9173. :  30%|███       | 30/100 [00:08<00:19,  3.52it/s]Train Iter: 1031/5000. LR: 0.0496. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0488. T_Loss: 4.8108. Mask: 0.9173. :  31%|███       | 31/100 [00:08<00:16,  4.23it/s]Train Iter: 1032/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0485. T_Loss: 4.8403. Mask: 0.9199. :  31%|███       | 31/100 [00:08<00:16,  4.23it/s]Train Iter: 1032/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0485. T_Loss: 4.8403. Mask: 0.9199. :  32%|███▏      | 32/100 [00:08<00:13,  4.98it/s]Train Iter: 1033/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0448. T_Loss: 4.8324. Mask: 0.9214. :  32%|███▏      | 32/100 [00:08<00:13,  4.98it/s]Train Iter: 1033/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0448. T_Loss: 4.8324. Mask: 0.9214. :  33%|███▎      | 33/100 [00:08<00:11,  5.59it/s]Train Iter: 1034/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0413. T_Loss: 4.8285. Mask: 0.9219. :  33%|███▎      | 33/100 [00:09<00:11,  5.59it/s]Train Iter: 1034/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0413. T_Loss: 4.8285. Mask: 0.9219. :  34%|███▍      | 34/100 [00:09<00:10,  6.16it/s]Train Iter: 1035/5000. LR: 0.0496. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0387. T_Loss: 4.8141. Mask: 0.9232. :  34%|███▍      | 34/100 [00:09<00:10,  6.16it/s]Train Iter: 1035/5000. LR: 0.0496. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0387. T_Loss: 4.8141. Mask: 0.9232. :  35%|███▌      | 35/100 [00:09<00:12,  5.31it/s]Train Iter: 1036/5000. LR: 0.0496. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0384. T_Loss: 4.7998. Mask: 0.9219. :  35%|███▌      | 35/100 [00:09<00:12,  5.31it/s]Train Iter: 1036/5000. LR: 0.0496. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0384. T_Loss: 4.7998. Mask: 0.9219. :  36%|███▌      | 36/100 [00:09<00:10,  5.95it/s]Train Iter: 1037/5000. LR: 0.0496. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0367. T_Loss: 4.8116. Mask: 0.9240. :  36%|███▌      | 36/100 [00:09<00:10,  5.95it/s]Train Iter: 1037/5000. LR: 0.0496. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0367. T_Loss: 4.8116. Mask: 0.9240. :  37%|███▋      | 37/100 [00:09<00:09,  6.49it/s]Train Iter: 1038/5000. LR: 0.0496. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0373. T_Loss: 4.8065. Mask: 0.9243. :  37%|███▋      | 37/100 [00:09<00:09,  6.49it/s]Train Iter: 1038/5000. LR: 0.0496. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0373. T_Loss: 4.8065. Mask: 0.9243. :  38%|███▊      | 38/100 [00:09<00:09,  6.60it/s]Train Iter: 1039/5000. LR: 0.0496. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0362. T_Loss: 4.7824. Mask: 0.9223. :  38%|███▊      | 38/100 [00:10<00:09,  6.60it/s]Train Iter: 1039/5000. LR: 0.0496. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0362. T_Loss: 4.7824. Mask: 0.9223. :  39%|███▉      | 39/100 [00:10<00:13,  4.64it/s]Train Iter: 1040/5000. LR: 0.0496. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0361. T_Loss: 4.7755. Mask: 0.9211. :  39%|███▉      | 39/100 [00:10<00:13,  4.64it/s]Train Iter: 1040/5000. LR: 0.0496. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0361. T_Loss: 4.7755. Mask: 0.9211. :  40%|████      | 40/100 [00:10<00:11,  5.33it/s]Train Iter: 1041/5000. LR: 0.0496. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0370. T_Loss: 4.7683. Mask: 0.9207. :  40%|████      | 40/100 [00:10<00:11,  5.33it/s]Train Iter: 1041/5000. LR: 0.0496. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0370. T_Loss: 4.7683. Mask: 0.9207. :  41%|████      | 41/100 [00:10<00:10,  5.62it/s]Train Iter: 1042/5000. LR: 0.0496. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0370. T_Loss: 4.7724. Mask: 0.9211. :  41%|████      | 41/100 [00:10<00:10,  5.62it/s]Train Iter: 1042/5000. LR: 0.0496. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0370. T_Loss: 4.7724. Mask: 0.9211. :  42%|████▏     | 42/100 [00:10<00:09,  6.24it/s]Train Iter: 1043/5000. LR: 0.0496. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0347. T_Loss: 4.7548. Mask: 0.9208. :  42%|████▏     | 42/100 [00:10<00:09,  6.24it/s]Train Iter: 1043/5000. LR: 0.0496. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0347. T_Loss: 4.7548. Mask: 0.9208. :  43%|████▎     | 43/100 [00:10<00:08,  6.62it/s]Train Iter: 1044/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0338. T_Loss: 4.7596. Mask: 0.9226. :  43%|████▎     | 43/100 [00:10<00:08,  6.62it/s]Train Iter: 1044/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0338. T_Loss: 4.7596. Mask: 0.9226. :  44%|████▍     | 44/100 [00:10<00:07,  7.10it/s]Train Iter: 1045/5000. LR: 0.0496. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0332. T_Loss: 4.7733. Mask: 0.9229. :  44%|████▍     | 44/100 [00:11<00:07,  7.10it/s]Train Iter: 1045/5000. LR: 0.0496. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0332. T_Loss: 4.7733. Mask: 0.9229. :  45%|████▌     | 45/100 [00:11<00:11,  4.61it/s]Train Iter: 1046/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0363. T_Loss: 4.7679. Mask: 0.9219. :  45%|████▌     | 45/100 [00:11<00:11,  4.61it/s]Train Iter: 1046/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0363. T_Loss: 4.7679. Mask: 0.9219. :  46%|████▌     | 46/100 [00:11<00:10,  5.30it/s]Train Iter: 1047/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0368. T_Loss: 4.7566. Mask: 0.9222. :  46%|████▌     | 46/100 [00:11<00:10,  5.30it/s]Train Iter: 1047/5000. LR: 0.0496. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0368. T_Loss: 4.7566. Mask: 0.9222. :  47%|████▋     | 47/100 [00:11<00:09,  5.85it/s]Train Iter: 1048/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0353. T_Loss: 4.7680. Mask: 0.9219. :  47%|████▋     | 47/100 [00:11<00:09,  5.85it/s]Train Iter: 1048/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0353. T_Loss: 4.7680. Mask: 0.9219. :  48%|████▊     | 48/100 [00:11<00:08,  6.19it/s]Train Iter: 1049/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0325. T_Loss: 4.7494. Mask: 0.9209. :  48%|████▊     | 48/100 [00:11<00:08,  6.19it/s]Train Iter: 1049/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0325. T_Loss: 4.7494. Mask: 0.9209. :  49%|████▉     | 49/100 [00:11<00:10,  4.73it/s]Train Iter: 1050/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0332. T_Loss: 4.7673. Mask: 0.9206. :  49%|████▉     | 49/100 [00:11<00:10,  4.73it/s]Train Iter: 1050/5000. LR: 0.0496. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0332. T_Loss: 4.7673. Mask: 0.9206. :  50%|█████     | 50/100 [00:11<00:09,  5.41it/s]total : 5000  current step :  1026
total : 5000  current step :  1027
total : 5000  current step :  1028
total : 5000  current step :  1029
total : 5000  current step :  1030
total : 5000  current step :  1031
total : 5000  current step :  1032
total : 5000  current step :  1033
total : 5000  current step :  1034
total : 5000  current step :  1035
total : 5000  current step :  1036
total : 5000  current step :  1037
total : 5000  current step :  1038
total : 5000  current step :  1039
total : 5000  current step :  1040
total : 5000  current step :  1041
total : 5000  current step :  1042
total : 5000  current step :  1043
total : 5000  current step :  1044
total : 5000  current step :  1045
total : 5000  current step :  1046
total : 5000  current step :  1047
total : 5000  current step :  1048
total : 5000  current step :  1049
total : 5000  current step :  1050
Train Iter: 1051/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0338. T_Loss: 4.7884. Mask: 0.9203. :  50%|█████     | 50/100 [00:14<00:09,  5.41it/s]Train Iter: 1051/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0338. T_Loss: 4.7884. Mask: 0.9203. :  51%|█████     | 51/100 [00:14<00:37,  1.32it/s]Train Iter: 1052/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0337. T_Loss: 4.7880. Mask: 0.9201. :  51%|█████     | 51/100 [00:14<00:37,  1.32it/s]Train Iter: 1052/5000. LR: 0.0496. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0337. T_Loss: 4.7880. Mask: 0.9201. :  52%|█████▏    | 52/100 [00:14<00:27,  1.75it/s]Train Iter: 1053/5000. LR: 0.0496. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0342. T_Loss: 4.7892. Mask: 0.9204. :  52%|█████▏    | 52/100 [00:14<00:27,  1.75it/s]Train Iter: 1053/5000. LR: 0.0496. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0342. T_Loss: 4.7892. Mask: 0.9204. :  53%|█████▎    | 53/100 [00:14<00:20,  2.27it/s]Train Iter: 1054/5000. LR: 0.0496. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0333. T_Loss: 4.7909. Mask: 0.9196. :  53%|█████▎    | 53/100 [00:14<00:20,  2.27it/s]Train Iter: 1054/5000. LR: 0.0496. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0333. T_Loss: 4.7909. Mask: 0.9196. :  54%|█████▍    | 54/100 [00:14<00:15,  2.88it/s]Train Iter: 1055/5000. LR: 0.0495. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0312. T_Loss: 4.7888. Mask: 0.9193. :  54%|█████▍    | 54/100 [00:14<00:15,  2.88it/s]Train Iter: 1055/5000. LR: 0.0495. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0312. T_Loss: 4.7888. Mask: 0.9193. :  55%|█████▌    | 55/100 [00:14<00:14,  3.07it/s]Train Iter: 1056/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0310. T_Loss: 4.7937. Mask: 0.9185. :  55%|█████▌    | 55/100 [00:14<00:14,  3.07it/s]Train Iter: 1056/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0310. T_Loss: 4.7937. Mask: 0.9185. :  56%|█████▌    | 56/100 [00:14<00:11,  3.71it/s]Train Iter: 1057/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0299. T_Loss: 4.7934. Mask: 0.9183. :  56%|█████▌    | 56/100 [00:15<00:11,  3.71it/s]Train Iter: 1057/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0299. T_Loss: 4.7934. Mask: 0.9183. :  57%|█████▋    | 57/100 [00:15<00:09,  4.36it/s]Train Iter: 1058/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0296. T_Loss: 4.7838. Mask: 0.9159. :  57%|█████▋    | 57/100 [00:15<00:09,  4.36it/s]Train Iter: 1058/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0296. T_Loss: 4.7838. Mask: 0.9159. :  58%|█████▊    | 58/100 [00:15<00:08,  4.95it/s]Train Iter: 1059/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0317. T_Loss: 4.7973. Mask: 0.9158. :  58%|█████▊    | 58/100 [00:15<00:08,  4.95it/s]Train Iter: 1059/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0317. T_Loss: 4.7973. Mask: 0.9158. :  59%|█████▉    | 59/100 [00:15<00:08,  5.06it/s]Train Iter: 1060/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0319. T_Loss: 4.7971. Mask: 0.9146. :  59%|█████▉    | 59/100 [00:15<00:08,  5.06it/s]Train Iter: 1060/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0319. T_Loss: 4.7971. Mask: 0.9146. :  60%|██████    | 60/100 [00:15<00:07,  5.66it/s]Train Iter: 1061/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0325. T_Loss: 4.7993. Mask: 0.9144. :  60%|██████    | 60/100 [00:15<00:07,  5.66it/s]Train Iter: 1061/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0325. T_Loss: 4.7993. Mask: 0.9144. :  61%|██████    | 61/100 [00:15<00:06,  6.24it/s]Train Iter: 1062/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0315. T_Loss: 4.7933. Mask: 0.9148. :  61%|██████    | 61/100 [00:15<00:06,  6.24it/s]Train Iter: 1063/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0324. T_Loss: 4.7975. Mask: 0.9152. :  62%|██████▏   | 62/100 [00:15<00:06,  6.24it/s]Train Iter: 1063/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0324. T_Loss: 4.7975. Mask: 0.9152. :  63%|██████▎   | 63/100 [00:15<00:05,  7.34it/s]Train Iter: 1064/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0326. T_Loss: 4.7880. Mask: 0.9150. :  63%|██████▎   | 63/100 [00:15<00:05,  7.34it/s]Train Iter: 1064/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0326. T_Loss: 4.7880. Mask: 0.9150. :  64%|██████▍   | 64/100 [00:15<00:04,  7.53it/s]Train Iter: 1065/5000. LR: 0.0495. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0328. T_Loss: 4.7837. Mask: 0.9154. :  64%|██████▍   | 64/100 [00:16<00:04,  7.53it/s]Train Iter: 1065/5000. LR: 0.0495. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0328. T_Loss: 4.7837. Mask: 0.9154. :  65%|██████▌   | 65/100 [00:16<00:06,  5.45it/s]Train Iter: 1066/5000. LR: 0.0495. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0339. T_Loss: 4.7800. Mask: 0.9148. :  65%|██████▌   | 65/100 [00:16<00:06,  5.45it/s]Train Iter: 1066/5000. LR: 0.0495. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0339. T_Loss: 4.7800. Mask: 0.9148. :  66%|██████▌   | 66/100 [00:16<00:05,  5.74it/s]Train Iter: 1067/5000. LR: 0.0495. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0331. T_Loss: 4.7751. Mask: 0.9142. :  66%|██████▌   | 66/100 [00:16<00:05,  5.74it/s]Train Iter: 1067/5000. LR: 0.0495. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0331. T_Loss: 4.7751. Mask: 0.9142. :  67%|██████▋   | 67/100 [00:16<00:05,  6.24it/s]Train Iter: 1068/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0351. T_Loss: 4.7722. Mask: 0.9141. :  67%|██████▋   | 67/100 [00:16<00:05,  6.24it/s]Train Iter: 1068/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0351. T_Loss: 4.7722. Mask: 0.9141. :  68%|██████▊   | 68/100 [00:16<00:04,  6.66it/s]Train Iter: 1069/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0349. T_Loss: 4.7628. Mask: 0.9149. :  68%|██████▊   | 68/100 [00:16<00:04,  6.66it/s]Train Iter: 1069/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0349. T_Loss: 4.7628. Mask: 0.9149. :  69%|██████▉   | 69/100 [00:16<00:06,  4.95it/s]Train Iter: 1070/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0366. T_Loss: 4.7797. Mask: 0.9152. :  69%|██████▉   | 69/100 [00:17<00:06,  4.95it/s]Train Iter: 1070/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0366. T_Loss: 4.7797. Mask: 0.9152. :  70%|███████   | 70/100 [00:17<00:05,  5.77it/s]Train Iter: 1071/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0365. T_Loss: 4.7784. Mask: 0.9151. :  70%|███████   | 70/100 [00:17<00:05,  5.77it/s]Train Iter: 1071/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0365. T_Loss: 4.7784. Mask: 0.9151. :  71%|███████   | 71/100 [00:17<00:04,  6.55it/s]Train Iter: 1072/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0361. T_Loss: 4.7752. Mask: 0.9149. :  71%|███████   | 71/100 [00:17<00:04,  6.55it/s]Train Iter: 1072/5000. LR: 0.0495. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0361. T_Loss: 4.7752. Mask: 0.9149. :  72%|███████▏  | 72/100 [00:17<00:03,  7.02it/s]Train Iter: 1073/5000. LR: 0.0495. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0368. T_Loss: 4.7752. Mask: 0.9148. :  72%|███████▏  | 72/100 [00:17<00:03,  7.02it/s]Train Iter: 1073/5000. LR: 0.0495. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0368. T_Loss: 4.7752. Mask: 0.9148. :  73%|███████▎  | 73/100 [00:17<00:03,  7.46it/s]Train Iter: 1074/5000. LR: 0.0495. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0369. T_Loss: 4.7790. Mask: 0.9147. :  73%|███████▎  | 73/100 [00:17<00:03,  7.46it/s]Train Iter: 1074/5000. LR: 0.0495. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0369. T_Loss: 4.7790. Mask: 0.9147. :  74%|███████▍  | 74/100 [00:17<00:03,  7.86it/s]Train Iter: 1075/5000. LR: 0.0495. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0381. T_Loss: 4.7922. Mask: 0.9146. :  74%|███████▍  | 74/100 [00:17<00:03,  7.86it/s]Train Iter: 1075/5000. LR: 0.0495. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0381. T_Loss: 4.7922. Mask: 0.9146. :  75%|███████▌  | 75/100 [00:17<00:03,  7.78it/s]total : 5000  current step :  1051
total : 5000  current step :  1052
total : 5000  current step :  1053
total : 5000  current step :  1054
total : 5000  current step :  1055
total : 5000  current step :  1056
total : 5000  current step :  1057
total : 5000  current step :  1058
total : 5000  current step :  1059
total : 5000  current step :  1060
total : 5000  current step :  1061
total : 5000  current step :  1062
total : 5000  current step :  1063
total : 5000  current step :  1064
total : 5000  current step :  1065
total : 5000  current step :  1066
total : 5000  current step :  1067
total : 5000  current step :  1068
total : 5000  current step :  1069
total : 5000  current step :  1070
total : 5000  current step :  1071
total : 5000  current step :  1072
total : 5000  current step :  1073
total : 5000  current step :  1074
total : 5000  current step :  1075
Train Iter: 1076/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0380. T_Loss: 4.7891. Mask: 0.9141. :  75%|███████▌  | 75/100 [00:19<00:03,  7.78it/s]Train Iter: 1076/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0380. T_Loss: 4.7891. Mask: 0.9141. :  76%|███████▌  | 76/100 [00:19<00:17,  1.37it/s]Train Iter: 1077/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0377. T_Loss: 4.7959. Mask: 0.9140. :  76%|███████▌  | 76/100 [00:19<00:17,  1.37it/s]Train Iter: 1077/5000. LR: 0.0495. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0377. T_Loss: 4.7959. Mask: 0.9140. :  77%|███████▋  | 77/100 [00:19<00:12,  1.84it/s]Train Iter: 1078/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0389. T_Loss: 4.7934. Mask: 0.9131. :  77%|███████▋  | 77/100 [00:19<00:12,  1.84it/s]Train Iter: 1079/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0384. T_Loss: 4.7947. Mask: 0.9134. :  78%|███████▊  | 78/100 [00:20<00:11,  1.84it/s]Train Iter: 1079/5000. LR: 0.0495. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0384. T_Loss: 4.7947. Mask: 0.9134. :  79%|███████▉  | 79/100 [00:20<00:08,  2.56it/s]Train Iter: 1080/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0399. T_Loss: 4.8012. Mask: 0.9125. :  79%|███████▉  | 79/100 [00:20<00:08,  2.56it/s]Train Iter: 1080/5000. LR: 0.0495. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0399. T_Loss: 4.8012. Mask: 0.9125. :  80%|████████  | 80/100 [00:20<00:06,  3.10it/s]Train Iter: 1081/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0396. T_Loss: 4.7990. Mask: 0.9117. :  80%|████████  | 80/100 [00:20<00:06,  3.10it/s]Train Iter: 1081/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0396. T_Loss: 4.7990. Mask: 0.9117. :  81%|████████  | 81/100 [00:20<00:05,  3.77it/s]Train Iter: 1082/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0395. T_Loss: 4.8046. Mask: 0.9120. :  81%|████████  | 81/100 [00:20<00:05,  3.77it/s]Train Iter: 1082/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0395. T_Loss: 4.8046. Mask: 0.9120. :  82%|████████▏ | 82/100 [00:20<00:04,  4.43it/s]Train Iter: 1083/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0386. T_Loss: 4.8120. Mask: 0.9127. :  82%|████████▏ | 82/100 [00:20<00:04,  4.43it/s]Train Iter: 1083/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0386. T_Loss: 4.8120. Mask: 0.9127. :  83%|████████▎ | 83/100 [00:20<00:03,  5.07it/s]Train Iter: 1084/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0378. T_Loss: 4.8019. Mask: 0.9122. :  83%|████████▎ | 83/100 [00:20<00:03,  5.07it/s]Train Iter: 1085/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0371. T_Loss: 4.7969. Mask: 0.9114. :  84%|████████▍ | 84/100 [00:21<00:03,  5.07it/s]Train Iter: 1085/5000. LR: 0.0494. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0371. T_Loss: 4.7969. Mask: 0.9114. :  85%|████████▌ | 85/100 [00:21<00:02,  6.06it/s]Train Iter: 1086/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0368. T_Loss: 4.7978. Mask: 0.9117. :  85%|████████▌ | 85/100 [00:21<00:02,  6.06it/s]Train Iter: 1086/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0368. T_Loss: 4.7978. Mask: 0.9117. :  86%|████████▌ | 86/100 [00:21<00:02,  6.38it/s]Train Iter: 1087/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0359. T_Loss: 4.7945. Mask: 0.9116. :  86%|████████▌ | 86/100 [00:21<00:02,  6.38it/s]Train Iter: 1087/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0359. T_Loss: 4.7945. Mask: 0.9116. :  87%|████████▋ | 87/100 [00:21<00:01,  6.97it/s]Train Iter: 1088/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0351. T_Loss: 4.7937. Mask: 0.9119. :  87%|████████▋ | 87/100 [00:21<00:01,  6.97it/s]Train Iter: 1088/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0351. T_Loss: 4.7937. Mask: 0.9119. :  88%|████████▊ | 88/100 [00:21<00:01,  7.34it/s]Train Iter: 1089/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0341. T_Loss: 4.7840. Mask: 0.9122. :  88%|████████▊ | 88/100 [00:21<00:01,  7.34it/s]Train Iter: 1089/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0341. T_Loss: 4.7840. Mask: 0.9122. :  89%|████████▉ | 89/100 [00:21<00:02,  5.24it/s]Train Iter: 1090/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0331. T_Loss: 4.7751. Mask: 0.9122. :  89%|████████▉ | 89/100 [00:21<00:02,  5.24it/s]Train Iter: 1090/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0331. T_Loss: 4.7751. Mask: 0.9122. :  90%|█████████ | 90/100 [00:21<00:01,  5.78it/s]Train Iter: 1091/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0327. T_Loss: 4.7725. Mask: 0.9128. :  90%|█████████ | 90/100 [00:21<00:01,  5.78it/s]Train Iter: 1091/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0327. T_Loss: 4.7725. Mask: 0.9128. :  91%|█████████ | 91/100 [00:21<00:01,  6.23it/s]Train Iter: 1092/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0322. T_Loss: 4.7766. Mask: 0.9134. :  91%|█████████ | 91/100 [00:22<00:01,  6.23it/s]Train Iter: 1092/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0322. T_Loss: 4.7766. Mask: 0.9134. :  92%|█████████▏| 92/100 [00:22<00:01,  6.73it/s]Train Iter: 1093/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0315. T_Loss: 4.7729. Mask: 0.9136. :  92%|█████████▏| 92/100 [00:22<00:01,  6.73it/s]Train Iter: 1093/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0315. T_Loss: 4.7729. Mask: 0.9136. :  93%|█████████▎| 93/100 [00:22<00:01,  6.74it/s]Train Iter: 1094/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0315. T_Loss: 4.7692. Mask: 0.9129. :  93%|█████████▎| 93/100 [00:22<00:01,  6.74it/s]Train Iter: 1094/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0315. T_Loss: 4.7692. Mask: 0.9129. :  94%|█████████▍| 94/100 [00:22<00:00,  7.09it/s]Train Iter: 1095/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0295. T_Loss: 4.7540. Mask: 0.9125. :  94%|█████████▍| 94/100 [00:22<00:00,  7.09it/s]Train Iter: 1095/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0295. T_Loss: 4.7540. Mask: 0.9125. :  95%|█████████▌| 95/100 [00:22<00:01,  4.58it/s]Train Iter: 1096/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0292. T_Loss: 4.7598. Mask: 0.9124. :  95%|█████████▌| 95/100 [00:22<00:01,  4.58it/s]Train Iter: 1096/5000. LR: 0.0494. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0292. T_Loss: 4.7598. Mask: 0.9124. :  96%|█████████▌| 96/100 [00:22<00:00,  5.23it/s]Train Iter: 1097/5000. LR: 0.0494. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0297. T_Loss: 4.7652. Mask: 0.9127. :  96%|█████████▌| 96/100 [00:23<00:00,  5.23it/s]Train Iter: 1097/5000. LR: 0.0494. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0297. T_Loss: 4.7652. Mask: 0.9127. :  97%|█████████▋| 97/100 [00:23<00:00,  5.70it/s]Train Iter: 1098/5000. LR: 0.0494. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0293. T_Loss: 4.7611. Mask: 0.9129. :  97%|█████████▋| 97/100 [00:23<00:00,  5.70it/s]Train Iter: 1098/5000. LR: 0.0494. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0293. T_Loss: 4.7611. Mask: 0.9129. :  98%|█████████▊| 98/100 [00:23<00:00,  6.18it/s]Train Iter: 1099/5000. LR: 0.0494. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0298. T_Loss: 4.7628. Mask: 0.9126. :  98%|█████████▊| 98/100 [00:23<00:00,  6.18it/s]Train Iter: 1099/5000. LR: 0.0494. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0298. T_Loss: 4.7628. Mask: 0.9126. :  99%|█████████▉| 99/100 [00:23<00:00,  6.08it/s]Train Iter: 1100/5000. LR: 0.0494. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0302. T_Loss: 4.7708. Mask: 0.9128. :  99%|█████████▉| 99/100 [00:23<00:00,  6.08it/s]Train Iter: 1100/5000. LR: 0.0494. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0302. T_Loss: 4.7708. Mask: 0.9128. : 100%|██████████| 100/100 [00:23<00:00,  6.50it/s]Train Iter: 1100/5000. LR: 0.0494. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0302. T_Loss: 4.7708. Mask: 0.9128. : 100%|██████████| 100/100 [00:23<00:00,  4.26it/s]
total : 5000  current step :  1076
total : 5000  current step :  1077
total : 5000  current step :  1078
total : 5000  current step :  1079
total : 5000  current step :  1080
total : 5000  current step :  1081
total : 5000  current step :  1082
total : 5000  current step :  1083
total : 5000  current step :  1084
total : 5000  current step :  1085
total : 5000  current step :  1086
total : 5000  current step :  1087
total : 5000  current step :  1088
total : 5000  current step :  1089
total : 5000  current step :  1090
total : 5000  current step :  1091
total : 5000  current step :  1092
total : 5000  current step :  1093
total : 5000  current step :  1094
total : 5000  current step :  1095
total : 5000  current step :  1096
total : 5000  current step :  1097
total : 5000  current step :  1098
total : 5000  current step :  1099
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 1.6043. top1: 53.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 1.6043. top1: 53.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 1.5192. top1: 57.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 1.4119. top1: 63.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 1.4591. top1: 60.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 1.4280. top1: 61.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 1.4397. top1: 60.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 1.4491. top1: 61.61. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 1.4491. top1: 61.61. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.73it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.4737. top1: 59.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.73it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.4606. top1: 59.72. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.73it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.4787. top1: 58.44. top5: 99.69. :  11%|█         | 7/63 [00:02<00:11,  4.73it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.4472. top1: 59.38. top5: 99.72. :  11%|█         | 7/63 [00:02<00:11,  4.73it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.4534. top1: 58.33. top5: 99.74. :  11%|█         | 7/63 [00:02<00:11,  4.73it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.4407. top1: 58.65. top5: 99.76. :  11%|█         | 7/63 [00:02<00:11,  4.73it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.4472. top1: 58.48. top5: 99.78. :  11%|█         | 7/63 [00:02<00:11,  4.73it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.4255. top1: 60.21. top5: 99.79. :  11%|█         | 7/63 [00:02<00:11,  4.73it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4204. top1: 60.74. top5: 99.80. :  11%|█         | 7/63 [00:02<00:11,  4.73it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4204. top1: 60.74. top5: 99.80. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4129. top1: 61.03. top5: 99.82. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4140. top1: 60.07. top5: 99.83. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4119. top1: 60.36. top5: 99.67. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4088. top1: 60.62. top5: 99.69. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4238. top1: 59.67. top5: 99.55. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4146. top1: 60.23. top5: 99.57. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4067. top1: 60.46. top5: 99.59. :  25%|██▌       | 16/63 [00:02<00:03, 12.36it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4067. top1: 60.46. top5: 99.59. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4012. top1: 60.68. top5: 99.61. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3998. top1: 60.62. top5: 99.62. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4093. top1: 59.86. top5: 99.64. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4025. top1: 60.42. top5: 99.65. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4084. top1: 60.49. top5: 99.55. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4072. top1: 60.67. top5: 99.57. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4054. top1: 60.73. top5: 99.58. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4073. top1: 60.69. top5: 99.60. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4020. top1: 61.04. top5: 99.61. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3854. top1: 62.03. top5: 99.62. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3774. top1: 62.59. top5: 99.54. :  37%|███▋      | 23/63 [00:02<00:02, 18.94it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3774. top1: 62.59. top5: 99.54. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3638. top1: 63.30. top5: 99.55. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3632. top1: 63.63. top5: 99.48. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3499. top1: 64.27. top5: 99.49. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3367. top1: 64.97. top5: 99.51. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3369. top1: 65.22. top5: 99.28. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3273. top1: 65.86. top5: 99.22. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3190. top1: 66.39. top5: 99.24. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3112. top1: 66.82. top5: 99.26. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3018. top1: 67.30. top5: 99.27. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2921. top1: 67.90. top5: 99.29. :  54%|█████▍    | 34/63 [00:02<00:00, 31.48it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2921. top1: 67.90. top5: 99.29. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2819. top1: 68.47. top5: 99.31. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2739. top1: 68.95. top5: 99.32. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2694. top1: 69.28. top5: 99.27. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2615. top1: 69.79. top5: 99.28. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2564. top1: 70.03. top5: 99.30. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2510. top1: 70.31. top5: 99.31. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2515. top1: 70.28. top5: 99.20. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2449. top1: 70.67. top5: 99.22. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2421. top1: 71.05. top5: 99.12. :  70%|██████▉   | 44/63 [00:02<00:00, 42.46it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2421. top1: 71.05. top5: 99.12. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2371. top1: 71.35. top5: 99.13. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2324. top1: 71.65. top5: 99.15. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2269. top1: 71.88. top5: 99.16. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2261. top1: 72.04. top5: 99.18. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2217. top1: 72.25. top5: 99.19. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2196. top1: 72.35. top5: 99.21. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2137. top1: 72.66. top5: 99.22. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2120. top1: 72.64. top5: 99.23. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2131. top1: 72.58. top5: 99.19. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2115. top1: 72.65. top5: 99.20. :  84%|████████▍ | 53/63 [00:02<00:00, 50.15it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2115. top1: 72.65. top5: 99.20. : 100%|██████████| 63/63 [00:02<00:00, 59.48it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2115. top1: 72.65. top5: 99.20. : 100%|██████████| 63/63 [00:02<00:00, 22.38it/s]
total : 5000  current step :  1100
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1101/5000. LR: 0.0494. Data: 2.16s. Batch: 2.28s. S_Loss: 0.9132. T_Loss: 5.1428. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1101/5000. LR: 0.0494. Data: 2.16s. Batch: 2.28s. S_Loss: 0.9132. T_Loss: 5.1428. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:45,  2.28s/it]Train Iter: 1102/5000. LR: 0.0494. Data: 1.09s. Batch: 1.18s. S_Loss: 0.9397. T_Loss: 4.7571. Mask: 0.8906. :   1%|          | 1/100 [00:02<03:45,  2.28s/it]Train Iter: 1103/5000. LR: 0.0494. Data: 0.73s. Batch: 0.82s. S_Loss: 0.9393. T_Loss: 4.5491. Mask: 0.8958. :   2%|▏         | 2/100 [00:02<03:43,  2.28s/it]Train Iter: 1103/5000. LR: 0.0494. Data: 0.73s. Batch: 0.82s. S_Loss: 0.9393. T_Loss: 4.5491. Mask: 0.8958. :   3%|▎         | 3/100 [00:02<01:03,  1.53it/s]Train Iter: 1104/5000. LR: 0.0494. Data: 0.55s. Batch: 0.63s. S_Loss: 0.9155. T_Loss: 4.5796. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<01:03,  1.53it/s]Train Iter: 1105/5000. LR: 0.0494. Data: 0.44s. Batch: 0.54s. S_Loss: 0.9311. T_Loss: 4.5584. Mask: 0.9187. :   4%|▍         | 4/100 [00:02<01:02,  1.53it/s]Train Iter: 1105/5000. LR: 0.0494. Data: 0.44s. Batch: 0.54s. S_Loss: 0.9311. T_Loss: 4.5584. Mask: 0.9187. :   5%|▌         | 5/100 [00:02<00:36,  2.58it/s]Train Iter: 1106/5000. LR: 0.0493. Data: 0.37s. Batch: 0.47s. S_Loss: 0.9432. T_Loss: 4.5158. Mask: 0.9167. :   5%|▌         | 5/100 [00:02<00:36,  2.58it/s]Train Iter: 1107/5000. LR: 0.0493. Data: 0.31s. Batch: 0.41s. S_Loss: 0.9687. T_Loss: 4.6877. Mask: 0.9196. :   6%|▌         | 6/100 [00:02<00:36,  2.58it/s]Train Iter: 1107/5000. LR: 0.0493. Data: 0.31s. Batch: 0.41s. S_Loss: 0.9687. T_Loss: 4.6877. Mask: 0.9196. :   7%|▋         | 7/100 [00:02<00:23,  3.91it/s]Train Iter: 1108/5000. LR: 0.0493. Data: 0.27s. Batch: 0.37s. S_Loss: 0.9550. T_Loss: 4.6635. Mask: 0.9219. :   7%|▋         | 7/100 [00:02<00:23,  3.91it/s]Train Iter: 1109/5000. LR: 0.0493. Data: 0.24s. Batch: 0.37s. S_Loss: 0.9635. T_Loss: 4.6888. Mask: 0.9236. :   8%|▊         | 8/100 [00:03<00:23,  3.91it/s]Train Iter: 1109/5000. LR: 0.0493. Data: 0.24s. Batch: 0.37s. S_Loss: 0.9635. T_Loss: 4.6888. Mask: 0.9236. :   9%|▉         | 9/100 [00:03<00:21,  4.17it/s]Train Iter: 1110/5000. LR: 0.0493. Data: 0.22s. Batch: 0.34s. S_Loss: 0.9705. T_Loss: 4.6201. Mask: 0.9156. :   9%|▉         | 9/100 [00:03<00:21,  4.17it/s]Train Iter: 1110/5000. LR: 0.0493. Data: 0.22s. Batch: 0.34s. S_Loss: 0.9705. T_Loss: 4.6201. Mask: 0.9156. :  10%|█         | 10/100 [00:03<00:19,  4.64it/s]Train Iter: 1111/5000. LR: 0.0493. Data: 0.20s. Batch: 0.32s. S_Loss: 0.9806. T_Loss: 4.6868. Mask: 0.9176. :  10%|█         | 10/100 [00:03<00:19,  4.64it/s]Train Iter: 1111/5000. LR: 0.0493. Data: 0.20s. Batch: 0.32s. S_Loss: 0.9806. T_Loss: 4.6868. Mask: 0.9176. :  11%|█         | 11/100 [00:03<00:17,  5.15it/s]Train Iter: 1112/5000. LR: 0.0493. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9941. T_Loss: 4.6781. Mask: 0.9115. :  11%|█         | 11/100 [00:03<00:17,  5.15it/s]Train Iter: 1112/5000. LR: 0.0493. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9941. T_Loss: 4.6781. Mask: 0.9115. :  12%|█▏        | 12/100 [00:03<00:15,  5.65it/s]Train Iter: 1113/5000. LR: 0.0493. Data: 0.17s. Batch: 0.29s. S_Loss: 1.0059. T_Loss: 4.6943. Mask: 0.9111. :  12%|█▏        | 12/100 [00:03<00:15,  5.65it/s]Train Iter: 1113/5000. LR: 0.0493. Data: 0.17s. Batch: 0.29s. S_Loss: 1.0059. T_Loss: 4.6943. Mask: 0.9111. :  13%|█▎        | 13/100 [00:03<00:14,  6.14it/s]Train Iter: 1114/5000. LR: 0.0493. Data: 0.16s. Batch: 0.28s. S_Loss: 1.0179. T_Loss: 4.6804. Mask: 0.9085. :  13%|█▎        | 13/100 [00:03<00:14,  6.14it/s]Train Iter: 1114/5000. LR: 0.0493. Data: 0.16s. Batch: 0.28s. S_Loss: 1.0179. T_Loss: 4.6804. Mask: 0.9085. :  14%|█▍        | 14/100 [00:03<00:13,  6.55it/s]Train Iter: 1115/5000. LR: 0.0493. Data: 0.15s. Batch: 0.27s. S_Loss: 1.0269. T_Loss: 4.6323. Mask: 0.9042. :  14%|█▍        | 14/100 [00:04<00:13,  6.55it/s]Train Iter: 1115/5000. LR: 0.0493. Data: 0.15s. Batch: 0.27s. S_Loss: 1.0269. T_Loss: 4.6323. Mask: 0.9042. :  15%|█▌        | 15/100 [00:04<00:12,  6.85it/s]Train Iter: 1116/5000. LR: 0.0493. Data: 0.14s. Batch: 0.26s. S_Loss: 1.0240. T_Loss: 4.5765. Mask: 0.9023. :  15%|█▌        | 15/100 [00:04<00:12,  6.85it/s]Train Iter: 1116/5000. LR: 0.0493. Data: 0.14s. Batch: 0.26s. S_Loss: 1.0240. T_Loss: 4.5765. Mask: 0.9023. :  16%|█▌        | 16/100 [00:04<00:12,  6.84it/s]Train Iter: 1117/5000. LR: 0.0493. Data: 0.13s. Batch: 0.25s. S_Loss: 1.0213. T_Loss: 4.5784. Mask: 0.9007. :  16%|█▌        | 16/100 [00:04<00:12,  6.84it/s]Train Iter: 1117/5000. LR: 0.0493. Data: 0.13s. Batch: 0.25s. S_Loss: 1.0213. T_Loss: 4.5784. Mask: 0.9007. :  17%|█▋        | 17/100 [00:04<00:11,  7.16it/s]Train Iter: 1118/5000. LR: 0.0493. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0193. T_Loss: 4.5997. Mask: 0.9045. :  17%|█▋        | 17/100 [00:04<00:11,  7.16it/s]Train Iter: 1118/5000. LR: 0.0493. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0193. T_Loss: 4.5997. Mask: 0.9045. :  18%|█▊        | 18/100 [00:04<00:10,  7.50it/s]Train Iter: 1119/5000. LR: 0.0493. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0164. T_Loss: 4.5629. Mask: 0.8964. :  18%|█▊        | 18/100 [00:04<00:10,  7.50it/s]Train Iter: 1119/5000. LR: 0.0493. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0164. T_Loss: 4.5629. Mask: 0.8964. :  19%|█▉        | 19/100 [00:04<00:14,  5.44it/s]Train Iter: 1120/5000. LR: 0.0493. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0139. T_Loss: 4.5797. Mask: 0.8984. :  19%|█▉        | 19/100 [00:04<00:14,  5.44it/s]Train Iter: 1120/5000. LR: 0.0493. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0139. T_Loss: 4.5797. Mask: 0.8984. :  20%|██        | 20/100 [00:04<00:13,  6.04it/s]Train Iter: 1121/5000. LR: 0.0493. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0292. T_Loss: 4.6342. Mask: 0.8958. :  20%|██        | 20/100 [00:04<00:13,  6.04it/s]Train Iter: 1121/5000. LR: 0.0493. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0292. T_Loss: 4.6342. Mask: 0.8958. :  21%|██        | 21/100 [00:04<00:12,  6.46it/s]Train Iter: 1122/5000. LR: 0.0493. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0309. T_Loss: 4.6728. Mask: 0.8963. :  21%|██        | 21/100 [00:05<00:12,  6.46it/s]Train Iter: 1122/5000. LR: 0.0493. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0309. T_Loss: 4.6728. Mask: 0.8963. :  22%|██▏       | 22/100 [00:05<00:11,  6.89it/s]Train Iter: 1123/5000. LR: 0.0493. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0435. T_Loss: 4.6992. Mask: 0.8899. :  22%|██▏       | 22/100 [00:05<00:11,  6.89it/s]Train Iter: 1123/5000. LR: 0.0493. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0435. T_Loss: 4.6992. Mask: 0.8899. :  23%|██▎       | 23/100 [00:05<00:11,  6.88it/s]Train Iter: 1124/5000. LR: 0.0493. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0458. T_Loss: 4.7089. Mask: 0.8867. :  23%|██▎       | 23/100 [00:05<00:11,  6.88it/s]Train Iter: 1124/5000. LR: 0.0493. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0458. T_Loss: 4.7089. Mask: 0.8867. :  24%|██▍       | 24/100 [00:05<00:10,  7.14it/s]Train Iter: 1125/5000. LR: 0.0493. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0498. T_Loss: 4.7622. Mask: 0.8850. :  24%|██▍       | 24/100 [00:05<00:10,  7.14it/s]Train Iter: 1125/5000. LR: 0.0493. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0498. T_Loss: 4.7622. Mask: 0.8850. :  25%|██▌       | 25/100 [00:05<00:14,  5.29it/s]total : 5000  current step :  1101
total : 5000  current step :  1102
total : 5000  current step :  1103
total : 5000  current step :  1104
total : 5000  current step :  1105
total : 5000  current step :  1106
total : 5000  current step :  1107
total : 5000  current step :  1108
total : 5000  current step :  1109
total : 5000  current step :  1110
total : 5000  current step :  1111
total : 5000  current step :  1112
total : 5000  current step :  1113
total : 5000  current step :  1114
total : 5000  current step :  1115
total : 5000  current step :  1116
total : 5000  current step :  1117
total : 5000  current step :  1118
total : 5000  current step :  1119
total : 5000  current step :  1120
total : 5000  current step :  1121
total : 5000  current step :  1122
total : 5000  current step :  1123
total : 5000  current step :  1124
total : 5000  current step :  1125
Train Iter: 1126/5000. LR: 0.0493. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0493. T_Loss: 4.7878. Mask: 0.8858. :  25%|██▌       | 25/100 [00:07<00:14,  5.29it/s]Train Iter: 1126/5000. LR: 0.0493. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0493. T_Loss: 4.7878. Mask: 0.8858. :  26%|██▌       | 26/100 [00:07<00:55,  1.33it/s]Train Iter: 1127/5000. LR: 0.0493. Data: 0.16s. Batch: 0.29s. S_Loss: 1.0513. T_Loss: 4.7886. Mask: 0.8808. :  26%|██▌       | 26/100 [00:07<00:55,  1.33it/s]Train Iter: 1127/5000. LR: 0.0493. Data: 0.16s. Batch: 0.29s. S_Loss: 1.0513. T_Loss: 4.7886. Mask: 0.8808. :  27%|██▋       | 27/100 [00:07<00:41,  1.74it/s]Train Iter: 1128/5000. LR: 0.0493. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0502. T_Loss: 4.8100. Mask: 0.8817. :  27%|██▋       | 27/100 [00:08<00:41,  1.74it/s]Train Iter: 1128/5000. LR: 0.0493. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0502. T_Loss: 4.8100. Mask: 0.8817. :  28%|██▊       | 28/100 [00:08<00:31,  2.29it/s]Train Iter: 1129/5000. LR: 0.0492. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0542. T_Loss: 4.8017. Mask: 0.8793. :  28%|██▊       | 28/100 [00:08<00:31,  2.29it/s]Train Iter: 1129/5000. LR: 0.0492. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0542. T_Loss: 4.8017. Mask: 0.8793. :  29%|██▉       | 29/100 [00:08<00:27,  2.54it/s]Train Iter: 1130/5000. LR: 0.0492. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0545. T_Loss: 4.7991. Mask: 0.8802. :  29%|██▉       | 29/100 [00:08<00:27,  2.54it/s]Train Iter: 1130/5000. LR: 0.0492. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0545. T_Loss: 4.7991. Mask: 0.8802. :  30%|███       | 30/100 [00:08<00:22,  3.13it/s]Train Iter: 1131/5000. LR: 0.0492. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0527. T_Loss: 4.7955. Mask: 0.8800. :  30%|███       | 30/100 [00:08<00:22,  3.13it/s]Train Iter: 1131/5000. LR: 0.0492. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0527. T_Loss: 4.7955. Mask: 0.8800. :  31%|███       | 31/100 [00:08<00:18,  3.74it/s]Train Iter: 1132/5000. LR: 0.0492. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0497. T_Loss: 4.7798. Mask: 0.8809. :  31%|███       | 31/100 [00:08<00:18,  3.74it/s]Train Iter: 1132/5000. LR: 0.0492. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0497. T_Loss: 4.7798. Mask: 0.8809. :  32%|███▏      | 32/100 [00:08<00:15,  4.48it/s]Train Iter: 1133/5000. LR: 0.0492. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0476. T_Loss: 4.7741. Mask: 0.8835. :  32%|███▏      | 32/100 [00:08<00:15,  4.48it/s]Train Iter: 1133/5000. LR: 0.0492. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0476. T_Loss: 4.7741. Mask: 0.8835. :  33%|███▎      | 33/100 [00:08<00:12,  5.18it/s]Train Iter: 1134/5000. LR: 0.0492. Data: 0.13s. Batch: 0.26s. S_Loss: 1.0461. T_Loss: 4.7969. Mask: 0.8869. :  33%|███▎      | 33/100 [00:08<00:12,  5.18it/s]Train Iter: 1134/5000. LR: 0.0492. Data: 0.13s. Batch: 0.26s. S_Loss: 1.0461. T_Loss: 4.7969. Mask: 0.8869. :  34%|███▍      | 34/100 [00:08<00:11,  5.75it/s]Train Iter: 1135/5000. LR: 0.0492. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0447. T_Loss: 4.7708. Mask: 0.8866. :  34%|███▍      | 34/100 [00:09<00:11,  5.75it/s]Train Iter: 1135/5000. LR: 0.0492. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0447. T_Loss: 4.7708. Mask: 0.8866. :  35%|███▌      | 35/100 [00:09<00:13,  4.67it/s]Train Iter: 1136/5000. LR: 0.0492. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0401. T_Loss: 4.7469. Mask: 0.8880. :  35%|███▌      | 35/100 [00:09<00:13,  4.67it/s]Train Iter: 1136/5000. LR: 0.0492. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0401. T_Loss: 4.7469. Mask: 0.8880. :  36%|███▌      | 36/100 [00:09<00:12,  5.29it/s]Train Iter: 1137/5000. LR: 0.0492. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0397. T_Loss: 4.7471. Mask: 0.8885. :  36%|███▌      | 36/100 [00:09<00:12,  5.29it/s]Train Iter: 1137/5000. LR: 0.0492. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0397. T_Loss: 4.7471. Mask: 0.8885. :  37%|███▋      | 37/100 [00:09<00:10,  5.82it/s]Train Iter: 1138/5000. LR: 0.0492. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0382. T_Loss: 4.7483. Mask: 0.8898. :  37%|███▋      | 37/100 [00:09<00:10,  5.82it/s]Train Iter: 1138/5000. LR: 0.0492. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0382. T_Loss: 4.7483. Mask: 0.8898. :  38%|███▊      | 38/100 [00:09<00:09,  6.32it/s]Train Iter: 1139/5000. LR: 0.0492. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0380. T_Loss: 4.7603. Mask: 0.8910. :  38%|███▊      | 38/100 [00:10<00:09,  6.32it/s]Train Iter: 1139/5000. LR: 0.0492. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0380. T_Loss: 4.7603. Mask: 0.8910. :  39%|███▉      | 39/100 [00:10<00:12,  4.76it/s]Train Iter: 1140/5000. LR: 0.0492. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0394. T_Loss: 4.7594. Mask: 0.8922. :  39%|███▉      | 39/100 [00:10<00:12,  4.76it/s]Train Iter: 1140/5000. LR: 0.0492. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0394. T_Loss: 4.7594. Mask: 0.8922. :  40%|████      | 40/100 [00:10<00:11,  5.38it/s]Train Iter: 1141/5000. LR: 0.0492. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0413. T_Loss: 4.7850. Mask: 0.8933. :  40%|████      | 40/100 [00:10<00:11,  5.38it/s]Train Iter: 1141/5000. LR: 0.0492. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0413. T_Loss: 4.7850. Mask: 0.8933. :  41%|████      | 41/100 [00:10<00:10,  5.82it/s]Train Iter: 1142/5000. LR: 0.0492. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0433. T_Loss: 4.7641. Mask: 0.8921. :  41%|████      | 41/100 [00:10<00:10,  5.82it/s]Train Iter: 1142/5000. LR: 0.0492. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0433. T_Loss: 4.7641. Mask: 0.8921. :  42%|████▏     | 42/100 [00:10<00:08,  6.57it/s]Train Iter: 1143/5000. LR: 0.0492. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0505. T_Loss: 4.7526. Mask: 0.8924. :  42%|████▏     | 42/100 [00:10<00:08,  6.57it/s]Train Iter: 1143/5000. LR: 0.0492. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0505. T_Loss: 4.7526. Mask: 0.8924. :  43%|████▎     | 43/100 [00:10<00:08,  6.84it/s]Train Iter: 1144/5000. LR: 0.0492. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0523. T_Loss: 4.7482. Mask: 0.8935. :  43%|████▎     | 43/100 [00:10<00:08,  6.84it/s]Train Iter: 1144/5000. LR: 0.0492. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0523. T_Loss: 4.7482. Mask: 0.8935. :  44%|████▍     | 44/100 [00:10<00:07,  7.20it/s]Train Iter: 1145/5000. LR: 0.0492. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0592. T_Loss: 4.7804. Mask: 0.8944. :  44%|████▍     | 44/100 [00:11<00:07,  7.20it/s]Train Iter: 1145/5000. LR: 0.0492. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0592. T_Loss: 4.7804. Mask: 0.8944. :  45%|████▌     | 45/100 [00:11<00:11,  4.80it/s]Train Iter: 1146/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0625. T_Loss: 4.7677. Mask: 0.8933. :  45%|████▌     | 45/100 [00:11<00:11,  4.80it/s]Train Iter: 1146/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0625. T_Loss: 4.7677. Mask: 0.8933. :  46%|████▌     | 46/100 [00:11<00:09,  5.44it/s]Train Iter: 1147/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0639. T_Loss: 4.7474. Mask: 0.8923. :  46%|████▌     | 46/100 [00:11<00:09,  5.44it/s]Train Iter: 1147/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0639. T_Loss: 4.7474. Mask: 0.8923. :  47%|████▋     | 47/100 [00:11<00:08,  6.06it/s]Train Iter: 1148/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0638. T_Loss: 4.7187. Mask: 0.8926. :  47%|████▋     | 47/100 [00:11<00:08,  6.06it/s]Train Iter: 1148/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0638. T_Loss: 4.7187. Mask: 0.8926. :  48%|████▊     | 48/100 [00:11<00:08,  6.39it/s]Train Iter: 1149/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0637. T_Loss: 4.6934. Mask: 0.8941. :  48%|████▊     | 48/100 [00:11<00:08,  6.39it/s]Train Iter: 1149/5000. LR: 0.0492. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0637. T_Loss: 4.6934. Mask: 0.8941. :  49%|████▉     | 49/100 [00:11<00:09,  5.19it/s]Train Iter: 1150/5000. LR: 0.0491. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0629. T_Loss: 4.7008. Mask: 0.8950. :  49%|████▉     | 49/100 [00:11<00:09,  5.19it/s]total : 5000  current step :  1126
total : 5000  current step :  1127
total : 5000  current step :  1128
total : 5000  current step :  1129
total : 5000  current step :  1130
total : 5000  current step :  1131
total : 5000  current step :  1132
total : 5000  current step :  1133
total : 5000  current step :  1134
total : 5000  current step :  1135
total : 5000  current step :  1136
total : 5000  current step :  1137
total : 5000  current step :  1138
total : 5000  current step :  1139
total : 5000  current step :  1140
total : 5000  current step :  1141
total : 5000  current step :  1142
total : 5000  current step :  1143
total : 5000  current step :  1144
total : 5000  current step :  1145
total : 5000  current step :  1146
total : 5000  current step :  1147
total : 5000  current step :  1148
total : 5000  current step :  1149
total : 5000  current step :  1150
Train Iter: 1151/5000. LR: 0.0491. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0627. T_Loss: 4.6943. Mask: 0.8971. :  50%|█████     | 50/100 [00:13<00:09,  5.19it/s]Train Iter: 1151/5000. LR: 0.0491. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0627. T_Loss: 4.6943. Mask: 0.8971. :  51%|█████     | 51/100 [00:13<00:29,  1.65it/s]Train Iter: 1152/5000. LR: 0.0491. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0630. T_Loss: 4.6945. Mask: 0.8984. :  51%|█████     | 51/100 [00:13<00:29,  1.65it/s]Train Iter: 1152/5000. LR: 0.0491. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0630. T_Loss: 4.6945. Mask: 0.8984. :  52%|█████▏    | 52/100 [00:13<00:23,  2.05it/s]Train Iter: 1153/5000. LR: 0.0491. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0621. T_Loss: 4.6874. Mask: 0.8998. :  52%|█████▏    | 52/100 [00:14<00:23,  2.05it/s]Train Iter: 1153/5000. LR: 0.0491. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0621. T_Loss: 4.6874. Mask: 0.8998. :  53%|█████▎    | 53/100 [00:14<00:18,  2.54it/s]Train Iter: 1154/5000. LR: 0.0491. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0607. T_Loss: 4.6723. Mask: 0.8999. :  53%|█████▎    | 53/100 [00:14<00:18,  2.54it/s]Train Iter: 1154/5000. LR: 0.0491. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0607. T_Loss: 4.6723. Mask: 0.8999. :  54%|█████▍    | 54/100 [00:14<00:14,  3.10it/s]Train Iter: 1155/5000. LR: 0.0491. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0623. T_Loss: 4.6717. Mask: 0.9011. :  54%|█████▍    | 54/100 [00:14<00:14,  3.10it/s]Train Iter: 1155/5000. LR: 0.0491. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0623. T_Loss: 4.6717. Mask: 0.9011. :  55%|█████▌    | 55/100 [00:14<00:13,  3.41it/s]Train Iter: 1156/5000. LR: 0.0491. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0605. T_Loss: 4.6622. Mask: 0.9018. :  55%|█████▌    | 55/100 [00:14<00:13,  3.41it/s]Train Iter: 1156/5000. LR: 0.0491. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0605. T_Loss: 4.6622. Mask: 0.9018. :  56%|█████▌    | 56/100 [00:14<00:10,  4.11it/s]Train Iter: 1157/5000. LR: 0.0491. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0597. T_Loss: 4.6568. Mask: 0.9024. :  56%|█████▌    | 56/100 [00:14<00:10,  4.11it/s]Train Iter: 1157/5000. LR: 0.0491. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0597. T_Loss: 4.6568. Mask: 0.9024. :  57%|█████▋    | 57/100 [00:14<00:09,  4.74it/s]Train Iter: 1158/5000. LR: 0.0491. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0607. T_Loss: 4.6655. Mask: 0.9036. :  57%|█████▋    | 57/100 [00:14<00:09,  4.74it/s]Train Iter: 1159/5000. LR: 0.0491. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0598. T_Loss: 4.6647. Mask: 0.9041. :  58%|█████▊    | 58/100 [00:15<00:08,  4.74it/s]Train Iter: 1159/5000. LR: 0.0491. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0598. T_Loss: 4.6647. Mask: 0.9041. :  59%|█████▉    | 59/100 [00:15<00:07,  5.28it/s]Train Iter: 1160/5000. LR: 0.0491. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0620. T_Loss: 4.6777. Mask: 0.9047. :  59%|█████▉    | 59/100 [00:15<00:07,  5.28it/s]Train Iter: 1160/5000. LR: 0.0491. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0620. T_Loss: 4.6777. Mask: 0.9047. :  60%|██████    | 60/100 [00:15<00:06,  5.95it/s]Train Iter: 1161/5000. LR: 0.0491. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0671. T_Loss: 4.6925. Mask: 0.9042. :  60%|██████    | 60/100 [00:15<00:06,  5.95it/s]Train Iter: 1162/5000. LR: 0.0491. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0727. T_Loss: 4.7014. Mask: 0.9042. :  61%|██████    | 61/100 [00:15<00:06,  5.95it/s]Train Iter: 1162/5000. LR: 0.0491. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0727. T_Loss: 4.7014. Mask: 0.9042. :  62%|██████▏   | 62/100 [00:15<00:05,  7.29it/s]Train Iter: 1163/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0753. T_Loss: 4.7087. Mask: 0.9048. :  62%|██████▏   | 62/100 [00:15<00:05,  7.29it/s]Train Iter: 1164/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0808. T_Loss: 4.7153. Mask: 0.9048. :  63%|██████▎   | 63/100 [00:15<00:05,  7.29it/s]Train Iter: 1164/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0808. T_Loss: 4.7153. Mask: 0.9048. :  64%|██████▍   | 64/100 [00:15<00:04,  7.94it/s]Train Iter: 1165/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0826. T_Loss: 4.7024. Mask: 0.9043. :  64%|██████▍   | 64/100 [00:15<00:04,  7.94it/s]Train Iter: 1165/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0826. T_Loss: 4.7024. Mask: 0.9043. :  65%|██████▌   | 65/100 [00:15<00:05,  6.17it/s]Train Iter: 1166/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0846. T_Loss: 4.7040. Mask: 0.9044. :  65%|██████▌   | 65/100 [00:15<00:05,  6.17it/s]Train Iter: 1166/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0846. T_Loss: 4.7040. Mask: 0.9044. :  66%|██████▌   | 66/100 [00:15<00:05,  6.26it/s]Train Iter: 1167/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0875. T_Loss: 4.6941. Mask: 0.9035. :  66%|██████▌   | 66/100 [00:16<00:05,  6.26it/s]Train Iter: 1167/5000. LR: 0.0491. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0875. T_Loss: 4.6941. Mask: 0.9035. :  67%|██████▋   | 67/100 [00:16<00:05,  6.55it/s]Train Iter: 1168/5000. LR: 0.0491. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0884. T_Loss: 4.6803. Mask: 0.9030. :  67%|██████▋   | 67/100 [00:16<00:05,  6.55it/s]Train Iter: 1168/5000. LR: 0.0491. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0884. T_Loss: 4.6803. Mask: 0.9030. :  68%|██████▊   | 68/100 [00:16<00:04,  6.80it/s]Train Iter: 1169/5000. LR: 0.0491. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0882. T_Loss: 4.6755. Mask: 0.9035. :  68%|██████▊   | 68/100 [00:16<00:04,  6.80it/s]Train Iter: 1169/5000. LR: 0.0491. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0882. T_Loss: 4.6755. Mask: 0.9035. :  69%|██████▉   | 69/100 [00:16<00:06,  5.13it/s]Train Iter: 1170/5000. LR: 0.0490. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0865. T_Loss: 4.6605. Mask: 0.9040. :  69%|██████▉   | 69/100 [00:16<00:06,  5.13it/s]Train Iter: 1170/5000. LR: 0.0490. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0865. T_Loss: 4.6605. Mask: 0.9040. :  70%|███████   | 70/100 [00:16<00:05,  5.79it/s]Train Iter: 1171/5000. LR: 0.0490. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0861. T_Loss: 4.6419. Mask: 0.9040. :  70%|███████   | 70/100 [00:16<00:05,  5.79it/s]Train Iter: 1171/5000. LR: 0.0490. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0861. T_Loss: 4.6419. Mask: 0.9040. :  71%|███████   | 71/100 [00:16<00:04,  6.29it/s]Train Iter: 1172/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0834. T_Loss: 4.6315. Mask: 0.9045. :  71%|███████   | 71/100 [00:16<00:04,  6.29it/s]Train Iter: 1172/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0834. T_Loss: 4.6315. Mask: 0.9045. :  72%|███████▏  | 72/100 [00:16<00:04,  6.65it/s]Train Iter: 1173/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0799. T_Loss: 4.6129. Mask: 0.9058. :  72%|███████▏  | 72/100 [00:17<00:04,  6.65it/s]Train Iter: 1173/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0799. T_Loss: 4.6129. Mask: 0.9058. :  73%|███████▎  | 73/100 [00:17<00:03,  6.82it/s]Train Iter: 1174/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0763. T_Loss: 4.6013. Mask: 0.9067. :  73%|███████▎  | 73/100 [00:17<00:03,  6.82it/s]Train Iter: 1174/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0763. T_Loss: 4.6013. Mask: 0.9067. :  74%|███████▍  | 74/100 [00:17<00:03,  7.43it/s]Train Iter: 1175/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0724. T_Loss: 4.5835. Mask: 0.9075. :  74%|███████▍  | 74/100 [00:17<00:03,  7.43it/s]Train Iter: 1175/5000. LR: 0.0490. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0724. T_Loss: 4.5835. Mask: 0.9075. :  75%|███████▌  | 75/100 [00:17<00:05,  4.75it/s]total : 5000  current step :  1151
total : 5000  current step :  1152
total : 5000  current step :  1153
total : 5000  current step :  1154
total : 5000  current step :  1155
total : 5000  current step :  1156
total : 5000  current step :  1157
total : 5000  current step :  1158
total : 5000  current step :  1159
total : 5000  current step :  1160
total : 5000  current step :  1161
total : 5000  current step :  1162
total : 5000  current step :  1163
total : 5000  current step :  1164
total : 5000  current step :  1165
total : 5000  current step :  1166
total : 5000  current step :  1167
total : 5000  current step :  1168
total : 5000  current step :  1169
total : 5000  current step :  1170
total : 5000  current step :  1171
total : 5000  current step :  1172
total : 5000  current step :  1173
total : 5000  current step :  1174
total : 5000  current step :  1175
Train Iter: 1176/5000. LR: 0.0490. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0684. T_Loss: 4.5723. Mask: 0.9083. :  75%|███████▌  | 75/100 [00:19<00:05,  4.75it/s]Train Iter: 1176/5000. LR: 0.0490. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0684. T_Loss: 4.5723. Mask: 0.9083. :  76%|███████▌  | 76/100 [00:19<00:18,  1.28it/s]Train Iter: 1177/5000. LR: 0.0490. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0655. T_Loss: 4.5605. Mask: 0.9087. :  76%|███████▌  | 76/100 [00:19<00:18,  1.28it/s]Train Iter: 1177/5000. LR: 0.0490. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0655. T_Loss: 4.5605. Mask: 0.9087. :  77%|███████▋  | 77/100 [00:19<00:13,  1.67it/s]Train Iter: 1178/5000. LR: 0.0490. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0626. T_Loss: 4.5624. Mask: 0.9095. :  77%|███████▋  | 77/100 [00:20<00:13,  1.67it/s]Train Iter: 1178/5000. LR: 0.0490. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0626. T_Loss: 4.5624. Mask: 0.9095. :  78%|███████▊  | 78/100 [00:20<00:10,  2.16it/s]Train Iter: 1179/5000. LR: 0.0490. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0605. T_Loss: 4.5635. Mask: 0.9106. :  78%|███████▊  | 78/100 [00:20<00:10,  2.16it/s]Train Iter: 1179/5000. LR: 0.0490. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0605. T_Loss: 4.5635. Mask: 0.9106. :  79%|███████▉  | 79/100 [00:20<00:08,  2.59it/s]Train Iter: 1180/5000. LR: 0.0490. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0605. T_Loss: 4.5609. Mask: 0.9098. :  79%|███████▉  | 79/100 [00:20<00:08,  2.59it/s]Train Iter: 1181/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0621. T_Loss: 4.5653. Mask: 0.9093. :  80%|████████  | 80/100 [00:20<00:07,  2.59it/s]Train Iter: 1181/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0621. T_Loss: 4.5653. Mask: 0.9093. :  81%|████████  | 81/100 [00:20<00:04,  3.81it/s]Train Iter: 1182/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0609. T_Loss: 4.5674. Mask: 0.9089. :  81%|████████  | 81/100 [00:20<00:04,  3.81it/s]Train Iter: 1182/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0609. T_Loss: 4.5674. Mask: 0.9089. :  82%|████████▏ | 82/100 [00:20<00:04,  4.29it/s]Train Iter: 1183/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0611. T_Loss: 4.5835. Mask: 0.9093. :  82%|████████▏ | 82/100 [00:20<00:04,  4.29it/s]Train Iter: 1183/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0611. T_Loss: 4.5835. Mask: 0.9093. :  83%|████████▎ | 83/100 [00:20<00:03,  4.91it/s]Train Iter: 1184/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0704. T_Loss: 4.6129. Mask: 0.9089. :  83%|████████▎ | 83/100 [00:20<00:03,  4.91it/s]Train Iter: 1184/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0704. T_Loss: 4.6129. Mask: 0.9089. :  84%|████████▍ | 84/100 [00:20<00:02,  5.37it/s]Train Iter: 1185/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0734. T_Loss: 4.6235. Mask: 0.9077. :  84%|████████▍ | 84/100 [00:21<00:02,  5.37it/s]Train Iter: 1185/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0734. T_Loss: 4.6235. Mask: 0.9077. :  85%|████████▌ | 85/100 [00:21<00:03,  4.41it/s]Train Iter: 1186/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0827. T_Loss: 4.6418. Mask: 0.9081. :  85%|████████▌ | 85/100 [00:21<00:03,  4.41it/s]Train Iter: 1186/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0827. T_Loss: 4.6418. Mask: 0.9081. :  86%|████████▌ | 86/100 [00:21<00:02,  5.01it/s]Train Iter: 1187/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0887. T_Loss: 4.6517. Mask: 0.9080. :  86%|████████▌ | 86/100 [00:21<00:02,  5.01it/s]Train Iter: 1187/5000. LR: 0.0490. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0887. T_Loss: 4.6517. Mask: 0.9080. :  87%|████████▋ | 87/100 [00:21<00:02,  5.42it/s]Train Iter: 1188/5000. LR: 0.0490. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0967. T_Loss: 4.6608. Mask: 0.9073. :  87%|████████▋ | 87/100 [00:21<00:02,  5.42it/s]Train Iter: 1188/5000. LR: 0.0490. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0967. T_Loss: 4.6608. Mask: 0.9073. :  88%|████████▊ | 88/100 [00:21<00:02,  5.97it/s]Train Iter: 1189/5000. LR: 0.0489. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1026. T_Loss: 4.6666. Mask: 0.9073. :  88%|████████▊ | 88/100 [00:22<00:02,  5.97it/s]Train Iter: 1189/5000. LR: 0.0489. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1026. T_Loss: 4.6666. Mask: 0.9073. :  89%|████████▉ | 89/100 [00:22<00:02,  4.09it/s]Train Iter: 1190/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1087. T_Loss: 4.6638. Mask: 0.9076. :  89%|████████▉ | 89/100 [00:22<00:02,  4.09it/s]Train Iter: 1190/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1087. T_Loss: 4.6638. Mask: 0.9076. :  90%|█████████ | 90/100 [00:22<00:02,  4.67it/s]Train Iter: 1191/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1123. T_Loss: 4.6540. Mask: 0.9076. :  90%|█████████ | 90/100 [00:22<00:02,  4.67it/s]Train Iter: 1191/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1123. T_Loss: 4.6540. Mask: 0.9076. :  91%|█████████ | 91/100 [00:22<00:01,  5.30it/s]Train Iter: 1192/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1151. T_Loss: 4.6451. Mask: 0.9069. :  91%|█████████ | 91/100 [00:22<00:01,  5.30it/s]Train Iter: 1192/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1151. T_Loss: 4.6451. Mask: 0.9069. :  92%|█████████▏| 92/100 [00:22<00:01,  5.91it/s]Train Iter: 1193/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1171. T_Loss: 4.6333. Mask: 0.9069. :  92%|█████████▏| 92/100 [00:22<00:01,  5.91it/s]Train Iter: 1193/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1171. T_Loss: 4.6333. Mask: 0.9069. :  93%|█████████▎| 93/100 [00:22<00:01,  6.18it/s]Train Iter: 1194/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1176. T_Loss: 4.6121. Mask: 0.9066. :  93%|█████████▎| 93/100 [00:22<00:01,  6.18it/s]Train Iter: 1194/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1176. T_Loss: 4.6121. Mask: 0.9066. :  94%|█████████▍| 94/100 [00:22<00:00,  6.53it/s]Train Iter: 1195/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1175. T_Loss: 4.6046. Mask: 0.9072. :  94%|█████████▍| 94/100 [00:22<00:00,  6.53it/s]Train Iter: 1195/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1175. T_Loss: 4.6046. Mask: 0.9072. :  95%|█████████▌| 95/100 [00:22<00:00,  6.84it/s]Train Iter: 1196/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1173. T_Loss: 4.5987. Mask: 0.9069. :  95%|█████████▌| 95/100 [00:22<00:00,  6.84it/s]Train Iter: 1196/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1173. T_Loss: 4.5987. Mask: 0.9069. :  96%|█████████▌| 96/100 [00:22<00:00,  7.01it/s]Train Iter: 1197/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1169. T_Loss: 4.5916. Mask: 0.9062. :  96%|█████████▌| 96/100 [00:23<00:00,  7.01it/s]Train Iter: 1197/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1169. T_Loss: 4.5916. Mask: 0.9062. :  97%|█████████▋| 97/100 [00:23<00:00,  7.29it/s]Train Iter: 1198/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1168. T_Loss: 4.5815. Mask: 0.9069. :  97%|█████████▋| 97/100 [00:23<00:00,  7.29it/s]Train Iter: 1198/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1168. T_Loss: 4.5815. Mask: 0.9069. :  98%|█████████▊| 98/100 [00:23<00:00,  7.45it/s]Train Iter: 1199/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1158. T_Loss: 4.5761. Mask: 0.9075. :  98%|█████████▊| 98/100 [00:23<00:00,  7.45it/s]Train Iter: 1199/5000. LR: 0.0489. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1158. T_Loss: 4.5761. Mask: 0.9075. :  99%|█████████▉| 99/100 [00:23<00:00,  5.60it/s]Train Iter: 1200/5000. LR: 0.0489. Data: 0.09s. Batch: 0.23s. S_Loss: 1.1168. T_Loss: 4.5899. Mask: 0.9081. :  99%|█████████▉| 99/100 [00:23<00:00,  5.60it/s]Train Iter: 1200/5000. LR: 0.0489. Data: 0.09s. Batch: 0.23s. S_Loss: 1.1168. T_Loss: 4.5899. Mask: 0.9081. : 100%|██████████| 100/100 [00:23<00:00,  6.07it/s]Train Iter: 1200/5000. LR: 0.0489. Data: 0.09s. Batch: 0.23s. S_Loss: 1.1168. T_Loss: 4.5899. Mask: 0.9081. : 100%|██████████| 100/100 [00:23<00:00,  4.23it/s]
total : 5000  current step :  1176
total : 5000  current step :  1177
total : 5000  current step :  1178
total : 5000  current step :  1179
total : 5000  current step :  1180
total : 5000  current step :  1181
total : 5000  current step :  1182
total : 5000  current step :  1183
total : 5000  current step :  1184
total : 5000  current step :  1185
total : 5000  current step :  1186
total : 5000  current step :  1187
total : 5000  current step :  1188
total : 5000  current step :  1189
total : 5000  current step :  1190
total : 5000  current step :  1191
total : 5000  current step :  1192
total : 5000  current step :  1193
total : 5000  current step :  1194
total : 5000  current step :  1195
total : 5000  current step :  1196
total : 5000  current step :  1197
total : 5000  current step :  1198
total : 5000  current step :  1199
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 1.6571. top1: 40.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 1.6571. top1: 40.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.83s. Loss: 1.5922. top1: 46.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 1.4796. top1: 53.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 1.5035. top1: 53.91. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 1.4788. top1: 55.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 1.4806. top1: 53.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.4815. top1: 54.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.5090. top1: 53.52. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.4925. top1: 54.17. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.4925. top1: 54.17. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.5138. top1: 53.75. top5: 99.69. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.4889. top1: 54.83. top5: 99.72. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.4929. top1: 53.65. top5: 99.74. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.4811. top1: 53.61. top5: 99.76. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4876. top1: 53.35. top5: 99.78. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4704. top1: 55.00. top5: 99.79. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4704. top1: 55.00. top5: 99.79. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4654. top1: 55.66. top5: 99.80. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4622. top1: 55.51. top5: 99.82. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4643. top1: 54.86. top5: 99.83. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4617. top1: 55.10. top5: 99.67. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4589. top1: 55.78. top5: 99.69. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4748. top1: 54.61. top5: 99.55. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4692. top1: 54.69. top5: 99.57. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4619. top1: 55.16. top5: 99.59. :  24%|██▍       | 15/63 [00:01<00:03, 12.26it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4619. top1: 55.16. top5: 99.59. :  37%|███▋      | 23/63 [00:01<00:01, 20.43it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4562. top1: 55.47. top5: 99.61. :  37%|███▋      | 23/63 [00:01<00:01, 20.43it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4552. top1: 55.38. top5: 99.62. :  37%|███▋      | 23/63 [00:01<00:01, 20.43it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4638. top1: 54.93. top5: 99.64. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4592. top1: 55.09. top5: 99.65. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4659. top1: 55.02. top5: 99.55. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4629. top1: 55.28. top5: 99.57. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4606. top1: 55.21. top5: 99.58. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4616. top1: 54.94. top5: 99.60. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4532. top1: 55.47. top5: 99.61. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4342. top1: 56.63. top5: 99.62. :  37%|███▋      | 23/63 [00:02<00:01, 20.43it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4342. top1: 56.63. top5: 99.62. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4213. top1: 57.44. top5: 99.63. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.4053. top1: 58.39. top5: 99.64. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3977. top1: 58.85. top5: 99.65. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3825. top1: 59.80. top5: 99.66. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3680. top1: 60.69. top5: 99.67. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3621. top1: 61.14. top5: 99.60. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3499. top1: 61.95. top5: 99.61. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3388. top1: 62.58. top5: 99.62. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3285. top1: 63.17. top5: 99.63. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3177. top1: 63.81. top5: 99.64. :  52%|█████▏    | 33/63 [00:02<00:00, 31.94it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3177. top1: 63.81. top5: 99.64. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.3067. top1: 64.49. top5: 99.64. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2956. top1: 65.21. top5: 99.65. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2862. top1: 65.83. top5: 99.66. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2786. top1: 66.29. top5: 99.67. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2694. top1: 66.86. top5: 99.67. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2618. top1: 67.28. top5: 99.68. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2553. top1: 67.75. top5: 99.69. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2512. top1: 68.08. top5: 99.69. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2443. top1: 68.51. top5: 99.70. :  68%|██████▊   | 43/63 [00:02<00:00, 43.67it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2443. top1: 68.51. top5: 99.70. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2393. top1: 68.93. top5: 99.71. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2323. top1: 69.39. top5: 99.71. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2260. top1: 69.83. top5: 99.72. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2197. top1: 70.20. top5: 99.72. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2159. top1: 70.39. top5: 99.73. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2106. top1: 70.69. top5: 99.73. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2065. top1: 70.97. top5: 99.74. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.2003. top1: 71.35. top5: 99.74. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1975. top1: 71.57. top5: 99.74. :  83%|████████▎ | 52/63 [00:02<00:00, 52.56it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1975. top1: 71.57. top5: 99.74. :  97%|█████████▋| 61/63 [00:02<00:00, 55.22it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1962. top1: 71.47. top5: 99.75. :  97%|█████████▋| 61/63 [00:02<00:00, 55.22it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1940. top1: 71.65. top5: 99.75. :  97%|█████████▋| 61/63 [00:02<00:00, 55.22it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1940. top1: 71.65. top5: 99.75. : 100%|██████████| 63/63 [00:02<00:00, 23.57it/s]
total : 5000  current step :  1200
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1201/5000. LR: 0.0489. Data: 2.23s. Batch: 2.35s. S_Loss: 1.2949. T_Loss: 4.0520. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1201/5000. LR: 0.0489. Data: 2.23s. Batch: 2.35s. S_Loss: 1.2949. T_Loss: 4.0520. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:53,  2.35s/it]Train Iter: 1202/5000. LR: 0.0489. Data: 1.12s. Batch: 1.24s. S_Loss: 1.3399. T_Loss: 4.6291. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:53,  2.35s/it]Train Iter: 1202/5000. LR: 0.0489. Data: 1.12s. Batch: 1.24s. S_Loss: 1.3399. T_Loss: 4.6291. Mask: 0.9688. :   2%|▏         | 2/100 [00:02<01:42,  1.04s/it]Train Iter: 1203/5000. LR: 0.0489. Data: 0.75s. Batch: 0.87s. S_Loss: 1.3219. T_Loss: 4.4581. Mask: 0.9688. :   2%|▏         | 2/100 [00:02<01:42,  1.04s/it]Train Iter: 1203/5000. LR: 0.0489. Data: 0.75s. Batch: 0.87s. S_Loss: 1.3219. T_Loss: 4.4581. Mask: 0.9688. :   3%|▎         | 3/100 [00:02<01:01,  1.58it/s]Train Iter: 1204/5000. LR: 0.0489. Data: 0.56s. Batch: 0.69s. S_Loss: 1.3722. T_Loss: 4.5065. Mask: 0.9453. :   3%|▎         | 3/100 [00:02<01:01,  1.58it/s]Train Iter: 1204/5000. LR: 0.0489. Data: 0.56s. Batch: 0.69s. S_Loss: 1.3722. T_Loss: 4.5065. Mask: 0.9453. :   4%|▍         | 4/100 [00:02<00:41,  2.30it/s]Train Iter: 1205/5000. LR: 0.0489. Data: 0.45s. Batch: 0.60s. S_Loss: 1.4315. T_Loss: 4.6287. Mask: 0.9500. :   4%|▍         | 4/100 [00:03<00:41,  2.30it/s]Train Iter: 1205/5000. LR: 0.0489. Data: 0.45s. Batch: 0.60s. S_Loss: 1.4315. T_Loss: 4.6287. Mask: 0.9500. :   5%|▌         | 5/100 [00:03<00:35,  2.68it/s]Train Iter: 1206/5000. LR: 0.0489. Data: 0.38s. Batch: 0.52s. S_Loss: 1.4548. T_Loss: 4.6013. Mask: 0.9531. :   5%|▌         | 5/100 [00:03<00:35,  2.68it/s]Train Iter: 1206/5000. LR: 0.0489. Data: 0.38s. Batch: 0.52s. S_Loss: 1.4548. T_Loss: 4.6013. Mask: 0.9531. :   6%|▌         | 6/100 [00:03<00:27,  3.43it/s]Train Iter: 1207/5000. LR: 0.0489. Data: 0.32s. Batch: 0.47s. S_Loss: 1.4749. T_Loss: 4.5251. Mask: 0.9464. :   6%|▌         | 6/100 [00:03<00:27,  3.43it/s]Train Iter: 1207/5000. LR: 0.0489. Data: 0.32s. Batch: 0.47s. S_Loss: 1.4749. T_Loss: 4.5251. Mask: 0.9464. :   7%|▋         | 7/100 [00:03<00:21,  4.28it/s]Train Iter: 1208/5000. LR: 0.0488. Data: 0.28s. Batch: 0.42s. S_Loss: 1.4884. T_Loss: 4.4653. Mask: 0.9453. :   7%|▋         | 7/100 [00:03<00:21,  4.28it/s]Train Iter: 1208/5000. LR: 0.0488. Data: 0.28s. Batch: 0.42s. S_Loss: 1.4884. T_Loss: 4.4653. Mask: 0.9453. :   8%|▊         | 8/100 [00:03<00:18,  5.01it/s]Train Iter: 1209/5000. LR: 0.0488. Data: 0.25s. Batch: 0.42s. S_Loss: 1.4849. T_Loss: 4.4267. Mask: 0.9375. :   8%|▊         | 8/100 [00:03<00:18,  5.01it/s]Train Iter: 1209/5000. LR: 0.0488. Data: 0.25s. Batch: 0.42s. S_Loss: 1.4849. T_Loss: 4.4267. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:22,  3.97it/s]Train Iter: 1210/5000. LR: 0.0488. Data: 0.23s. Batch: 0.39s. S_Loss: 1.4822. T_Loss: 4.3845. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:22,  3.97it/s]Train Iter: 1210/5000. LR: 0.0488. Data: 0.23s. Batch: 0.39s. S_Loss: 1.4822. T_Loss: 4.3845. Mask: 0.9375. :  10%|█         | 10/100 [00:03<00:19,  4.66it/s]Train Iter: 1211/5000. LR: 0.0488. Data: 0.21s. Batch: 0.36s. S_Loss: 1.4723. T_Loss: 4.3310. Mask: 0.9375. :  10%|█         | 10/100 [00:04<00:19,  4.66it/s]Train Iter: 1211/5000. LR: 0.0488. Data: 0.21s. Batch: 0.36s. S_Loss: 1.4723. T_Loss: 4.3310. Mask: 0.9375. :  11%|█         | 11/100 [00:04<00:16,  5.30it/s]Train Iter: 1212/5000. LR: 0.0488. Data: 0.19s. Batch: 0.35s. S_Loss: 1.4546. T_Loss: 4.3624. Mask: 0.9375. :  11%|█         | 11/100 [00:04<00:16,  5.30it/s]Train Iter: 1212/5000. LR: 0.0488. Data: 0.19s. Batch: 0.35s. S_Loss: 1.4546. T_Loss: 4.3624. Mask: 0.9375. :  12%|█▏        | 12/100 [00:04<00:15,  5.64it/s]Train Iter: 1213/5000. LR: 0.0488. Data: 0.18s. Batch: 0.33s. S_Loss: 1.4468. T_Loss: 4.4260. Mask: 0.9351. :  12%|█▏        | 12/100 [00:04<00:15,  5.64it/s]Train Iter: 1213/5000. LR: 0.0488. Data: 0.18s. Batch: 0.33s. S_Loss: 1.4468. T_Loss: 4.4260. Mask: 0.9351. :  13%|█▎        | 13/100 [00:04<00:14,  6.11it/s]Train Iter: 1214/5000. LR: 0.0488. Data: 0.16s. Batch: 0.31s. S_Loss: 1.4324. T_Loss: 4.4290. Mask: 0.9330. :  13%|█▎        | 13/100 [00:04<00:14,  6.11it/s]Train Iter: 1214/5000. LR: 0.0488. Data: 0.16s. Batch: 0.31s. S_Loss: 1.4324. T_Loss: 4.4290. Mask: 0.9330. :  14%|█▍        | 14/100 [00:04<00:12,  6.65it/s]Train Iter: 1215/5000. LR: 0.0488. Data: 0.15s. Batch: 0.30s. S_Loss: 1.4160. T_Loss: 4.3672. Mask: 0.9292. :  14%|█▍        | 14/100 [00:04<00:12,  6.65it/s]Train Iter: 1215/5000. LR: 0.0488. Data: 0.15s. Batch: 0.30s. S_Loss: 1.4160. T_Loss: 4.3672. Mask: 0.9292. :  15%|█▌        | 15/100 [00:04<00:12,  6.95it/s]Train Iter: 1216/5000. LR: 0.0488. Data: 0.14s. Batch: 0.29s. S_Loss: 1.4015. T_Loss: 4.3501. Mask: 0.9258. :  15%|█▌        | 15/100 [00:04<00:12,  6.95it/s]Train Iter: 1216/5000. LR: 0.0488. Data: 0.14s. Batch: 0.29s. S_Loss: 1.4015. T_Loss: 4.3501. Mask: 0.9258. :  16%|█▌        | 16/100 [00:04<00:11,  7.22it/s]Train Iter: 1217/5000. LR: 0.0488. Data: 0.14s. Batch: 0.28s. S_Loss: 1.3892. T_Loss: 4.3490. Mask: 0.9283. :  16%|█▌        | 16/100 [00:04<00:11,  7.22it/s]Train Iter: 1217/5000. LR: 0.0488. Data: 0.14s. Batch: 0.28s. S_Loss: 1.3892. T_Loss: 4.3490. Mask: 0.9283. :  17%|█▋        | 17/100 [00:04<00:11,  7.29it/s]Train Iter: 1218/5000. LR: 0.0488. Data: 0.13s. Batch: 0.27s. S_Loss: 1.3794. T_Loss: 4.3876. Mask: 0.9271. :  17%|█▋        | 17/100 [00:04<00:11,  7.29it/s]Train Iter: 1218/5000. LR: 0.0488. Data: 0.13s. Batch: 0.27s. S_Loss: 1.3794. T_Loss: 4.3876. Mask: 0.9271. :  18%|█▊        | 18/100 [00:04<00:11,  7.45it/s]Train Iter: 1219/5000. LR: 0.0488. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3684. T_Loss: 4.3706. Mask: 0.9243. :  18%|█▊        | 18/100 [00:05<00:11,  7.45it/s]Train Iter: 1219/5000. LR: 0.0488. Data: 0.12s. Batch: 0.28s. S_Loss: 1.3684. T_Loss: 4.3706. Mask: 0.9243. :  19%|█▉        | 19/100 [00:05<00:17,  4.72it/s]Train Iter: 1220/5000. LR: 0.0488. Data: 0.12s. Batch: 0.27s. S_Loss: 1.3574. T_Loss: 4.4085. Mask: 0.9250. :  19%|█▉        | 19/100 [00:05<00:17,  4.72it/s]Train Iter: 1220/5000. LR: 0.0488. Data: 0.12s. Batch: 0.27s. S_Loss: 1.3574. T_Loss: 4.4085. Mask: 0.9250. :  20%|██        | 20/100 [00:05<00:14,  5.34it/s]Train Iter: 1221/5000. LR: 0.0488. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3446. T_Loss: 4.4327. Mask: 0.9271. :  20%|██        | 20/100 [00:05<00:14,  5.34it/s]Train Iter: 1221/5000. LR: 0.0488. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3446. T_Loss: 4.4327. Mask: 0.9271. :  21%|██        | 21/100 [00:05<00:13,  5.95it/s]Train Iter: 1222/5000. LR: 0.0488. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3402. T_Loss: 4.4093. Mask: 0.9247. :  21%|██        | 21/100 [00:05<00:13,  5.95it/s]Train Iter: 1222/5000. LR: 0.0488. Data: 0.11s. Batch: 0.26s. S_Loss: 1.3402. T_Loss: 4.4093. Mask: 0.9247. :  22%|██▏       | 22/100 [00:05<00:11,  6.51it/s]Train Iter: 1223/5000. LR: 0.0488. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3338. T_Loss: 4.4246. Mask: 0.9239. :  22%|██▏       | 22/100 [00:05<00:11,  6.51it/s]Train Iter: 1223/5000. LR: 0.0488. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3338. T_Loss: 4.4246. Mask: 0.9239. :  23%|██▎       | 23/100 [00:05<00:11,  6.78it/s]Train Iter: 1224/5000. LR: 0.0488. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3289. T_Loss: 4.4462. Mask: 0.9245. :  23%|██▎       | 23/100 [00:05<00:11,  6.78it/s]Train Iter: 1224/5000. LR: 0.0488. Data: 0.10s. Batch: 0.25s. S_Loss: 1.3289. T_Loss: 4.4462. Mask: 0.9245. :  24%|██▍       | 24/100 [00:05<00:10,  7.02it/s]Train Iter: 1225/5000. LR: 0.0487. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3203. T_Loss: 4.4667. Mask: 0.9250. :  24%|██▍       | 24/100 [00:06<00:10,  7.02it/s]Train Iter: 1225/5000. LR: 0.0487. Data: 0.09s. Batch: 0.25s. S_Loss: 1.3203. T_Loss: 4.4667. Mask: 0.9250. :  25%|██▌       | 25/100 [00:06<00:15,  4.73it/s]total : 5000  current step :  1201
total : 5000  current step :  1202
total : 5000  current step :  1203
total : 5000  current step :  1204
total : 5000  current step :  1205
total : 5000  current step :  1206
total : 5000  current step :  1207
total : 5000  current step :  1208
total : 5000  current step :  1209
total : 5000  current step :  1210
total : 5000  current step :  1211
total : 5000  current step :  1212
total : 5000  current step :  1213
total : 5000  current step :  1214
total : 5000  current step :  1215
total : 5000  current step :  1216
total : 5000  current step :  1217
total : 5000  current step :  1218
total : 5000  current step :  1219
total : 5000  current step :  1220
total : 5000  current step :  1221
total : 5000  current step :  1222
total : 5000  current step :  1223
total : 5000  current step :  1224
total : 5000  current step :  1225
Train Iter: 1226/5000. LR: 0.0487. Data: 0.17s. Batch: 0.32s. S_Loss: 1.3132. T_Loss: 4.4418. Mask: 0.9207. :  25%|██▌       | 25/100 [00:08<00:15,  4.73it/s]Train Iter: 1226/5000. LR: 0.0487. Data: 0.17s. Batch: 0.32s. S_Loss: 1.3132. T_Loss: 4.4418. Mask: 0.9207. :  26%|██▌       | 26/100 [00:08<00:57,  1.28it/s]Train Iter: 1227/5000. LR: 0.0487. Data: 0.16s. Batch: 0.32s. S_Loss: 1.3074. T_Loss: 4.4586. Mask: 0.9190. :  26%|██▌       | 26/100 [00:08<00:57,  1.28it/s]Train Iter: 1227/5000. LR: 0.0487. Data: 0.16s. Batch: 0.32s. S_Loss: 1.3074. T_Loss: 4.4586. Mask: 0.9190. :  27%|██▋       | 27/100 [00:08<00:43,  1.70it/s]Train Iter: 1228/5000. LR: 0.0487. Data: 0.15s. Batch: 0.31s. S_Loss: 1.2986. T_Loss: 4.4710. Mask: 0.9196. :  27%|██▋       | 27/100 [00:08<00:43,  1.70it/s]Train Iter: 1228/5000. LR: 0.0487. Data: 0.15s. Batch: 0.31s. S_Loss: 1.2986. T_Loss: 4.4710. Mask: 0.9196. :  28%|██▊       | 28/100 [00:08<00:32,  2.24it/s]Train Iter: 1229/5000. LR: 0.0487. Data: 0.15s. Batch: 0.31s. S_Loss: 1.2906. T_Loss: 4.4682. Mask: 0.9213. :  28%|██▊       | 28/100 [00:09<00:32,  2.24it/s]Train Iter: 1229/5000. LR: 0.0487. Data: 0.15s. Batch: 0.31s. S_Loss: 1.2906. T_Loss: 4.4682. Mask: 0.9213. :  29%|██▉       | 29/100 [00:09<00:29,  2.42it/s]Train Iter: 1230/5000. LR: 0.0487. Data: 0.14s. Batch: 0.30s. S_Loss: 1.2841. T_Loss: 4.4767. Mask: 0.9229. :  29%|██▉       | 29/100 [00:09<00:29,  2.42it/s]Train Iter: 1230/5000. LR: 0.0487. Data: 0.14s. Batch: 0.30s. S_Loss: 1.2841. T_Loss: 4.4767. Mask: 0.9229. :  30%|███       | 30/100 [00:09<00:22,  3.05it/s]Train Iter: 1231/5000. LR: 0.0487. Data: 0.14s. Batch: 0.30s. S_Loss: 1.2786. T_Loss: 4.4754. Mask: 0.9214. :  30%|███       | 30/100 [00:09<00:22,  3.05it/s]Train Iter: 1231/5000. LR: 0.0487. Data: 0.14s. Batch: 0.30s. S_Loss: 1.2786. T_Loss: 4.4754. Mask: 0.9214. :  31%|███       | 31/100 [00:09<00:18,  3.71it/s]Train Iter: 1232/5000. LR: 0.0487. Data: 0.14s. Batch: 0.29s. S_Loss: 1.2734. T_Loss: 4.4727. Mask: 0.9199. :  31%|███       | 31/100 [00:09<00:18,  3.71it/s]Train Iter: 1232/5000. LR: 0.0487. Data: 0.14s. Batch: 0.29s. S_Loss: 1.2734. T_Loss: 4.4727. Mask: 0.9199. :  32%|███▏      | 32/100 [00:09<00:15,  4.40it/s]Train Iter: 1233/5000. LR: 0.0487. Data: 0.13s. Batch: 0.29s. S_Loss: 1.2699. T_Loss: 4.4937. Mask: 0.9167. :  32%|███▏      | 32/100 [00:09<00:15,  4.40it/s]Train Iter: 1233/5000. LR: 0.0487. Data: 0.13s. Batch: 0.29s. S_Loss: 1.2699. T_Loss: 4.4937. Mask: 0.9167. :  33%|███▎      | 33/100 [00:09<00:13,  4.93it/s]Train Iter: 1234/5000. LR: 0.0487. Data: 0.13s. Batch: 0.28s. S_Loss: 1.2639. T_Loss: 4.4938. Mask: 0.9173. :  33%|███▎      | 33/100 [00:09<00:13,  4.93it/s]Train Iter: 1234/5000. LR: 0.0487. Data: 0.13s. Batch: 0.28s. S_Loss: 1.2639. T_Loss: 4.4938. Mask: 0.9173. :  34%|███▍      | 34/100 [00:09<00:11,  5.62it/s]Train Iter: 1235/5000. LR: 0.0487. Data: 0.12s. Batch: 0.29s. S_Loss: 1.2575. T_Loss: 4.4937. Mask: 0.9187. :  34%|███▍      | 34/100 [00:10<00:11,  5.62it/s]Train Iter: 1235/5000. LR: 0.0487. Data: 0.12s. Batch: 0.29s. S_Loss: 1.2575. T_Loss: 4.4937. Mask: 0.9187. :  35%|███▌      | 35/100 [00:10<00:15,  4.25it/s]Train Iter: 1236/5000. LR: 0.0487. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2558. T_Loss: 4.4943. Mask: 0.9201. :  35%|███▌      | 35/100 [00:10<00:15,  4.25it/s]Train Iter: 1236/5000. LR: 0.0487. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2558. T_Loss: 4.4943. Mask: 0.9201. :  36%|███▌      | 36/100 [00:10<00:12,  5.01it/s]Train Iter: 1237/5000. LR: 0.0487. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2491. T_Loss: 4.4968. Mask: 0.9206. :  36%|███▌      | 36/100 [00:10<00:12,  5.01it/s]Train Iter: 1237/5000. LR: 0.0487. Data: 0.12s. Batch: 0.28s. S_Loss: 1.2491. T_Loss: 4.4968. Mask: 0.9206. :  37%|███▋      | 37/100 [00:10<00:11,  5.61it/s]Train Iter: 1238/5000. LR: 0.0487. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2428. T_Loss: 4.4690. Mask: 0.9194. :  37%|███▋      | 37/100 [00:10<00:11,  5.61it/s]Train Iter: 1238/5000. LR: 0.0487. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2428. T_Loss: 4.4690. Mask: 0.9194. :  38%|███▊      | 38/100 [00:10<00:09,  6.21it/s]Train Iter: 1239/5000. LR: 0.0487. Data: 0.11s. Batch: 0.28s. S_Loss: 1.2382. T_Loss: 4.4679. Mask: 0.9215. :  38%|███▊      | 38/100 [00:10<00:09,  6.21it/s]Train Iter: 1239/5000. LR: 0.0487. Data: 0.11s. Batch: 0.28s. S_Loss: 1.2382. T_Loss: 4.4679. Mask: 0.9215. :  39%|███▉      | 39/100 [00:10<00:13,  4.38it/s]Train Iter: 1240/5000. LR: 0.0487. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2328. T_Loss: 4.4745. Mask: 0.9227. :  39%|███▉      | 39/100 [00:10<00:13,  4.38it/s]Train Iter: 1240/5000. LR: 0.0487. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2328. T_Loss: 4.4745. Mask: 0.9227. :  40%|████      | 40/100 [00:10<00:11,  5.03it/s]Train Iter: 1241/5000. LR: 0.0487. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2302. T_Loss: 4.5003. Mask: 0.9215. :  40%|████      | 40/100 [00:11<00:11,  5.03it/s]Train Iter: 1241/5000. LR: 0.0487. Data: 0.11s. Batch: 0.27s. S_Loss: 1.2302. T_Loss: 4.5003. Mask: 0.9215. :  41%|████      | 41/100 [00:11<00:10,  5.46it/s]Train Iter: 1242/5000. LR: 0.0486. Data: 0.10s. Batch: 0.27s. S_Loss: 1.2241. T_Loss: 4.4905. Mask: 0.9226. :  41%|████      | 41/100 [00:11<00:10,  5.46it/s]Train Iter: 1242/5000. LR: 0.0486. Data: 0.10s. Batch: 0.27s. S_Loss: 1.2241. T_Loss: 4.4905. Mask: 0.9226. :  42%|████▏     | 42/100 [00:11<00:09,  6.02it/s]Train Iter: 1243/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2217. T_Loss: 4.4886. Mask: 0.9215. :  42%|████▏     | 42/100 [00:11<00:09,  6.02it/s]Train Iter: 1243/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2217. T_Loss: 4.4886. Mask: 0.9215. :  43%|████▎     | 43/100 [00:11<00:08,  6.52it/s]Train Iter: 1244/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2185. T_Loss: 4.4915. Mask: 0.9226. :  43%|████▎     | 43/100 [00:11<00:08,  6.52it/s]Train Iter: 1244/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2185. T_Loss: 4.4915. Mask: 0.9226. :  44%|████▍     | 44/100 [00:11<00:08,  6.87it/s]Train Iter: 1245/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2141. T_Loss: 4.5357. Mask: 0.9236. :  44%|████▍     | 44/100 [00:11<00:08,  6.87it/s]Train Iter: 1245/5000. LR: 0.0486. Data: 0.10s. Batch: 0.26s. S_Loss: 1.2141. T_Loss: 4.5357. Mask: 0.9236. :  45%|████▌     | 45/100 [00:11<00:07,  6.98it/s]Train Iter: 1246/5000. LR: 0.0486. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2125. T_Loss: 4.5378. Mask: 0.9246. :  45%|████▌     | 45/100 [00:11<00:07,  6.98it/s]Train Iter: 1246/5000. LR: 0.0486. Data: 0.10s. Batch: 0.25s. S_Loss: 1.2125. T_Loss: 4.5378. Mask: 0.9246. :  46%|████▌     | 46/100 [00:11<00:07,  7.49it/s]Train Iter: 1247/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2085. T_Loss: 4.5375. Mask: 0.9249. :  46%|████▌     | 46/100 [00:11<00:07,  7.49it/s]Train Iter: 1247/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2085. T_Loss: 4.5375. Mask: 0.9249. :  47%|████▋     | 47/100 [00:11<00:06,  7.67it/s]Train Iter: 1248/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2067. T_Loss: 4.5478. Mask: 0.9258. :  47%|████▋     | 47/100 [00:11<00:06,  7.67it/s]Train Iter: 1248/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2067. T_Loss: 4.5478. Mask: 0.9258. :  48%|████▊     | 48/100 [00:11<00:06,  7.86it/s]Train Iter: 1249/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2041. T_Loss: 4.5495. Mask: 0.9260. :  48%|████▊     | 48/100 [00:12<00:06,  7.86it/s]Train Iter: 1249/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2041. T_Loss: 4.5495. Mask: 0.9260. :  49%|████▉     | 49/100 [00:12<00:09,  5.12it/s]Train Iter: 1250/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2020. T_Loss: 4.5443. Mask: 0.9250. :  49%|████▉     | 49/100 [00:12<00:09,  5.12it/s]Train Iter: 1250/5000. LR: 0.0486. Data: 0.09s. Batch: 0.25s. S_Loss: 1.2020. T_Loss: 4.5443. Mask: 0.9250. :  50%|█████     | 50/100 [00:12<00:08,  5.76it/s]total : 5000  current step :  1226
total : 5000  current step :  1227
total : 5000  current step :  1228
total : 5000  current step :  1229
total : 5000  current step :  1230
total : 5000  current step :  1231
total : 5000  current step :  1232
total : 5000  current step :  1233
total : 5000  current step :  1234
total : 5000  current step :  1235
total : 5000  current step :  1236
total : 5000  current step :  1237
total : 5000  current step :  1238
total : 5000  current step :  1239
total : 5000  current step :  1240
total : 5000  current step :  1241
total : 5000  current step :  1242
total : 5000  current step :  1243
total : 5000  current step :  1244
total : 5000  current step :  1245
total : 5000  current step :  1246
total : 5000  current step :  1247
total : 5000  current step :  1248
total : 5000  current step :  1249
total : 5000  current step :  1250
Train Iter: 1251/5000. LR: 0.0486. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1994. T_Loss: 4.5356. Mask: 0.9259. :  50%|█████     | 50/100 [00:14<00:08,  5.76it/s]Train Iter: 1251/5000. LR: 0.0486. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1994. T_Loss: 4.5356. Mask: 0.9259. :  51%|█████     | 51/100 [00:14<00:36,  1.33it/s]total : 5000  current step :  1251
Train Iter: 1252/5000. LR: 0.0486. Data: 0.16s. Batch: 0.32s. S_Loss: 1.1960. T_Loss: 4.5260. Mask: 0.9273. :  51%|█████     | 51/100 [00:16<00:36,  1.33it/s]Train Iter: 1252/5000. LR: 0.0486. Data: 0.16s. Batch: 0.32s. S_Loss: 1.1960. T_Loss: 4.5260. Mask: 0.9273. :  52%|█████▏    | 52/100 [00:16<00:53,  1.11s/it]Train Iter: 1253/5000. LR: 0.0486. Data: 0.16s. Batch: 0.31s. S_Loss: 1.1937. T_Loss: 4.5281. Mask: 0.9287. :  52%|█████▏    | 52/100 [00:16<00:53,  1.11s/it]Train Iter: 1253/5000. LR: 0.0486. Data: 0.16s. Batch: 0.31s. S_Loss: 1.1937. T_Loss: 4.5281. Mask: 0.9287. :  53%|█████▎    | 53/100 [00:16<00:37,  1.24it/s]Train Iter: 1254/5000. LR: 0.0486. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1903. T_Loss: 4.5255. Mask: 0.9294. :  53%|█████▎    | 53/100 [00:16<00:37,  1.24it/s]Train Iter: 1254/5000. LR: 0.0486. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1903. T_Loss: 4.5255. Mask: 0.9294. :  54%|█████▍    | 54/100 [00:16<00:27,  1.65it/s]Train Iter: 1255/5000. LR: 0.0486. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1889. T_Loss: 4.5240. Mask: 0.9301. :  54%|█████▍    | 54/100 [00:17<00:27,  1.65it/s]Train Iter: 1255/5000. LR: 0.0486. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1889. T_Loss: 4.5240. Mask: 0.9301. :  55%|█████▌    | 55/100 [00:17<00:23,  1.94it/s]Train Iter: 1256/5000. LR: 0.0486. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1869. T_Loss: 4.5328. Mask: 0.9308. :  55%|█████▌    | 55/100 [00:17<00:23,  1.94it/s]Train Iter: 1256/5000. LR: 0.0486. Data: 0.15s. Batch: 0.31s. S_Loss: 1.1869. T_Loss: 4.5328. Mask: 0.9308. :  56%|█████▌    | 56/100 [00:17<00:17,  2.46it/s]Train Iter: 1257/5000. LR: 0.0486. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1840. T_Loss: 4.5244. Mask: 0.9304. :  56%|█████▌    | 56/100 [00:17<00:17,  2.46it/s]Train Iter: 1257/5000. LR: 0.0486. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1840. T_Loss: 4.5244. Mask: 0.9304. :  57%|█████▋    | 57/100 [00:17<00:13,  3.11it/s]Train Iter: 1258/5000. LR: 0.0485. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1794. T_Loss: 4.5021. Mask: 0.9310. :  57%|█████▋    | 57/100 [00:17<00:13,  3.11it/s]Train Iter: 1258/5000. LR: 0.0485. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1794. T_Loss: 4.5021. Mask: 0.9310. :  58%|█████▊    | 58/100 [00:17<00:11,  3.79it/s]Train Iter: 1259/5000. LR: 0.0485. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1781. T_Loss: 4.5176. Mask: 0.9322. :  58%|█████▊    | 58/100 [00:17<00:11,  3.79it/s]Train Iter: 1259/5000. LR: 0.0485. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1781. T_Loss: 4.5176. Mask: 0.9322. :  59%|█████▉    | 59/100 [00:17<00:12,  3.34it/s]Train Iter: 1260/5000. LR: 0.0485. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1763. T_Loss: 4.5052. Mask: 0.9318. :  59%|█████▉    | 59/100 [00:17<00:12,  3.34it/s]Train Iter: 1261/5000. LR: 0.0485. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1747. T_Loss: 4.5252. Mask: 0.9324. :  60%|██████    | 60/100 [00:18<00:11,  3.34it/s]Train Iter: 1261/5000. LR: 0.0485. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1747. T_Loss: 4.5252. Mask: 0.9324. :  61%|██████    | 61/100 [00:18<00:08,  4.80it/s]Train Iter: 1262/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1715. T_Loss: 4.5134. Mask: 0.9315. :  61%|██████    | 61/100 [00:18<00:08,  4.80it/s]Train Iter: 1262/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1715. T_Loss: 4.5134. Mask: 0.9315. :  62%|██████▏   | 62/100 [00:18<00:07,  5.28it/s]Train Iter: 1263/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1703. T_Loss: 4.5145. Mask: 0.9311. :  62%|██████▏   | 62/100 [00:18<00:07,  5.28it/s]Train Iter: 1263/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1703. T_Loss: 4.5145. Mask: 0.9311. :  63%|██████▎   | 63/100 [00:18<00:06,  5.71it/s]Train Iter: 1264/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1674. T_Loss: 4.5156. Mask: 0.9307. :  63%|██████▎   | 63/100 [00:18<00:06,  5.71it/s]Train Iter: 1264/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1674. T_Loss: 4.5156. Mask: 0.9307. :  64%|██████▍   | 64/100 [00:18<00:05,  6.13it/s]Train Iter: 1265/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1653. T_Loss: 4.5366. Mask: 0.9317. :  64%|██████▍   | 64/100 [00:18<00:05,  6.13it/s]Train Iter: 1265/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1653. T_Loss: 4.5366. Mask: 0.9317. :  65%|██████▌   | 65/100 [00:18<00:07,  4.70it/s]Train Iter: 1266/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1629. T_Loss: 4.5310. Mask: 0.9313. :  65%|██████▌   | 65/100 [00:18<00:07,  4.70it/s]Train Iter: 1266/5000. LR: 0.0485. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1629. T_Loss: 4.5310. Mask: 0.9313. :  66%|██████▌   | 66/100 [00:18<00:06,  5.04it/s]Train Iter: 1267/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1629. T_Loss: 4.5263. Mask: 0.9305. :  66%|██████▌   | 66/100 [00:19<00:06,  5.04it/s]Train Iter: 1267/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1629. T_Loss: 4.5263. Mask: 0.9305. :  67%|██████▋   | 67/100 [00:19<00:05,  5.64it/s]Train Iter: 1268/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1603. T_Loss: 4.5159. Mask: 0.9288. :  67%|██████▋   | 67/100 [00:19<00:05,  5.64it/s]Train Iter: 1268/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1603. T_Loss: 4.5159. Mask: 0.9288. :  68%|██████▊   | 68/100 [00:19<00:05,  5.85it/s]Train Iter: 1269/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1581. T_Loss: 4.5031. Mask: 0.9271. :  68%|██████▊   | 68/100 [00:19<00:05,  5.85it/s]Train Iter: 1269/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1581. T_Loss: 4.5031. Mask: 0.9271. :  69%|██████▉   | 69/100 [00:19<00:06,  5.09it/s]Train Iter: 1270/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1550. T_Loss: 4.5051. Mask: 0.9268. :  69%|██████▉   | 69/100 [00:19<00:06,  5.09it/s]Train Iter: 1270/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1550. T_Loss: 4.5051. Mask: 0.9268. :  70%|███████   | 70/100 [00:19<00:05,  5.78it/s]Train Iter: 1271/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1518. T_Loss: 4.5040. Mask: 0.9265. :  70%|███████   | 70/100 [00:19<00:05,  5.78it/s]Train Iter: 1271/5000. LR: 0.0485. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1518. T_Loss: 4.5040. Mask: 0.9265. :  71%|███████   | 71/100 [00:19<00:04,  6.34it/s]Train Iter: 1272/5000. LR: 0.0485. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1495. T_Loss: 4.5089. Mask: 0.9271. :  71%|███████   | 71/100 [00:19<00:04,  6.34it/s]Train Iter: 1272/5000. LR: 0.0485. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1495. T_Loss: 4.5089. Mask: 0.9271. :  72%|███████▏  | 72/100 [00:19<00:04,  6.61it/s]Train Iter: 1273/5000. LR: 0.0485. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1476. T_Loss: 4.5043. Mask: 0.9259. :  72%|███████▏  | 72/100 [00:19<00:04,  6.61it/s]Train Iter: 1273/5000. LR: 0.0485. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1476. T_Loss: 4.5043. Mask: 0.9259. :  73%|███████▎  | 73/100 [00:19<00:03,  7.09it/s]Train Iter: 1274/5000. LR: 0.0484. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1454. T_Loss: 4.5111. Mask: 0.9253. :  73%|███████▎  | 73/100 [00:20<00:03,  7.09it/s]Train Iter: 1274/5000. LR: 0.0484. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1454. T_Loss: 4.5111. Mask: 0.9253. :  74%|███████▍  | 74/100 [00:20<00:03,  7.18it/s]Train Iter: 1275/5000. LR: 0.0484. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1440. T_Loss: 4.5164. Mask: 0.9242. :  74%|███████▍  | 74/100 [00:20<00:03,  7.18it/s]Train Iter: 1275/5000. LR: 0.0484. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1440. T_Loss: 4.5164. Mask: 0.9242. :  75%|███████▌  | 75/100 [00:20<00:04,  5.24it/s]total : 5000  current step :  1252
total : 5000  current step :  1253
total : 5000  current step :  1254
total : 5000  current step :  1255
total : 5000  current step :  1256
total : 5000  current step :  1257
total : 5000  current step :  1258
total : 5000  current step :  1259
total : 5000  current step :  1260
total : 5000  current step :  1261
total : 5000  current step :  1262
total : 5000  current step :  1263
total : 5000  current step :  1264
total : 5000  current step :  1265
total : 5000  current step :  1266
total : 5000  current step :  1267
total : 5000  current step :  1268
total : 5000  current step :  1269
total : 5000  current step :  1270
total : 5000  current step :  1271
total : 5000  current step :  1272
total : 5000  current step :  1273
total : 5000  current step :  1274
total : 5000  current step :  1275
Train Iter: 1276/5000. LR: 0.0484. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1449. T_Loss: 4.5274. Mask: 0.9235. :  75%|███████▌  | 75/100 [00:22<00:04,  5.24it/s]Train Iter: 1276/5000. LR: 0.0484. Data: 0.14s. Batch: 0.30s. S_Loss: 1.1449. T_Loss: 4.5274. Mask: 0.9235. :  76%|███████▌  | 76/100 [00:22<00:19,  1.25it/s]Train Iter: 1277/5000. LR: 0.0484. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1442. T_Loss: 4.5370. Mask: 0.9229. :  76%|███████▌  | 76/100 [00:22<00:19,  1.25it/s]Train Iter: 1277/5000. LR: 0.0484. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1442. T_Loss: 4.5370. Mask: 0.9229. :  77%|███████▋  | 77/100 [00:22<00:13,  1.67it/s]Train Iter: 1278/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1475. T_Loss: 4.5419. Mask: 0.9227. :  77%|███████▋  | 77/100 [00:22<00:13,  1.67it/s]Train Iter: 1278/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1475. T_Loss: 4.5419. Mask: 0.9227. :  78%|███████▊  | 78/100 [00:22<00:10,  2.19it/s]Train Iter: 1279/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1478. T_Loss: 4.5503. Mask: 0.9213. :  78%|███████▊  | 78/100 [00:23<00:10,  2.19it/s]Train Iter: 1279/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1478. T_Loss: 4.5503. Mask: 0.9213. :  79%|███████▉  | 79/100 [00:23<00:08,  2.46it/s]Train Iter: 1280/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1479. T_Loss: 4.5606. Mask: 0.9219. :  79%|███████▉  | 79/100 [00:23<00:08,  2.46it/s]Train Iter: 1280/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1479. T_Loss: 4.5606. Mask: 0.9219. :  80%|████████  | 80/100 [00:23<00:06,  3.11it/s]Train Iter: 1281/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1474. T_Loss: 4.5680. Mask: 0.9217. :  80%|████████  | 80/100 [00:23<00:06,  3.11it/s]Train Iter: 1281/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1474. T_Loss: 4.5680. Mask: 0.9217. :  81%|████████  | 81/100 [00:23<00:05,  3.74it/s]Train Iter: 1282/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1479. T_Loss: 4.5837. Mask: 0.9219. :  81%|████████  | 81/100 [00:23<00:05,  3.74it/s]Train Iter: 1282/5000. LR: 0.0484. Data: 0.13s. Batch: 0.29s. S_Loss: 1.1479. T_Loss: 4.5837. Mask: 0.9219. :  82%|████████▏ | 82/100 [00:23<00:03,  4.50it/s]Train Iter: 1283/5000. LR: 0.0484. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1478. T_Loss: 4.5787. Mask: 0.9209. :  82%|████████▏ | 82/100 [00:23<00:03,  4.50it/s]Train Iter: 1283/5000. LR: 0.0484. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1478. T_Loss: 4.5787. Mask: 0.9209. :  83%|████████▎ | 83/100 [00:23<00:03,  5.20it/s]Train Iter: 1284/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1454. T_Loss: 4.5796. Mask: 0.9215. :  83%|████████▎ | 83/100 [00:23<00:03,  5.20it/s]Train Iter: 1284/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1454. T_Loss: 4.5796. Mask: 0.9215. :  84%|████████▍ | 84/100 [00:23<00:02,  5.83it/s]Train Iter: 1285/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1445. T_Loss: 4.5763. Mask: 0.9213. :  84%|████████▍ | 84/100 [00:24<00:02,  5.83it/s]Train Iter: 1285/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1445. T_Loss: 4.5763. Mask: 0.9213. :  85%|████████▌ | 85/100 [00:24<00:03,  4.53it/s]Train Iter: 1286/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1436. T_Loss: 4.5861. Mask: 0.9219. :  85%|████████▌ | 85/100 [00:24<00:03,  4.53it/s]Train Iter: 1286/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1436. T_Loss: 4.5861. Mask: 0.9219. :  86%|████████▌ | 86/100 [00:24<00:02,  5.23it/s]Train Iter: 1287/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1431. T_Loss: 4.5873. Mask: 0.9213. :  86%|████████▌ | 86/100 [00:24<00:02,  5.23it/s]Train Iter: 1287/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1431. T_Loss: 4.5873. Mask: 0.9213. :  87%|████████▋ | 87/100 [00:24<00:02,  5.78it/s]Train Iter: 1288/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1420. T_Loss: 4.5891. Mask: 0.9215. :  87%|████████▋ | 87/100 [00:24<00:02,  5.78it/s]Train Iter: 1288/5000. LR: 0.0484. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1420. T_Loss: 4.5891. Mask: 0.9215. :  88%|████████▊ | 88/100 [00:24<00:01,  6.28it/s]Train Iter: 1289/5000. LR: 0.0483. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1413. T_Loss: 4.5830. Mask: 0.9213. :  88%|████████▊ | 88/100 [00:24<00:01,  6.28it/s]Train Iter: 1289/5000. LR: 0.0483. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1413. T_Loss: 4.5830. Mask: 0.9213. :  89%|████████▉ | 89/100 [00:24<00:02,  4.92it/s]Train Iter: 1290/5000. LR: 0.0483. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1400. T_Loss: 4.5722. Mask: 0.9208. :  89%|████████▉ | 89/100 [00:24<00:02,  4.92it/s]Train Iter: 1290/5000. LR: 0.0483. Data: 0.12s. Batch: 0.28s. S_Loss: 1.1400. T_Loss: 4.5722. Mask: 0.9208. :  90%|█████████ | 90/100 [00:24<00:01,  5.56it/s]Train Iter: 1291/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1405. T_Loss: 4.5861. Mask: 0.9217. :  90%|█████████ | 90/100 [00:25<00:01,  5.56it/s]Train Iter: 1291/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1405. T_Loss: 4.5861. Mask: 0.9217. :  91%|█████████ | 91/100 [00:25<00:01,  5.84it/s]Train Iter: 1292/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1398. T_Loss: 4.5743. Mask: 0.9219. :  91%|█████████ | 91/100 [00:25<00:01,  5.84it/s]Train Iter: 1292/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1398. T_Loss: 4.5743. Mask: 0.9219. :  92%|█████████▏| 92/100 [00:25<00:01,  6.38it/s]Train Iter: 1293/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1395. T_Loss: 4.5630. Mask: 0.9214. :  92%|█████████▏| 92/100 [00:25<00:01,  6.38it/s]Train Iter: 1293/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1395. T_Loss: 4.5630. Mask: 0.9214. :  93%|█████████▎| 93/100 [00:25<00:01,  6.86it/s]Train Iter: 1294/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1415. T_Loss: 4.5656. Mask: 0.9219. :  93%|█████████▎| 93/100 [00:25<00:01,  6.86it/s]Train Iter: 1294/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1415. T_Loss: 4.5656. Mask: 0.9219. :  94%|█████████▍| 94/100 [00:25<00:00,  7.22it/s]Train Iter: 1295/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1402. T_Loss: 4.5724. Mask: 0.9224. :  94%|█████████▍| 94/100 [00:25<00:00,  7.22it/s]Train Iter: 1295/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1402. T_Loss: 4.5724. Mask: 0.9224. :  95%|█████████▌| 95/100 [00:25<00:00,  7.48it/s]Train Iter: 1296/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1411. T_Loss: 4.5684. Mask: 0.9222. :  95%|█████████▌| 95/100 [00:25<00:00,  7.48it/s]Train Iter: 1296/5000. LR: 0.0483. Data: 0.11s. Batch: 0.27s. S_Loss: 1.1411. T_Loss: 4.5684. Mask: 0.9222. :  96%|█████████▌| 96/100 [00:25<00:00,  7.51it/s]Train Iter: 1297/5000. LR: 0.0483. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1407. T_Loss: 4.5765. Mask: 0.9230. :  96%|█████████▌| 96/100 [00:25<00:00,  7.51it/s]Train Iter: 1297/5000. LR: 0.0483. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1407. T_Loss: 4.5765. Mask: 0.9230. :  97%|█████████▋| 97/100 [00:25<00:00,  7.69it/s]Train Iter: 1298/5000. LR: 0.0483. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1404. T_Loss: 4.5789. Mask: 0.9232. :  97%|█████████▋| 97/100 [00:25<00:00,  7.69it/s]Train Iter: 1298/5000. LR: 0.0483. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1404. T_Loss: 4.5789. Mask: 0.9232. :  98%|█████████▊| 98/100 [00:25<00:00,  7.88it/s]Train Iter: 1299/5000. LR: 0.0483. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1401. T_Loss: 4.5772. Mask: 0.9227. :  98%|█████████▊| 98/100 [00:26<00:00,  7.88it/s]Train Iter: 1299/5000. LR: 0.0483. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1401. T_Loss: 4.5772. Mask: 0.9227. :  99%|█████████▉| 99/100 [00:26<00:00,  5.70it/s]Train Iter: 1300/5000. LR: 0.0483. Data: 0.10s. Batch: 0.26s. S_Loss: 1.1394. T_Loss: 4.5741. Mask: 0.9228. :  99%|█████████▉| 99/100 [00:26<00:00,  5.70it/s]Train Iter: 1300/5000. LR: 0.0483. Data: 0.10s. Batch: 0.26s. S_Loss: 1.1394. T_Loss: 4.5741. Mask: 0.9228. : 100%|██████████| 100/100 [00:26<00:00,  6.23it/s]Train Iter: 1300/5000. LR: 0.0483. Data: 0.10s. Batch: 0.26s. S_Loss: 1.1394. T_Loss: 4.5741. Mask: 0.9228. : 100%|██████████| 100/100 [00:26<00:00,  3.79it/s]
total : 5000  current step :  1276
total : 5000  current step :  1277
total : 5000  current step :  1278
total : 5000  current step :  1279
total : 5000  current step :  1280
total : 5000  current step :  1281
total : 5000  current step :  1282
total : 5000  current step :  1283
total : 5000  current step :  1284
total : 5000  current step :  1285
total : 5000  current step :  1286
total : 5000  current step :  1287
total : 5000  current step :  1288
total : 5000  current step :  1289
total : 5000  current step :  1290
total : 5000  current step :  1291
total : 5000  current step :  1292
total : 5000  current step :  1293
total : 5000  current step :  1294
total : 5000  current step :  1295
total : 5000  current step :  1296
total : 5000  current step :  1297
total : 5000  current step :  1298
total : 5000  current step :  1299
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.84s. Loss: 1.5975. top1: 31.25. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.84s. Loss: 1.5975. top1: 31.25. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.42s. Loss: 1.5631. top1: 32.81. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.95s. Loss: 1.4955. top1: 40.62. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.72s. Loss: 1.5013. top1: 38.28. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.58s. Loss: 1.4927. top1: 38.75. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.48s. Loss: 1.4867. top1: 39.06. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.42s. Loss: 1.4838. top1: 39.73. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.37s. Loss: 1.4935. top1: 38.28. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:55,  2.84s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.34s. Loss: 1.4859. top1: 39.58. top5: 100.00. :   2%|▏         | 1/63 [00:03<02:55,  2.84s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.34s. Loss: 1.4859. top1: 39.58. top5: 100.00. :  14%|█▍        | 9/63 [00:03<00:13,  3.97it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.4949. top1: 39.38. top5: 100.00. :  14%|█▍        | 9/63 [00:03<00:13,  3.97it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.28s. Loss: 1.4841. top1: 40.06. top5: 100.00. :  14%|█▍        | 9/63 [00:03<00:13,  3.97it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.4841. top1: 39.58. top5: 100.00. :  14%|█▍        | 9/63 [00:03<00:13,  3.97it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.4760. top1: 40.38. top5: 100.00. :  14%|█▍        | 9/63 [00:03<00:13,  3.97it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.4821. top1: 39.51. top5: 100.00. :  14%|█▍        | 9/63 [00:03<00:13,  3.97it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.4732. top1: 40.83. top5: 100.00. :  14%|█▍        | 9/63 [00:03<00:13,  3.97it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.4732. top1: 40.83. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.4705. top1: 41.60. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.4693. top1: 41.73. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.4704. top1: 41.32. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.4698. top1: 41.12. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.4701. top1: 40.47. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.4778. top1: 39.73. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.4732. top1: 40.06. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.4693. top1: 39.95. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4663. top1: 40.23. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4654. top1: 40.38. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4696. top1: 40.02. top5: 100.00. :  24%|██▍       | 15/63 [00:03<00:06,  7.40it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4696. top1: 40.02. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4690. top1: 40.16. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4728. top1: 40.18. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4710. top1: 40.30. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4698. top1: 40.52. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4705. top1: 40.52. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4586. top1: 41.60. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4400. top1: 43.37. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4239. top1: 44.76. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4081. top1: 46.34. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3954. top1: 47.48. top5: 100.00. :  41%|████▏     | 26/63 [00:03<00:02, 15.53it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3954. top1: 47.48. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3802. top1: 48.90. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3663. top1: 50.25. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3552. top1: 51.12. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3427. top1: 52.27. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3305. top1: 53.28. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3202. top1: 54.32. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3090. top1: 55.31. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2981. top1: 56.25. top5: 100.00. :  57%|█████▋    | 36/63 [00:03<00:01, 24.12it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2981. top1: 56.25. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2880. top1: 57.15. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2788. top1: 58.08. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2700. top1: 58.91. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2615. top1: 59.70. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2530. top1: 60.46. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2457. top1: 61.12. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2396. top1: 61.64. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2324. top1: 62.26. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2261. top1: 62.85. top5: 100.00. :  70%|██████▉   | 44/63 [00:03<00:00, 30.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2261. top1: 62.85. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2197. top1: 63.54. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2130. top1: 64.15. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2066. top1: 64.79. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2018. top1: 65.19. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1965. top1: 65.73. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1913. top1: 66.21. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1854. top1: 66.67. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1812. top1: 67.06. top5: 100.00. :  84%|████████▍ | 53/63 [00:03<00:00, 38.90it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1812. top1: 67.06. top5: 100.00. :  97%|█████████▋| 61/63 [00:03<00:00, 45.81it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1778. top1: 67.39. top5: 100.00. :  97%|█████████▋| 61/63 [00:03<00:00, 45.81it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1753. top1: 67.60. top5: 100.00. :  97%|█████████▋| 61/63 [00:03<00:00, 45.81it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1753. top1: 67.60. top5: 100.00. : 100%|██████████| 63/63 [00:03<00:00, 15.79it/s]
total : 5000  current step :  1300
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1301/5000. LR: 0.0483. Data: 2.17s. Batch: 2.27s. S_Loss: 1.1413. T_Loss: 4.8324. Mask: 0.9062. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1301/5000. LR: 0.0483. Data: 2.17s. Batch: 2.27s. S_Loss: 1.1413. T_Loss: 4.8324. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:44,  2.27s/it]Train Iter: 1302/5000. LR: 0.0483. Data: 1.09s. Batch: 1.20s. S_Loss: 1.1041. T_Loss: 4.1353. Mask: 0.8281. :   1%|          | 1/100 [00:02<03:44,  2.27s/it]Train Iter: 1302/5000. LR: 0.0483. Data: 1.09s. Batch: 1.20s. S_Loss: 1.1041. T_Loss: 4.1353. Mask: 0.8281. :   2%|▏         | 2/100 [00:02<01:39,  1.02s/it]Train Iter: 1303/5000. LR: 0.0483. Data: 0.73s. Batch: 0.85s. S_Loss: 1.0889. T_Loss: 4.4550. Mask: 0.8438. :   2%|▏         | 2/100 [00:02<01:39,  1.02s/it]Train Iter: 1303/5000. LR: 0.0483. Data: 0.73s. Batch: 0.85s. S_Loss: 1.0889. T_Loss: 4.4550. Mask: 0.8438. :   3%|▎         | 3/100 [00:02<01:00,  1.61it/s]Train Iter: 1304/5000. LR: 0.0482. Data: 0.55s. Batch: 0.67s. S_Loss: 1.0760. T_Loss: 4.4793. Mask: 0.8359. :   3%|▎         | 3/100 [00:02<01:00,  1.61it/s]Train Iter: 1304/5000. LR: 0.0482. Data: 0.55s. Batch: 0.67s. S_Loss: 1.0760. T_Loss: 4.4793. Mask: 0.8359. :   4%|▍         | 4/100 [00:02<00:41,  2.32it/s]Train Iter: 1305/5000. LR: 0.0482. Data: 0.44s. Batch: 0.58s. S_Loss: 1.0422. T_Loss: 4.6334. Mask: 0.8500. :   4%|▍         | 4/100 [00:02<00:41,  2.32it/s]Train Iter: 1305/5000. LR: 0.0482. Data: 0.44s. Batch: 0.58s. S_Loss: 1.0422. T_Loss: 4.6334. Mask: 0.8500. :   5%|▌         | 5/100 [00:02<00:33,  2.87it/s]Train Iter: 1306/5000. LR: 0.0482. Data: 0.37s. Batch: 0.50s. S_Loss: 1.0411. T_Loss: 4.7455. Mask: 0.8542. :   5%|▌         | 5/100 [00:03<00:33,  2.87it/s]Train Iter: 1306/5000. LR: 0.0482. Data: 0.37s. Batch: 0.50s. S_Loss: 1.0411. T_Loss: 4.7455. Mask: 0.8542. :   6%|▌         | 6/100 [00:03<00:25,  3.70it/s]Train Iter: 1307/5000. LR: 0.0482. Data: 0.32s. Batch: 0.45s. S_Loss: 1.0483. T_Loss: 4.8896. Mask: 0.8571. :   6%|▌         | 6/100 [00:03<00:25,  3.70it/s]Train Iter: 1307/5000. LR: 0.0482. Data: 0.32s. Batch: 0.45s. S_Loss: 1.0483. T_Loss: 4.8896. Mask: 0.8571. :   7%|▋         | 7/100 [00:03<00:20,  4.47it/s]Train Iter: 1308/5000. LR: 0.0482. Data: 0.28s. Batch: 0.41s. S_Loss: 1.0733. T_Loss: 5.0015. Mask: 0.8594. :   7%|▋         | 7/100 [00:03<00:20,  4.47it/s]Train Iter: 1308/5000. LR: 0.0482. Data: 0.28s. Batch: 0.41s. S_Loss: 1.0733. T_Loss: 5.0015. Mask: 0.8594. :   8%|▊         | 8/100 [00:03<00:17,  5.22it/s]Train Iter: 1309/5000. LR: 0.0482. Data: 0.25s. Batch: 0.39s. S_Loss: 1.0889. T_Loss: 5.0962. Mask: 0.8542. :   8%|▊         | 8/100 [00:03<00:17,  5.22it/s]Train Iter: 1309/5000. LR: 0.0482. Data: 0.25s. Batch: 0.39s. S_Loss: 1.0889. T_Loss: 5.0962. Mask: 0.8542. :   9%|▉         | 9/100 [00:03<00:19,  4.59it/s]Train Iter: 1310/5000. LR: 0.0482. Data: 0.22s. Batch: 0.37s. S_Loss: 1.1011. T_Loss: 5.1248. Mask: 0.8469. :   9%|▉         | 9/100 [00:03<00:19,  4.59it/s]Train Iter: 1310/5000. LR: 0.0482. Data: 0.22s. Batch: 0.37s. S_Loss: 1.1011. T_Loss: 5.1248. Mask: 0.8469. :  10%|█         | 10/100 [00:03<00:17,  5.29it/s]Train Iter: 1311/5000. LR: 0.0482. Data: 0.20s. Batch: 0.34s. S_Loss: 1.1154. T_Loss: 5.1583. Mask: 0.8409. :  10%|█         | 10/100 [00:03<00:17,  5.29it/s]Train Iter: 1311/5000. LR: 0.0482. Data: 0.20s. Batch: 0.34s. S_Loss: 1.1154. T_Loss: 5.1583. Mask: 0.8409. :  11%|█         | 11/100 [00:03<00:14,  5.99it/s]Train Iter: 1312/5000. LR: 0.0482. Data: 0.18s. Batch: 0.32s. S_Loss: 1.1408. T_Loss: 5.1690. Mask: 0.8307. :  11%|█         | 11/100 [00:03<00:14,  5.99it/s]Train Iter: 1312/5000. LR: 0.0482. Data: 0.18s. Batch: 0.32s. S_Loss: 1.1408. T_Loss: 5.1690. Mask: 0.8307. :  12%|█▏        | 12/100 [00:03<00:13,  6.52it/s]Train Iter: 1313/5000. LR: 0.0482. Data: 0.17s. Batch: 0.31s. S_Loss: 1.1464. T_Loss: 5.1708. Mask: 0.8221. :  12%|█▏        | 12/100 [00:04<00:13,  6.52it/s]Train Iter: 1313/5000. LR: 0.0482. Data: 0.17s. Batch: 0.31s. S_Loss: 1.1464. T_Loss: 5.1708. Mask: 0.8221. :  13%|█▎        | 13/100 [00:04<00:12,  6.95it/s]Train Iter: 1314/5000. LR: 0.0482. Data: 0.16s. Batch: 0.30s. S_Loss: 1.1578. T_Loss: 5.2434. Mask: 0.8214. :  13%|█▎        | 13/100 [00:04<00:12,  6.95it/s]Train Iter: 1314/5000. LR: 0.0482. Data: 0.16s. Batch: 0.30s. S_Loss: 1.1578. T_Loss: 5.2434. Mask: 0.8214. :  14%|█▍        | 14/100 [00:04<00:11,  7.26it/s]Train Iter: 1315/5000. LR: 0.0482. Data: 0.15s. Batch: 0.28s. S_Loss: 1.1608. T_Loss: 5.2300. Mask: 0.8146. :  14%|█▍        | 14/100 [00:04<00:11,  7.26it/s]Train Iter: 1315/5000. LR: 0.0482. Data: 0.15s. Batch: 0.28s. S_Loss: 1.1608. T_Loss: 5.2300. Mask: 0.8146. :  15%|█▌        | 15/100 [00:04<00:11,  7.46it/s]Train Iter: 1316/5000. LR: 0.0482. Data: 0.14s. Batch: 0.27s. S_Loss: 1.1582. T_Loss: 5.2310. Mask: 0.8086. :  15%|█▌        | 15/100 [00:04<00:11,  7.46it/s]Train Iter: 1316/5000. LR: 0.0482. Data: 0.14s. Batch: 0.27s. S_Loss: 1.1582. T_Loss: 5.2310. Mask: 0.8086. :  16%|█▌        | 16/100 [00:04<00:11,  7.60it/s]Train Iter: 1317/5000. LR: 0.0482. Data: 0.13s. Batch: 0.26s. S_Loss: 1.1537. T_Loss: 5.2783. Mask: 0.8107. :  16%|█▌        | 16/100 [00:04<00:11,  7.60it/s]Train Iter: 1317/5000. LR: 0.0482. Data: 0.13s. Batch: 0.26s. S_Loss: 1.1537. T_Loss: 5.2783. Mask: 0.8107. :  17%|█▋        | 17/100 [00:04<00:10,  8.19it/s]Train Iter: 1318/5000. LR: 0.0481. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1584. T_Loss: 5.3137. Mask: 0.8090. :  17%|█▋        | 17/100 [00:04<00:10,  8.19it/s]Train Iter: 1318/5000. LR: 0.0481. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1584. T_Loss: 5.3137. Mask: 0.8090. :  18%|█▊        | 18/100 [00:04<00:10,  8.17it/s]Train Iter: 1319/5000. LR: 0.0481. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1557. T_Loss: 5.3490. Mask: 0.8141. :  18%|█▊        | 18/100 [00:04<00:10,  8.17it/s]Train Iter: 1319/5000. LR: 0.0481. Data: 0.12s. Batch: 0.26s. S_Loss: 1.1557. T_Loss: 5.3490. Mask: 0.8141. :  19%|█▉        | 19/100 [00:04<00:15,  5.19it/s]Train Iter: 1320/5000. LR: 0.0481. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1575. T_Loss: 5.3510. Mask: 0.8141. :  19%|█▉        | 19/100 [00:05<00:15,  5.19it/s]Train Iter: 1320/5000. LR: 0.0481. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1575. T_Loss: 5.3510. Mask: 0.8141. :  20%|██        | 20/100 [00:05<00:13,  5.81it/s]Train Iter: 1321/5000. LR: 0.0481. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1527. T_Loss: 5.3661. Mask: 0.8170. :  20%|██        | 20/100 [00:05<00:13,  5.81it/s]Train Iter: 1321/5000. LR: 0.0481. Data: 0.11s. Batch: 0.25s. S_Loss: 1.1527. T_Loss: 5.3661. Mask: 0.8170. :  21%|██        | 21/100 [00:05<00:12,  6.38it/s]Train Iter: 1322/5000. LR: 0.0481. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1531. T_Loss: 5.3555. Mask: 0.8153. :  21%|██        | 21/100 [00:05<00:12,  6.38it/s]Train Iter: 1322/5000. LR: 0.0481. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1531. T_Loss: 5.3555. Mask: 0.8153. :  22%|██▏       | 22/100 [00:05<00:11,  6.85it/s]Train Iter: 1323/5000. LR: 0.0481. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1533. T_Loss: 5.3592. Mask: 0.8179. :  22%|██▏       | 22/100 [00:05<00:11,  6.85it/s]Train Iter: 1323/5000. LR: 0.0481. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1533. T_Loss: 5.3592. Mask: 0.8179. :  23%|██▎       | 23/100 [00:05<00:10,  7.34it/s]Train Iter: 1324/5000. LR: 0.0481. Data: 0.09s. Batch: 0.23s. S_Loss: 1.1508. T_Loss: 5.3259. Mask: 0.8190. :  23%|██▎       | 23/100 [00:05<00:10,  7.34it/s]Train Iter: 1324/5000. LR: 0.0481. Data: 0.09s. Batch: 0.23s. S_Loss: 1.1508. T_Loss: 5.3259. Mask: 0.8190. :  24%|██▍       | 24/100 [00:05<00:09,  7.93it/s]Train Iter: 1325/5000. LR: 0.0481. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1483. T_Loss: 5.2987. Mask: 0.8237. :  24%|██▍       | 24/100 [00:05<00:09,  7.93it/s]Train Iter: 1325/5000. LR: 0.0481. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1483. T_Loss: 5.2987. Mask: 0.8237. :  25%|██▌       | 25/100 [00:05<00:15,  4.93it/s]total : 5000  current step :  1301
total : 5000  current step :  1302
total : 5000  current step :  1303
total : 5000  current step :  1304
total : 5000  current step :  1305
total : 5000  current step :  1306
total : 5000  current step :  1307
total : 5000  current step :  1308
total : 5000  current step :  1309
total : 5000  current step :  1310
total : 5000  current step :  1311
total : 5000  current step :  1312
total : 5000  current step :  1313
total : 5000  current step :  1314
total : 5000  current step :  1315
total : 5000  current step :  1316
total : 5000  current step :  1317
total : 5000  current step :  1318
total : 5000  current step :  1319
total : 5000  current step :  1320
total : 5000  current step :  1321
total : 5000  current step :  1322
total : 5000  current step :  1323
total : 5000  current step :  1324
total : 5000  current step :  1325
Train Iter: 1326/5000. LR: 0.0481. Data: 0.16s. Batch: 0.30s. S_Loss: 1.1486. T_Loss: 5.3291. Mask: 0.8293. :  25%|██▌       | 25/100 [00:07<00:15,  4.93it/s]Train Iter: 1326/5000. LR: 0.0481. Data: 0.16s. Batch: 0.30s. S_Loss: 1.1486. T_Loss: 5.3291. Mask: 0.8293. :  26%|██▌       | 26/100 [00:07<00:54,  1.36it/s]Train Iter: 1327/5000. LR: 0.0481. Data: 0.15s. Batch: 0.30s. S_Loss: 1.1455. T_Loss: 5.3048. Mask: 0.8287. :  26%|██▌       | 26/100 [00:08<00:54,  1.36it/s]Train Iter: 1328/5000. LR: 0.0481. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1443. T_Loss: 5.2775. Mask: 0.8292. :  27%|██▋       | 27/100 [00:08<00:53,  1.36it/s]Train Iter: 1328/5000. LR: 0.0481. Data: 0.15s. Batch: 0.29s. S_Loss: 1.1443. T_Loss: 5.2775. Mask: 0.8292. :  28%|██▊       | 28/100 [00:08<00:32,  2.23it/s]Train Iter: 1329/5000. LR: 0.0481. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1426. T_Loss: 5.2459. Mask: 0.8308. :  28%|██▊       | 28/100 [00:08<00:32,  2.23it/s]Train Iter: 1329/5000. LR: 0.0481. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1426. T_Loss: 5.2459. Mask: 0.8308. :  29%|██▉       | 29/100 [00:08<00:29,  2.37it/s]Train Iter: 1330/5000. LR: 0.0481. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1408. T_Loss: 5.2324. Mask: 0.8333. :  29%|██▉       | 29/100 [00:08<00:29,  2.37it/s]Train Iter: 1330/5000. LR: 0.0481. Data: 0.14s. Batch: 0.29s. S_Loss: 1.1408. T_Loss: 5.2324. Mask: 0.8333. :  30%|███       | 30/100 [00:08<00:24,  2.91it/s]Train Iter: 1331/5000. LR: 0.0481. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1379. T_Loss: 5.2125. Mask: 0.8377. :  30%|███       | 30/100 [00:08<00:24,  2.91it/s]Train Iter: 1331/5000. LR: 0.0481. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1379. T_Loss: 5.2125. Mask: 0.8377. :  31%|███       | 31/100 [00:08<00:19,  3.53it/s]Train Iter: 1332/5000. LR: 0.0480. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1358. T_Loss: 5.1923. Mask: 0.8418. :  31%|███       | 31/100 [00:08<00:19,  3.53it/s]Train Iter: 1332/5000. LR: 0.0480. Data: 0.13s. Batch: 0.28s. S_Loss: 1.1358. T_Loss: 5.1923. Mask: 0.8418. :  32%|███▏      | 32/100 [00:08<00:16,  4.20it/s]Train Iter: 1333/5000. LR: 0.0480. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1347. T_Loss: 5.1673. Mask: 0.8419. :  32%|███▏      | 32/100 [00:08<00:16,  4.20it/s]Train Iter: 1333/5000. LR: 0.0480. Data: 0.13s. Batch: 0.27s. S_Loss: 1.1347. T_Loss: 5.1673. Mask: 0.8419. :  33%|███▎      | 33/100 [00:08<00:13,  4.80it/s]Train Iter: 1334/5000. LR: 0.0480. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1351. T_Loss: 5.1508. Mask: 0.8428. :  33%|███▎      | 33/100 [00:09<00:13,  4.80it/s]Train Iter: 1334/5000. LR: 0.0480. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1351. T_Loss: 5.1508. Mask: 0.8428. :  34%|███▍      | 34/100 [00:09<00:12,  5.48it/s]Train Iter: 1335/5000. LR: 0.0480. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1348. T_Loss: 5.1577. Mask: 0.8455. :  34%|███▍      | 34/100 [00:09<00:12,  5.48it/s]Train Iter: 1335/5000. LR: 0.0480. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1348. T_Loss: 5.1577. Mask: 0.8455. :  35%|███▌      | 35/100 [00:09<00:15,  4.24it/s]Train Iter: 1336/5000. LR: 0.0480. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1320. T_Loss: 5.1265. Mask: 0.8455. :  35%|███▌      | 35/100 [00:09<00:15,  4.24it/s]Train Iter: 1336/5000. LR: 0.0480. Data: 0.12s. Batch: 0.27s. S_Loss: 1.1320. T_Loss: 5.1265. Mask: 0.8455. :  36%|███▌      | 36/100 [00:09<00:12,  4.94it/s]Train Iter: 1337/5000. LR: 0.0480. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1297. T_Loss: 5.1046. Mask: 0.8480. :  36%|███▌      | 36/100 [00:09<00:12,  4.94it/s]Train Iter: 1337/5000. LR: 0.0480. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1297. T_Loss: 5.1046. Mask: 0.8480. :  37%|███▋      | 37/100 [00:09<00:11,  5.51it/s]Train Iter: 1338/5000. LR: 0.0480. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1275. T_Loss: 5.0969. Mask: 0.8487. :  37%|███▋      | 37/100 [00:09<00:11,  5.51it/s]Train Iter: 1339/5000. LR: 0.0480. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1249. T_Loss: 5.0850. Mask: 0.8502. :  38%|███▊      | 38/100 [00:10<00:11,  5.51it/s]Train Iter: 1339/5000. LR: 0.0480. Data: 0.11s. Batch: 0.26s. S_Loss: 1.1249. T_Loss: 5.0850. Mask: 0.8502. :  39%|███▉      | 39/100 [00:10<00:11,  5.39it/s]Train Iter: 1340/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1221. T_Loss: 5.0841. Mask: 0.8531. :  39%|███▉      | 39/100 [00:10<00:11,  5.39it/s]Train Iter: 1340/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1221. T_Loss: 5.0841. Mask: 0.8531. :  40%|████      | 40/100 [00:10<00:10,  5.91it/s]Train Iter: 1341/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1213. T_Loss: 5.0601. Mask: 0.8521. :  40%|████      | 40/100 [00:10<00:10,  5.91it/s]Train Iter: 1341/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1213. T_Loss: 5.0601. Mask: 0.8521. :  41%|████      | 41/100 [00:10<00:09,  6.28it/s]Train Iter: 1342/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1167. T_Loss: 5.0510. Mask: 0.8542. :  41%|████      | 41/100 [00:10<00:09,  6.28it/s]Train Iter: 1342/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1167. T_Loss: 5.0510. Mask: 0.8542. :  42%|████▏     | 42/100 [00:10<00:08,  6.73it/s]Train Iter: 1343/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1149. T_Loss: 5.0374. Mask: 0.8561. :  42%|████▏     | 42/100 [00:10<00:08,  6.73it/s]Train Iter: 1343/5000. LR: 0.0480. Data: 0.10s. Batch: 0.25s. S_Loss: 1.1149. T_Loss: 5.0374. Mask: 0.8561. :  43%|████▎     | 43/100 [00:10<00:07,  7.13it/s]Train Iter: 1344/5000. LR: 0.0480. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1117. T_Loss: 5.0319. Mask: 0.8572. :  43%|████▎     | 43/100 [00:10<00:07,  7.13it/s]Train Iter: 1344/5000. LR: 0.0480. Data: 0.10s. Batch: 0.24s. S_Loss: 1.1117. T_Loss: 5.0319. Mask: 0.8572. :  44%|████▍     | 44/100 [00:10<00:07,  7.34it/s]Train Iter: 1345/5000. LR: 0.0480. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1119. T_Loss: 5.0102. Mask: 0.8583. :  44%|████▍     | 44/100 [00:11<00:07,  7.34it/s]Train Iter: 1345/5000. LR: 0.0480. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1119. T_Loss: 5.0102. Mask: 0.8583. :  45%|████▌     | 45/100 [00:11<00:10,  5.34it/s]Train Iter: 1346/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1098. T_Loss: 4.9991. Mask: 0.8601. :  45%|████▌     | 45/100 [00:11<00:10,  5.34it/s]Train Iter: 1346/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1098. T_Loss: 4.9991. Mask: 0.8601. :  46%|████▌     | 46/100 [00:11<00:09,  5.56it/s]Train Iter: 1347/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1081. T_Loss: 4.9945. Mask: 0.8624. :  46%|████▌     | 46/100 [00:11<00:09,  5.56it/s]Train Iter: 1347/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1081. T_Loss: 4.9945. Mask: 0.8624. :  47%|████▋     | 47/100 [00:11<00:08,  6.14it/s]Train Iter: 1348/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1061. T_Loss: 4.9833. Mask: 0.8626. :  47%|████▋     | 47/100 [00:11<00:08,  6.14it/s]Train Iter: 1348/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1061. T_Loss: 4.9833. Mask: 0.8626. :  48%|████▊     | 48/100 [00:11<00:07,  6.59it/s]Train Iter: 1349/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1036. T_Loss: 4.9605. Mask: 0.8635. :  48%|████▊     | 48/100 [00:11<00:07,  6.59it/s]Train Iter: 1349/5000. LR: 0.0479. Data: 0.09s. Batch: 0.24s. S_Loss: 1.1036. T_Loss: 4.9605. Mask: 0.8635. :  49%|████▉     | 49/100 [00:11<00:09,  5.26it/s]Train Iter: 1350/5000. LR: 0.0479. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1008. T_Loss: 4.9453. Mask: 0.8650. :  49%|████▉     | 49/100 [00:11<00:09,  5.26it/s]Train Iter: 1350/5000. LR: 0.0479. Data: 0.08s. Batch: 0.24s. S_Loss: 1.1008. T_Loss: 4.9453. Mask: 0.8650. :  50%|█████     | 50/100 [00:11<00:08,  5.98it/s]total : 5000  current step :  1326
total : 5000  current step :  1327
total : 5000  current step :  1328
total : 5000  current step :  1329
total : 5000  current step :  1330
total : 5000  current step :  1331
total : 5000  current step :  1332
total : 5000  current step :  1333
total : 5000  current step :  1334
total : 5000  current step :  1335
total : 5000  current step :  1336
total : 5000  current step :  1337
total : 5000  current step :  1338
total : 5000  current step :  1339
total : 5000  current step :  1340
total : 5000  current step :  1341
total : 5000  current step :  1342
total : 5000  current step :  1343
total : 5000  current step :  1344
total : 5000  current step :  1345
total : 5000  current step :  1346
total : 5000  current step :  1347
total : 5000  current step :  1348
total : 5000  current step :  1349
total : 5000  current step :  1350
Train Iter: 1351/5000. LR: 0.0479. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0983. T_Loss: 4.9334. Mask: 0.8664. :  50%|█████     | 50/100 [00:13<00:08,  5.98it/s]Train Iter: 1351/5000. LR: 0.0479. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0983. T_Loss: 4.9334. Mask: 0.8664. :  51%|█████     | 51/100 [00:13<00:36,  1.36it/s]Train Iter: 1352/5000. LR: 0.0479. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0966. T_Loss: 4.9205. Mask: 0.8678. :  51%|█████     | 51/100 [00:14<00:36,  1.36it/s]Train Iter: 1352/5000. LR: 0.0479. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0966. T_Loss: 4.9205. Mask: 0.8678. :  52%|█████▏    | 52/100 [00:14<00:26,  1.79it/s]Train Iter: 1353/5000. LR: 0.0479. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0942. T_Loss: 4.9005. Mask: 0.8679. :  52%|█████▏    | 52/100 [00:14<00:26,  1.79it/s]Train Iter: 1353/5000. LR: 0.0479. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0942. T_Loss: 4.9005. Mask: 0.8679. :  53%|█████▎    | 53/100 [00:14<00:20,  2.26it/s]Train Iter: 1354/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0918. T_Loss: 4.8961. Mask: 0.8686. :  53%|█████▎    | 53/100 [00:14<00:20,  2.26it/s]Train Iter: 1354/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0918. T_Loss: 4.8961. Mask: 0.8686. :  54%|█████▍    | 54/100 [00:14<00:16,  2.87it/s]Train Iter: 1355/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0907. T_Loss: 4.9086. Mask: 0.8710. :  54%|█████▍    | 54/100 [00:14<00:16,  2.87it/s]Train Iter: 1355/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0907. T_Loss: 4.9086. Mask: 0.8710. :  55%|█████▌    | 55/100 [00:14<00:13,  3.22it/s]Train Iter: 1356/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0883. T_Loss: 4.9022. Mask: 0.8728. :  55%|█████▌    | 55/100 [00:14<00:13,  3.22it/s]Train Iter: 1356/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0883. T_Loss: 4.9022. Mask: 0.8728. :  56%|█████▌    | 56/100 [00:14<00:11,  3.98it/s]Train Iter: 1357/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0870. T_Loss: 4.8763. Mask: 0.8728. :  56%|█████▌    | 56/100 [00:14<00:11,  3.98it/s]Train Iter: 1357/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0870. T_Loss: 4.8763. Mask: 0.8728. :  57%|█████▋    | 57/100 [00:14<00:09,  4.68it/s]Train Iter: 1358/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0842. T_Loss: 4.8527. Mask: 0.8739. :  57%|█████▋    | 57/100 [00:14<00:09,  4.68it/s]Train Iter: 1358/5000. LR: 0.0479. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0842. T_Loss: 4.8527. Mask: 0.8739. :  58%|█████▊    | 58/100 [00:14<00:07,  5.42it/s]Train Iter: 1359/5000. LR: 0.0478. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0814. T_Loss: 4.8429. Mask: 0.8745. :  58%|█████▊    | 58/100 [00:15<00:07,  5.42it/s]Train Iter: 1359/5000. LR: 0.0478. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0814. T_Loss: 4.8429. Mask: 0.8745. :  59%|█████▉    | 59/100 [00:15<00:09,  4.53it/s]Train Iter: 1360/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0796. T_Loss: 4.8408. Mask: 0.8760. :  59%|█████▉    | 59/100 [00:15<00:09,  4.53it/s]Train Iter: 1360/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0796. T_Loss: 4.8408. Mask: 0.8760. :  60%|██████    | 60/100 [00:15<00:07,  5.12it/s]Train Iter: 1361/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0785. T_Loss: 4.8435. Mask: 0.8776. :  60%|██████    | 60/100 [00:15<00:07,  5.12it/s]Train Iter: 1361/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0785. T_Loss: 4.8435. Mask: 0.8776. :  61%|██████    | 61/100 [00:15<00:06,  5.75it/s]Train Iter: 1362/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0768. T_Loss: 4.8348. Mask: 0.8775. :  61%|██████    | 61/100 [00:15<00:06,  5.75it/s]Train Iter: 1362/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0768. T_Loss: 4.8348. Mask: 0.8775. :  62%|██████▏   | 62/100 [00:15<00:06,  6.27it/s]Train Iter: 1363/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0757. T_Loss: 4.8381. Mask: 0.8785. :  62%|██████▏   | 62/100 [00:15<00:06,  6.27it/s]Train Iter: 1363/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0757. T_Loss: 4.8381. Mask: 0.8785. :  63%|██████▎   | 63/100 [00:15<00:05,  6.58it/s]Train Iter: 1364/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0755. T_Loss: 4.8420. Mask: 0.8789. :  63%|██████▎   | 63/100 [00:15<00:05,  6.58it/s]Train Iter: 1364/5000. LR: 0.0478. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0755. T_Loss: 4.8420. Mask: 0.8789. :  64%|██████▍   | 64/100 [00:15<00:05,  7.00it/s]Train Iter: 1365/5000. LR: 0.0478. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0753. T_Loss: 4.8587. Mask: 0.8808. :  64%|██████▍   | 64/100 [00:16<00:05,  7.00it/s]Train Iter: 1365/5000. LR: 0.0478. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0753. T_Loss: 4.8587. Mask: 0.8808. :  65%|██████▌   | 65/100 [00:16<00:04,  7.31it/s]Train Iter: 1366/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0744. T_Loss: 4.8598. Mask: 0.8816. :  65%|██████▌   | 65/100 [00:16<00:04,  7.31it/s]Train Iter: 1366/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0744. T_Loss: 4.8598. Mask: 0.8816. :  66%|██████▌   | 66/100 [00:16<00:04,  7.12it/s]Train Iter: 1367/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0720. T_Loss: 4.8552. Mask: 0.8825. :  66%|██████▌   | 66/100 [00:16<00:04,  7.12it/s]Train Iter: 1367/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0720. T_Loss: 4.8552. Mask: 0.8825. :  67%|██████▋   | 67/100 [00:16<00:04,  7.40it/s]Train Iter: 1368/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0710. T_Loss: 4.8570. Mask: 0.8828. :  67%|██████▋   | 67/100 [00:16<00:04,  7.40it/s]Train Iter: 1368/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0710. T_Loss: 4.8570. Mask: 0.8828. :  68%|██████▊   | 68/100 [00:16<00:04,  7.67it/s]Train Iter: 1369/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0693. T_Loss: 4.8472. Mask: 0.8827. :  68%|██████▊   | 68/100 [00:16<00:04,  7.67it/s]Train Iter: 1369/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0693. T_Loss: 4.8472. Mask: 0.8827. :  69%|██████▉   | 69/100 [00:16<00:05,  5.56it/s]Train Iter: 1370/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0678. T_Loss: 4.8508. Mask: 0.8835. :  69%|██████▉   | 69/100 [00:16<00:05,  5.56it/s]Train Iter: 1370/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0678. T_Loss: 4.8508. Mask: 0.8835. :  70%|███████   | 70/100 [00:16<00:04,  6.17it/s]Train Iter: 1371/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0657. T_Loss: 4.8381. Mask: 0.8847. :  70%|███████   | 70/100 [00:16<00:04,  6.17it/s]Train Iter: 1371/5000. LR: 0.0478. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0657. T_Loss: 4.8381. Mask: 0.8847. :  71%|███████   | 71/100 [00:16<00:04,  6.54it/s]Train Iter: 1372/5000. LR: 0.0477. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0647. T_Loss: 4.8304. Mask: 0.8841. :  71%|███████   | 71/100 [00:17<00:04,  6.54it/s]Train Iter: 1372/5000. LR: 0.0477. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0647. T_Loss: 4.8304. Mask: 0.8841. :  72%|███████▏  | 72/100 [00:17<00:04,  6.90it/s]Train Iter: 1373/5000. LR: 0.0477. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0641. T_Loss: 4.8264. Mask: 0.8840. :  72%|███████▏  | 72/100 [00:17<00:04,  6.90it/s]Train Iter: 1373/5000. LR: 0.0477. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0641. T_Loss: 4.8264. Mask: 0.8840. :  73%|███████▎  | 73/100 [00:17<00:03,  7.14it/s]Train Iter: 1374/5000. LR: 0.0477. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0644. T_Loss: 4.8338. Mask: 0.8843. :  73%|███████▎  | 73/100 [00:17<00:03,  7.14it/s]Train Iter: 1374/5000. LR: 0.0477. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0644. T_Loss: 4.8338. Mask: 0.8843. :  74%|███████▍  | 74/100 [00:17<00:03,  7.30it/s]Train Iter: 1375/5000. LR: 0.0477. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0633. T_Loss: 4.8432. Mask: 0.8858. :  74%|███████▍  | 74/100 [00:17<00:03,  7.30it/s]Train Iter: 1375/5000. LR: 0.0477. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0633. T_Loss: 4.8432. Mask: 0.8858. :  75%|███████▌  | 75/100 [00:17<00:04,  5.04it/s]total : 5000  current step :  1351
total : 5000  current step :  1352
total : 5000  current step :  1353
total : 5000  current step :  1354
total : 5000  current step :  1355
total : 5000  current step :  1356
total : 5000  current step :  1357
total : 5000  current step :  1358
total : 5000  current step :  1359
total : 5000  current step :  1360
total : 5000  current step :  1361
total : 5000  current step :  1362
total : 5000  current step :  1363
total : 5000  current step :  1364
total : 5000  current step :  1365
total : 5000  current step :  1366
total : 5000  current step :  1367
total : 5000  current step :  1368
total : 5000  current step :  1369
total : 5000  current step :  1370
total : 5000  current step :  1371
total : 5000  current step :  1372
total : 5000  current step :  1373
total : 5000  current step :  1374
total : 5000  current step :  1375
Train Iter: 1376/5000. LR: 0.0477. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0630. T_Loss: 4.8307. Mask: 0.8849. :  75%|███████▌  | 75/100 [00:19<00:04,  5.04it/s]Train Iter: 1376/5000. LR: 0.0477. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0630. T_Loss: 4.8307. Mask: 0.8849. :  76%|███████▌  | 76/100 [00:19<00:18,  1.27it/s]Train Iter: 1377/5000. LR: 0.0477. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0631. T_Loss: 4.8528. Mask: 0.8864. :  76%|███████▌  | 76/100 [00:19<00:18,  1.27it/s]Train Iter: 1377/5000. LR: 0.0477. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0631. T_Loss: 4.8528. Mask: 0.8864. :  77%|███████▋  | 77/100 [00:19<00:13,  1.72it/s]Train Iter: 1378/5000. LR: 0.0477. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0614. T_Loss: 4.8442. Mask: 0.8858. :  77%|███████▋  | 77/100 [00:20<00:13,  1.72it/s]Train Iter: 1379/5000. LR: 0.0477. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0618. T_Loss: 4.8471. Mask: 0.8861. :  78%|███████▊  | 78/100 [00:20<00:12,  1.72it/s]Train Iter: 1379/5000. LR: 0.0477. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0618. T_Loss: 4.8471. Mask: 0.8861. :  79%|███████▉  | 79/100 [00:20<00:08,  2.39it/s]Train Iter: 1380/5000. LR: 0.0477. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0605. T_Loss: 4.8451. Mask: 0.8863. :  79%|███████▉  | 79/100 [00:20<00:08,  2.39it/s]Train Iter: 1380/5000. LR: 0.0477. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0605. T_Loss: 4.8451. Mask: 0.8863. :  80%|████████  | 80/100 [00:20<00:06,  2.88it/s]Train Iter: 1381/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0587. T_Loss: 4.8331. Mask: 0.8862. :  80%|████████  | 80/100 [00:20<00:06,  2.88it/s]Train Iter: 1382/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0575. T_Loss: 4.8241. Mask: 0.8857. :  81%|████████  | 81/100 [00:20<00:06,  2.88it/s]Train Iter: 1382/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0575. T_Loss: 4.8241. Mask: 0.8857. :  82%|████████▏ | 82/100 [00:20<00:04,  4.04it/s]Train Iter: 1383/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0566. T_Loss: 4.8249. Mask: 0.8859. :  82%|████████▏ | 82/100 [00:20<00:04,  4.04it/s]Train Iter: 1383/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0566. T_Loss: 4.8249. Mask: 0.8859. :  83%|████████▎ | 83/100 [00:20<00:03,  4.61it/s]Train Iter: 1384/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0549. T_Loss: 4.8287. Mask: 0.8865. :  83%|████████▎ | 83/100 [00:20<00:03,  4.61it/s]Train Iter: 1384/5000. LR: 0.0477. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0549. T_Loss: 4.8287. Mask: 0.8865. :  84%|████████▍ | 84/100 [00:20<00:03,  5.16it/s]Train Iter: 1385/5000. LR: 0.0476. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0557. T_Loss: 4.8333. Mask: 0.8864. :  84%|████████▍ | 84/100 [00:21<00:03,  5.16it/s]Train Iter: 1385/5000. LR: 0.0476. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0557. T_Loss: 4.8333. Mask: 0.8864. :  85%|████████▌ | 85/100 [00:21<00:03,  4.29it/s]Train Iter: 1386/5000. LR: 0.0476. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0545. T_Loss: 4.8346. Mask: 0.8863. :  85%|████████▌ | 85/100 [00:21<00:03,  4.29it/s]Train Iter: 1386/5000. LR: 0.0476. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0545. T_Loss: 4.8346. Mask: 0.8863. :  86%|████████▌ | 86/100 [00:21<00:02,  4.87it/s]Train Iter: 1387/5000. LR: 0.0476. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0550. T_Loss: 4.8380. Mask: 0.8861. :  86%|████████▌ | 86/100 [00:21<00:02,  4.87it/s]Train Iter: 1387/5000. LR: 0.0476. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0550. T_Loss: 4.8380. Mask: 0.8861. :  87%|████████▋ | 87/100 [00:21<00:02,  5.46it/s]Train Iter: 1388/5000. LR: 0.0476. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0538. T_Loss: 4.8388. Mask: 0.8867. :  87%|████████▋ | 87/100 [00:21<00:02,  5.46it/s]Train Iter: 1388/5000. LR: 0.0476. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0538. T_Loss: 4.8388. Mask: 0.8867. :  88%|████████▊ | 88/100 [00:21<00:01,  6.07it/s]Train Iter: 1389/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0523. T_Loss: 4.8368. Mask: 0.8869. :  88%|████████▊ | 88/100 [00:21<00:01,  6.07it/s]Train Iter: 1389/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0523. T_Loss: 4.8368. Mask: 0.8869. :  89%|████████▉ | 89/100 [00:21<00:01,  6.56it/s]Train Iter: 1390/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0504. T_Loss: 4.8332. Mask: 0.8878. :  89%|████████▉ | 89/100 [00:21<00:01,  6.56it/s]Train Iter: 1390/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0504. T_Loss: 4.8332. Mask: 0.8878. :  90%|█████████ | 90/100 [00:21<00:01,  6.90it/s]Train Iter: 1391/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0497. T_Loss: 4.8257. Mask: 0.8877. :  90%|█████████ | 90/100 [00:22<00:01,  6.90it/s]Train Iter: 1391/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0497. T_Loss: 4.8257. Mask: 0.8877. :  91%|█████████ | 91/100 [00:22<00:01,  7.07it/s]Train Iter: 1392/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0484. T_Loss: 4.8242. Mask: 0.8879. :  91%|█████████ | 91/100 [00:22<00:01,  7.07it/s]Train Iter: 1392/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0484. T_Loss: 4.8242. Mask: 0.8879. :  92%|█████████▏| 92/100 [00:22<00:01,  7.40it/s]Train Iter: 1393/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0494. T_Loss: 4.8375. Mask: 0.8884. :  92%|█████████▏| 92/100 [00:22<00:01,  7.40it/s]Train Iter: 1393/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0494. T_Loss: 4.8375. Mask: 0.8884. :  93%|█████████▎| 93/100 [00:22<00:00,  7.68it/s]Train Iter: 1394/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0493. T_Loss: 4.8482. Mask: 0.8893. :  93%|█████████▎| 93/100 [00:22<00:00,  7.68it/s]Train Iter: 1394/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0493. T_Loss: 4.8482. Mask: 0.8893. :  94%|█████████▍| 94/100 [00:22<00:00,  7.50it/s]Train Iter: 1395/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0489. T_Loss: 4.8524. Mask: 0.8901. :  94%|█████████▍| 94/100 [00:22<00:00,  7.50it/s]Train Iter: 1395/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0489. T_Loss: 4.8524. Mask: 0.8901. :  95%|█████████▌| 95/100 [00:22<00:00,  5.29it/s]Train Iter: 1396/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0479. T_Loss: 4.8560. Mask: 0.8910. :  95%|█████████▌| 95/100 [00:22<00:00,  5.29it/s]Train Iter: 1396/5000. LR: 0.0476. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0479. T_Loss: 4.8560. Mask: 0.8910. :  96%|█████████▌| 96/100 [00:22<00:00,  5.74it/s]Train Iter: 1397/5000. LR: 0.0475. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0468. T_Loss: 4.8528. Mask: 0.8914. :  96%|█████████▌| 96/100 [00:23<00:00,  5.74it/s]Train Iter: 1397/5000. LR: 0.0475. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0468. T_Loss: 4.8528. Mask: 0.8914. :  97%|█████████▋| 97/100 [00:23<00:00,  6.37it/s]Train Iter: 1398/5000. LR: 0.0475. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0455. T_Loss: 4.8513. Mask: 0.8919. :  97%|█████████▋| 97/100 [00:23<00:00,  6.37it/s]Train Iter: 1398/5000. LR: 0.0475. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0455. T_Loss: 4.8513. Mask: 0.8919. :  98%|█████████▊| 98/100 [00:23<00:00,  6.77it/s]Train Iter: 1399/5000. LR: 0.0475. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0449. T_Loss: 4.8473. Mask: 0.8914. :  98%|█████████▊| 98/100 [00:23<00:00,  6.77it/s]Train Iter: 1399/5000. LR: 0.0475. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0449. T_Loss: 4.8473. Mask: 0.8914. :  99%|█████████▉| 99/100 [00:23<00:00,  5.03it/s]Train Iter: 1400/5000. LR: 0.0475. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0451. T_Loss: 4.8474. Mask: 0.8922. :  99%|█████████▉| 99/100 [00:23<00:00,  5.03it/s]Train Iter: 1400/5000. LR: 0.0475. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0451. T_Loss: 4.8474. Mask: 0.8922. : 100%|██████████| 100/100 [00:23<00:00,  5.82it/s]Train Iter: 1400/5000. LR: 0.0475. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0451. T_Loss: 4.8474. Mask: 0.8922. : 100%|██████████| 100/100 [00:23<00:00,  4.24it/s]
total : 5000  current step :  1376
total : 5000  current step :  1377
total : 5000  current step :  1378
total : 5000  current step :  1379
total : 5000  current step :  1380
total : 5000  current step :  1381
total : 5000  current step :  1382
total : 5000  current step :  1383
total : 5000  current step :  1384
total : 5000  current step :  1385
total : 5000  current step :  1386
total : 5000  current step :  1387
total : 5000  current step :  1388
total : 5000  current step :  1389
total : 5000  current step :  1390
total : 5000  current step :  1391
total : 5000  current step :  1392
total : 5000  current step :  1393
total : 5000  current step :  1394
total : 5000  current step :  1395
total : 5000  current step :  1396
total : 5000  current step :  1397
total : 5000  current step :  1398
total : 5000  current step :  1399
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 1.5725. top1: 37.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 1.5725. top1: 37.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.93s. Loss: 1.5280. top1: 39.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 1.4437. top1: 45.83. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 1.4525. top1: 46.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 1.4414. top1: 48.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 1.4377. top1: 46.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.4403. top1: 48.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.4505. top1: 46.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.4432. top1: 47.57. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.4432. top1: 47.57. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.30it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.4526. top1: 47.19. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.30it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.4376. top1: 48.01. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.30it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.4369. top1: 47.66. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.30it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.4266. top1: 48.32. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.30it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.4323. top1: 47.99. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.30it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4213. top1: 49.38. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.30it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4188. top1: 50.20. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.30it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.4188. top1: 50.20. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.4156. top1: 50.00. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4160. top1: 49.48. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.4157. top1: 49.01. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4150. top1: 49.06. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4241. top1: 48.36. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.4175. top1: 48.30. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4132. top1: 48.23. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4093. top1: 48.57. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.4079. top1: 48.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4125. top1: 47.84. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.10it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4125. top1: 47.84. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4106. top1: 47.92. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4149. top1: 47.66. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.4137. top1: 47.63. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4125. top1: 47.60. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4134. top1: 47.48. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4029. top1: 48.34. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3857. top1: 49.81. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3717. top1: 51.01. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.22it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3717. top1: 51.01. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3571. top1: 52.32. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3465. top1: 53.12. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3325. top1: 54.22. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3199. top1: 55.35. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3110. top1: 56.01. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2996. top1: 57.03. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2886. top1: 57.93. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2796. top1: 58.78. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2695. top1: 59.59. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2594. top1: 60.44. top5: 100.00. :  54%|█████▍    | 34/63 [00:02<00:00, 30.37it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2594. top1: 60.44. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2499. top1: 61.25. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2414. top1: 62.02. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2335. top1: 62.77. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2260. top1: 63.41. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2185. top1: 64.03. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2119. top1: 64.62. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2075. top1: 64.95. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2008. top1: 65.50. top5: 100.00. :  70%|██████▉   | 44/63 [00:02<00:00, 41.49it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2008. top1: 65.50. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1951. top1: 65.98. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1895. top1: 66.49. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1836. top1: 66.99. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1776. top1: 67.52. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1738. top1: 67.76. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1688. top1: 68.21. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1645. top1: 68.54. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1590. top1: 68.96. top5: 100.00. :  83%|████████▎ | 52/63 [00:02<00:00, 48.02it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1590. top1: 68.96. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 53.95it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1554. top1: 69.26. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 53.95it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1526. top1: 69.35. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 53.95it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1504. top1: 69.55. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 53.95it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1504. top1: 69.55. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 22.49it/s]
total : 5000  current step :  1400
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1401/5000. LR: 0.0475. Data: 1.88s. Batch: 2.01s. S_Loss: 1.1334. T_Loss: 4.7049. Mask: 0.8750. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1401/5000. LR: 0.0475. Data: 1.88s. Batch: 2.01s. S_Loss: 1.1334. T_Loss: 4.7049. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:19,  2.01s/it]Train Iter: 1402/5000. LR: 0.0475. Data: 0.94s. Batch: 1.07s. S_Loss: 1.0196. T_Loss: 4.8382. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:19,  2.01s/it]Train Iter: 1402/5000. LR: 0.0475. Data: 0.94s. Batch: 1.07s. S_Loss: 1.0196. T_Loss: 4.8382. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:28,  1.10it/s]Train Iter: 1403/5000. LR: 0.0475. Data: 0.63s. Batch: 0.76s. S_Loss: 0.9792. T_Loss: 4.8376. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:28,  1.10it/s]Train Iter: 1403/5000. LR: 0.0475. Data: 0.63s. Batch: 0.76s. S_Loss: 0.9792. T_Loss: 4.8376. Mask: 0.9375. :   3%|▎         | 3/100 [00:02<00:53,  1.81it/s]Train Iter: 1404/5000. LR: 0.0475. Data: 0.47s. Batch: 0.60s. S_Loss: 0.9925. T_Loss: 4.7442. Mask: 0.9297. :   3%|▎         | 3/100 [00:02<00:53,  1.81it/s]Train Iter: 1404/5000. LR: 0.0475. Data: 0.47s. Batch: 0.60s. S_Loss: 0.9925. T_Loss: 4.7442. Mask: 0.9297. :   4%|▍         | 4/100 [00:02<00:36,  2.63it/s]Train Iter: 1405/5000. LR: 0.0475. Data: 0.38s. Batch: 0.55s. S_Loss: 0.9738. T_Loss: 4.5894. Mask: 0.9313. :   4%|▍         | 4/100 [00:02<00:36,  2.63it/s]Train Iter: 1405/5000. LR: 0.0475. Data: 0.38s. Batch: 0.55s. S_Loss: 0.9738. T_Loss: 4.5894. Mask: 0.9313. :   5%|▌         | 5/100 [00:02<00:35,  2.68it/s]Train Iter: 1406/5000. LR: 0.0475. Data: 0.32s. Batch: 0.48s. S_Loss: 0.9657. T_Loss: 4.5213. Mask: 0.9323. :   5%|▌         | 5/100 [00:02<00:35,  2.68it/s]Train Iter: 1406/5000. LR: 0.0475. Data: 0.32s. Batch: 0.48s. S_Loss: 0.9657. T_Loss: 4.5213. Mask: 0.9323. :   6%|▌         | 6/100 [00:02<00:27,  3.47it/s]Train Iter: 1407/5000. LR: 0.0475. Data: 0.27s. Batch: 0.43s. S_Loss: 0.9622. T_Loss: 4.4081. Mask: 0.9286. :   6%|▌         | 6/100 [00:02<00:27,  3.47it/s]Train Iter: 1407/5000. LR: 0.0475. Data: 0.27s. Batch: 0.43s. S_Loss: 0.9622. T_Loss: 4.4081. Mask: 0.9286. :   7%|▋         | 7/100 [00:02<00:21,  4.28it/s]Train Iter: 1408/5000. LR: 0.0475. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9652. T_Loss: 4.4442. Mask: 0.9258. :   7%|▋         | 7/100 [00:03<00:21,  4.28it/s]Train Iter: 1408/5000. LR: 0.0475. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9652. T_Loss: 4.4442. Mask: 0.9258. :   8%|▊         | 8/100 [00:03<00:18,  5.03it/s]Train Iter: 1409/5000. LR: 0.0475. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9657. T_Loss: 4.4626. Mask: 0.9340. :   8%|▊         | 8/100 [00:03<00:18,  5.03it/s]Train Iter: 1409/5000. LR: 0.0475. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9657. T_Loss: 4.4626. Mask: 0.9340. :   9%|▉         | 9/100 [00:03<00:19,  4.56it/s]Train Iter: 1410/5000. LR: 0.0474. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9766. T_Loss: 4.5783. Mask: 0.9406. :   9%|▉         | 9/100 [00:03<00:19,  4.56it/s]Train Iter: 1410/5000. LR: 0.0474. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9766. T_Loss: 4.5783. Mask: 0.9406. :  10%|█         | 10/100 [00:03<00:17,  5.26it/s]Train Iter: 1411/5000. LR: 0.0474. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9785. T_Loss: 4.5051. Mask: 0.9318. :  10%|█         | 10/100 [00:03<00:17,  5.26it/s]Train Iter: 1411/5000. LR: 0.0474. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9785. T_Loss: 4.5051. Mask: 0.9318. :  11%|█         | 11/100 [00:03<00:15,  5.92it/s]Train Iter: 1412/5000. LR: 0.0474. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9844. T_Loss: 4.4359. Mask: 0.9219. :  11%|█         | 11/100 [00:03<00:15,  5.92it/s]Train Iter: 1412/5000. LR: 0.0474. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9844. T_Loss: 4.4359. Mask: 0.9219. :  12%|█▏        | 12/100 [00:03<00:13,  6.41it/s]Train Iter: 1413/5000. LR: 0.0474. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9828. T_Loss: 4.4020. Mask: 0.9207. :  12%|█▏        | 12/100 [00:03<00:13,  6.41it/s]Train Iter: 1413/5000. LR: 0.0474. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9828. T_Loss: 4.4020. Mask: 0.9207. :  13%|█▎        | 13/100 [00:03<00:12,  6.74it/s]Train Iter: 1414/5000. LR: 0.0474. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9935. T_Loss: 4.4493. Mask: 0.9219. :  13%|█▎        | 13/100 [00:04<00:12,  6.74it/s]Train Iter: 1414/5000. LR: 0.0474. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9935. T_Loss: 4.4493. Mask: 0.9219. :  14%|█▍        | 14/100 [00:04<00:12,  7.07it/s]Train Iter: 1415/5000. LR: 0.0474. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0009. T_Loss: 4.4997. Mask: 0.9250. :  14%|█▍        | 14/100 [00:04<00:12,  7.07it/s]Train Iter: 1415/5000. LR: 0.0474. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0009. T_Loss: 4.4997. Mask: 0.9250. :  15%|█▌        | 15/100 [00:04<00:16,  5.17it/s]Train Iter: 1416/5000. LR: 0.0474. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9936. T_Loss: 4.4482. Mask: 0.9277. :  15%|█▌        | 15/100 [00:04<00:16,  5.17it/s]Train Iter: 1416/5000. LR: 0.0474. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9936. T_Loss: 4.4482. Mask: 0.9277. :  16%|█▌        | 16/100 [00:04<00:14,  5.71it/s]Train Iter: 1417/5000. LR: 0.0474. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9914. T_Loss: 4.4062. Mask: 0.9283. :  16%|█▌        | 16/100 [00:04<00:14,  5.71it/s]Train Iter: 1417/5000. LR: 0.0474. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9914. T_Loss: 4.4062. Mask: 0.9283. :  17%|█▋        | 17/100 [00:04<00:13,  6.25it/s]Train Iter: 1418/5000. LR: 0.0474. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9917. T_Loss: 4.4175. Mask: 0.9323. :  17%|█▋        | 17/100 [00:04<00:13,  6.25it/s]Train Iter: 1418/5000. LR: 0.0474. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9917. T_Loss: 4.4175. Mask: 0.9323. :  18%|█▊        | 18/100 [00:04<00:12,  6.65it/s]Train Iter: 1419/5000. LR: 0.0474. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9986. T_Loss: 4.4701. Mask: 0.9309. :  18%|█▊        | 18/100 [00:05<00:12,  6.65it/s]Train Iter: 1419/5000. LR: 0.0474. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9986. T_Loss: 4.4701. Mask: 0.9309. :  19%|█▉        | 19/100 [00:05<00:16,  5.01it/s]Train Iter: 1420/5000. LR: 0.0474. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9934. T_Loss: 4.4803. Mask: 0.9328. :  19%|█▉        | 19/100 [00:05<00:16,  5.01it/s]Train Iter: 1420/5000. LR: 0.0474. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9934. T_Loss: 4.4803. Mask: 0.9328. :  20%|██        | 20/100 [00:05<00:14,  5.56it/s]Train Iter: 1421/5000. LR: 0.0474. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9911. T_Loss: 4.4952. Mask: 0.9360. :  20%|██        | 20/100 [00:05<00:14,  5.56it/s]Train Iter: 1421/5000. LR: 0.0474. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9911. T_Loss: 4.4952. Mask: 0.9360. :  21%|██        | 21/100 [00:05<00:12,  6.19it/s]Train Iter: 1422/5000. LR: 0.0473. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9930. T_Loss: 4.5257. Mask: 0.9361. :  21%|██        | 21/100 [00:05<00:12,  6.19it/s]Train Iter: 1422/5000. LR: 0.0473. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9930. T_Loss: 4.5257. Mask: 0.9361. :  22%|██▏       | 22/100 [00:05<00:11,  6.53it/s]Train Iter: 1423/5000. LR: 0.0473. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9924. T_Loss: 4.5320. Mask: 0.9334. :  22%|██▏       | 22/100 [00:05<00:11,  6.53it/s]Train Iter: 1423/5000. LR: 0.0473. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9924. T_Loss: 4.5320. Mask: 0.9334. :  23%|██▎       | 23/100 [00:05<00:11,  6.98it/s]Train Iter: 1424/5000. LR: 0.0473. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9886. T_Loss: 4.4872. Mask: 0.9310. :  23%|██▎       | 23/100 [00:05<00:11,  6.98it/s]Train Iter: 1424/5000. LR: 0.0473. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9886. T_Loss: 4.4872. Mask: 0.9310. :  24%|██▍       | 24/100 [00:05<00:10,  7.42it/s]Train Iter: 1425/5000. LR: 0.0473. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9902. T_Loss: 4.5300. Mask: 0.9313. :  24%|██▍       | 24/100 [00:05<00:10,  7.42it/s]Train Iter: 1425/5000. LR: 0.0473. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9902. T_Loss: 4.5300. Mask: 0.9313. :  25%|██▌       | 25/100 [00:05<00:09,  7.71it/s]total : 5000  current step :  1401
total : 5000  current step :  1402
total : 5000  current step :  1403
total : 5000  current step :  1404
total : 5000  current step :  1405
total : 5000  current step :  1406
total : 5000  current step :  1407
total : 5000  current step :  1408
total : 5000  current step :  1409
total : 5000  current step :  1410
total : 5000  current step :  1411
total : 5000  current step :  1412
total : 5000  current step :  1413
total : 5000  current step :  1414
total : 5000  current step :  1415
total : 5000  current step :  1416
total : 5000  current step :  1417
total : 5000  current step :  1418
total : 5000  current step :  1419
total : 5000  current step :  1420
total : 5000  current step :  1421
total : 5000  current step :  1422
total : 5000  current step :  1423
total : 5000  current step :  1424
total : 5000  current step :  1425
Train Iter: 1426/5000. LR: 0.0473. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9866. T_Loss: 4.5157. Mask: 0.9327. :  25%|██▌       | 25/100 [00:07<00:09,  7.71it/s]Train Iter: 1426/5000. LR: 0.0473. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9866. T_Loss: 4.5157. Mask: 0.9327. :  26%|██▌       | 26/100 [00:07<00:48,  1.51it/s]Train Iter: 1427/5000. LR: 0.0473. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9863. T_Loss: 4.5308. Mask: 0.9306. :  26%|██▌       | 26/100 [00:07<00:48,  1.51it/s]Train Iter: 1427/5000. LR: 0.0473. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9863. T_Loss: 4.5308. Mask: 0.9306. :  27%|██▋       | 27/100 [00:07<00:36,  1.98it/s]Train Iter: 1428/5000. LR: 0.0473. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9897. T_Loss: 4.5592. Mask: 0.9308. :  27%|██▋       | 27/100 [00:07<00:36,  1.98it/s]Train Iter: 1428/5000. LR: 0.0473. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9897. T_Loss: 4.5592. Mask: 0.9308. :  28%|██▊       | 28/100 [00:07<00:27,  2.57it/s]Train Iter: 1429/5000. LR: 0.0473. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9877. T_Loss: 4.5824. Mask: 0.9321. :  28%|██▊       | 28/100 [00:08<00:27,  2.57it/s]Train Iter: 1429/5000. LR: 0.0473. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9877. T_Loss: 4.5824. Mask: 0.9321. :  29%|██▉       | 29/100 [00:08<00:22,  3.14it/s]Train Iter: 1430/5000. LR: 0.0473. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9865. T_Loss: 4.6055. Mask: 0.9344. :  29%|██▉       | 29/100 [00:08<00:22,  3.14it/s]Train Iter: 1430/5000. LR: 0.0473. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9865. T_Loss: 4.6055. Mask: 0.9344. :  30%|███       | 30/100 [00:08<00:18,  3.85it/s]Train Iter: 1431/5000. LR: 0.0473. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9821. T_Loss: 4.6208. Mask: 0.9365. :  30%|███       | 30/100 [00:08<00:18,  3.85it/s]Train Iter: 1431/5000. LR: 0.0473. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9821. T_Loss: 4.6208. Mask: 0.9365. :  31%|███       | 31/100 [00:08<00:15,  4.59it/s]Train Iter: 1432/5000. LR: 0.0473. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9817. T_Loss: 4.6276. Mask: 0.9346. :  31%|███       | 31/100 [00:08<00:15,  4.59it/s]Train Iter: 1432/5000. LR: 0.0473. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9817. T_Loss: 4.6276. Mask: 0.9346. :  32%|███▏      | 32/100 [00:08<00:12,  5.35it/s]Train Iter: 1433/5000. LR: 0.0472. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9792. T_Loss: 4.6421. Mask: 0.9347. :  32%|███▏      | 32/100 [00:08<00:12,  5.35it/s]Train Iter: 1433/5000. LR: 0.0472. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9792. T_Loss: 4.6421. Mask: 0.9347. :  33%|███▎      | 33/100 [00:08<00:11,  5.94it/s]Train Iter: 1434/5000. LR: 0.0472. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.6409. Mask: 0.9320. :  33%|███▎      | 33/100 [00:08<00:11,  5.94it/s]Train Iter: 1434/5000. LR: 0.0472. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.6409. Mask: 0.9320. :  34%|███▍      | 34/100 [00:08<00:10,  6.55it/s]Train Iter: 1435/5000. LR: 0.0472. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9800. T_Loss: 4.6487. Mask: 0.9313. :  34%|███▍      | 34/100 [00:09<00:10,  6.55it/s]Train Iter: 1435/5000. LR: 0.0472. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9800. T_Loss: 4.6487. Mask: 0.9313. :  35%|███▌      | 35/100 [00:09<00:13,  4.82it/s]Train Iter: 1436/5000. LR: 0.0472. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9794. T_Loss: 4.6472. Mask: 0.9297. :  35%|███▌      | 35/100 [00:09<00:13,  4.82it/s]Train Iter: 1436/5000. LR: 0.0472. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9794. T_Loss: 4.6472. Mask: 0.9297. :  36%|███▌      | 36/100 [00:09<00:11,  5.61it/s]Train Iter: 1437/5000. LR: 0.0472. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9799. T_Loss: 4.6697. Mask: 0.9307. :  36%|███▌      | 36/100 [00:09<00:11,  5.61it/s]Train Iter: 1437/5000. LR: 0.0472. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9799. T_Loss: 4.6697. Mask: 0.9307. :  37%|███▋      | 37/100 [00:09<00:10,  6.19it/s]Train Iter: 1438/5000. LR: 0.0472. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9823. T_Loss: 4.6829. Mask: 0.9293. :  37%|███▋      | 37/100 [00:09<00:10,  6.19it/s]Train Iter: 1438/5000. LR: 0.0472. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9823. T_Loss: 4.6829. Mask: 0.9293. :  38%|███▊      | 38/100 [00:09<00:09,  6.65it/s]Train Iter: 1439/5000. LR: 0.0472. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9821. T_Loss: 4.6869. Mask: 0.9295. :  38%|███▊      | 38/100 [00:09<00:09,  6.65it/s]Train Iter: 1439/5000. LR: 0.0472. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9821. T_Loss: 4.6869. Mask: 0.9295. :  39%|███▉      | 39/100 [00:09<00:10,  5.58it/s]Train Iter: 1440/5000. LR: 0.0472. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9882. T_Loss: 4.7082. Mask: 0.9266. :  39%|███▉      | 39/100 [00:09<00:10,  5.58it/s]Train Iter: 1440/5000. LR: 0.0472. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9882. T_Loss: 4.7082. Mask: 0.9266. :  40%|████      | 40/100 [00:09<00:09,  6.22it/s]Train Iter: 1441/5000. LR: 0.0472. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9900. T_Loss: 4.7215. Mask: 0.9284. :  40%|████      | 40/100 [00:09<00:09,  6.22it/s]Train Iter: 1441/5000. LR: 0.0472. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9900. T_Loss: 4.7215. Mask: 0.9284. :  41%|████      | 41/100 [00:09<00:08,  6.90it/s]Train Iter: 1442/5000. LR: 0.0472. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9902. T_Loss: 4.7113. Mask: 0.9271. :  41%|████      | 41/100 [00:09<00:08,  6.90it/s]Train Iter: 1442/5000. LR: 0.0472. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9902. T_Loss: 4.7113. Mask: 0.9271. :  42%|████▏     | 42/100 [00:09<00:07,  7.37it/s]Train Iter: 1443/5000. LR: 0.0472. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9917. T_Loss: 4.7253. Mask: 0.9281. :  42%|████▏     | 42/100 [00:10<00:07,  7.37it/s]Train Iter: 1443/5000. LR: 0.0472. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9917. T_Loss: 4.7253. Mask: 0.9281. :  43%|████▎     | 43/100 [00:10<00:07,  7.70it/s]Train Iter: 1444/5000. LR: 0.0472. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9940. T_Loss: 4.7005. Mask: 0.9276. :  43%|████▎     | 43/100 [00:10<00:07,  7.70it/s]Train Iter: 1444/5000. LR: 0.0472. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9940. T_Loss: 4.7005. Mask: 0.9276. :  44%|████▍     | 44/100 [00:10<00:07,  7.94it/s]Train Iter: 1445/5000. LR: 0.0471. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9950. T_Loss: 4.6876. Mask: 0.9278. :  44%|████▍     | 44/100 [00:10<00:07,  7.94it/s]Train Iter: 1445/5000. LR: 0.0471. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9950. T_Loss: 4.6876. Mask: 0.9278. :  45%|████▌     | 45/100 [00:10<00:07,  7.48it/s]Train Iter: 1446/5000. LR: 0.0471. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9947. T_Loss: 4.6918. Mask: 0.9280. :  45%|████▌     | 45/100 [00:10<00:07,  7.48it/s]Train Iter: 1446/5000. LR: 0.0471. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9947. T_Loss: 4.6918. Mask: 0.9280. :  46%|████▌     | 46/100 [00:10<00:06,  7.76it/s]Train Iter: 1447/5000. LR: 0.0471. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9988. T_Loss: 4.6950. Mask: 0.9269. :  46%|████▌     | 46/100 [00:10<00:06,  7.76it/s]Train Iter: 1447/5000. LR: 0.0471. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9988. T_Loss: 4.6950. Mask: 0.9269. :  47%|████▋     | 47/100 [00:10<00:06,  7.95it/s]Train Iter: 1448/5000. LR: 0.0471. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9969. T_Loss: 4.6825. Mask: 0.9271. :  47%|████▋     | 47/100 [00:10<00:06,  7.95it/s]Train Iter: 1448/5000. LR: 0.0471. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9969. T_Loss: 4.6825. Mask: 0.9271. :  48%|████▊     | 48/100 [00:10<00:06,  7.95it/s]Train Iter: 1449/5000. LR: 0.0471. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0000. T_Loss: 4.6785. Mask: 0.9260. :  48%|████▊     | 48/100 [00:10<00:06,  7.95it/s]Train Iter: 1449/5000. LR: 0.0471. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0000. T_Loss: 4.6785. Mask: 0.9260. :  49%|████▉     | 49/100 [00:10<00:08,  5.97it/s]Train Iter: 1450/5000. LR: 0.0471. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0022. T_Loss: 4.6648. Mask: 0.9244. :  49%|████▉     | 49/100 [00:11<00:08,  5.97it/s]total : 5000  current step :  1426
total : 5000  current step :  1427
total : 5000  current step :  1428
total : 5000  current step :  1429
total : 5000  current step :  1430
total : 5000  current step :  1431
total : 5000  current step :  1432
total : 5000  current step :  1433
total : 5000  current step :  1434
total : 5000  current step :  1435
total : 5000  current step :  1436
total : 5000  current step :  1437
total : 5000  current step :  1438
total : 5000  current step :  1439
total : 5000  current step :  1440
total : 5000  current step :  1441
total : 5000  current step :  1442
total : 5000  current step :  1443
total : 5000  current step :  1444
total : 5000  current step :  1445
total : 5000  current step :  1446
total : 5000  current step :  1447
total : 5000  current step :  1448
total : 5000  current step :  1449
total : 5000  current step :  1450
Train Iter: 1451/5000. LR: 0.0471. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0031. T_Loss: 4.6591. Mask: 0.9246. :  50%|█████     | 50/100 [00:13<00:08,  5.97it/s]Train Iter: 1451/5000. LR: 0.0471. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0031. T_Loss: 4.6591. Mask: 0.9246. :  51%|█████     | 51/100 [00:13<00:31,  1.57it/s]Train Iter: 1452/5000. LR: 0.0471. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0055. T_Loss: 4.6425. Mask: 0.9243. :  51%|█████     | 51/100 [00:13<00:31,  1.57it/s]Train Iter: 1452/5000. LR: 0.0471. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0055. T_Loss: 4.6425. Mask: 0.9243. :  52%|█████▏    | 52/100 [00:13<00:24,  1.92it/s]Train Iter: 1453/5000. LR: 0.0471. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0086. T_Loss: 4.6387. Mask: 0.9228. :  52%|█████▏    | 52/100 [00:13<00:24,  1.92it/s]Train Iter: 1453/5000. LR: 0.0471. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0086. T_Loss: 4.6387. Mask: 0.9228. :  53%|█████▎    | 53/100 [00:13<00:19,  2.42it/s]Train Iter: 1454/5000. LR: 0.0471. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0059. T_Loss: 4.6197. Mask: 0.9236. :  53%|█████▎    | 53/100 [00:13<00:19,  2.42it/s]Train Iter: 1454/5000. LR: 0.0471. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0059. T_Loss: 4.6197. Mask: 0.9236. :  54%|█████▍    | 54/100 [00:13<00:15,  3.00it/s]Train Iter: 1455/5000. LR: 0.0471. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0077. T_Loss: 4.6159. Mask: 0.9233. :  54%|█████▍    | 54/100 [00:13<00:15,  3.00it/s]Train Iter: 1455/5000. LR: 0.0471. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0077. T_Loss: 4.6159. Mask: 0.9233. :  55%|█████▌    | 55/100 [00:13<00:12,  3.70it/s]Train Iter: 1456/5000. LR: 0.0471. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0088. T_Loss: 4.6260. Mask: 0.9235. :  55%|█████▌    | 55/100 [00:13<00:12,  3.70it/s]Train Iter: 1456/5000. LR: 0.0471. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0088. T_Loss: 4.6260. Mask: 0.9235. :  56%|█████▌    | 56/100 [00:13<00:10,  4.38it/s]Train Iter: 1457/5000. LR: 0.0470. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0102. T_Loss: 4.6449. Mask: 0.9249. :  56%|█████▌    | 56/100 [00:14<00:10,  4.38it/s]Train Iter: 1457/5000. LR: 0.0470. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0102. T_Loss: 4.6449. Mask: 0.9249. :  57%|█████▋    | 57/100 [00:14<00:08,  5.00it/s]Train Iter: 1458/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0102. T_Loss: 4.6303. Mask: 0.9256. :  57%|█████▋    | 57/100 [00:14<00:08,  5.00it/s]Train Iter: 1458/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0102. T_Loss: 4.6303. Mask: 0.9256. :  58%|█████▊    | 58/100 [00:14<00:07,  5.42it/s]Train Iter: 1459/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0090. T_Loss: 4.6172. Mask: 0.9258. :  58%|█████▊    | 58/100 [00:14<00:07,  5.42it/s]Train Iter: 1459/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0090. T_Loss: 4.6172. Mask: 0.9258. :  59%|█████▉    | 59/100 [00:14<00:08,  4.79it/s]Train Iter: 1460/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0095. T_Loss: 4.6294. Mask: 0.9260. :  59%|█████▉    | 59/100 [00:14<00:08,  4.79it/s]Train Iter: 1461/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0085. T_Loss: 4.6138. Mask: 0.9242. :  60%|██████    | 60/100 [00:14<00:08,  4.79it/s]Train Iter: 1461/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0085. T_Loss: 4.6138. Mask: 0.9242. :  61%|██████    | 61/100 [00:14<00:05,  6.70it/s]Train Iter: 1462/5000. LR: 0.0470. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0095. T_Loss: 4.6187. Mask: 0.9249. :  61%|██████    | 61/100 [00:14<00:05,  6.70it/s]Train Iter: 1463/5000. LR: 0.0470. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0095. T_Loss: 4.6155. Mask: 0.9246. :  62%|██████▏   | 62/100 [00:14<00:05,  6.70it/s]Train Iter: 1463/5000. LR: 0.0470. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0095. T_Loss: 4.6155. Mask: 0.9246. :  63%|██████▎   | 63/100 [00:14<00:04,  8.09it/s]Train Iter: 1464/5000. LR: 0.0470. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0102. T_Loss: 4.6050. Mask: 0.9248. :  63%|██████▎   | 63/100 [00:14<00:04,  8.09it/s]Train Iter: 1464/5000. LR: 0.0470. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0102. T_Loss: 4.6050. Mask: 0.9248. :  64%|██████▍   | 64/100 [00:14<00:04,  7.80it/s]Train Iter: 1465/5000. LR: 0.0470. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0100. T_Loss: 4.5977. Mask: 0.9245. :  64%|██████▍   | 64/100 [00:15<00:04,  7.80it/s]Train Iter: 1465/5000. LR: 0.0470. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0100. T_Loss: 4.5977. Mask: 0.9245. :  65%|██████▌   | 65/100 [00:15<00:05,  6.32it/s]Train Iter: 1466/5000. LR: 0.0470. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0104. T_Loss: 4.6102. Mask: 0.9252. :  65%|██████▌   | 65/100 [00:15<00:05,  6.32it/s]Train Iter: 1466/5000. LR: 0.0470. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0104. T_Loss: 4.6102. Mask: 0.9252. :  66%|██████▌   | 66/100 [00:15<00:05,  6.66it/s]Train Iter: 1467/5000. LR: 0.0470. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0098. T_Loss: 4.6007. Mask: 0.9240. :  66%|██████▌   | 66/100 [00:15<00:05,  6.66it/s]Train Iter: 1467/5000. LR: 0.0470. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0098. T_Loss: 4.6007. Mask: 0.9240. :  67%|██████▋   | 67/100 [00:15<00:04,  6.97it/s]Train Iter: 1468/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0092. T_Loss: 4.6085. Mask: 0.9242. :  67%|██████▋   | 67/100 [00:15<00:04,  6.97it/s]Train Iter: 1468/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0092. T_Loss: 4.6085. Mask: 0.9242. :  68%|██████▊   | 68/100 [00:15<00:04,  7.09it/s]Train Iter: 1469/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0075. T_Loss: 4.6056. Mask: 0.9253. :  68%|██████▊   | 68/100 [00:15<00:04,  7.09it/s]Train Iter: 1469/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0075. T_Loss: 4.6056. Mask: 0.9253. :  69%|██████▉   | 69/100 [00:15<00:05,  5.48it/s]Train Iter: 1470/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0068. T_Loss: 4.6029. Mask: 0.9254. :  69%|██████▉   | 69/100 [00:16<00:05,  5.48it/s]Train Iter: 1470/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0068. T_Loss: 4.6029. Mask: 0.9254. :  70%|███████   | 70/100 [00:16<00:04,  6.02it/s]Train Iter: 1471/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0070. T_Loss: 4.5962. Mask: 0.9243. :  70%|███████   | 70/100 [00:16<00:04,  6.02it/s]Train Iter: 1471/5000. LR: 0.0469. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0070. T_Loss: 4.5962. Mask: 0.9243. :  71%|███████   | 71/100 [00:16<00:04,  6.61it/s]Train Iter: 1472/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0058. T_Loss: 4.5943. Mask: 0.9245. :  71%|███████   | 71/100 [00:16<00:04,  6.61it/s]Train Iter: 1472/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0058. T_Loss: 4.5943. Mask: 0.9245. :  72%|███████▏  | 72/100 [00:16<00:03,  7.12it/s]Train Iter: 1473/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0072. T_Loss: 4.6016. Mask: 0.9229. :  72%|███████▏  | 72/100 [00:16<00:03,  7.12it/s]Train Iter: 1473/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0072. T_Loss: 4.6016. Mask: 0.9229. :  73%|███████▎  | 73/100 [00:16<00:03,  7.34it/s]Train Iter: 1474/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0068. T_Loss: 4.5975. Mask: 0.9236. :  73%|███████▎  | 73/100 [00:16<00:03,  7.34it/s]Train Iter: 1474/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0068. T_Loss: 4.5975. Mask: 0.9236. :  74%|███████▍  | 74/100 [00:16<00:03,  7.66it/s]Train Iter: 1475/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0079. T_Loss: 4.6074. Mask: 0.9225. :  74%|███████▍  | 74/100 [00:16<00:03,  7.66it/s]Train Iter: 1475/5000. LR: 0.0469. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0079. T_Loss: 4.6074. Mask: 0.9225. :  75%|███████▌  | 75/100 [00:16<00:03,  6.31it/s]total : 5000  current step :  1451
total : 5000  current step :  1452
total : 5000  current step :  1453
total : 5000  current step :  1454
total : 5000  current step :  1455
total : 5000  current step :  1456
total : 5000  current step :  1457
total : 5000  current step :  1458
total : 5000  current step :  1459
total : 5000  current step :  1460
total : 5000  current step :  1461
total : 5000  current step :  1462
total : 5000  current step :  1463
total : 5000  current step :  1464
total : 5000  current step :  1465
total : 5000  current step :  1466
total : 5000  current step :  1467
total : 5000  current step :  1468
total : 5000  current step :  1469
total : 5000  current step :  1470
total : 5000  current step :  1471
total : 5000  current step :  1472
total : 5000  current step :  1473
total : 5000  current step :  1474
total : 5000  current step :  1475
Train Iter: 1476/5000. LR: 0.0469. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0104. T_Loss: 4.6195. Mask: 0.9231. :  75%|███████▌  | 75/100 [00:18<00:03,  6.31it/s]Train Iter: 1476/5000. LR: 0.0469. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0104. T_Loss: 4.6195. Mask: 0.9231. :  76%|███████▌  | 76/100 [00:18<00:18,  1.33it/s]Train Iter: 1477/5000. LR: 0.0469. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0103. T_Loss: 4.6194. Mask: 0.9229. :  76%|███████▌  | 76/100 [00:19<00:18,  1.33it/s]Train Iter: 1477/5000. LR: 0.0469. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0103. T_Loss: 4.6194. Mask: 0.9229. :  77%|███████▋  | 77/100 [00:19<00:13,  1.74it/s]Train Iter: 1478/5000. LR: 0.0469. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0104. T_Loss: 4.6221. Mask: 0.9223. :  77%|███████▋  | 77/100 [00:19<00:13,  1.74it/s]Train Iter: 1478/5000. LR: 0.0469. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0104. T_Loss: 4.6221. Mask: 0.9223. :  78%|███████▊  | 78/100 [00:19<00:09,  2.25it/s]Train Iter: 1479/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0114. T_Loss: 4.6330. Mask: 0.9225. :  78%|███████▊  | 78/100 [00:19<00:09,  2.25it/s]Train Iter: 1479/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0114. T_Loss: 4.6330. Mask: 0.9225. :  79%|███████▉  | 79/100 [00:19<00:08,  2.57it/s]Train Iter: 1480/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0129. T_Loss: 4.6322. Mask: 0.9215. :  79%|███████▉  | 79/100 [00:19<00:08,  2.57it/s]Train Iter: 1480/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0129. T_Loss: 4.6322. Mask: 0.9215. :  80%|████████  | 80/100 [00:19<00:06,  3.23it/s]Train Iter: 1481/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0138. T_Loss: 4.6307. Mask: 0.9201. :  80%|████████  | 80/100 [00:19<00:06,  3.23it/s]Train Iter: 1481/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0138. T_Loss: 4.6307. Mask: 0.9201. :  81%|████████  | 81/100 [00:19<00:04,  3.95it/s]Train Iter: 1482/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0137. T_Loss: 4.6360. Mask: 0.9200. :  81%|████████  | 81/100 [00:19<00:04,  3.95it/s]Train Iter: 1482/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0137. T_Loss: 4.6360. Mask: 0.9200. :  82%|████████▏ | 82/100 [00:19<00:03,  4.70it/s]Train Iter: 1483/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0125. T_Loss: 4.6344. Mask: 0.9198. :  82%|████████▏ | 82/100 [00:19<00:03,  4.70it/s]Train Iter: 1483/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0125. T_Loss: 4.6344. Mask: 0.9198. :  83%|████████▎ | 83/100 [00:19<00:03,  5.37it/s]Train Iter: 1484/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0121. T_Loss: 4.6442. Mask: 0.9200. :  83%|████████▎ | 83/100 [00:20<00:03,  5.37it/s]Train Iter: 1484/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0121. T_Loss: 4.6442. Mask: 0.9200. :  84%|████████▍ | 84/100 [00:20<00:02,  6.02it/s]Train Iter: 1485/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0113. T_Loss: 4.6434. Mask: 0.9202. :  84%|████████▍ | 84/100 [00:20<00:02,  6.02it/s]Train Iter: 1485/5000. LR: 0.0468. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0113. T_Loss: 4.6434. Mask: 0.9202. :  85%|████████▌ | 85/100 [00:20<00:02,  6.36it/s]Train Iter: 1486/5000. LR: 0.0468. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0121. T_Loss: 4.6475. Mask: 0.9201. :  85%|████████▌ | 85/100 [00:20<00:02,  6.36it/s]Train Iter: 1486/5000. LR: 0.0468. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0121. T_Loss: 4.6475. Mask: 0.9201. :  86%|████████▌ | 86/100 [00:20<00:02,  6.99it/s]Train Iter: 1487/5000. LR: 0.0468. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0126. T_Loss: 4.6612. Mask: 0.9203. :  86%|████████▌ | 86/100 [00:20<00:02,  6.99it/s]Train Iter: 1487/5000. LR: 0.0468. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0126. T_Loss: 4.6612. Mask: 0.9203. :  87%|████████▋ | 87/100 [00:20<00:01,  7.30it/s]Train Iter: 1488/5000. LR: 0.0468. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0127. T_Loss: 4.6675. Mask: 0.9205. :  87%|████████▋ | 87/100 [00:20<00:01,  7.30it/s]Train Iter: 1488/5000. LR: 0.0468. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0127. T_Loss: 4.6675. Mask: 0.9205. :  88%|████████▊ | 88/100 [00:20<00:01,  7.54it/s]Train Iter: 1489/5000. LR: 0.0468. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0118. T_Loss: 4.6577. Mask: 0.9210. :  88%|████████▊ | 88/100 [00:20<00:01,  7.54it/s]Train Iter: 1489/5000. LR: 0.0468. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0118. T_Loss: 4.6577. Mask: 0.9210. :  89%|████████▉ | 89/100 [00:20<00:02,  5.48it/s]Train Iter: 1490/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0127. T_Loss: 4.6586. Mask: 0.9212. :  89%|████████▉ | 89/100 [00:20<00:02,  5.48it/s]Train Iter: 1490/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0127. T_Loss: 4.6586. Mask: 0.9212. :  90%|█████████ | 90/100 [00:20<00:01,  6.11it/s]Train Iter: 1491/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0124. T_Loss: 4.6593. Mask: 0.9220. :  90%|█████████ | 90/100 [00:21<00:01,  6.11it/s]Train Iter: 1491/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0124. T_Loss: 4.6593. Mask: 0.9220. :  91%|█████████ | 91/100 [00:21<00:01,  6.29it/s]Train Iter: 1492/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0121. T_Loss: 4.6635. Mask: 0.9222. :  91%|█████████ | 91/100 [00:21<00:01,  6.29it/s]Train Iter: 1492/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0121. T_Loss: 4.6635. Mask: 0.9222. :  92%|█████████▏| 92/100 [00:21<00:01,  6.70it/s]Train Iter: 1493/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0118. T_Loss: 4.6639. Mask: 0.9231. :  92%|█████████▏| 92/100 [00:21<00:01,  6.70it/s]Train Iter: 1493/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0118. T_Loss: 4.6639. Mask: 0.9231. :  93%|█████████▎| 93/100 [00:21<00:00,  7.03it/s]Train Iter: 1494/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0107. T_Loss: 4.6537. Mask: 0.9232. :  93%|█████████▎| 93/100 [00:21<00:00,  7.03it/s]Train Iter: 1494/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0107. T_Loss: 4.6537. Mask: 0.9232. :  94%|█████████▍| 94/100 [00:21<00:00,  7.35it/s]Train Iter: 1495/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0105. T_Loss: 4.6470. Mask: 0.9220. :  94%|█████████▍| 94/100 [00:21<00:00,  7.35it/s]Train Iter: 1495/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0105. T_Loss: 4.6470. Mask: 0.9220. :  95%|█████████▌| 95/100 [00:21<00:00,  5.47it/s]Train Iter: 1496/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0106. T_Loss: 4.6446. Mask: 0.9219. :  95%|█████████▌| 95/100 [00:21<00:00,  5.47it/s]Train Iter: 1496/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0106. T_Loss: 4.6446. Mask: 0.9219. :  96%|█████████▌| 96/100 [00:21<00:00,  5.89it/s]Train Iter: 1497/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0106. T_Loss: 4.6474. Mask: 0.9220. :  96%|█████████▌| 96/100 [00:22<00:00,  5.89it/s]Train Iter: 1497/5000. LR: 0.0467. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0106. T_Loss: 4.6474. Mask: 0.9220. :  97%|█████████▋| 97/100 [00:22<00:00,  6.49it/s]Train Iter: 1498/5000. LR: 0.0467. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0106. T_Loss: 4.6550. Mask: 0.9225. :  97%|█████████▋| 97/100 [00:22<00:00,  6.49it/s]Train Iter: 1498/5000. LR: 0.0467. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0106. T_Loss: 4.6550. Mask: 0.9225. :  98%|█████████▊| 98/100 [00:22<00:00,  6.98it/s]Train Iter: 1499/5000. LR: 0.0467. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0106. T_Loss: 4.6577. Mask: 0.9230. :  98%|█████████▊| 98/100 [00:22<00:00,  6.98it/s]Train Iter: 1499/5000. LR: 0.0467. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0106. T_Loss: 4.6577. Mask: 0.9230. :  99%|█████████▉| 99/100 [00:22<00:00,  7.13it/s]Train Iter: 1500/5000. LR: 0.0467. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0114. T_Loss: 4.6569. Mask: 0.9225. :  99%|█████████▉| 99/100 [00:22<00:00,  7.13it/s]Train Iter: 1500/5000. LR: 0.0467. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0114. T_Loss: 4.6569. Mask: 0.9225. : 100%|██████████| 100/100 [00:22<00:00,  7.69it/s]Train Iter: 1500/5000. LR: 0.0467. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0114. T_Loss: 4.6569. Mask: 0.9225. : 100%|██████████| 100/100 [00:22<00:00,  4.47it/s]
total : 5000  current step :  1476
total : 5000  current step :  1477
total : 5000  current step :  1478
total : 5000  current step :  1479
total : 5000  current step :  1480
total : 5000  current step :  1481
total : 5000  current step :  1482
total : 5000  current step :  1483
total : 5000  current step :  1484
total : 5000  current step :  1485
total : 5000  current step :  1486
total : 5000  current step :  1487
total : 5000  current step :  1488
total : 5000  current step :  1489
total : 5000  current step :  1490
total : 5000  current step :  1491
total : 5000  current step :  1492
total : 5000  current step :  1493
total : 5000  current step :  1494
total : 5000  current step :  1495
total : 5000  current step :  1496
total : 5000  current step :  1497
total : 5000  current step :  1498
total : 5000  current step :  1499
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 1.5439. top1: 50.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 1.5439. top1: 50.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 1.4803. top1: 54.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 1.3858. top1: 57.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 1.3952. top1: 57.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 1.3835. top1: 56.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.3812. top1: 55.73. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.3812. top1: 55.73. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.3893. top1: 56.70. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.4046. top1: 55.47. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.3938. top1: 55.90. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.4074. top1: 55.31. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.3875. top1: 56.25. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.3862. top1: 55.47. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.3752. top1: 56.01. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.3793. top1: 55.80. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.3674. top1: 56.88. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.3656. top1: 57.42. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.48it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.3656. top1: 57.42. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.3608. top1: 57.72. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.3610. top1: 57.12. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.3610. top1: 57.24. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.3586. top1: 57.97. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3711. top1: 56.99. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3637. top1: 57.24. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3579. top1: 57.34. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3533. top1: 57.42. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3514. top1: 57.25. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3575. top1: 56.85. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 14.06it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3575. top1: 56.85. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 24.69it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3549. top1: 57.18. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 24.69it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3594. top1: 56.92. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3577. top1: 56.79. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3562. top1: 56.67. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3572. top1: 56.65. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3494. top1: 57.23. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3341. top1: 58.43. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3217. top1: 59.38. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3090. top1: 60.18. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.3014. top1: 60.68. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2890. top1: 61.49. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.69it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2890. top1: 61.49. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2777. top1: 62.25. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2713. top1: 62.74. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2613. top1: 63.52. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2522. top1: 64.10. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2449. top1: 64.51. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2365. top1: 65.04. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2272. top1: 65.70. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2186. top1: 66.32. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2113. top1: 66.85. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 37.15it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2113. top1: 66.85. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.2047. top1: 67.29. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1978. top1: 67.77. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1916. top1: 68.11. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1858. top1: 68.56. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1827. top1: 68.75. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1768. top1: 69.29. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1724. top1: 69.69. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1675. top1: 70.02. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1624. top1: 70.45. top5: 100.00. :  73%|███████▎  | 46/63 [00:02<00:00, 44.71it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1624. top1: 70.45. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1568. top1: 70.87. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1538. top1: 71.00. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1493. top1: 71.23. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1459. top1: 71.45. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1407. top1: 71.82. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1379. top1: 72.03. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1361. top1: 72.08. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1341. top1: 72.25. top5: 100.00. :  87%|████████▋ | 55/63 [00:02<00:00, 50.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1341. top1: 72.25. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 24.28it/s]
total : 5000  current step :  1500
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1501/5000. LR: 0.0466. Data: 1.96s. Batch: 2.07s. S_Loss: 1.0498. T_Loss: 5.0842. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1501/5000. LR: 0.0466. Data: 1.96s. Batch: 2.07s. S_Loss: 1.0498. T_Loss: 5.0842. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:25,  2.07s/it]Train Iter: 1502/5000. LR: 0.0466. Data: 0.99s. Batch: 1.09s. S_Loss: 1.0444. T_Loss: 4.9255. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:25,  2.07s/it]Train Iter: 1502/5000. LR: 0.0466. Data: 0.99s. Batch: 1.09s. S_Loss: 1.0444. T_Loss: 4.9255. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:30,  1.09it/s]Train Iter: 1503/5000. LR: 0.0466. Data: 0.66s. Batch: 0.77s. S_Loss: 1.0088. T_Loss: 4.8493. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:30,  1.09it/s]Train Iter: 1503/5000. LR: 0.0466. Data: 0.66s. Batch: 0.77s. S_Loss: 1.0088. T_Loss: 4.8493. Mask: 0.9167. :   3%|▎         | 3/100 [00:02<00:54,  1.79it/s]Train Iter: 1504/5000. LR: 0.0466. Data: 0.50s. Batch: 0.61s. S_Loss: 1.0088. T_Loss: 4.9731. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:54,  1.79it/s]Train Iter: 1504/5000. LR: 0.0466. Data: 0.50s. Batch: 0.61s. S_Loss: 1.0088. T_Loss: 4.9731. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:37,  2.58it/s]Train Iter: 1505/5000. LR: 0.0466. Data: 0.40s. Batch: 0.51s. S_Loss: 1.0048. T_Loss: 5.0629. Mask: 0.9250. :   4%|▍         | 4/100 [00:02<00:37,  2.58it/s]Train Iter: 1505/5000. LR: 0.0466. Data: 0.40s. Batch: 0.51s. S_Loss: 1.0048. T_Loss: 5.0629. Mask: 0.9250. :   5%|▌         | 5/100 [00:02<00:27,  3.43it/s]Train Iter: 1506/5000. LR: 0.0466. Data: 0.33s. Batch: 0.45s. S_Loss: 1.0038. T_Loss: 5.1580. Mask: 0.9271. :   5%|▌         | 5/100 [00:02<00:27,  3.43it/s]Train Iter: 1506/5000. LR: 0.0466. Data: 0.33s. Batch: 0.45s. S_Loss: 1.0038. T_Loss: 5.1580. Mask: 0.9271. :   6%|▌         | 6/100 [00:02<00:21,  4.28it/s]Train Iter: 1507/5000. LR: 0.0466. Data: 0.29s. Batch: 0.40s. S_Loss: 1.0042. T_Loss: 5.0873. Mask: 0.9196. :   6%|▌         | 6/100 [00:02<00:21,  4.28it/s]Train Iter: 1507/5000. LR: 0.0466. Data: 0.29s. Batch: 0.40s. S_Loss: 1.0042. T_Loss: 5.0873. Mask: 0.9196. :   7%|▋         | 7/100 [00:02<00:18,  4.94it/s]Train Iter: 1508/5000. LR: 0.0466. Data: 0.25s. Batch: 0.37s. S_Loss: 0.9980. T_Loss: 5.0608. Mask: 0.9141. :   7%|▋         | 7/100 [00:02<00:18,  4.94it/s]Train Iter: 1508/5000. LR: 0.0466. Data: 0.25s. Batch: 0.37s. S_Loss: 0.9980. T_Loss: 5.0608. Mask: 0.9141. :   8%|▊         | 8/100 [00:02<00:16,  5.67it/s]Train Iter: 1509/5000. LR: 0.0466. Data: 0.22s. Batch: 0.35s. S_Loss: 1.0013. T_Loss: 5.1428. Mask: 0.9201. :   8%|▊         | 8/100 [00:03<00:16,  5.67it/s]Train Iter: 1509/5000. LR: 0.0466. Data: 0.22s. Batch: 0.35s. S_Loss: 1.0013. T_Loss: 5.1428. Mask: 0.9201. :   9%|▉         | 9/100 [00:03<00:18,  4.92it/s]Train Iter: 1510/5000. LR: 0.0466. Data: 0.20s. Batch: 0.33s. S_Loss: 0.9897. T_Loss: 5.0944. Mask: 0.9187. :   9%|▉         | 9/100 [00:03<00:18,  4.92it/s]Train Iter: 1510/5000. LR: 0.0466. Data: 0.20s. Batch: 0.33s. S_Loss: 0.9897. T_Loss: 5.0944. Mask: 0.9187. :  10%|█         | 10/100 [00:03<00:15,  5.70it/s]Train Iter: 1511/5000. LR: 0.0465. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9875. T_Loss: 5.0472. Mask: 0.9148. :  10%|█         | 10/100 [00:03<00:15,  5.70it/s]Train Iter: 1511/5000. LR: 0.0465. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9875. T_Loss: 5.0472. Mask: 0.9148. :  11%|█         | 11/100 [00:03<00:14,  6.14it/s]Train Iter: 1512/5000. LR: 0.0465. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9878. T_Loss: 5.0266. Mask: 0.9115. :  11%|█         | 11/100 [00:03<00:14,  6.14it/s]Train Iter: 1512/5000. LR: 0.0465. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9878. T_Loss: 5.0266. Mask: 0.9115. :  12%|█▏        | 12/100 [00:03<00:13,  6.45it/s]Train Iter: 1513/5000. LR: 0.0465. Data: 0.16s. Batch: 0.28s. S_Loss: 0.9893. T_Loss: 5.0685. Mask: 0.9111. :  12%|█▏        | 12/100 [00:03<00:13,  6.45it/s]Train Iter: 1513/5000. LR: 0.0465. Data: 0.16s. Batch: 0.28s. S_Loss: 0.9893. T_Loss: 5.0685. Mask: 0.9111. :  13%|█▎        | 13/100 [00:03<00:12,  7.08it/s]Train Iter: 1514/5000. LR: 0.0465. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9862. T_Loss: 5.0785. Mask: 0.9152. :  13%|█▎        | 13/100 [00:03<00:12,  7.08it/s]Train Iter: 1514/5000. LR: 0.0465. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9862. T_Loss: 5.0785. Mask: 0.9152. :  14%|█▍        | 14/100 [00:03<00:11,  7.64it/s]Train Iter: 1515/5000. LR: 0.0465. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9794. T_Loss: 4.9770. Mask: 0.9125. :  14%|█▍        | 14/100 [00:04<00:11,  7.64it/s]Train Iter: 1515/5000. LR: 0.0465. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9794. T_Loss: 4.9770. Mask: 0.9125. :  15%|█▌        | 15/100 [00:04<00:16,  5.16it/s]Train Iter: 1516/5000. LR: 0.0465. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9768. T_Loss: 4.9900. Mask: 0.9160. :  15%|█▌        | 15/100 [00:04<00:16,  5.16it/s]Train Iter: 1516/5000. LR: 0.0465. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9768. T_Loss: 4.9900. Mask: 0.9160. :  16%|█▌        | 16/100 [00:04<00:14,  5.81it/s]Train Iter: 1517/5000. LR: 0.0465. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9726. T_Loss: 5.0007. Mask: 0.9210. :  16%|█▌        | 16/100 [00:04<00:14,  5.81it/s]Train Iter: 1517/5000. LR: 0.0465. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9726. T_Loss: 5.0007. Mask: 0.9210. :  17%|█▋        | 17/100 [00:04<00:13,  6.35it/s]Train Iter: 1518/5000. LR: 0.0465. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9758. T_Loss: 4.9833. Mask: 0.9219. :  17%|█▋        | 17/100 [00:04<00:13,  6.35it/s]Train Iter: 1518/5000. LR: 0.0465. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9758. T_Loss: 4.9833. Mask: 0.9219. :  18%|█▊        | 18/100 [00:04<00:12,  6.62it/s]Train Iter: 1519/5000. LR: 0.0465. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9771. T_Loss: 4.9929. Mask: 0.9243. :  18%|█▊        | 18/100 [00:04<00:12,  6.62it/s]Train Iter: 1519/5000. LR: 0.0465. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9771. T_Loss: 4.9929. Mask: 0.9243. :  19%|█▉        | 19/100 [00:04<00:11,  6.82it/s]Train Iter: 1520/5000. LR: 0.0465. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9769. T_Loss: 5.0435. Mask: 0.9250. :  19%|█▉        | 19/100 [00:04<00:11,  6.82it/s]Train Iter: 1520/5000. LR: 0.0465. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9769. T_Loss: 5.0435. Mask: 0.9250. :  20%|██        | 20/100 [00:04<00:11,  6.83it/s]Train Iter: 1521/5000. LR: 0.0465. Data: 0.10s. Batch: 0.23s. S_Loss: 0.9769. T_Loss: 5.0278. Mask: 0.9271. :  20%|██        | 20/100 [00:04<00:11,  6.83it/s]Train Iter: 1521/5000. LR: 0.0465. Data: 0.10s. Batch: 0.23s. S_Loss: 0.9769. T_Loss: 5.0278. Mask: 0.9271. :  21%|██        | 21/100 [00:04<00:10,  7.20it/s]Train Iter: 1522/5000. LR: 0.0464. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9750. T_Loss: 4.9759. Mask: 0.9261. :  21%|██        | 21/100 [00:05<00:10,  7.20it/s]Train Iter: 1522/5000. LR: 0.0464. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9750. T_Loss: 4.9759. Mask: 0.9261. :  22%|██▏       | 22/100 [00:05<00:10,  7.75it/s]Train Iter: 1523/5000. LR: 0.0464. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9741. T_Loss: 4.9631. Mask: 0.9253. :  22%|██▏       | 22/100 [00:05<00:10,  7.75it/s]Train Iter: 1524/5000. LR: 0.0464. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9697. T_Loss: 4.9659. Mask: 0.9271. :  23%|██▎       | 23/100 [00:05<00:09,  7.75it/s]Train Iter: 1524/5000. LR: 0.0464. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9697. T_Loss: 4.9659. Mask: 0.9271. :  24%|██▍       | 24/100 [00:05<00:08,  8.60it/s]Train Iter: 1525/5000. LR: 0.0464. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9644. T_Loss: 4.9119. Mask: 0.9275. :  24%|██▍       | 24/100 [00:05<00:08,  8.60it/s]Train Iter: 1525/5000. LR: 0.0464. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9644. T_Loss: 4.9119. Mask: 0.9275. :  25%|██▌       | 25/100 [00:05<00:12,  6.21it/s]total : 5000  current step :  1501
total : 5000  current step :  1502
total : 5000  current step :  1503
total : 5000  current step :  1504
total : 5000  current step :  1505
total : 5000  current step :  1506
total : 5000  current step :  1507
total : 5000  current step :  1508
total : 5000  current step :  1509
total : 5000  current step :  1510
total : 5000  current step :  1511
total : 5000  current step :  1512
total : 5000  current step :  1513
total : 5000  current step :  1514
total : 5000  current step :  1515
total : 5000  current step :  1516
total : 5000  current step :  1517
total : 5000  current step :  1518
total : 5000  current step :  1519
total : 5000  current step :  1520
total : 5000  current step :  1521
total : 5000  current step :  1522
total : 5000  current step :  1523
total : 5000  current step :  1524
total : 5000  current step :  1525
Train Iter: 1526/5000. LR: 0.0464. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9640. T_Loss: 4.8868. Mask: 0.9267. :  25%|██▌       | 25/100 [00:07<00:12,  6.21it/s]Train Iter: 1526/5000. LR: 0.0464. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9640. T_Loss: 4.8868. Mask: 0.9267. :  26%|██▌       | 26/100 [00:07<00:45,  1.61it/s]Train Iter: 1527/5000. LR: 0.0464. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9644. T_Loss: 4.8848. Mask: 0.9294. :  26%|██▌       | 26/100 [00:07<00:45,  1.61it/s]Train Iter: 1528/5000. LR: 0.0464. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9618. T_Loss: 4.8588. Mask: 0.9275. :  27%|██▋       | 27/100 [00:07<00:45,  1.61it/s]Train Iter: 1528/5000. LR: 0.0464. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9618. T_Loss: 4.8588. Mask: 0.9275. :  28%|██▊       | 28/100 [00:07<00:28,  2.52it/s]Train Iter: 1529/5000. LR: 0.0464. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9608. T_Loss: 4.8562. Mask: 0.9267. :  28%|██▊       | 28/100 [00:07<00:28,  2.52it/s]Train Iter: 1529/5000. LR: 0.0464. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9608. T_Loss: 4.8562. Mask: 0.9267. :  29%|██▉       | 29/100 [00:07<00:24,  2.88it/s]Train Iter: 1530/5000. LR: 0.0464. Data: 0.13s. Batch: 0.26s. S_Loss: 0.9585. T_Loss: 4.8465. Mask: 0.9281. :  29%|██▉       | 29/100 [00:07<00:24,  2.88it/s]Train Iter: 1531/5000. LR: 0.0464. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9607. T_Loss: 4.8452. Mask: 0.9274. :  30%|███       | 30/100 [00:08<00:24,  2.88it/s]Train Iter: 1531/5000. LR: 0.0464. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9607. T_Loss: 4.8452. Mask: 0.9274. :  31%|███       | 31/100 [00:08<00:17,  4.05it/s]Train Iter: 1532/5000. LR: 0.0463. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9584. T_Loss: 4.8374. Mask: 0.9268. :  31%|███       | 31/100 [00:08<00:17,  4.05it/s]Train Iter: 1532/5000. LR: 0.0463. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9584. T_Loss: 4.8374. Mask: 0.9268. :  32%|███▏      | 32/100 [00:08<00:14,  4.59it/s]Train Iter: 1533/5000. LR: 0.0463. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9573. T_Loss: 4.8435. Mask: 0.9280. :  32%|███▏      | 32/100 [00:08<00:14,  4.59it/s]Train Iter: 1533/5000. LR: 0.0463. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9573. T_Loss: 4.8435. Mask: 0.9280. :  33%|███▎      | 33/100 [00:08<00:12,  5.18it/s]Train Iter: 1534/5000. LR: 0.0463. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9555. T_Loss: 4.8097. Mask: 0.9292. :  33%|███▎      | 33/100 [00:08<00:12,  5.18it/s]Train Iter: 1534/5000. LR: 0.0463. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9555. T_Loss: 4.8097. Mask: 0.9292. :  34%|███▍      | 34/100 [00:08<00:11,  5.64it/s]Train Iter: 1535/5000. LR: 0.0463. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9592. T_Loss: 4.8041. Mask: 0.9277. :  34%|███▍      | 34/100 [00:08<00:11,  5.64it/s]Train Iter: 1535/5000. LR: 0.0463. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9592. T_Loss: 4.8041. Mask: 0.9277. :  35%|███▌      | 35/100 [00:08<00:13,  4.74it/s]Train Iter: 1536/5000. LR: 0.0463. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9592. T_Loss: 4.8059. Mask: 0.9280. :  35%|███▌      | 35/100 [00:08<00:13,  4.74it/s]Train Iter: 1536/5000. LR: 0.0463. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9592. T_Loss: 4.8059. Mask: 0.9280. :  36%|███▌      | 36/100 [00:08<00:11,  5.48it/s]Train Iter: 1537/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9636. T_Loss: 4.8191. Mask: 0.9291. :  36%|███▌      | 36/100 [00:08<00:11,  5.48it/s]Train Iter: 1537/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9636. T_Loss: 4.8191. Mask: 0.9291. :  37%|███▋      | 37/100 [00:08<00:10,  6.15it/s]Train Iter: 1538/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9653. T_Loss: 4.8540. Mask: 0.9293. :  37%|███▋      | 37/100 [00:09<00:10,  6.15it/s]Train Iter: 1538/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9653. T_Loss: 4.8540. Mask: 0.9293. :  38%|███▊      | 38/100 [00:09<00:09,  6.60it/s]Train Iter: 1539/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9654. T_Loss: 4.8501. Mask: 0.9287. :  38%|███▊      | 38/100 [00:09<00:09,  6.60it/s]Train Iter: 1539/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9654. T_Loss: 4.8501. Mask: 0.9287. :  39%|███▉      | 39/100 [00:09<00:11,  5.13it/s]Train Iter: 1540/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9686. T_Loss: 4.8397. Mask: 0.9273. :  39%|███▉      | 39/100 [00:09<00:11,  5.13it/s]Train Iter: 1540/5000. LR: 0.0463. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9686. T_Loss: 4.8397. Mask: 0.9273. :  40%|████      | 40/100 [00:09<00:10,  5.63it/s]Train Iter: 1541/5000. LR: 0.0463. Data: 0.10s. Batch: 0.23s. S_Loss: 0.9672. T_Loss: 4.8280. Mask: 0.9284. :  40%|████      | 40/100 [00:09<00:10,  5.63it/s]Train Iter: 1541/5000. LR: 0.0463. Data: 0.10s. Batch: 0.23s. S_Loss: 0.9672. T_Loss: 4.8280. Mask: 0.9284. :  41%|████      | 41/100 [00:09<00:09,  6.21it/s]Train Iter: 1542/5000. LR: 0.0462. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9670. T_Loss: 4.8220. Mask: 0.9278. :  41%|████      | 41/100 [00:09<00:09,  6.21it/s]Train Iter: 1542/5000. LR: 0.0462. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9670. T_Loss: 4.8220. Mask: 0.9278. :  42%|████▏     | 42/100 [00:09<00:08,  6.82it/s]Train Iter: 1543/5000. LR: 0.0462. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9671. T_Loss: 4.8086. Mask: 0.9266. :  42%|████▏     | 42/100 [00:09<00:08,  6.82it/s]Train Iter: 1543/5000. LR: 0.0462. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9671. T_Loss: 4.8086. Mask: 0.9266. :  43%|████▎     | 43/100 [00:09<00:07,  7.17it/s]Train Iter: 1544/5000. LR: 0.0462. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9700. T_Loss: 4.8129. Mask: 0.9240. :  43%|████▎     | 43/100 [00:09<00:07,  7.17it/s]Train Iter: 1544/5000. LR: 0.0462. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9700. T_Loss: 4.8129. Mask: 0.9240. :  44%|████▍     | 44/100 [00:09<00:07,  7.59it/s]Train Iter: 1545/5000. LR: 0.0462. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9704. T_Loss: 4.8226. Mask: 0.9250. :  44%|████▍     | 44/100 [00:10<00:07,  7.59it/s]Train Iter: 1545/5000. LR: 0.0462. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9704. T_Loss: 4.8226. Mask: 0.9250. :  45%|████▌     | 45/100 [00:10<00:06,  8.08it/s]Train Iter: 1546/5000. LR: 0.0462. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9690. T_Loss: 4.8221. Mask: 0.9260. :  45%|████▌     | 45/100 [00:10<00:06,  8.08it/s]Train Iter: 1546/5000. LR: 0.0462. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9690. T_Loss: 4.8221. Mask: 0.9260. :  46%|████▌     | 46/100 [00:10<00:06,  8.52it/s]Train Iter: 1547/5000. LR: 0.0462. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9680. T_Loss: 4.8258. Mask: 0.9262. :  46%|████▌     | 46/100 [00:10<00:06,  8.52it/s]Train Iter: 1547/5000. LR: 0.0462. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9680. T_Loss: 4.8258. Mask: 0.9262. :  47%|████▋     | 47/100 [00:10<00:06,  8.55it/s]Train Iter: 1548/5000. LR: 0.0462. Data: 0.08s. Batch: 0.21s. S_Loss: 0.9694. T_Loss: 4.8440. Mask: 0.9277. :  47%|████▋     | 47/100 [00:10<00:06,  8.55it/s]Train Iter: 1548/5000. LR: 0.0462. Data: 0.08s. Batch: 0.21s. S_Loss: 0.9694. T_Loss: 4.8440. Mask: 0.9277. :  48%|████▊     | 48/100 [00:10<00:06,  8.48it/s]Train Iter: 1549/5000. LR: 0.0462. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9673. T_Loss: 4.8258. Mask: 0.9273. :  48%|████▊     | 48/100 [00:10<00:06,  8.48it/s]Train Iter: 1549/5000. LR: 0.0462. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9673. T_Loss: 4.8258. Mask: 0.9273. :  49%|████▉     | 49/100 [00:10<00:10,  5.07it/s]Train Iter: 1550/5000. LR: 0.0462. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9673. T_Loss: 4.8101. Mask: 0.9263. :  49%|████▉     | 49/100 [00:10<00:10,  5.07it/s]Train Iter: 1550/5000. LR: 0.0462. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9673. T_Loss: 4.8101. Mask: 0.9263. :  50%|█████     | 50/100 [00:10<00:08,  5.78it/s]total : 5000  current step :  1526
total : 5000  current step :  1527
total : 5000  current step :  1528
total : 5000  current step :  1529
total : 5000  current step :  1530
total : 5000  current step :  1531
total : 5000  current step :  1532
total : 5000  current step :  1533
total : 5000  current step :  1534
total : 5000  current step :  1535
total : 5000  current step :  1536
total : 5000  current step :  1537
total : 5000  current step :  1538
total : 5000  current step :  1539
total : 5000  current step :  1540
total : 5000  current step :  1541
total : 5000  current step :  1542
total : 5000  current step :  1543
total : 5000  current step :  1544
total : 5000  current step :  1545
total : 5000  current step :  1546
total : 5000  current step :  1547
total : 5000  current step :  1548
total : 5000  current step :  1549
total : 5000  current step :  1550
Train Iter: 1551/5000. LR: 0.0462. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9660. T_Loss: 4.8116. Mask: 0.9271. :  50%|█████     | 50/100 [00:12<00:08,  5.78it/s]Train Iter: 1551/5000. LR: 0.0462. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9660. T_Loss: 4.8116. Mask: 0.9271. :  51%|█████     | 51/100 [00:12<00:34,  1.43it/s]Train Iter: 1552/5000. LR: 0.0461. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9677. T_Loss: 4.8242. Mask: 0.9273. :  51%|█████     | 51/100 [00:12<00:34,  1.43it/s]Train Iter: 1552/5000. LR: 0.0461. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9677. T_Loss: 4.8242. Mask: 0.9273. :  52%|█████▏    | 52/100 [00:12<00:25,  1.86it/s]Train Iter: 1553/5000. LR: 0.0461. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9698. T_Loss: 4.8227. Mask: 0.9263. :  52%|█████▏    | 52/100 [00:13<00:25,  1.86it/s]Train Iter: 1553/5000. LR: 0.0461. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9698. T_Loss: 4.8227. Mask: 0.9263. :  53%|█████▎    | 53/100 [00:13<00:19,  2.35it/s]Train Iter: 1554/5000. LR: 0.0461. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9675. T_Loss: 4.7976. Mask: 0.9253. :  53%|█████▎    | 53/100 [00:13<00:19,  2.35it/s]Train Iter: 1554/5000. LR: 0.0461. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9675. T_Loss: 4.7976. Mask: 0.9253. :  54%|█████▍    | 54/100 [00:13<00:15,  2.95it/s]Train Iter: 1555/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9672. T_Loss: 4.7916. Mask: 0.9256. :  54%|█████▍    | 54/100 [00:13<00:15,  2.95it/s]Train Iter: 1555/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9672. T_Loss: 4.7916. Mask: 0.9256. :  55%|█████▌    | 55/100 [00:13<00:12,  3.59it/s]Train Iter: 1556/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9664. T_Loss: 4.7857. Mask: 0.9258. :  55%|█████▌    | 55/100 [00:13<00:12,  3.59it/s]Train Iter: 1556/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9664. T_Loss: 4.7857. Mask: 0.9258. :  56%|█████▌    | 56/100 [00:13<00:10,  4.30it/s]Train Iter: 1557/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9655. T_Loss: 4.7744. Mask: 0.9254. :  56%|█████▌    | 56/100 [00:13<00:10,  4.30it/s]Train Iter: 1557/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9655. T_Loss: 4.7744. Mask: 0.9254. :  57%|█████▋    | 57/100 [00:13<00:08,  5.00it/s]Train Iter: 1558/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9644. T_Loss: 4.7591. Mask: 0.9251. :  57%|█████▋    | 57/100 [00:13<00:08,  5.00it/s]Train Iter: 1558/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9644. T_Loss: 4.7591. Mask: 0.9251. :  58%|█████▊    | 58/100 [00:13<00:07,  5.77it/s]Train Iter: 1559/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9657. T_Loss: 4.7465. Mask: 0.9237. :  58%|█████▊    | 58/100 [00:14<00:07,  5.77it/s]Train Iter: 1559/5000. LR: 0.0461. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9657. T_Loss: 4.7465. Mask: 0.9237. :  59%|█████▉    | 59/100 [00:14<00:08,  4.74it/s]Train Iter: 1560/5000. LR: 0.0461. Data: 0.10s. Batch: 0.23s. S_Loss: 0.9661. T_Loss: 4.7479. Mask: 0.9245. :  59%|█████▉    | 59/100 [00:14<00:08,  4.74it/s]Train Iter: 1561/5000. LR: 0.0461. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9668. T_Loss: 4.7376. Mask: 0.9232. :  60%|██████    | 60/100 [00:14<00:08,  4.74it/s]Train Iter: 1561/5000. LR: 0.0461. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9668. T_Loss: 4.7376. Mask: 0.9232. :  61%|██████    | 61/100 [00:14<00:05,  6.58it/s]Train Iter: 1562/5000. LR: 0.0460. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9684. T_Loss: 4.7387. Mask: 0.9234. :  61%|██████    | 61/100 [00:14<00:05,  6.58it/s]Train Iter: 1563/5000. LR: 0.0460. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9682. T_Loss: 4.7372. Mask: 0.9241. :  62%|██████▏   | 62/100 [00:14<00:05,  6.58it/s]Train Iter: 1563/5000. LR: 0.0460. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9682. T_Loss: 4.7372. Mask: 0.9241. :  63%|██████▎   | 63/100 [00:14<00:05,  7.32it/s]Train Iter: 1564/5000. LR: 0.0460. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9663. T_Loss: 4.7183. Mask: 0.9238. :  63%|██████▎   | 63/100 [00:14<00:05,  7.32it/s]Train Iter: 1564/5000. LR: 0.0460. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9663. T_Loss: 4.7183. Mask: 0.9238. :  64%|██████▍   | 64/100 [00:14<00:04,  7.30it/s]total : 5000  current step :  1551
total : 5000  current step :  1552
total : 5000  current step :  1553
total : 5000  current step :  1554
total : 5000  current step :  1555
total : 5000  current step :  1556
total : 5000  current step :  1557
total : 5000  current step :  1558
total : 5000  current step :  1559
total : 5000  current step :  1560
total : 5000  current step :  1561
total : 5000  current step :  1562
total : 5000  current step :  1563
total : 5000  current step :  1564
Train Iter: 1565/5000. LR: 0.0460. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9642. T_Loss: 4.7088. Mask: 0.9245. :  64%|██████▍   | 64/100 [00:16<00:04,  7.30it/s]Train Iter: 1565/5000. LR: 0.0460. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9642. T_Loss: 4.7088. Mask: 0.9245. :  65%|██████▌   | 65/100 [00:16<00:21,  1.61it/s]Train Iter: 1566/5000. LR: 0.0460. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9648. T_Loss: 4.7063. Mask: 0.9242. :  65%|██████▌   | 65/100 [00:16<00:21,  1.61it/s]Train Iter: 1566/5000. LR: 0.0460. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9648. T_Loss: 4.7063. Mask: 0.9242. :  66%|██████▌   | 66/100 [00:16<00:16,  2.02it/s]Train Iter: 1567/5000. LR: 0.0460. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9645. T_Loss: 4.7022. Mask: 0.9244. :  66%|██████▌   | 66/100 [00:17<00:16,  2.02it/s]Train Iter: 1567/5000. LR: 0.0460. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9645. T_Loss: 4.7022. Mask: 0.9244. :  67%|██████▋   | 67/100 [00:17<00:13,  2.46it/s]Train Iter: 1568/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6995. Mask: 0.9237. :  67%|██████▋   | 67/100 [00:17<00:13,  2.46it/s]Train Iter: 1568/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6995. Mask: 0.9237. :  68%|██████▊   | 68/100 [00:17<00:10,  3.03it/s]Train Iter: 1569/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9629. T_Loss: 4.7001. Mask: 0.9235. :  68%|██████▊   | 68/100 [00:17<00:10,  3.03it/s]Train Iter: 1569/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9629. T_Loss: 4.7001. Mask: 0.9235. :  69%|██████▉   | 69/100 [00:17<00:10,  2.85it/s]Train Iter: 1570/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9629. T_Loss: 4.6999. Mask: 0.9241. :  69%|██████▉   | 69/100 [00:17<00:10,  2.85it/s]Train Iter: 1570/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9629. T_Loss: 4.6999. Mask: 0.9241. :  70%|███████   | 70/100 [00:17<00:08,  3.45it/s]Train Iter: 1571/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9620. T_Loss: 4.6950. Mask: 0.9230. :  70%|███████   | 70/100 [00:17<00:08,  3.45it/s]Train Iter: 1571/5000. LR: 0.0460. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9620. T_Loss: 4.6950. Mask: 0.9230. :  71%|███████   | 71/100 [00:17<00:07,  4.13it/s]Train Iter: 1572/5000. LR: 0.0459. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9643. T_Loss: 4.7140. Mask: 0.9223. :  71%|███████   | 71/100 [00:17<00:07,  4.13it/s]Train Iter: 1572/5000. LR: 0.0459. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9643. T_Loss: 4.7140. Mask: 0.9223. :  72%|███████▏  | 72/100 [00:17<00:05,  4.89it/s]Train Iter: 1573/5000. LR: 0.0459. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9663. T_Loss: 4.7129. Mask: 0.9208. :  72%|███████▏  | 72/100 [00:18<00:05,  4.89it/s]Train Iter: 1573/5000. LR: 0.0459. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9663. T_Loss: 4.7129. Mask: 0.9208. :  73%|███████▎  | 73/100 [00:18<00:04,  5.71it/s]Train Iter: 1574/5000. LR: 0.0459. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9686. T_Loss: 4.7213. Mask: 0.9202. :  73%|███████▎  | 73/100 [00:18<00:04,  5.71it/s]Train Iter: 1574/5000. LR: 0.0459. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9686. T_Loss: 4.7213. Mask: 0.9202. :  74%|███████▍  | 74/100 [00:18<00:04,  6.47it/s]Train Iter: 1575/5000. LR: 0.0459. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9708. T_Loss: 4.7281. Mask: 0.9200. :  74%|███████▍  | 74/100 [00:18<00:04,  6.47it/s]Train Iter: 1575/5000. LR: 0.0459. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9708. T_Loss: 4.7281. Mask: 0.9200. :  75%|███████▌  | 75/100 [00:18<00:05,  4.92it/s]total : 5000  current step :  1565
total : 5000  current step :  1566
total : 5000  current step :  1567
total : 5000  current step :  1568
total : 5000  current step :  1569
total : 5000  current step :  1570
total : 5000  current step :  1571
total : 5000  current step :  1572
total : 5000  current step :  1573
total : 5000  current step :  1574
total : 5000  current step :  1575
Train Iter: 1576/5000. LR: 0.0459. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9713. T_Loss: 4.7294. Mask: 0.9202. :  75%|███████▌  | 75/100 [00:20<00:05,  4.92it/s]Train Iter: 1576/5000. LR: 0.0459. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9713. T_Loss: 4.7294. Mask: 0.9202. :  76%|███████▌  | 76/100 [00:20<00:19,  1.24it/s]Train Iter: 1577/5000. LR: 0.0459. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9700. T_Loss: 4.7374. Mask: 0.9209. :  76%|███████▌  | 76/100 [00:20<00:19,  1.24it/s]Train Iter: 1577/5000. LR: 0.0459. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9700. T_Loss: 4.7374. Mask: 0.9209. :  77%|███████▋  | 77/100 [00:20<00:14,  1.62it/s]Train Iter: 1578/5000. LR: 0.0459. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9708. T_Loss: 4.7354. Mask: 0.9207. :  77%|███████▋  | 77/100 [00:21<00:14,  1.62it/s]Train Iter: 1578/5000. LR: 0.0459. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9708. T_Loss: 4.7354. Mask: 0.9207. :  78%|███████▊  | 78/100 [00:21<00:10,  2.11it/s]Train Iter: 1579/5000. LR: 0.0459. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9725. T_Loss: 4.7449. Mask: 0.9209. :  78%|███████▊  | 78/100 [00:21<00:10,  2.11it/s]Train Iter: 1579/5000. LR: 0.0459. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9725. T_Loss: 4.7449. Mask: 0.9209. :  79%|███████▉  | 79/100 [00:21<00:08,  2.55it/s]Train Iter: 1580/5000. LR: 0.0459. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9733. T_Loss: 4.7395. Mask: 0.9203. :  79%|███████▉  | 79/100 [00:21<00:08,  2.55it/s]Train Iter: 1580/5000. LR: 0.0459. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9733. T_Loss: 4.7395. Mask: 0.9203. :  80%|████████  | 80/100 [00:21<00:06,  2.98it/s]Train Iter: 1581/5000. LR: 0.0459. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9737. T_Loss: 4.7413. Mask: 0.9205. :  80%|████████  | 80/100 [00:21<00:06,  2.98it/s]Train Iter: 1581/5000. LR: 0.0459. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9737. T_Loss: 4.7413. Mask: 0.9205. :  81%|████████  | 81/100 [00:21<00:05,  3.60it/s]Train Iter: 1582/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9750. T_Loss: 4.7636. Mask: 0.9207. :  81%|████████  | 81/100 [00:21<00:05,  3.60it/s]Train Iter: 1582/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9750. T_Loss: 4.7636. Mask: 0.9207. :  82%|████████▏ | 82/100 [00:21<00:04,  4.23it/s]Train Iter: 1583/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9760. T_Loss: 4.7690. Mask: 0.9206. :  82%|████████▏ | 82/100 [00:21<00:04,  4.23it/s]Train Iter: 1583/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9760. T_Loss: 4.7690. Mask: 0.9206. :  83%|████████▎ | 83/100 [00:21<00:03,  4.95it/s]Train Iter: 1584/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9760. T_Loss: 4.7705. Mask: 0.9200. :  83%|████████▎ | 83/100 [00:21<00:03,  4.95it/s]Train Iter: 1584/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9760. T_Loss: 4.7705. Mask: 0.9200. :  84%|████████▍ | 84/100 [00:21<00:02,  5.53it/s]Train Iter: 1585/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9759. T_Loss: 4.7743. Mask: 0.9202. :  84%|████████▍ | 84/100 [00:22<00:02,  5.53it/s]Train Iter: 1585/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9759. T_Loss: 4.7743. Mask: 0.9202. :  85%|████████▌ | 85/100 [00:22<00:03,  4.84it/s]Train Iter: 1586/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9765. T_Loss: 4.7804. Mask: 0.9208. :  85%|████████▌ | 85/100 [00:22<00:03,  4.84it/s]Train Iter: 1586/5000. LR: 0.0458. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9765. T_Loss: 4.7804. Mask: 0.9208. :  86%|████████▌ | 86/100 [00:22<00:02,  5.50it/s]Train Iter: 1587/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9771. T_Loss: 4.7909. Mask: 0.9213. :  86%|████████▌ | 86/100 [00:22<00:02,  5.50it/s]Train Iter: 1587/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9771. T_Loss: 4.7909. Mask: 0.9213. :  87%|████████▋ | 87/100 [00:22<00:02,  5.97it/s]Train Iter: 1588/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9786. T_Loss: 4.7968. Mask: 0.9222. :  87%|████████▋ | 87/100 [00:22<00:02,  5.97it/s]Train Iter: 1588/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9786. T_Loss: 4.7968. Mask: 0.9222. :  88%|████████▊ | 88/100 [00:22<00:01,  6.31it/s]Train Iter: 1589/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9791. T_Loss: 4.8009. Mask: 0.9213. :  88%|████████▊ | 88/100 [00:22<00:01,  6.31it/s]Train Iter: 1589/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9791. T_Loss: 4.8009. Mask: 0.9213. :  89%|████████▉ | 89/100 [00:22<00:02,  4.62it/s]Train Iter: 1590/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9788. T_Loss: 4.7988. Mask: 0.9215. :  89%|████████▉ | 89/100 [00:23<00:02,  4.62it/s]Train Iter: 1590/5000. LR: 0.0458. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9788. T_Loss: 4.7988. Mask: 0.9215. :  90%|█████████ | 90/100 [00:23<00:01,  5.36it/s]Train Iter: 1591/5000. LR: 0.0458. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9786. T_Loss: 4.8029. Mask: 0.9220. :  90%|█████████ | 90/100 [00:23<00:01,  5.36it/s]Train Iter: 1591/5000. LR: 0.0458. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9786. T_Loss: 4.8029. Mask: 0.9220. :  91%|█████████ | 91/100 [00:23<00:01,  5.61it/s]Train Iter: 1592/5000. LR: 0.0457. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9791. T_Loss: 4.7967. Mask: 0.9212. :  91%|█████████ | 91/100 [00:23<00:01,  5.61it/s]Train Iter: 1592/5000. LR: 0.0457. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9791. T_Loss: 4.7967. Mask: 0.9212. :  92%|█████████▏| 92/100 [00:23<00:01,  6.13it/s]Train Iter: 1593/5000. LR: 0.0457. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9807. T_Loss: 4.8000. Mask: 0.9210. :  92%|█████████▏| 92/100 [00:23<00:01,  6.13it/s]Train Iter: 1593/5000. LR: 0.0457. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9807. T_Loss: 4.8000. Mask: 0.9210. :  93%|█████████▎| 93/100 [00:23<00:01,  6.66it/s]Train Iter: 1594/5000. LR: 0.0457. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9810. T_Loss: 4.7940. Mask: 0.9202. :  93%|█████████▎| 93/100 [00:23<00:01,  6.66it/s]Train Iter: 1594/5000. LR: 0.0457. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9810. T_Loss: 4.7940. Mask: 0.9202. :  94%|█████████▍| 94/100 [00:23<00:00,  7.01it/s]Train Iter: 1595/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.7847. Mask: 0.9191. :  94%|█████████▍| 94/100 [00:23<00:00,  7.01it/s]Train Iter: 1595/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.7847. Mask: 0.9191. :  95%|█████████▌| 95/100 [00:23<00:00,  5.55it/s]Train Iter: 1596/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9810. T_Loss: 4.7875. Mask: 0.9193. :  95%|█████████▌| 95/100 [00:24<00:00,  5.55it/s]Train Iter: 1596/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9810. T_Loss: 4.7875. Mask: 0.9193. :  96%|█████████▌| 96/100 [00:24<00:00,  5.95it/s]Train Iter: 1597/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9813. T_Loss: 4.7797. Mask: 0.9182. :  96%|█████████▌| 96/100 [00:24<00:00,  5.95it/s]Train Iter: 1597/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9813. T_Loss: 4.7797. Mask: 0.9182. :  97%|█████████▋| 97/100 [00:24<00:00,  6.42it/s]Train Iter: 1598/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.7748. Mask: 0.9190. :  97%|█████████▋| 97/100 [00:24<00:00,  6.42it/s]Train Iter: 1598/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.7748. Mask: 0.9190. :  98%|█████████▊| 98/100 [00:24<00:00,  6.58it/s]Train Iter: 1599/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9801. T_Loss: 4.7702. Mask: 0.9192. :  98%|█████████▊| 98/100 [00:24<00:00,  6.58it/s]Train Iter: 1599/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9801. T_Loss: 4.7702. Mask: 0.9192. :  99%|█████████▉| 99/100 [00:24<00:00,  5.06it/s]Train Iter: 1600/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9827. T_Loss: 4.7724. Mask: 0.9187. :  99%|█████████▉| 99/100 [00:24<00:00,  5.06it/s]Train Iter: 1600/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9827. T_Loss: 4.7724. Mask: 0.9187. : 100%|██████████| 100/100 [00:24<00:00,  5.64it/s]Train Iter: 1600/5000. LR: 0.0457. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9827. T_Loss: 4.7724. Mask: 0.9187. : 100%|██████████| 100/100 [00:24<00:00,  4.04it/s]
total : 5000  current step :  1576
total : 5000  current step :  1577
total : 5000  current step :  1578
total : 5000  current step :  1579
total : 5000  current step :  1580
total : 5000  current step :  1581
total : 5000  current step :  1582
total : 5000  current step :  1583
total : 5000  current step :  1584
total : 5000  current step :  1585
total : 5000  current step :  1586
total : 5000  current step :  1587
total : 5000  current step :  1588
total : 5000  current step :  1589
total : 5000  current step :  1590
total : 5000  current step :  1591
total : 5000  current step :  1592
total : 5000  current step :  1593
total : 5000  current step :  1594
total : 5000  current step :  1595
total : 5000  current step :  1596
total : 5000  current step :  1597
total : 5000  current step :  1598
total : 5000  current step :  1599
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 1.4457. top1: 53.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 1.4457. top1: 53.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 1.3791. top1: 64.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 1.2860. top1: 67.71. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 1.2990. top1: 65.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 1.2838. top1: 65.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.2866. top1: 64.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.2998. top1: 64.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.3167. top1: 62.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.3053. top1: 63.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.3053. top1: 63.19. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.34it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.3215. top1: 62.19. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.34it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.2986. top1: 63.92. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.34it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.2978. top1: 62.76. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.34it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.2870. top1: 62.98. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.34it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.2905. top1: 62.72. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.34it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2785. top1: 64.17. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.34it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2781. top1: 64.45. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.34it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2781. top1: 64.45. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.2721. top1: 64.89. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.2721. top1: 64.41. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.2720. top1: 64.31. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.2680. top1: 64.69. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.2816. top1: 63.84. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.2741. top1: 64.49. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2670. top1: 64.67. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2625. top1: 64.71. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2601. top1: 64.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2670. top1: 63.82. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.12it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2670. top1: 63.82. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2640. top1: 64.12. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2687. top1: 63.95. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2672. top1: 63.79. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2657. top1: 63.85. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2669. top1: 63.81. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2633. top1: 64.16. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2517. top1: 64.96. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2433. top1: 65.53. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2338. top1: 66.07. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2322. top1: 65.97. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2227. top1: 66.64. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 22.34it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2227. top1: 66.64. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2140. top1: 67.19. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2121. top1: 67.31. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.2050. top1: 67.89. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1985. top1: 68.37. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1944. top1: 68.53. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1884. top1: 68.90. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1808. top1: 69.39. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1737. top1: 69.93. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1687. top1: 70.24. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1644. top1: 70.55. top5: 100.00. :  59%|█████▊    | 37/63 [00:02<00:00, 34.43it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1644. top1: 70.55. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1590. top1: 70.77. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1552. top1: 70.98. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1510. top1: 71.25. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1507. top1: 71.14. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1463. top1: 71.45. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1442. top1: 71.64. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1411. top1: 71.93. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1375. top1: 72.10. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1329. top1: 72.38. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 45.13it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1329. top1: 72.38. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1317. top1: 72.48. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1286. top1: 72.68. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1268. top1: 72.83. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1223. top1: 73.18. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1211. top1: 73.26. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1211. top1: 73.19. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1195. top1: 73.30. top5: 100.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.76it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1195. top1: 73.30. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 23.02it/s]
total : 5000  current step :  1600
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1601/5000. LR: 0.0456. Data: 2.06s. Batch: 2.17s. S_Loss: 0.9508. T_Loss: 4.1358. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1601/5000. LR: 0.0456. Data: 2.06s. Batch: 2.17s. S_Loss: 0.9508. T_Loss: 4.1358. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:35,  2.18s/it]Train Iter: 1602/5000. LR: 0.0456. Data: 1.03s. Batch: 1.16s. S_Loss: 0.9496. T_Loss: 4.1658. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:35,  2.18s/it]Train Iter: 1602/5000. LR: 0.0456. Data: 1.03s. Batch: 1.16s. S_Loss: 0.9496. T_Loss: 4.1658. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:35,  1.02it/s]Train Iter: 1603/5000. LR: 0.0456. Data: 0.69s. Batch: 0.81s. S_Loss: 0.9891. T_Loss: 4.4308. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:35,  1.02it/s]Train Iter: 1603/5000. LR: 0.0456. Data: 0.69s. Batch: 0.81s. S_Loss: 0.9891. T_Loss: 4.4308. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 1604/5000. LR: 0.0456. Data: 0.52s. Batch: 0.64s. S_Loss: 1.0175. T_Loss: 4.3454. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 1604/5000. LR: 0.0456. Data: 0.52s. Batch: 0.64s. S_Loss: 1.0175. T_Loss: 4.3454. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:38,  2.46it/s]Train Iter: 1605/5000. LR: 0.0456. Data: 0.42s. Batch: 0.56s. S_Loss: 0.9889. T_Loss: 4.3490. Mask: 0.9250. :   4%|▍         | 4/100 [00:02<00:38,  2.46it/s]Train Iter: 1605/5000. LR: 0.0456. Data: 0.42s. Batch: 0.56s. S_Loss: 0.9889. T_Loss: 4.3490. Mask: 0.9250. :   5%|▌         | 5/100 [00:02<00:32,  2.91it/s]Train Iter: 1606/5000. LR: 0.0456. Data: 0.35s. Batch: 0.48s. S_Loss: 0.9784. T_Loss: 4.1985. Mask: 0.9271. :   5%|▌         | 5/100 [00:02<00:32,  2.91it/s]Train Iter: 1606/5000. LR: 0.0456. Data: 0.35s. Batch: 0.48s. S_Loss: 0.9784. T_Loss: 4.1985. Mask: 0.9271. :   6%|▌         | 6/100 [00:02<00:24,  3.76it/s]Train Iter: 1607/5000. LR: 0.0456. Data: 0.30s. Batch: 0.43s. S_Loss: 0.9612. T_Loss: 4.1470. Mask: 0.9330. :   6%|▌         | 6/100 [00:03<00:24,  3.76it/s]Train Iter: 1607/5000. LR: 0.0456. Data: 0.30s. Batch: 0.43s. S_Loss: 0.9612. T_Loss: 4.1470. Mask: 0.9330. :   7%|▋         | 7/100 [00:03<00:20,  4.59it/s]Train Iter: 1608/5000. LR: 0.0456. Data: 0.26s. Batch: 0.39s. S_Loss: 0.9637. T_Loss: 4.1588. Mask: 0.9336. :   7%|▋         | 7/100 [00:03<00:20,  4.59it/s]Train Iter: 1608/5000. LR: 0.0456. Data: 0.26s. Batch: 0.39s. S_Loss: 0.9637. T_Loss: 4.1588. Mask: 0.9336. :   8%|▊         | 8/100 [00:03<00:17,  5.25it/s]Train Iter: 1609/5000. LR: 0.0456. Data: 0.23s. Batch: 0.39s. S_Loss: 0.9749. T_Loss: 4.3598. Mask: 0.9375. :   8%|▊         | 8/100 [00:03<00:17,  5.25it/s]Train Iter: 1609/5000. LR: 0.0456. Data: 0.23s. Batch: 0.39s. S_Loss: 0.9749. T_Loss: 4.3598. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:21,  4.30it/s]Train Iter: 1610/5000. LR: 0.0456. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9758. T_Loss: 4.3931. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:21,  4.30it/s]Train Iter: 1610/5000. LR: 0.0456. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9758. T_Loss: 4.3931. Mask: 0.9375. :  10%|█         | 10/100 [00:03<00:18,  4.85it/s]Train Iter: 1611/5000. LR: 0.0455. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9813. T_Loss: 4.4097. Mask: 0.9375. :  10%|█         | 10/100 [00:03<00:18,  4.85it/s]Train Iter: 1611/5000. LR: 0.0455. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9813. T_Loss: 4.4097. Mask: 0.9375. :  11%|█         | 11/100 [00:03<00:16,  5.37it/s]Train Iter: 1612/5000. LR: 0.0455. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9762. T_Loss: 4.4297. Mask: 0.9375. :  11%|█         | 11/100 [00:03<00:16,  5.37it/s]Train Iter: 1612/5000. LR: 0.0455. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9762. T_Loss: 4.4297. Mask: 0.9375. :  12%|█▏        | 12/100 [00:03<00:14,  5.87it/s]Train Iter: 1613/5000. LR: 0.0455. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9910. T_Loss: 4.4286. Mask: 0.9327. :  12%|█▏        | 12/100 [00:04<00:14,  5.87it/s]Train Iter: 1613/5000. LR: 0.0455. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9910. T_Loss: 4.4286. Mask: 0.9327. :  13%|█▎        | 13/100 [00:04<00:13,  6.37it/s]Train Iter: 1614/5000. LR: 0.0455. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9992. T_Loss: 4.4711. Mask: 0.9330. :  13%|█▎        | 13/100 [00:04<00:13,  6.37it/s]Train Iter: 1614/5000. LR: 0.0455. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9992. T_Loss: 4.4711. Mask: 0.9330. :  14%|█▍        | 14/100 [00:04<00:12,  6.88it/s]Train Iter: 1615/5000. LR: 0.0455. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9957. T_Loss: 4.4949. Mask: 0.9354. :  14%|█▍        | 14/100 [00:04<00:12,  6.88it/s]Train Iter: 1615/5000. LR: 0.0455. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9957. T_Loss: 4.4949. Mask: 0.9354. :  15%|█▌        | 15/100 [00:04<00:16,  5.03it/s]Train Iter: 1616/5000. LR: 0.0455. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9936. T_Loss: 4.5875. Mask: 0.9395. :  15%|█▌        | 15/100 [00:04<00:16,  5.03it/s]Train Iter: 1616/5000. LR: 0.0455. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9936. T_Loss: 4.5875. Mask: 0.9395. :  16%|█▌        | 16/100 [00:04<00:15,  5.53it/s]Train Iter: 1617/5000. LR: 0.0455. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9930. T_Loss: 4.6186. Mask: 0.9375. :  16%|█▌        | 16/100 [00:04<00:15,  5.53it/s]Train Iter: 1617/5000. LR: 0.0455. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9930. T_Loss: 4.6186. Mask: 0.9375. :  17%|█▋        | 17/100 [00:04<00:13,  6.16it/s]Train Iter: 1618/5000. LR: 0.0455. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9951. T_Loss: 4.6001. Mask: 0.9288. :  17%|█▋        | 17/100 [00:04<00:13,  6.16it/s]Train Iter: 1618/5000. LR: 0.0455. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9951. T_Loss: 4.6001. Mask: 0.9288. :  18%|█▊        | 18/100 [00:04<00:12,  6.70it/s]Train Iter: 1619/5000. LR: 0.0455. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9965. T_Loss: 4.6374. Mask: 0.9260. :  18%|█▊        | 18/100 [00:05<00:12,  6.70it/s]Train Iter: 1619/5000. LR: 0.0455. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9965. T_Loss: 4.6374. Mask: 0.9260. :  19%|█▉        | 19/100 [00:05<00:12,  6.51it/s]Train Iter: 1620/5000. LR: 0.0454. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0005. T_Loss: 4.6559. Mask: 0.9234. :  19%|█▉        | 19/100 [00:05<00:12,  6.51it/s]Train Iter: 1621/5000. LR: 0.0454. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0062. T_Loss: 4.7008. Mask: 0.9182. :  20%|██        | 20/100 [00:05<00:12,  6.51it/s]Train Iter: 1621/5000. LR: 0.0454. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0062. T_Loss: 4.7008. Mask: 0.9182. :  21%|██        | 21/100 [00:05<00:10,  7.64it/s]Train Iter: 1622/5000. LR: 0.0454. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0030. T_Loss: 4.7240. Mask: 0.9176. :  21%|██        | 21/100 [00:05<00:10,  7.64it/s]Train Iter: 1622/5000. LR: 0.0454. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0030. T_Loss: 4.7240. Mask: 0.9176. :  22%|██▏       | 22/100 [00:05<00:10,  7.67it/s]Train Iter: 1623/5000. LR: 0.0454. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0044. T_Loss: 4.7465. Mask: 0.9158. :  22%|██▏       | 22/100 [00:05<00:10,  7.67it/s]Train Iter: 1623/5000. LR: 0.0454. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0044. T_Loss: 4.7465. Mask: 0.9158. :  23%|██▎       | 23/100 [00:05<00:09,  7.98it/s]Train Iter: 1624/5000. LR: 0.0454. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0020. T_Loss: 4.8027. Mask: 0.9180. :  23%|██▎       | 23/100 [00:05<00:09,  7.98it/s]Train Iter: 1624/5000. LR: 0.0454. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0020. T_Loss: 4.8027. Mask: 0.9180. :  24%|██▍       | 24/100 [00:05<00:09,  8.14it/s]Train Iter: 1625/5000. LR: 0.0454. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0029. T_Loss: 4.8199. Mask: 0.9175. :  24%|██▍       | 24/100 [00:05<00:09,  8.14it/s]Train Iter: 1625/5000. LR: 0.0454. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0029. T_Loss: 4.8199. Mask: 0.9175. :  25%|██▌       | 25/100 [00:05<00:13,  5.57it/s]total : 5000  current step :  1601
total : 5000  current step :  1602
total : 5000  current step :  1603
total : 5000  current step :  1604
total : 5000  current step :  1605
total : 5000  current step :  1606
total : 5000  current step :  1607
total : 5000  current step :  1608
total : 5000  current step :  1609
total : 5000  current step :  1610
total : 5000  current step :  1611
total : 5000  current step :  1612
total : 5000  current step :  1613
total : 5000  current step :  1614
total : 5000  current step :  1615
total : 5000  current step :  1616
total : 5000  current step :  1617
total : 5000  current step :  1618
total : 5000  current step :  1619
total : 5000  current step :  1620
total : 5000  current step :  1621
total : 5000  current step :  1622
total : 5000  current step :  1623
total : 5000  current step :  1624
total : 5000  current step :  1625
Train Iter: 1626/5000. LR: 0.0454. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0030. T_Loss: 4.8337. Mask: 0.9183. :  25%|██▌       | 25/100 [00:07<00:13,  5.57it/s]Train Iter: 1626/5000. LR: 0.0454. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0030. T_Loss: 4.8337. Mask: 0.9183. :  26%|██▌       | 26/100 [00:07<00:51,  1.43it/s]Train Iter: 1627/5000. LR: 0.0454. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0029. T_Loss: 4.8230. Mask: 0.9155. :  26%|██▌       | 26/100 [00:08<00:51,  1.43it/s]Train Iter: 1627/5000. LR: 0.0454. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0029. T_Loss: 4.8230. Mask: 0.9155. :  27%|██▋       | 27/100 [00:08<00:39,  1.86it/s]Train Iter: 1628/5000. LR: 0.0454. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0057. T_Loss: 4.8327. Mask: 0.9163. :  27%|██▋       | 27/100 [00:08<00:39,  1.86it/s]Train Iter: 1628/5000. LR: 0.0454. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0057. T_Loss: 4.8327. Mask: 0.9163. :  28%|██▊       | 28/100 [00:08<00:30,  2.40it/s]Train Iter: 1629/5000. LR: 0.0453. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0064. T_Loss: 4.8286. Mask: 0.9149. :  28%|██▊       | 28/100 [00:08<00:30,  2.40it/s]Train Iter: 1629/5000. LR: 0.0453. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0064. T_Loss: 4.8286. Mask: 0.9149. :  29%|██▉       | 29/100 [00:08<00:26,  2.69it/s]Train Iter: 1630/5000. LR: 0.0453. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0104. T_Loss: 4.8389. Mask: 0.9156. :  29%|██▉       | 29/100 [00:08<00:26,  2.69it/s]Train Iter: 1630/5000. LR: 0.0453. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0104. T_Loss: 4.8389. Mask: 0.9156. :  30%|███       | 30/100 [00:08<00:20,  3.37it/s]Train Iter: 1631/5000. LR: 0.0453. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0099. T_Loss: 4.8185. Mask: 0.9143. :  30%|███       | 30/100 [00:08<00:20,  3.37it/s]Train Iter: 1631/5000. LR: 0.0453. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0099. T_Loss: 4.8185. Mask: 0.9143. :  31%|███       | 31/100 [00:08<00:17,  4.03it/s]Train Iter: 1632/5000. LR: 0.0453. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0131. T_Loss: 4.8124. Mask: 0.9160. :  31%|███       | 31/100 [00:08<00:17,  4.03it/s]Train Iter: 1632/5000. LR: 0.0453. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0131. T_Loss: 4.8124. Mask: 0.9160. :  32%|███▏      | 32/100 [00:08<00:14,  4.69it/s]Train Iter: 1633/5000. LR: 0.0453. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0132. T_Loss: 4.7870. Mask: 0.9148. :  32%|███▏      | 32/100 [00:08<00:14,  4.69it/s]Train Iter: 1633/5000. LR: 0.0453. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0132. T_Loss: 4.7870. Mask: 0.9148. :  33%|███▎      | 33/100 [00:08<00:12,  5.30it/s]Train Iter: 1634/5000. LR: 0.0453. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0136. T_Loss: 4.7806. Mask: 0.9164. :  33%|███▎      | 33/100 [00:09<00:12,  5.30it/s]Train Iter: 1634/5000. LR: 0.0453. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0136. T_Loss: 4.7806. Mask: 0.9164. :  34%|███▍      | 34/100 [00:09<00:11,  5.86it/s]Train Iter: 1635/5000. LR: 0.0453. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0110. T_Loss: 4.7520. Mask: 0.9170. :  34%|███▍      | 34/100 [00:09<00:11,  5.86it/s]Train Iter: 1635/5000. LR: 0.0453. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0110. T_Loss: 4.7520. Mask: 0.9170. :  35%|███▌      | 35/100 [00:09<00:12,  5.02it/s]Train Iter: 1636/5000. LR: 0.0453. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0102. T_Loss: 4.7380. Mask: 0.9175. :  35%|███▌      | 35/100 [00:09<00:12,  5.02it/s]Train Iter: 1636/5000. LR: 0.0453. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0102. T_Loss: 4.7380. Mask: 0.9175. :  36%|███▌      | 36/100 [00:09<00:10,  5.88it/s]Train Iter: 1637/5000. LR: 0.0453. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0110. T_Loss: 4.7044. Mask: 0.9155. :  36%|███▌      | 36/100 [00:09<00:10,  5.88it/s]Train Iter: 1637/5000. LR: 0.0453. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0110. T_Loss: 4.7044. Mask: 0.9155. :  37%|███▋      | 37/100 [00:09<00:09,  6.38it/s]Train Iter: 1638/5000. LR: 0.0452. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0129. T_Loss: 4.6993. Mask: 0.9153. :  37%|███▋      | 37/100 [00:09<00:09,  6.38it/s]Train Iter: 1638/5000. LR: 0.0452. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0129. T_Loss: 4.6993. Mask: 0.9153. :  38%|███▊      | 38/100 [00:09<00:09,  6.85it/s]Train Iter: 1639/5000. LR: 0.0452. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0128. T_Loss: 4.6901. Mask: 0.9151. :  38%|███▊      | 38/100 [00:09<00:09,  6.85it/s]Train Iter: 1639/5000. LR: 0.0452. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0128. T_Loss: 4.6901. Mask: 0.9151. :  39%|███▉      | 39/100 [00:09<00:08,  7.11it/s]Train Iter: 1640/5000. LR: 0.0452. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0101. T_Loss: 4.6870. Mask: 0.9172. :  39%|███▉      | 39/100 [00:09<00:08,  7.11it/s]Train Iter: 1640/5000. LR: 0.0452. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0101. T_Loss: 4.6870. Mask: 0.9172. :  40%|████      | 40/100 [00:09<00:08,  7.10it/s]Train Iter: 1641/5000. LR: 0.0452. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0087. T_Loss: 4.7068. Mask: 0.9184. :  40%|████      | 40/100 [00:10<00:08,  7.10it/s]Train Iter: 1641/5000. LR: 0.0452. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0087. T_Loss: 4.7068. Mask: 0.9184. :  41%|████      | 41/100 [00:10<00:08,  7.25it/s]Train Iter: 1642/5000. LR: 0.0452. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0105. T_Loss: 4.7320. Mask: 0.9189. :  41%|████      | 41/100 [00:10<00:08,  7.25it/s]Train Iter: 1642/5000. LR: 0.0452. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0105. T_Loss: 4.7320. Mask: 0.9189. :  42%|████▏     | 42/100 [00:10<00:07,  7.44it/s]Train Iter: 1643/5000. LR: 0.0452. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0109. T_Loss: 4.7391. Mask: 0.9201. :  42%|████▏     | 42/100 [00:10<00:07,  7.44it/s]Train Iter: 1643/5000. LR: 0.0452. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0109. T_Loss: 4.7391. Mask: 0.9201. :  43%|████▎     | 43/100 [00:10<00:07,  7.62it/s]Train Iter: 1644/5000. LR: 0.0452. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0123. T_Loss: 4.7345. Mask: 0.9212. :  43%|████▎     | 43/100 [00:10<00:07,  7.62it/s]Train Iter: 1644/5000. LR: 0.0452. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0123. T_Loss: 4.7345. Mask: 0.9212. :  44%|████▍     | 44/100 [00:10<00:06,  8.13it/s]Train Iter: 1645/5000. LR: 0.0452. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0147. T_Loss: 4.7296. Mask: 0.9208. :  44%|████▍     | 44/100 [00:10<00:06,  8.13it/s]Train Iter: 1645/5000. LR: 0.0452. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0147. T_Loss: 4.7296. Mask: 0.9208. :  45%|████▌     | 45/100 [00:10<00:09,  5.72it/s]Train Iter: 1646/5000. LR: 0.0452. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0264. T_Loss: 4.7312. Mask: 0.9212. :  45%|████▌     | 45/100 [00:10<00:09,  5.72it/s]Train Iter: 1646/5000. LR: 0.0452. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0264. T_Loss: 4.7312. Mask: 0.9212. :  46%|████▌     | 46/100 [00:10<00:08,  6.53it/s]Train Iter: 1647/5000. LR: 0.0451. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0319. T_Loss: 4.7291. Mask: 0.9209. :  46%|████▌     | 46/100 [00:10<00:08,  6.53it/s]Train Iter: 1647/5000. LR: 0.0451. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0319. T_Loss: 4.7291. Mask: 0.9209. :  47%|████▋     | 47/100 [00:10<00:07,  6.93it/s]Train Iter: 1648/5000. LR: 0.0451. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0378. T_Loss: 4.7151. Mask: 0.9199. :  47%|████▋     | 47/100 [00:11<00:07,  6.93it/s]Train Iter: 1648/5000. LR: 0.0451. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0378. T_Loss: 4.7151. Mask: 0.9199. :  48%|████▊     | 48/100 [00:11<00:07,  7.25it/s]Train Iter: 1649/5000. LR: 0.0451. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0397. T_Loss: 4.7042. Mask: 0.9196. :  48%|████▊     | 48/100 [00:11<00:07,  7.25it/s]Train Iter: 1649/5000. LR: 0.0451. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0397. T_Loss: 4.7042. Mask: 0.9196. :  49%|████▉     | 49/100 [00:11<00:09,  5.43it/s]Train Iter: 1650/5000. LR: 0.0451. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0422. T_Loss: 4.6901. Mask: 0.9187. :  49%|████▉     | 49/100 [00:11<00:09,  5.43it/s]Train Iter: 1650/5000. LR: 0.0451. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0422. T_Loss: 4.6901. Mask: 0.9187. :  50%|█████     | 50/100 [00:11<00:08,  6.08it/s]total : 5000  current step :  1626
total : 5000  current step :  1627
total : 5000  current step :  1628
total : 5000  current step :  1629
total : 5000  current step :  1630
total : 5000  current step :  1631
total : 5000  current step :  1632
total : 5000  current step :  1633
total : 5000  current step :  1634
total : 5000  current step :  1635
total : 5000  current step :  1636
total : 5000  current step :  1637
total : 5000  current step :  1638
total : 5000  current step :  1639
total : 5000  current step :  1640
total : 5000  current step :  1641
total : 5000  current step :  1642
total : 5000  current step :  1643
total : 5000  current step :  1644
total : 5000  current step :  1645
total : 5000  current step :  1646
total : 5000  current step :  1647
total : 5000  current step :  1648
total : 5000  current step :  1649
total : 5000  current step :  1650
Train Iter: 1651/5000. LR: 0.0451. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0437. T_Loss: 4.6825. Mask: 0.9197. :  50%|█████     | 50/100 [00:13<00:08,  6.08it/s]Train Iter: 1651/5000. LR: 0.0451. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0437. T_Loss: 4.6825. Mask: 0.9197. :  51%|█████     | 51/100 [00:13<00:35,  1.37it/s]Train Iter: 1652/5000. LR: 0.0451. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0437. T_Loss: 4.7006. Mask: 0.9207. :  51%|█████     | 51/100 [00:13<00:35,  1.37it/s]Train Iter: 1652/5000. LR: 0.0451. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0437. T_Loss: 4.7006. Mask: 0.9207. :  52%|█████▏    | 52/100 [00:13<00:26,  1.83it/s]Train Iter: 1653/5000. LR: 0.0451. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0434. T_Loss: 4.6943. Mask: 0.9198. :  52%|█████▏    | 52/100 [00:13<00:26,  1.83it/s]Train Iter: 1653/5000. LR: 0.0451. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0434. T_Loss: 4.6943. Mask: 0.9198. :  53%|█████▎    | 53/100 [00:13<00:19,  2.40it/s]Train Iter: 1654/5000. LR: 0.0451. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0411. T_Loss: 4.6701. Mask: 0.9201. :  53%|█████▎    | 53/100 [00:13<00:19,  2.40it/s]Train Iter: 1654/5000. LR: 0.0451. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0411. T_Loss: 4.6701. Mask: 0.9201. :  54%|█████▍    | 54/100 [00:13<00:15,  3.05it/s]Train Iter: 1655/5000. LR: 0.0451. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0376. T_Loss: 4.6364. Mask: 0.9216. :  54%|█████▍    | 54/100 [00:14<00:15,  3.05it/s]Train Iter: 1655/5000. LR: 0.0451. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0376. T_Loss: 4.6364. Mask: 0.9216. :  55%|█████▌    | 55/100 [00:14<00:14,  3.17it/s]Train Iter: 1656/5000. LR: 0.0450. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0355. T_Loss: 4.6140. Mask: 0.9219. :  55%|█████▌    | 55/100 [00:14<00:14,  3.17it/s]Train Iter: 1656/5000. LR: 0.0450. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0355. T_Loss: 4.6140. Mask: 0.9219. :  56%|█████▌    | 56/100 [00:14<00:11,  3.84it/s]Train Iter: 1657/5000. LR: 0.0450. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0355. T_Loss: 4.6305. Mask: 0.9232. :  56%|█████▌    | 56/100 [00:14<00:11,  3.84it/s]Train Iter: 1657/5000. LR: 0.0450. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0355. T_Loss: 4.6305. Mask: 0.9232. :  57%|█████▋    | 57/100 [00:14<00:09,  4.56it/s]Train Iter: 1658/5000. LR: 0.0450. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0345. T_Loss: 4.6138. Mask: 0.9230. :  57%|█████▋    | 57/100 [00:14<00:09,  4.56it/s]Train Iter: 1658/5000. LR: 0.0450. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0345. T_Loss: 4.6138. Mask: 0.9230. :  58%|█████▊    | 58/100 [00:14<00:07,  5.26it/s]Train Iter: 1659/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0333. T_Loss: 4.5929. Mask: 0.9243. :  58%|█████▊    | 58/100 [00:14<00:07,  5.26it/s]Train Iter: 1659/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0333. T_Loss: 4.5929. Mask: 0.9243. :  59%|█████▉    | 59/100 [00:14<00:09,  4.48it/s]Train Iter: 1660/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0367. T_Loss: 4.5846. Mask: 0.9234. :  59%|█████▉    | 59/100 [00:14<00:09,  4.48it/s]Train Iter: 1660/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0367. T_Loss: 4.5846. Mask: 0.9234. :  60%|██████    | 60/100 [00:14<00:07,  5.16it/s]Train Iter: 1661/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0368. T_Loss: 4.5848. Mask: 0.9237. :  60%|██████    | 60/100 [00:15<00:07,  5.16it/s]Train Iter: 1661/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0368. T_Loss: 4.5848. Mask: 0.9237. :  61%|██████    | 61/100 [00:15<00:07,  5.42it/s]Train Iter: 1662/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0386. T_Loss: 4.5872. Mask: 0.9249. :  61%|██████    | 61/100 [00:15<00:07,  5.42it/s]Train Iter: 1662/5000. LR: 0.0450. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0386. T_Loss: 4.5872. Mask: 0.9249. :  62%|██████▏   | 62/100 [00:15<00:06,  5.63it/s]Train Iter: 1663/5000. LR: 0.0450. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0455. T_Loss: 4.6331. Mask: 0.9256. :  62%|██████▏   | 62/100 [00:15<00:06,  5.63it/s]Train Iter: 1663/5000. LR: 0.0450. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0455. T_Loss: 4.6331. Mask: 0.9256. :  63%|██████▎   | 63/100 [00:15<00:06,  6.12it/s]Train Iter: 1664/5000. LR: 0.0450. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0477. T_Loss: 4.6276. Mask: 0.9268. :  63%|██████▎   | 63/100 [00:15<00:06,  6.12it/s]Train Iter: 1664/5000. LR: 0.0450. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0477. T_Loss: 4.6276. Mask: 0.9268. :  64%|██████▍   | 64/100 [00:15<00:05,  6.51it/s]Train Iter: 1665/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0507. T_Loss: 4.6189. Mask: 0.9260. :  64%|██████▍   | 64/100 [00:15<00:05,  6.51it/s]Train Iter: 1665/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0507. T_Loss: 4.6189. Mask: 0.9260. :  65%|██████▌   | 65/100 [00:15<00:07,  4.40it/s]Train Iter: 1666/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0522. T_Loss: 4.6115. Mask: 0.9261. :  65%|██████▌   | 65/100 [00:16<00:07,  4.40it/s]Train Iter: 1666/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0522. T_Loss: 4.6115. Mask: 0.9261. :  66%|██████▌   | 66/100 [00:16<00:06,  5.02it/s]Train Iter: 1667/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0526. T_Loss: 4.5975. Mask: 0.9254. :  66%|██████▌   | 66/100 [00:16<00:06,  5.02it/s]Train Iter: 1667/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0526. T_Loss: 4.5975. Mask: 0.9254. :  67%|██████▋   | 67/100 [00:16<00:05,  5.59it/s]Train Iter: 1668/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0513. T_Loss: 4.6002. Mask: 0.9256. :  67%|██████▋   | 67/100 [00:16<00:05,  5.59it/s]Train Iter: 1668/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0513. T_Loss: 4.6002. Mask: 0.9256. :  68%|██████▊   | 68/100 [00:16<00:05,  6.17it/s]Train Iter: 1669/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0519. T_Loss: 4.6035. Mask: 0.9248. :  68%|██████▊   | 68/100 [00:16<00:05,  6.17it/s]Train Iter: 1669/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0519. T_Loss: 4.6035. Mask: 0.9248. :  69%|██████▉   | 69/100 [00:16<00:05,  5.96it/s]Train Iter: 1670/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0515. T_Loss: 4.6012. Mask: 0.9254. :  69%|██████▉   | 69/100 [00:16<00:05,  5.96it/s]Train Iter: 1670/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0515. T_Loss: 4.6012. Mask: 0.9254. :  70%|███████   | 70/100 [00:16<00:04,  6.52it/s]Train Iter: 1671/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0495. T_Loss: 4.5909. Mask: 0.9256. :  70%|███████   | 70/100 [00:16<00:04,  6.52it/s]Train Iter: 1671/5000. LR: 0.0449. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0495. T_Loss: 4.5909. Mask: 0.9256. :  71%|███████   | 71/100 [00:16<00:04,  7.04it/s]Train Iter: 1672/5000. LR: 0.0449. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0496. T_Loss: 4.5870. Mask: 0.9258. :  71%|███████   | 71/100 [00:16<00:04,  7.04it/s]Train Iter: 1672/5000. LR: 0.0449. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0496. T_Loss: 4.5870. Mask: 0.9258. :  72%|███████▏  | 72/100 [00:16<00:03,  7.33it/s]Train Iter: 1673/5000. LR: 0.0449. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0512. T_Loss: 4.5906. Mask: 0.9255. :  72%|███████▏  | 72/100 [00:17<00:03,  7.33it/s]Train Iter: 1673/5000. LR: 0.0449. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0512. T_Loss: 4.5906. Mask: 0.9255. :  73%|███████▎  | 73/100 [00:17<00:03,  7.51it/s]Train Iter: 1674/5000. LR: 0.0448. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0495. T_Loss: 4.5953. Mask: 0.9261. :  73%|███████▎  | 73/100 [00:17<00:03,  7.51it/s]Train Iter: 1674/5000. LR: 0.0448. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0495. T_Loss: 4.5953. Mask: 0.9261. :  74%|███████▍  | 74/100 [00:17<00:03,  7.82it/s]Train Iter: 1675/5000. LR: 0.0448. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0503. T_Loss: 4.6063. Mask: 0.9258. :  74%|███████▍  | 74/100 [00:17<00:03,  7.82it/s]Train Iter: 1675/5000. LR: 0.0448. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0503. T_Loss: 4.6063. Mask: 0.9258. :  75%|███████▌  | 75/100 [00:17<00:04,  5.62it/s]total : 5000  current step :  1651
total : 5000  current step :  1652
total : 5000  current step :  1653
total : 5000  current step :  1654
total : 5000  current step :  1655
total : 5000  current step :  1656
total : 5000  current step :  1657
total : 5000  current step :  1658
total : 5000  current step :  1659
total : 5000  current step :  1660
total : 5000  current step :  1661
total : 5000  current step :  1662
total : 5000  current step :  1663
total : 5000  current step :  1664
total : 5000  current step :  1665
total : 5000  current step :  1666
total : 5000  current step :  1667
total : 5000  current step :  1668
total : 5000  current step :  1669
total : 5000  current step :  1670
total : 5000  current step :  1671
total : 5000  current step :  1672
total : 5000  current step :  1673
total : 5000  current step :  1674
total : 5000  current step :  1675
Train Iter: 1676/5000. LR: 0.0448. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0515. T_Loss: 4.6240. Mask: 0.9252. :  75%|███████▌  | 75/100 [00:19<00:04,  5.62it/s]Train Iter: 1676/5000. LR: 0.0448. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0515. T_Loss: 4.6240. Mask: 0.9252. :  76%|███████▌  | 76/100 [00:19<00:17,  1.36it/s]Train Iter: 1677/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0501. T_Loss: 4.6278. Mask: 0.9253. :  76%|███████▌  | 76/100 [00:19<00:17,  1.36it/s]Train Iter: 1677/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0501. T_Loss: 4.6278. Mask: 0.9253. :  77%|███████▋  | 77/100 [00:19<00:12,  1.79it/s]Train Iter: 1678/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0495. T_Loss: 4.6382. Mask: 0.9251. :  77%|███████▋  | 77/100 [00:19<00:12,  1.79it/s]Train Iter: 1678/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0495. T_Loss: 4.6382. Mask: 0.9251. :  78%|███████▊  | 78/100 [00:19<00:09,  2.33it/s]Train Iter: 1679/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0500. T_Loss: 4.6425. Mask: 0.9244. :  78%|███████▊  | 78/100 [00:20<00:09,  2.33it/s]Train Iter: 1679/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0500. T_Loss: 4.6425. Mask: 0.9244. :  79%|███████▉  | 79/100 [00:20<00:08,  2.60it/s]Train Iter: 1680/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0516. T_Loss: 4.6492. Mask: 0.9242. :  79%|███████▉  | 79/100 [00:20<00:08,  2.60it/s]Train Iter: 1680/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0516. T_Loss: 4.6492. Mask: 0.9242. :  80%|████████  | 80/100 [00:20<00:06,  3.31it/s]Train Iter: 1681/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0506. T_Loss: 4.6657. Mask: 0.9240. :  80%|████████  | 80/100 [00:20<00:06,  3.31it/s]Train Iter: 1682/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0515. T_Loss: 4.6771. Mask: 0.9238. :  81%|████████  | 81/100 [00:20<00:05,  3.31it/s]Train Iter: 1682/5000. LR: 0.0448. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0515. T_Loss: 4.6771. Mask: 0.9238. :  82%|████████▏ | 82/100 [00:20<00:03,  4.73it/s]Train Iter: 1683/5000. LR: 0.0447. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0530. T_Loss: 4.6874. Mask: 0.9236. :  82%|████████▏ | 82/100 [00:20<00:03,  4.73it/s]Train Iter: 1683/5000. LR: 0.0447. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0530. T_Loss: 4.6874. Mask: 0.9236. :  83%|████████▎ | 83/100 [00:20<00:03,  5.28it/s]Train Iter: 1684/5000. LR: 0.0447. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0522. T_Loss: 4.6911. Mask: 0.9230. :  83%|████████▎ | 83/100 [00:20<00:03,  5.28it/s]Train Iter: 1684/5000. LR: 0.0447. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0522. T_Loss: 4.6911. Mask: 0.9230. :  84%|████████▍ | 84/100 [00:20<00:02,  5.81it/s]Train Iter: 1685/5000. LR: 0.0447. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0515. T_Loss: 4.6956. Mask: 0.9224. :  84%|████████▍ | 84/100 [00:20<00:02,  5.81it/s]Train Iter: 1685/5000. LR: 0.0447. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0515. T_Loss: 4.6956. Mask: 0.9224. :  85%|████████▌ | 85/100 [00:20<00:03,  4.78it/s]Train Iter: 1686/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0513. T_Loss: 4.6967. Mask: 0.9219. :  85%|████████▌ | 85/100 [00:21<00:03,  4.78it/s]Train Iter: 1686/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0513. T_Loss: 4.6967. Mask: 0.9219. :  86%|████████▌ | 86/100 [00:21<00:02,  5.37it/s]Train Iter: 1687/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0512. T_Loss: 4.6948. Mask: 0.9213. :  86%|████████▌ | 86/100 [00:21<00:02,  5.37it/s]Train Iter: 1687/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0512. T_Loss: 4.6948. Mask: 0.9213. :  87%|████████▋ | 87/100 [00:21<00:02,  5.97it/s]Train Iter: 1688/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0508. T_Loss: 4.7022. Mask: 0.9215. :  87%|████████▋ | 87/100 [00:21<00:02,  5.97it/s]Train Iter: 1688/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0508. T_Loss: 4.7022. Mask: 0.9215. :  88%|████████▊ | 88/100 [00:21<00:01,  6.48it/s]Train Iter: 1689/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0503. T_Loss: 4.6959. Mask: 0.9206. :  88%|████████▊ | 88/100 [00:21<00:01,  6.48it/s]Train Iter: 1689/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0503. T_Loss: 4.6959. Mask: 0.9206. :  89%|████████▉ | 89/100 [00:21<00:02,  4.52it/s]Train Iter: 1690/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0503. T_Loss: 4.7025. Mask: 0.9208. :  89%|████████▉ | 89/100 [00:21<00:02,  4.52it/s]Train Iter: 1690/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0503. T_Loss: 4.7025. Mask: 0.9208. :  90%|█████████ | 90/100 [00:21<00:01,  5.20it/s]Train Iter: 1691/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0508. T_Loss: 4.7081. Mask: 0.9203. :  90%|█████████ | 90/100 [00:21<00:01,  5.20it/s]Train Iter: 1691/5000. LR: 0.0447. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0508. T_Loss: 4.7081. Mask: 0.9203. :  91%|█████████ | 91/100 [00:21<00:01,  5.83it/s]Train Iter: 1692/5000. LR: 0.0446. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0510. T_Loss: 4.7080. Mask: 0.9198. :  91%|█████████ | 91/100 [00:22<00:01,  5.83it/s]Train Iter: 1692/5000. LR: 0.0446. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0510. T_Loss: 4.7080. Mask: 0.9198. :  92%|█████████▏| 92/100 [00:22<00:01,  6.26it/s]Train Iter: 1693/5000. LR: 0.0446. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0511. T_Loss: 4.7193. Mask: 0.9194. :  92%|█████████▏| 92/100 [00:22<00:01,  6.26it/s]Train Iter: 1693/5000. LR: 0.0446. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0511. T_Loss: 4.7193. Mask: 0.9194. :  93%|█████████▎| 93/100 [00:22<00:01,  6.72it/s]Train Iter: 1694/5000. LR: 0.0446. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0507. T_Loss: 4.7319. Mask: 0.9202. :  93%|█████████▎| 93/100 [00:22<00:01,  6.72it/s]Train Iter: 1694/5000. LR: 0.0446. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0507. T_Loss: 4.7319. Mask: 0.9202. :  94%|█████████▍| 94/100 [00:22<00:00,  6.99it/s]Train Iter: 1695/5000. LR: 0.0446. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0499. T_Loss: 4.7227. Mask: 0.9191. :  94%|█████████▍| 94/100 [00:22<00:00,  6.99it/s]Train Iter: 1695/5000. LR: 0.0446. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0499. T_Loss: 4.7227. Mask: 0.9191. :  95%|█████████▌| 95/100 [00:22<00:00,  7.30it/s]Train Iter: 1696/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0491. T_Loss: 4.7240. Mask: 0.9196. :  95%|█████████▌| 95/100 [00:22<00:00,  7.30it/s]Train Iter: 1696/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0491. T_Loss: 4.7240. Mask: 0.9196. :  96%|█████████▌| 96/100 [00:22<00:00,  7.60it/s]Train Iter: 1697/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0477. T_Loss: 4.7295. Mask: 0.9204. :  96%|█████████▌| 96/100 [00:22<00:00,  7.60it/s]Train Iter: 1697/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0477. T_Loss: 4.7295. Mask: 0.9204. :  97%|█████████▋| 97/100 [00:22<00:00,  7.94it/s]Train Iter: 1698/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0462. T_Loss: 4.7242. Mask: 0.9206. :  97%|█████████▋| 97/100 [00:22<00:00,  7.94it/s]Train Iter: 1698/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0462. T_Loss: 4.7242. Mask: 0.9206. :  98%|█████████▊| 98/100 [00:22<00:00,  7.90it/s]Train Iter: 1699/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0449. T_Loss: 4.7192. Mask: 0.9208. :  98%|█████████▊| 98/100 [00:23<00:00,  7.90it/s]Train Iter: 1699/5000. LR: 0.0446. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0449. T_Loss: 4.7192. Mask: 0.9208. :  99%|█████████▉| 99/100 [00:23<00:00,  5.54it/s]Train Iter: 1700/5000. LR: 0.0445. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0440. T_Loss: 4.7197. Mask: 0.9216. :  99%|█████████▉| 99/100 [00:23<00:00,  5.54it/s]Train Iter: 1700/5000. LR: 0.0445. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0440. T_Loss: 4.7197. Mask: 0.9216. : 100%|██████████| 100/100 [00:23<00:00,  6.14it/s]Train Iter: 1700/5000. LR: 0.0445. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0440. T_Loss: 4.7197. Mask: 0.9216. : 100%|██████████| 100/100 [00:23<00:00,  4.31it/s]
total : 5000  current step :  1676
total : 5000  current step :  1677
total : 5000  current step :  1678
total : 5000  current step :  1679
total : 5000  current step :  1680
total : 5000  current step :  1681
total : 5000  current step :  1682
total : 5000  current step :  1683
total : 5000  current step :  1684
total : 5000  current step :  1685
total : 5000  current step :  1686
total : 5000  current step :  1687
total : 5000  current step :  1688
total : 5000  current step :  1689
total : 5000  current step :  1690
total : 5000  current step :  1691
total : 5000  current step :  1692
total : 5000  current step :  1693
total : 5000  current step :  1694
total : 5000  current step :  1695
total : 5000  current step :  1696
total : 5000  current step :  1697
total : 5000  current step :  1698
total : 5000  current step :  1699
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 1.2640. top1: 56.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 1.2640. top1: 56.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 1.2135. top1: 68.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 1.1361. top1: 73.96. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 1.1537. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 1.1399. top1: 73.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.1440. top1: 72.40. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.1574. top1: 72.32. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.1725. top1: 70.70. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.1628. top1: 71.53. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.1769. top1: 70.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.1769. top1: 70.62. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.03it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.1558. top1: 71.88. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.03it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.1541. top1: 71.35. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.03it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.1451. top1: 71.39. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.03it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.1475. top1: 71.21. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.03it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1379. top1: 72.29. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.03it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1394. top1: 72.27. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  7.03it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1394. top1: 72.27. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1334. top1: 72.43. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1322. top1: 71.88. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1327. top1: 71.88. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1293. top1: 72.19. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1409. top1: 71.58. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1347. top1: 72.16. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1277. top1: 72.83. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1238. top1: 73.05. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1218. top1: 73.00. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1281. top1: 72.60. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1258. top1: 72.80. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1258. top1: 72.80. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1296. top1: 72.43. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1286. top1: 72.52. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1274. top1: 72.60. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1289. top1: 72.38. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1313. top1: 72.36. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1262. top1: 72.92. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1239. top1: 73.07. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1203. top1: 73.21. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1271. top1: 72.74. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1227. top1: 73.14. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1190. top1: 73.36. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.30it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1190. top1: 73.36. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1231. top1: 73.08. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1208. top1: 73.28. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1187. top1: 73.55. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1197. top1: 73.36. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1179. top1: 73.47. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1132. top1: 73.79. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1093. top1: 74.10. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1081. top1: 74.18. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1077. top1: 74.27. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 35.42it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1077. top1: 74.27. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1053. top1: 74.35. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1049. top1: 74.49. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1035. top1: 74.62. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1077. top1: 74.39. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1059. top1: 74.52. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1072. top1: 74.53. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1073. top1: 74.48. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1062. top1: 74.55. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1036. top1: 74.67. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1054. top1: 74.67. top5: 100.00. :  75%|███████▍  | 47/63 [00:02<00:00, 43.64it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1054. top1: 74.67. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 53.59it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1045. top1: 74.78. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 53.59it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1052. top1: 74.74. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 53.59it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1020. top1: 74.95. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 53.59it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1032. top1: 74.80. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 53.59it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1059. top1: 74.55. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 53.59it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1051. top1: 74.60. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 53.59it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1051. top1: 74.60. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 23.21it/s]
total : 5000  current step :  1700
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1701/5000. LR: 0.0445. Data: 1.88s. Batch: 2.02s. S_Loss: 1.1238. T_Loss: 5.1077. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1701/5000. LR: 0.0445. Data: 1.88s. Batch: 2.02s. S_Loss: 1.1238. T_Loss: 5.1077. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:20,  2.03s/it]Train Iter: 1702/5000. LR: 0.0445. Data: 0.95s. Batch: 1.09s. S_Loss: 1.0203. T_Loss: 4.7374. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:20,  2.03s/it]Train Iter: 1702/5000. LR: 0.0445. Data: 0.95s. Batch: 1.09s. S_Loss: 1.0203. T_Loss: 4.7374. Mask: 0.9688. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 1703/5000. LR: 0.0445. Data: 0.64s. Batch: 0.77s. S_Loss: 1.0205. T_Loss: 4.5876. Mask: 0.9479. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 1703/5000. LR: 0.0445. Data: 0.64s. Batch: 0.77s. S_Loss: 1.0205. T_Loss: 4.5876. Mask: 0.9479. :   3%|▎         | 3/100 [00:02<00:55,  1.76it/s]Train Iter: 1704/5000. LR: 0.0445. Data: 0.48s. Batch: 0.61s. S_Loss: 1.0143. T_Loss: 4.6557. Mask: 0.9531. :   3%|▎         | 3/100 [00:02<00:55,  1.76it/s]Train Iter: 1704/5000. LR: 0.0445. Data: 0.48s. Batch: 0.61s. S_Loss: 1.0143. T_Loss: 4.6557. Mask: 0.9531. :   4%|▍         | 4/100 [00:02<00:37,  2.53it/s]Train Iter: 1705/5000. LR: 0.0445. Data: 0.38s. Batch: 0.55s. S_Loss: 1.0221. T_Loss: 4.5711. Mask: 0.9437. :   4%|▍         | 4/100 [00:02<00:37,  2.53it/s]Train Iter: 1705/5000. LR: 0.0445. Data: 0.38s. Batch: 0.55s. S_Loss: 1.0221. T_Loss: 4.5711. Mask: 0.9437. :   5%|▌         | 5/100 [00:02<00:34,  2.77it/s]Train Iter: 1706/5000. LR: 0.0445. Data: 0.32s. Batch: 0.48s. S_Loss: 1.0187. T_Loss: 4.5659. Mask: 0.9531. :   5%|▌         | 5/100 [00:02<00:34,  2.77it/s]Train Iter: 1706/5000. LR: 0.0445. Data: 0.32s. Batch: 0.48s. S_Loss: 1.0187. T_Loss: 4.5659. Mask: 0.9531. :   6%|▌         | 6/100 [00:02<00:26,  3.60it/s]Train Iter: 1707/5000. LR: 0.0445. Data: 0.28s. Batch: 0.43s. S_Loss: 1.0165. T_Loss: 4.6213. Mask: 0.9509. :   6%|▌         | 6/100 [00:02<00:26,  3.60it/s]Train Iter: 1707/5000. LR: 0.0445. Data: 0.28s. Batch: 0.43s. S_Loss: 1.0165. T_Loss: 4.6213. Mask: 0.9509. :   7%|▋         | 7/100 [00:02<00:20,  4.47it/s]Train Iter: 1708/5000. LR: 0.0445. Data: 0.24s. Batch: 0.39s. S_Loss: 1.0171. T_Loss: 4.5115. Mask: 0.9375. :   7%|▋         | 7/100 [00:03<00:20,  4.47it/s]Train Iter: 1708/5000. LR: 0.0445. Data: 0.24s. Batch: 0.39s. S_Loss: 1.0171. T_Loss: 4.5115. Mask: 0.9375. :   8%|▊         | 8/100 [00:03<00:17,  5.25it/s]Train Iter: 1709/5000. LR: 0.0444. Data: 0.21s. Batch: 0.37s. S_Loss: 1.0127. T_Loss: 4.5897. Mask: 0.9375. :   8%|▊         | 8/100 [00:03<00:17,  5.25it/s]Train Iter: 1709/5000. LR: 0.0444. Data: 0.21s. Batch: 0.37s. S_Loss: 1.0127. T_Loss: 4.5897. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:18,  4.97it/s]Train Iter: 1710/5000. LR: 0.0444. Data: 0.19s. Batch: 0.34s. S_Loss: 1.0191. T_Loss: 4.5951. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:18,  4.97it/s]Train Iter: 1711/5000. LR: 0.0444. Data: 0.18s. Batch: 0.32s. S_Loss: 1.0202. T_Loss: 4.6677. Mask: 0.9375. :  10%|█         | 10/100 [00:03<00:18,  4.97it/s]Train Iter: 1711/5000. LR: 0.0444. Data: 0.18s. Batch: 0.32s. S_Loss: 1.0202. T_Loss: 4.6677. Mask: 0.9375. :  11%|█         | 11/100 [00:03<00:12,  7.03it/s]Train Iter: 1712/5000. LR: 0.0444. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0289. T_Loss: 4.6561. Mask: 0.9297. :  11%|█         | 11/100 [00:03<00:12,  7.03it/s]Train Iter: 1713/5000. LR: 0.0444. Data: 0.15s. Batch: 0.28s. S_Loss: 1.0303. T_Loss: 4.6189. Mask: 0.9255. :  12%|█▏        | 12/100 [00:03<00:12,  7.03it/s]Train Iter: 1713/5000. LR: 0.0444. Data: 0.15s. Batch: 0.28s. S_Loss: 1.0303. T_Loss: 4.6189. Mask: 0.9255. :  13%|█▎        | 13/100 [00:03<00:10,  8.68it/s]Train Iter: 1714/5000. LR: 0.0444. Data: 0.14s. Batch: 0.26s. S_Loss: 1.0372. T_Loss: 4.5971. Mask: 0.9174. :  13%|█▎        | 13/100 [00:03<00:10,  8.68it/s]Train Iter: 1715/5000. LR: 0.0444. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0408. T_Loss: 4.6236. Mask: 0.9167. :  14%|█▍        | 14/100 [00:04<00:09,  8.68it/s]Train Iter: 1715/5000. LR: 0.0444. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0408. T_Loss: 4.6236. Mask: 0.9167. :  15%|█▌        | 15/100 [00:04<00:12,  6.73it/s]Train Iter: 1716/5000. LR: 0.0444. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0366. T_Loss: 4.5761. Mask: 0.9102. :  15%|█▌        | 15/100 [00:04<00:12,  6.73it/s]Train Iter: 1716/5000. LR: 0.0444. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0366. T_Loss: 4.5761. Mask: 0.9102. :  16%|█▌        | 16/100 [00:04<00:12,  6.73it/s]Train Iter: 1717/5000. LR: 0.0443. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0369. T_Loss: 4.6121. Mask: 0.9099. :  16%|█▌        | 16/100 [00:04<00:12,  6.73it/s]Train Iter: 1717/5000. LR: 0.0443. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0369. T_Loss: 4.6121. Mask: 0.9099. :  17%|█▋        | 17/100 [00:04<00:11,  7.12it/s]Train Iter: 1718/5000. LR: 0.0443. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0468. T_Loss: 4.6456. Mask: 0.9080. :  17%|█▋        | 17/100 [00:04<00:11,  7.12it/s]Train Iter: 1718/5000. LR: 0.0443. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0468. T_Loss: 4.6456. Mask: 0.9080. :  18%|█▊        | 18/100 [00:04<00:10,  7.51it/s]Train Iter: 1719/5000. LR: 0.0443. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0587. T_Loss: 4.7707. Mask: 0.9112. :  18%|█▊        | 18/100 [00:04<00:10,  7.51it/s]Train Iter: 1719/5000. LR: 0.0443. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0587. T_Loss: 4.7707. Mask: 0.9112. :  19%|█▉        | 19/100 [00:04<00:10,  7.68it/s]Train Iter: 1720/5000. LR: 0.0443. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0555. T_Loss: 4.7695. Mask: 0.9094. :  19%|█▉        | 19/100 [00:04<00:10,  7.68it/s]Train Iter: 1720/5000. LR: 0.0443. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0555. T_Loss: 4.7695. Mask: 0.9094. :  20%|██        | 20/100 [00:04<00:10,  7.80it/s]Train Iter: 1721/5000. LR: 0.0443. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0577. T_Loss: 4.7580. Mask: 0.9077. :  20%|██        | 20/100 [00:04<00:10,  7.80it/s]Train Iter: 1721/5000. LR: 0.0443. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0577. T_Loss: 4.7580. Mask: 0.9077. :  21%|██        | 21/100 [00:04<00:09,  8.00it/s]Train Iter: 1722/5000. LR: 0.0443. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0526. T_Loss: 4.7617. Mask: 0.9091. :  21%|██        | 21/100 [00:04<00:09,  8.00it/s]Train Iter: 1722/5000. LR: 0.0443. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0526. T_Loss: 4.7617. Mask: 0.9091. :  22%|██▏       | 22/100 [00:04<00:09,  8.14it/s]Train Iter: 1723/5000. LR: 0.0443. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0496. T_Loss: 4.7709. Mask: 0.9130. :  22%|██▏       | 22/100 [00:05<00:09,  8.14it/s]Train Iter: 1723/5000. LR: 0.0443. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0496. T_Loss: 4.7709. Mask: 0.9130. :  23%|██▎       | 23/100 [00:05<00:09,  8.11it/s]Train Iter: 1724/5000. LR: 0.0443. Data: 0.08s. Batch: 0.21s. S_Loss: 1.0486. T_Loss: 4.7591. Mask: 0.9115. :  23%|██▎       | 23/100 [00:05<00:09,  8.11it/s]Train Iter: 1725/5000. LR: 0.0443. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0463. T_Loss: 4.7755. Mask: 0.9113. :  24%|██▍       | 24/100 [00:05<00:09,  8.11it/s]Train Iter: 1725/5000. LR: 0.0443. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0463. T_Loss: 4.7755. Mask: 0.9113. :  25%|██▌       | 25/100 [00:05<00:11,  6.29it/s]total : 5000  current step :  1701
total : 5000  current step :  1702
total : 5000  current step :  1703
total : 5000  current step :  1704
total : 5000  current step :  1705
total : 5000  current step :  1706
total : 5000  current step :  1707
total : 5000  current step :  1708
total : 5000  current step :  1709
total : 5000  current step :  1710
total : 5000  current step :  1711
total : 5000  current step :  1712
total : 5000  current step :  1713
total : 5000  current step :  1714
total : 5000  current step :  1715
total : 5000  current step :  1716
total : 5000  current step :  1717
total : 5000  current step :  1718
total : 5000  current step :  1719
total : 5000  current step :  1720
total : 5000  current step :  1721
total : 5000  current step :  1722
total : 5000  current step :  1723
total : 5000  current step :  1724
total : 5000  current step :  1725
Train Iter: 1726/5000. LR: 0.0442. Data: 0.15s. Batch: 0.28s. S_Loss: 1.0456. T_Loss: 4.7809. Mask: 0.9111. :  25%|██▌       | 25/100 [00:07<00:11,  6.29it/s]Train Iter: 1726/5000. LR: 0.0442. Data: 0.15s. Batch: 0.28s. S_Loss: 1.0456. T_Loss: 4.7809. Mask: 0.9111. :  26%|██▌       | 26/100 [00:07<00:45,  1.63it/s]Train Iter: 1727/5000. LR: 0.0442. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0420. T_Loss: 4.7828. Mask: 0.9120. :  26%|██▌       | 26/100 [00:07<00:45,  1.63it/s]Train Iter: 1727/5000. LR: 0.0442. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0420. T_Loss: 4.7828. Mask: 0.9120. :  27%|██▋       | 27/100 [00:07<00:35,  2.06it/s]Train Iter: 1728/5000. LR: 0.0442. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0441. T_Loss: 4.7948. Mask: 0.9096. :  27%|██▋       | 27/100 [00:07<00:35,  2.06it/s]Train Iter: 1728/5000. LR: 0.0442. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0441. T_Loss: 4.7948. Mask: 0.9096. :  28%|██▊       | 28/100 [00:07<00:29,  2.48it/s]Train Iter: 1729/5000. LR: 0.0442. Data: 0.14s. Batch: 0.27s. S_Loss: 1.0441. T_Loss: 4.8086. Mask: 0.9084. :  28%|██▊       | 28/100 [00:07<00:29,  2.48it/s]Train Iter: 1729/5000. LR: 0.0442. Data: 0.14s. Batch: 0.27s. S_Loss: 1.0441. T_Loss: 4.8086. Mask: 0.9084. :  29%|██▉       | 29/100 [00:07<00:24,  2.90it/s]Train Iter: 1730/5000. LR: 0.0442. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0416. T_Loss: 4.8222. Mask: 0.9094. :  29%|██▉       | 29/100 [00:08<00:24,  2.90it/s]Train Iter: 1730/5000. LR: 0.0442. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0416. T_Loss: 4.8222. Mask: 0.9094. :  30%|███       | 30/100 [00:08<00:19,  3.53it/s]Train Iter: 1731/5000. LR: 0.0442. Data: 0.13s. Batch: 0.26s. S_Loss: 1.0403. T_Loss: 4.8114. Mask: 0.9073. :  30%|███       | 30/100 [00:08<00:19,  3.53it/s]Train Iter: 1731/5000. LR: 0.0442. Data: 0.13s. Batch: 0.26s. S_Loss: 1.0403. T_Loss: 4.8114. Mask: 0.9073. :  31%|███       | 31/100 [00:08<00:16,  4.24it/s]Train Iter: 1732/5000. LR: 0.0442. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0374. T_Loss: 4.7992. Mask: 0.9102. :  31%|███       | 31/100 [00:08<00:16,  4.24it/s]Train Iter: 1732/5000. LR: 0.0442. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0374. T_Loss: 4.7992. Mask: 0.9102. :  32%|███▏      | 32/100 [00:08<00:13,  4.88it/s]Train Iter: 1733/5000. LR: 0.0442. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0322. T_Loss: 4.7816. Mask: 0.9129. :  32%|███▏      | 32/100 [00:08<00:13,  4.88it/s]Train Iter: 1733/5000. LR: 0.0442. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0322. T_Loss: 4.7816. Mask: 0.9129. :  33%|███▎      | 33/100 [00:08<00:12,  5.45it/s]Train Iter: 1734/5000. LR: 0.0441. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0319. T_Loss: 4.7966. Mask: 0.9136. :  33%|███▎      | 33/100 [00:08<00:12,  5.45it/s]Train Iter: 1734/5000. LR: 0.0441. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0319. T_Loss: 4.7966. Mask: 0.9136. :  34%|███▍      | 34/100 [00:08<00:11,  5.98it/s]Train Iter: 1735/5000. LR: 0.0441. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0315. T_Loss: 4.7825. Mask: 0.9125. :  34%|███▍      | 34/100 [00:08<00:11,  5.98it/s]Train Iter: 1735/5000. LR: 0.0441. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0315. T_Loss: 4.7825. Mask: 0.9125. :  35%|███▌      | 35/100 [00:08<00:13,  4.82it/s]Train Iter: 1736/5000. LR: 0.0441. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0323. T_Loss: 4.7911. Mask: 0.9123. :  35%|███▌      | 35/100 [00:09<00:13,  4.82it/s]Train Iter: 1736/5000. LR: 0.0441. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0323. T_Loss: 4.7911. Mask: 0.9123. :  36%|███▌      | 36/100 [00:09<00:11,  5.43it/s]Train Iter: 1737/5000. LR: 0.0441. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0321. T_Loss: 4.7944. Mask: 0.9122. :  36%|███▌      | 36/100 [00:09<00:11,  5.43it/s]Train Iter: 1737/5000. LR: 0.0441. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0321. T_Loss: 4.7944. Mask: 0.9122. :  37%|███▋      | 37/100 [00:09<00:10,  5.93it/s]Train Iter: 1738/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0287. T_Loss: 4.7633. Mask: 0.9112. :  37%|███▋      | 37/100 [00:09<00:10,  5.93it/s]Train Iter: 1738/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0287. T_Loss: 4.7633. Mask: 0.9112. :  38%|███▊      | 38/100 [00:09<00:09,  6.44it/s]Train Iter: 1739/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0293. T_Loss: 4.7522. Mask: 0.9095. :  38%|███▊      | 38/100 [00:09<00:09,  6.44it/s]Train Iter: 1739/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0293. T_Loss: 4.7522. Mask: 0.9095. :  39%|███▉      | 39/100 [00:09<00:11,  5.26it/s]Train Iter: 1740/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0283. T_Loss: 4.7416. Mask: 0.9109. :  39%|███▉      | 39/100 [00:09<00:11,  5.26it/s]Train Iter: 1740/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0283. T_Loss: 4.7416. Mask: 0.9109. :  40%|████      | 40/100 [00:09<00:10,  5.79it/s]Train Iter: 1741/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0308. T_Loss: 4.7328. Mask: 0.9108. :  40%|████      | 40/100 [00:09<00:10,  5.79it/s]Train Iter: 1741/5000. LR: 0.0441. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0308. T_Loss: 4.7328. Mask: 0.9108. :  41%|████      | 41/100 [00:09<00:09,  5.98it/s]Train Iter: 1742/5000. LR: 0.0440. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0274. T_Loss: 4.7028. Mask: 0.9107. :  41%|████      | 41/100 [00:09<00:09,  5.98it/s]Train Iter: 1742/5000. LR: 0.0440. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0274. T_Loss: 4.7028. Mask: 0.9107. :  42%|████▏     | 42/100 [00:09<00:08,  6.52it/s]Train Iter: 1743/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0295. T_Loss: 4.7318. Mask: 0.9121. :  42%|████▏     | 42/100 [00:10<00:08,  6.52it/s]Train Iter: 1743/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0295. T_Loss: 4.7318. Mask: 0.9121. :  43%|████▎     | 43/100 [00:10<00:08,  6.86it/s]Train Iter: 1744/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0296. T_Loss: 4.7442. Mask: 0.9141. :  43%|████▎     | 43/100 [00:10<00:08,  6.86it/s]Train Iter: 1744/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0296. T_Loss: 4.7442. Mask: 0.9141. :  44%|████▍     | 44/100 [00:10<00:07,  7.06it/s]Train Iter: 1745/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0279. T_Loss: 4.7461. Mask: 0.9139. :  44%|████▍     | 44/100 [00:10<00:07,  7.06it/s]Train Iter: 1745/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0279. T_Loss: 4.7461. Mask: 0.9139. :  45%|████▌     | 45/100 [00:10<00:11,  4.88it/s]Train Iter: 1746/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0292. T_Loss: 4.7504. Mask: 0.9130. :  45%|████▌     | 45/100 [00:10<00:11,  4.88it/s]Train Iter: 1746/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0292. T_Loss: 4.7504. Mask: 0.9130. :  46%|████▌     | 46/100 [00:10<00:10,  5.39it/s]Train Iter: 1747/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0306. T_Loss: 4.7709. Mask: 0.9116. :  46%|████▌     | 46/100 [00:10<00:10,  5.39it/s]Train Iter: 1747/5000. LR: 0.0440. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0306. T_Loss: 4.7709. Mask: 0.9116. :  47%|████▋     | 47/100 [00:10<00:09,  5.88it/s]Train Iter: 1748/5000. LR: 0.0440. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0324. T_Loss: 4.7854. Mask: 0.9115. :  47%|████▋     | 47/100 [00:10<00:09,  5.88it/s]Train Iter: 1748/5000. LR: 0.0440. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0324. T_Loss: 4.7854. Mask: 0.9115. :  48%|████▊     | 48/100 [00:10<00:08,  6.28it/s]Train Iter: 1749/5000. LR: 0.0440. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0325. T_Loss: 4.7889. Mask: 0.9126. :  48%|████▊     | 48/100 [00:11<00:08,  6.28it/s]Train Iter: 1749/5000. LR: 0.0440. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0325. T_Loss: 4.7889. Mask: 0.9126. :  49%|████▉     | 49/100 [00:11<00:07,  6.55it/s]Train Iter: 1750/5000. LR: 0.0439. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0304. T_Loss: 4.7863. Mask: 0.9131. :  49%|████▉     | 49/100 [00:11<00:07,  6.55it/s]Train Iter: 1750/5000. LR: 0.0439. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0304. T_Loss: 4.7863. Mask: 0.9131. :  50%|█████     | 50/100 [00:11<00:07,  6.94it/s]total : 5000  current step :  1726
total : 5000  current step :  1727
total : 5000  current step :  1728
total : 5000  current step :  1729
total : 5000  current step :  1730
total : 5000  current step :  1731
total : 5000  current step :  1732
total : 5000  current step :  1733
total : 5000  current step :  1734
total : 5000  current step :  1735
total : 5000  current step :  1736
total : 5000  current step :  1737
total : 5000  current step :  1738
total : 5000  current step :  1739
total : 5000  current step :  1740
total : 5000  current step :  1741
total : 5000  current step :  1742
total : 5000  current step :  1743
total : 5000  current step :  1744
total : 5000  current step :  1745
total : 5000  current step :  1746
total : 5000  current step :  1747
total : 5000  current step :  1748
total : 5000  current step :  1749
total : 5000  current step :  1750
Train Iter: 1751/5000. LR: 0.0439. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0310. T_Loss: 4.7921. Mask: 0.9148. :  50%|█████     | 50/100 [00:13<00:07,  6.94it/s]Train Iter: 1751/5000. LR: 0.0439. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0310. T_Loss: 4.7921. Mask: 0.9148. :  51%|█████     | 51/100 [00:13<00:35,  1.38it/s]Train Iter: 1752/5000. LR: 0.0439. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0325. T_Loss: 4.8067. Mask: 0.9153. :  51%|█████     | 51/100 [00:13<00:35,  1.38it/s]Train Iter: 1752/5000. LR: 0.0439. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0325. T_Loss: 4.8067. Mask: 0.9153. :  52%|█████▏    | 52/100 [00:13<00:25,  1.85it/s]Train Iter: 1753/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0329. T_Loss: 4.8082. Mask: 0.9157. :  52%|█████▏    | 52/100 [00:13<00:25,  1.85it/s]Train Iter: 1753/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0329. T_Loss: 4.8082. Mask: 0.9157. :  53%|█████▎    | 53/100 [00:13<00:19,  2.40it/s]Train Iter: 1754/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0330. T_Loss: 4.8073. Mask: 0.9155. :  53%|█████▎    | 53/100 [00:13<00:19,  2.40it/s]Train Iter: 1754/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0330. T_Loss: 4.8073. Mask: 0.9155. :  54%|█████▍    | 54/100 [00:13<00:15,  3.05it/s]Train Iter: 1755/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0329. T_Loss: 4.8190. Mask: 0.9153. :  54%|█████▍    | 54/100 [00:14<00:15,  3.05it/s]Train Iter: 1755/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0329. T_Loss: 4.8190. Mask: 0.9153. :  55%|█████▌    | 55/100 [00:14<00:15,  2.98it/s]Train Iter: 1756/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0347. T_Loss: 4.8377. Mask: 0.9152. :  55%|█████▌    | 55/100 [00:14<00:15,  2.98it/s]Train Iter: 1756/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0347. T_Loss: 4.8377. Mask: 0.9152. :  56%|█████▌    | 56/100 [00:14<00:12,  3.61it/s]Train Iter: 1757/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0344. T_Loss: 4.8456. Mask: 0.9156. :  56%|█████▌    | 56/100 [00:14<00:12,  3.61it/s]Train Iter: 1757/5000. LR: 0.0439. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0344. T_Loss: 4.8456. Mask: 0.9156. :  57%|█████▋    | 57/100 [00:14<00:09,  4.33it/s]Train Iter: 1758/5000. LR: 0.0439. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0345. T_Loss: 4.8462. Mask: 0.9143. :  57%|█████▋    | 57/100 [00:14<00:09,  4.33it/s]Train Iter: 1758/5000. LR: 0.0439. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0345. T_Loss: 4.8462. Mask: 0.9143. :  58%|█████▊    | 58/100 [00:14<00:08,  5.01it/s]Train Iter: 1759/5000. LR: 0.0438. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0320. T_Loss: 4.8557. Mask: 0.9147. :  58%|█████▊    | 58/100 [00:14<00:08,  5.01it/s]Train Iter: 1759/5000. LR: 0.0438. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0320. T_Loss: 4.8557. Mask: 0.9147. :  59%|█████▉    | 59/100 [00:14<00:09,  4.17it/s]Train Iter: 1760/5000. LR: 0.0438. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0324. T_Loss: 4.8590. Mask: 0.9130. :  59%|█████▉    | 59/100 [00:14<00:09,  4.17it/s]Train Iter: 1761/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0333. T_Loss: 4.8632. Mask: 0.9119. :  60%|██████    | 60/100 [00:14<00:09,  4.17it/s]Train Iter: 1761/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0333. T_Loss: 4.8632. Mask: 0.9119. :  61%|██████    | 61/100 [00:14<00:07,  5.53it/s]Train Iter: 1762/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0344. T_Loss: 4.8775. Mask: 0.9118. :  61%|██████    | 61/100 [00:15<00:07,  5.53it/s]Train Iter: 1762/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0344. T_Loss: 4.8775. Mask: 0.9118. :  62%|██████▏   | 62/100 [00:15<00:06,  6.02it/s]Train Iter: 1763/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0349. T_Loss: 4.8794. Mask: 0.9102. :  62%|██████▏   | 62/100 [00:15<00:06,  6.02it/s]Train Iter: 1763/5000. LR: 0.0438. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0349. T_Loss: 4.8794. Mask: 0.9102. :  63%|██████▎   | 63/100 [00:15<00:05,  6.38it/s]Train Iter: 1764/5000. LR: 0.0438. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0341. T_Loss: 4.8795. Mask: 0.9102. :  63%|██████▎   | 63/100 [00:15<00:05,  6.38it/s]Train Iter: 1764/5000. LR: 0.0438. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0341. T_Loss: 4.8795. Mask: 0.9102. :  64%|██████▍   | 64/100 [00:15<00:05,  6.68it/s]Train Iter: 1765/5000. LR: 0.0438. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0342. T_Loss: 4.8828. Mask: 0.9096. :  64%|██████▍   | 64/100 [00:15<00:05,  6.68it/s]Train Iter: 1765/5000. LR: 0.0438. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0342. T_Loss: 4.8828. Mask: 0.9096. :  65%|██████▌   | 65/100 [00:15<00:05,  6.77it/s]Train Iter: 1766/5000. LR: 0.0438. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0339. T_Loss: 4.8910. Mask: 0.9100. :  65%|██████▌   | 65/100 [00:15<00:05,  6.77it/s]Train Iter: 1766/5000. LR: 0.0438. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0339. T_Loss: 4.8910. Mask: 0.9100. :  66%|██████▌   | 66/100 [00:15<00:04,  7.08it/s]Train Iter: 1767/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0344. T_Loss: 4.8843. Mask: 0.9100. :  66%|██████▌   | 66/100 [00:15<00:04,  7.08it/s]Train Iter: 1767/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0344. T_Loss: 4.8843. Mask: 0.9100. :  67%|██████▋   | 67/100 [00:15<00:04,  7.29it/s]Train Iter: 1768/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0341. T_Loss: 4.8885. Mask: 0.9108. :  67%|██████▋   | 67/100 [00:15<00:04,  7.29it/s]Train Iter: 1768/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0341. T_Loss: 4.8885. Mask: 0.9108. :  68%|██████▊   | 68/100 [00:15<00:04,  7.42it/s]Train Iter: 1769/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0339. T_Loss: 4.8901. Mask: 0.9108. :  68%|██████▊   | 68/100 [00:16<00:04,  7.42it/s]Train Iter: 1769/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0339. T_Loss: 4.8901. Mask: 0.9108. :  69%|██████▉   | 69/100 [00:16<00:05,  5.36it/s]Train Iter: 1770/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0335. T_Loss: 4.8911. Mask: 0.9107. :  69%|██████▉   | 69/100 [00:16<00:05,  5.36it/s]Train Iter: 1770/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0335. T_Loss: 4.8911. Mask: 0.9107. :  70%|███████   | 70/100 [00:16<00:05,  5.98it/s]Train Iter: 1771/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0340. T_Loss: 4.8982. Mask: 0.9111. :  70%|███████   | 70/100 [00:16<00:05,  5.98it/s]Train Iter: 1771/5000. LR: 0.0437. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0340. T_Loss: 4.8982. Mask: 0.9111. :  71%|███████   | 71/100 [00:16<00:04,  6.70it/s]Train Iter: 1772/5000. LR: 0.0437. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0338. T_Loss: 4.9009. Mask: 0.9106. :  71%|███████   | 71/100 [00:16<00:04,  6.70it/s]Train Iter: 1772/5000. LR: 0.0437. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0338. T_Loss: 4.9009. Mask: 0.9106. :  72%|███████▏  | 72/100 [00:16<00:03,  7.21it/s]Train Iter: 1773/5000. LR: 0.0437. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0335. T_Loss: 4.8889. Mask: 0.9097. :  72%|███████▏  | 72/100 [00:16<00:03,  7.21it/s]Train Iter: 1773/5000. LR: 0.0437. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0335. T_Loss: 4.8889. Mask: 0.9097. :  73%|███████▎  | 73/100 [00:16<00:03,  7.56it/s]Train Iter: 1774/5000. LR: 0.0437. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0321. T_Loss: 4.8813. Mask: 0.9092. :  73%|███████▎  | 73/100 [00:16<00:03,  7.56it/s]Train Iter: 1774/5000. LR: 0.0437. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0321. T_Loss: 4.8813. Mask: 0.9092. :  74%|███████▍  | 74/100 [00:16<00:03,  7.77it/s]Train Iter: 1775/5000. LR: 0.0436. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0323. T_Loss: 4.8834. Mask: 0.9092. :  74%|███████▍  | 74/100 [00:17<00:03,  7.77it/s]Train Iter: 1775/5000. LR: 0.0436. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0323. T_Loss: 4.8834. Mask: 0.9092. :  75%|███████▌  | 75/100 [00:17<00:05,  4.95it/s]total : 5000  current step :  1751
total : 5000  current step :  1752
total : 5000  current step :  1753
total : 5000  current step :  1754
total : 5000  current step :  1755
total : 5000  current step :  1756
total : 5000  current step :  1757
total : 5000  current step :  1758
total : 5000  current step :  1759
total : 5000  current step :  1760
total : 5000  current step :  1761
total : 5000  current step :  1762
total : 5000  current step :  1763
total : 5000  current step :  1764
total : 5000  current step :  1765
total : 5000  current step :  1766
total : 5000  current step :  1767
total : 5000  current step :  1768
total : 5000  current step :  1769
total : 5000  current step :  1770
total : 5000  current step :  1771
total : 5000  current step :  1772
total : 5000  current step :  1773
total : 5000  current step :  1774
total : 5000  current step :  1775
Train Iter: 1776/5000. LR: 0.0436. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0316. T_Loss: 4.8802. Mask: 0.9083. :  75%|███████▌  | 75/100 [00:19<00:05,  4.95it/s]Train Iter: 1776/5000. LR: 0.0436. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0316. T_Loss: 4.8802. Mask: 0.9083. :  76%|███████▌  | 76/100 [00:19<00:18,  1.28it/s]Train Iter: 1777/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0304. T_Loss: 4.8679. Mask: 0.9075. :  76%|███████▌  | 76/100 [00:19<00:18,  1.28it/s]Train Iter: 1777/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0304. T_Loss: 4.8679. Mask: 0.9075. :  77%|███████▋  | 77/100 [00:19<00:13,  1.72it/s]Train Iter: 1778/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0297. T_Loss: 4.8728. Mask: 0.9083. :  77%|███████▋  | 77/100 [00:19<00:13,  1.72it/s]Train Iter: 1778/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0297. T_Loss: 4.8728. Mask: 0.9083. :  78%|███████▊  | 78/100 [00:19<00:09,  2.24it/s]Train Iter: 1779/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0285. T_Loss: 4.8593. Mask: 0.9086. :  78%|███████▊  | 78/100 [00:19<00:09,  2.24it/s]Train Iter: 1779/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0285. T_Loss: 4.8593. Mask: 0.9086. :  79%|███████▉  | 79/100 [00:19<00:08,  2.42it/s]Train Iter: 1780/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0277. T_Loss: 4.8461. Mask: 0.9082. :  79%|███████▉  | 79/100 [00:19<00:08,  2.42it/s]Train Iter: 1780/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0277. T_Loss: 4.8461. Mask: 0.9082. :  80%|████████  | 80/100 [00:19<00:06,  3.08it/s]Train Iter: 1781/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0281. T_Loss: 4.8452. Mask: 0.9086. :  80%|████████  | 80/100 [00:20<00:06,  3.08it/s]Train Iter: 1781/5000. LR: 0.0436. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0281. T_Loss: 4.8452. Mask: 0.9086. :  81%|████████  | 81/100 [00:20<00:04,  3.81it/s]Train Iter: 1782/5000. LR: 0.0436. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0285. T_Loss: 4.8301. Mask: 0.9082. :  81%|████████  | 81/100 [00:20<00:04,  3.81it/s]Train Iter: 1782/5000. LR: 0.0436. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0285. T_Loss: 4.8301. Mask: 0.9082. :  82%|████████▏ | 82/100 [00:20<00:03,  4.58it/s]Train Iter: 1783/5000. LR: 0.0435. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0301. T_Loss: 4.8303. Mask: 0.9078. :  82%|████████▏ | 82/100 [00:20<00:03,  4.58it/s]Train Iter: 1783/5000. LR: 0.0435. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0301. T_Loss: 4.8303. Mask: 0.9078. :  83%|████████▎ | 83/100 [00:20<00:03,  5.26it/s]Train Iter: 1784/5000. LR: 0.0435. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0310. T_Loss: 4.8348. Mask: 0.9081. :  83%|████████▎ | 83/100 [00:20<00:03,  5.26it/s]Train Iter: 1784/5000. LR: 0.0435. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0310. T_Loss: 4.8348. Mask: 0.9081. :  84%|████████▍ | 84/100 [00:20<00:02,  5.90it/s]Train Iter: 1785/5000. LR: 0.0435. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0325. T_Loss: 4.8268. Mask: 0.9074. :  84%|████████▍ | 84/100 [00:20<00:02,  5.90it/s]Train Iter: 1785/5000. LR: 0.0435. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0325. T_Loss: 4.8268. Mask: 0.9074. :  85%|████████▌ | 85/100 [00:20<00:03,  4.27it/s]Train Iter: 1786/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0312. T_Loss: 4.8187. Mask: 0.9084. :  85%|████████▌ | 85/100 [00:20<00:03,  4.27it/s]Train Iter: 1786/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0312. T_Loss: 4.8187. Mask: 0.9084. :  86%|████████▌ | 86/100 [00:20<00:02,  4.99it/s]Train Iter: 1787/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0300. T_Loss: 4.8111. Mask: 0.9077. :  86%|████████▌ | 86/100 [00:21<00:02,  4.99it/s]Train Iter: 1787/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0300. T_Loss: 4.8111. Mask: 0.9077. :  87%|████████▋ | 87/100 [00:21<00:02,  5.63it/s]Train Iter: 1788/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0295. T_Loss: 4.8186. Mask: 0.9084. :  87%|████████▋ | 87/100 [00:21<00:02,  5.63it/s]Train Iter: 1788/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0295. T_Loss: 4.8186. Mask: 0.9084. :  88%|████████▊ | 88/100 [00:21<00:01,  6.23it/s]Train Iter: 1789/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0283. T_Loss: 4.8030. Mask: 0.9084. :  88%|████████▊ | 88/100 [00:21<00:01,  6.23it/s]Train Iter: 1789/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0283. T_Loss: 4.8030. Mask: 0.9084. :  89%|████████▉ | 89/100 [00:21<00:01,  6.65it/s]Train Iter: 1790/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0286. T_Loss: 4.7962. Mask: 0.9090. :  89%|████████▉ | 89/100 [00:21<00:01,  6.65it/s]Train Iter: 1790/5000. LR: 0.0435. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0286. T_Loss: 4.7962. Mask: 0.9090. :  90%|█████████ | 90/100 [00:21<00:01,  7.02it/s]Train Iter: 1791/5000. LR: 0.0434. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0278. T_Loss: 4.7898. Mask: 0.9097. :  90%|█████████ | 90/100 [00:21<00:01,  7.02it/s]Train Iter: 1791/5000. LR: 0.0434. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0278. T_Loss: 4.7898. Mask: 0.9097. :  91%|█████████ | 91/100 [00:21<00:01,  7.00it/s]Train Iter: 1792/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0264. T_Loss: 4.7805. Mask: 0.9100. :  91%|█████████ | 91/100 [00:21<00:01,  7.00it/s]Train Iter: 1792/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0264. T_Loss: 4.7805. Mask: 0.9100. :  92%|█████████▏| 92/100 [00:21<00:01,  7.44it/s]Train Iter: 1793/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0253. T_Loss: 4.7715. Mask: 0.9106. :  92%|█████████▏| 92/100 [00:21<00:01,  7.44it/s]Train Iter: 1793/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0253. T_Loss: 4.7715. Mask: 0.9106. :  93%|█████████▎| 93/100 [00:21<00:00,  7.67it/s]Train Iter: 1794/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0245. T_Loss: 4.7667. Mask: 0.9099. :  93%|█████████▎| 93/100 [00:21<00:00,  7.67it/s]Train Iter: 1794/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0245. T_Loss: 4.7667. Mask: 0.9099. :  94%|█████████▍| 94/100 [00:21<00:00,  8.04it/s]Train Iter: 1795/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0225. T_Loss: 4.7454. Mask: 0.9102. :  94%|█████████▍| 94/100 [00:22<00:00,  8.04it/s]Train Iter: 1795/5000. LR: 0.0434. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0225. T_Loss: 4.7454. Mask: 0.9102. :  95%|█████████▌| 95/100 [00:22<00:00,  6.18it/s]Train Iter: 1796/5000. LR: 0.0434. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0217. T_Loss: 4.7501. Mask: 0.9108. :  95%|█████████▌| 95/100 [00:22<00:00,  6.18it/s]Train Iter: 1796/5000. LR: 0.0434. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0217. T_Loss: 4.7501. Mask: 0.9108. :  96%|█████████▌| 96/100 [00:22<00:00,  6.51it/s]Train Iter: 1797/5000. LR: 0.0434. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0211. T_Loss: 4.7446. Mask: 0.9114. :  96%|█████████▌| 96/100 [00:22<00:00,  6.51it/s]Train Iter: 1797/5000. LR: 0.0434. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0211. T_Loss: 4.7446. Mask: 0.9114. :  97%|█████████▋| 97/100 [00:22<00:00,  7.04it/s]Train Iter: 1798/5000. LR: 0.0434. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0191. T_Loss: 4.7328. Mask: 0.9120. :  97%|█████████▋| 97/100 [00:22<00:00,  7.04it/s]Train Iter: 1798/5000. LR: 0.0434. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0191. T_Loss: 4.7328. Mask: 0.9120. :  98%|█████████▊| 98/100 [00:22<00:00,  7.29it/s]Train Iter: 1799/5000. LR: 0.0433. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0190. T_Loss: 4.7256. Mask: 0.9122. :  98%|█████████▊| 98/100 [00:22<00:00,  7.29it/s]Train Iter: 1799/5000. LR: 0.0433. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0190. T_Loss: 4.7256. Mask: 0.9122. :  99%|█████████▉| 99/100 [00:22<00:00,  4.69it/s]Train Iter: 1800/5000. LR: 0.0433. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0178. T_Loss: 4.7187. Mask: 0.9125. :  99%|█████████▉| 99/100 [00:23<00:00,  4.69it/s]Train Iter: 1800/5000. LR: 0.0433. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0178. T_Loss: 4.7187. Mask: 0.9125. : 100%|██████████| 100/100 [00:23<00:00,  5.40it/s]Train Iter: 1800/5000. LR: 0.0433. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0178. T_Loss: 4.7187. Mask: 0.9125. : 100%|██████████| 100/100 [00:23<00:00,  4.33it/s]
total : 5000  current step :  1776
total : 5000  current step :  1777
total : 5000  current step :  1778
total : 5000  current step :  1779
total : 5000  current step :  1780
total : 5000  current step :  1781
total : 5000  current step :  1782
total : 5000  current step :  1783
total : 5000  current step :  1784
total : 5000  current step :  1785
total : 5000  current step :  1786
total : 5000  current step :  1787
total : 5000  current step :  1788
total : 5000  current step :  1789
total : 5000  current step :  1790
total : 5000  current step :  1791
total : 5000  current step :  1792
total : 5000  current step :  1793
total : 5000  current step :  1794
total : 5000  current step :  1795
total : 5000  current step :  1796
total : 5000  current step :  1797
total : 5000  current step :  1798
total : 5000  current step :  1799
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.72s. Loss: 1.2536. top1: 62.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.72s. Loss: 1.2536. top1: 62.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 1.2044. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.59s. Loss: 1.1254. top1: 76.04. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 1.1431. top1: 74.22. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.1286. top1: 76.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.1328. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.1461. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 1.1624. top1: 73.05. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 1.1624. top1: 73.05. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.1515. top1: 73.96. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.1649. top1: 73.12. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.1428. top1: 74.43. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.1399. top1: 73.70. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.1306. top1: 74.28. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1324. top1: 73.88. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1230. top1: 74.79. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1253. top1: 74.61. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.87it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1253. top1: 74.61. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1185. top1: 75.00. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1173. top1: 74.31. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1177. top1: 74.34. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1142. top1: 74.53. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1259. top1: 73.96. top5: 99.85. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1195. top1: 74.43. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1122. top1: 75.00. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1082. top1: 75.39. top5: 99.87. :  25%|██▌       | 16/63 [00:02<00:03, 13.16it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1061. top1: 75.25. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.16it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1124. top1: 74.88. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.16it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1100. top1: 75.00. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.16it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1100. top1: 75.00. top5: 99.88. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1135. top1: 74.67. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1124. top1: 74.68. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1114. top1: 74.69. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1131. top1: 74.40. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1165. top1: 74.22. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1119. top1: 74.72. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1107. top1: 74.82. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1079. top1: 74.91. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1164. top1: 74.39. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.91it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1164. top1: 74.39. top5: 99.91. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1125. top1: 74.75. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1095. top1: 74.92. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1149. top1: 74.60. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1134. top1: 74.77. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1120. top1: 75.00. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1144. top1: 74.78. top5: 99.93. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1135. top1: 74.85. top5: 99.93. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1092. top1: 75.14. top5: 99.93. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1054. top1: 75.35. top5: 99.93. :  57%|█████▋    | 36/63 [00:02<00:00, 34.51it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1054. top1: 75.35. top5: 99.93. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1050. top1: 75.34. top5: 99.93. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1053. top1: 75.27. top5: 99.93. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1033. top1: 75.33. top5: 99.93. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1037. top1: 75.45. top5: 99.94. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1027. top1: 75.44. top5: 99.94. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1079. top1: 75.12. top5: 99.94. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1064. top1: 75.24. top5: 99.94. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1083. top1: 75.18. top5: 99.94. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1089. top1: 75.06. top5: 99.94. :  71%|███████▏  | 45/63 [00:02<00:00, 43.77it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1089. top1: 75.06. top5: 99.94. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1082. top1: 75.11. top5: 99.94. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1060. top1: 75.22. top5: 99.94. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1082. top1: 75.22. top5: 99.95. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1077. top1: 75.27. top5: 99.95. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1087. top1: 75.26. top5: 99.95. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1055. top1: 75.47. top5: 99.95. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1072. top1: 75.31. top5: 99.95. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1103. top1: 75.10. top5: 99.95. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1096. top1: 75.15. top5: 99.95. :  86%|████████▌ | 54/63 [00:02<00:00, 51.88it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1096. top1: 75.15. top5: 99.95. : 100%|██████████| 63/63 [00:02<00:00, 59.97it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1096. top1: 75.15. top5: 99.95. : 100%|██████████| 63/63 [00:02<00:00, 23.57it/s]
total : 5000  current step :  1800
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1801/5000. LR: 0.0433. Data: 1.97s. Batch: 2.07s. S_Loss: 1.1826. T_Loss: 4.5605. Mask: 0.8438. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1801/5000. LR: 0.0433. Data: 1.97s. Batch: 2.07s. S_Loss: 1.1826. T_Loss: 4.5605. Mask: 0.8438. :   1%|          | 1/100 [00:02<03:24,  2.07s/it]Train Iter: 1802/5000. LR: 0.0433. Data: 0.98s. Batch: 1.10s. S_Loss: 1.0767. T_Loss: 4.3471. Mask: 0.8906. :   1%|          | 1/100 [00:02<03:24,  2.07s/it]Train Iter: 1802/5000. LR: 0.0433. Data: 0.98s. Batch: 1.10s. S_Loss: 1.0767. T_Loss: 4.3471. Mask: 0.8906. :   2%|▏         | 2/100 [00:02<01:30,  1.08it/s]Train Iter: 1803/5000. LR: 0.0433. Data: 0.66s. Batch: 0.77s. S_Loss: 1.0155. T_Loss: 4.3426. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:30,  1.08it/s]Train Iter: 1803/5000. LR: 0.0433. Data: 0.66s. Batch: 0.77s. S_Loss: 1.0155. T_Loss: 4.3426. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:54,  1.78it/s]Train Iter: 1804/5000. LR: 0.0433. Data: 0.49s. Batch: 0.61s. S_Loss: 1.0030. T_Loss: 4.1533. Mask: 0.8906. :   3%|▎         | 3/100 [00:02<00:54,  1.78it/s]Train Iter: 1804/5000. LR: 0.0433. Data: 0.49s. Batch: 0.61s. S_Loss: 1.0030. T_Loss: 4.1533. Mask: 0.8906. :   4%|▍         | 4/100 [00:02<00:37,  2.56it/s]Train Iter: 1805/5000. LR: 0.0433. Data: 0.40s. Batch: 0.53s. S_Loss: 0.9734. T_Loss: 4.0931. Mask: 0.9062. :   4%|▍         | 4/100 [00:02<00:37,  2.56it/s]Train Iter: 1805/5000. LR: 0.0433. Data: 0.40s. Batch: 0.53s. S_Loss: 0.9734. T_Loss: 4.0931. Mask: 0.9062. :   5%|▌         | 5/100 [00:02<00:31,  3.03it/s]Train Iter: 1806/5000. LR: 0.0432. Data: 0.33s. Batch: 0.46s. S_Loss: 0.9794. T_Loss: 4.3923. Mask: 0.9219. :   5%|▌         | 5/100 [00:02<00:31,  3.03it/s]Train Iter: 1806/5000. LR: 0.0432. Data: 0.33s. Batch: 0.46s. S_Loss: 0.9794. T_Loss: 4.3923. Mask: 0.9219. :   6%|▌         | 6/100 [00:02<00:24,  3.86it/s]Train Iter: 1807/5000. LR: 0.0432. Data: 0.28s. Batch: 0.42s. S_Loss: 0.9819. T_Loss: 4.4749. Mask: 0.9196. :   6%|▌         | 6/100 [00:02<00:24,  3.86it/s]Train Iter: 1807/5000. LR: 0.0432. Data: 0.28s. Batch: 0.42s. S_Loss: 0.9819. T_Loss: 4.4749. Mask: 0.9196. :   7%|▋         | 7/100 [00:02<00:21,  4.39it/s]Train Iter: 1808/5000. LR: 0.0432. Data: 0.25s. Batch: 0.38s. S_Loss: 0.9666. T_Loss: 4.4176. Mask: 0.9180. :   7%|▋         | 7/100 [00:03<00:21,  4.39it/s]Train Iter: 1808/5000. LR: 0.0432. Data: 0.25s. Batch: 0.38s. S_Loss: 0.9666. T_Loss: 4.4176. Mask: 0.9180. :   8%|▊         | 8/100 [00:03<00:18,  5.11it/s]Train Iter: 1809/5000. LR: 0.0432. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9804. T_Loss: 4.4944. Mask: 0.9167. :   8%|▊         | 8/100 [00:03<00:18,  5.11it/s]Train Iter: 1809/5000. LR: 0.0432. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9804. T_Loss: 4.4944. Mask: 0.9167. :   9%|▉         | 9/100 [00:03<00:16,  5.64it/s]Train Iter: 1810/5000. LR: 0.0432. Data: 0.20s. Batch: 0.33s. S_Loss: 1.0037. T_Loss: 4.5678. Mask: 0.9125. :   9%|▉         | 9/100 [00:03<00:16,  5.64it/s]Train Iter: 1810/5000. LR: 0.0432. Data: 0.20s. Batch: 0.33s. S_Loss: 1.0037. T_Loss: 4.5678. Mask: 0.9125. :  10%|█         | 10/100 [00:03<00:14,  6.24it/s]Train Iter: 1811/5000. LR: 0.0432. Data: 0.18s. Batch: 0.31s. S_Loss: 1.0066. T_Loss: 4.5929. Mask: 0.9119. :  10%|█         | 10/100 [00:03<00:14,  6.24it/s]Train Iter: 1811/5000. LR: 0.0432. Data: 0.18s. Batch: 0.31s. S_Loss: 1.0066. T_Loss: 4.5929. Mask: 0.9119. :  11%|█         | 11/100 [00:03<00:13,  6.73it/s]Train Iter: 1812/5000. LR: 0.0432. Data: 0.17s. Batch: 0.30s. S_Loss: 1.0138. T_Loss: 4.5295. Mask: 0.9010. :  11%|█         | 11/100 [00:03<00:13,  6.73it/s]Train Iter: 1812/5000. LR: 0.0432. Data: 0.17s. Batch: 0.30s. S_Loss: 1.0138. T_Loss: 4.5295. Mask: 0.9010. :  12%|█▏        | 12/100 [00:03<00:11,  7.34it/s]Train Iter: 1813/5000. LR: 0.0432. Data: 0.16s. Batch: 0.28s. S_Loss: 1.0150. T_Loss: 4.6063. Mask: 0.9087. :  12%|█▏        | 12/100 [00:03<00:11,  7.34it/s]Train Iter: 1813/5000. LR: 0.0432. Data: 0.16s. Batch: 0.28s. S_Loss: 1.0150. T_Loss: 4.6063. Mask: 0.9087. :  13%|█▎        | 13/100 [00:03<00:11,  7.60it/s]Train Iter: 1814/5000. LR: 0.0431. Data: 0.14s. Batch: 0.27s. S_Loss: 1.0319. T_Loss: 4.6514. Mask: 0.9040. :  13%|█▎        | 13/100 [00:03<00:11,  7.60it/s]Train Iter: 1814/5000. LR: 0.0431. Data: 0.14s. Batch: 0.27s. S_Loss: 1.0319. T_Loss: 4.6514. Mask: 0.9040. :  14%|█▍        | 14/100 [00:03<00:11,  7.50it/s]Train Iter: 1815/5000. LR: 0.0431. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0277. T_Loss: 4.6551. Mask: 0.9042. :  14%|█▍        | 14/100 [00:04<00:11,  7.50it/s]Train Iter: 1815/5000. LR: 0.0431. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0277. T_Loss: 4.6551. Mask: 0.9042. :  15%|█▌        | 15/100 [00:04<00:16,  5.28it/s]Train Iter: 1816/5000. LR: 0.0431. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0204. T_Loss: 4.6540. Mask: 0.9062. :  15%|█▌        | 15/100 [00:04<00:16,  5.28it/s]Train Iter: 1816/5000. LR: 0.0431. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0204. T_Loss: 4.6540. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:14,  5.66it/s]Train Iter: 1817/5000. LR: 0.0431. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0155. T_Loss: 4.6710. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:14,  5.66it/s]Train Iter: 1817/5000. LR: 0.0431. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0155. T_Loss: 4.6710. Mask: 0.9062. :  17%|█▋        | 17/100 [00:04<00:13,  6.33it/s]Train Iter: 1818/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0154. T_Loss: 4.6632. Mask: 0.9062. :  17%|█▋        | 17/100 [00:04<00:13,  6.33it/s]Train Iter: 1818/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0154. T_Loss: 4.6632. Mask: 0.9062. :  18%|█▊        | 18/100 [00:04<00:12,  6.83it/s]Train Iter: 1819/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0123. T_Loss: 4.6253. Mask: 0.9013. :  18%|█▊        | 18/100 [00:04<00:12,  6.83it/s]Train Iter: 1819/5000. LR: 0.0431. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0123. T_Loss: 4.6253. Mask: 0.9013. :  19%|█▉        | 19/100 [00:04<00:14,  5.42it/s]Train Iter: 1820/5000. LR: 0.0431. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0148. T_Loss: 4.5883. Mask: 0.8938. :  19%|█▉        | 19/100 [00:04<00:14,  5.42it/s]Train Iter: 1820/5000. LR: 0.0431. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0148. T_Loss: 4.5883. Mask: 0.8938. :  20%|██        | 20/100 [00:04<00:13,  6.04it/s]Train Iter: 1821/5000. LR: 0.0431. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0108. T_Loss: 4.5943. Mask: 0.8958. :  20%|██        | 20/100 [00:05<00:13,  6.04it/s]Train Iter: 1821/5000. LR: 0.0431. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0108. T_Loss: 4.5943. Mask: 0.8958. :  21%|██        | 21/100 [00:05<00:12,  6.55it/s]Train Iter: 1822/5000. LR: 0.0430. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0101. T_Loss: 4.5675. Mask: 0.8935. :  21%|██        | 21/100 [00:05<00:12,  6.55it/s]Train Iter: 1822/5000. LR: 0.0430. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0101. T_Loss: 4.5675. Mask: 0.8935. :  22%|██▏       | 22/100 [00:05<00:11,  6.97it/s]Train Iter: 1823/5000. LR: 0.0430. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0102. T_Loss: 4.5928. Mask: 0.8954. :  22%|██▏       | 22/100 [00:05<00:11,  6.97it/s]Train Iter: 1823/5000. LR: 0.0430. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0102. T_Loss: 4.5928. Mask: 0.8954. :  23%|██▎       | 23/100 [00:05<00:10,  7.29it/s]Train Iter: 1824/5000. LR: 0.0430. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0076. T_Loss: 4.5880. Mask: 0.8958. :  23%|██▎       | 23/100 [00:05<00:10,  7.29it/s]Train Iter: 1824/5000. LR: 0.0430. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0076. T_Loss: 4.5880. Mask: 0.8958. :  24%|██▍       | 24/100 [00:05<00:10,  7.44it/s]Train Iter: 1825/5000. LR: 0.0430. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0070. T_Loss: 4.5379. Mask: 0.8938. :  24%|██▍       | 24/100 [00:05<00:10,  7.44it/s]Train Iter: 1825/5000. LR: 0.0430. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0070. T_Loss: 4.5379. Mask: 0.8938. :  25%|██▌       | 25/100 [00:05<00:14,  5.11it/s]total : 5000  current step :  1801
total : 5000  current step :  1802
total : 5000  current step :  1803
total : 5000  current step :  1804
total : 5000  current step :  1805
total : 5000  current step :  1806
total : 5000  current step :  1807
total : 5000  current step :  1808
total : 5000  current step :  1809
total : 5000  current step :  1810
total : 5000  current step :  1811
total : 5000  current step :  1812
total : 5000  current step :  1813
total : 5000  current step :  1814
total : 5000  current step :  1815
total : 5000  current step :  1816
total : 5000  current step :  1817
total : 5000  current step :  1818
total : 5000  current step :  1819
total : 5000  current step :  1820
total : 5000  current step :  1821
total : 5000  current step :  1822
total : 5000  current step :  1823
total : 5000  current step :  1824
total : 5000  current step :  1825
Train Iter: 1826/5000. LR: 0.0430. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0115. T_Loss: 4.5970. Mask: 0.8966. :  25%|██▌       | 25/100 [00:07<00:14,  5.11it/s]Train Iter: 1826/5000. LR: 0.0430. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0115. T_Loss: 4.5970. Mask: 0.8966. :  26%|██▌       | 26/100 [00:07<00:55,  1.33it/s]Train Iter: 1827/5000. LR: 0.0430. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0098. T_Loss: 4.5746. Mask: 0.8970. :  26%|██▌       | 26/100 [00:07<00:55,  1.33it/s]Train Iter: 1827/5000. LR: 0.0430. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0098. T_Loss: 4.5746. Mask: 0.8970. :  27%|██▋       | 27/100 [00:07<00:41,  1.77it/s]Train Iter: 1828/5000. LR: 0.0430. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0079. T_Loss: 4.5769. Mask: 0.8996. :  27%|██▋       | 27/100 [00:08<00:41,  1.77it/s]Train Iter: 1828/5000. LR: 0.0430. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0079. T_Loss: 4.5769. Mask: 0.8996. :  28%|██▊       | 28/100 [00:08<00:31,  2.31it/s]Train Iter: 1829/5000. LR: 0.0430. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0090. T_Loss: 4.6139. Mask: 0.9009. :  28%|██▊       | 28/100 [00:08<00:31,  2.31it/s]Train Iter: 1829/5000. LR: 0.0430. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0090. T_Loss: 4.6139. Mask: 0.9009. :  29%|██▉       | 29/100 [00:08<00:26,  2.73it/s]Train Iter: 1830/5000. LR: 0.0429. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0077. T_Loss: 4.6464. Mask: 0.9010. :  29%|██▉       | 29/100 [00:08<00:26,  2.73it/s]Train Iter: 1831/5000. LR: 0.0429. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0093. T_Loss: 4.7015. Mask: 0.9032. :  30%|███       | 30/100 [00:08<00:25,  2.73it/s]Train Iter: 1831/5000. LR: 0.0429. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0093. T_Loss: 4.7015. Mask: 0.9032. :  31%|███       | 31/100 [00:08<00:16,  4.29it/s]Train Iter: 1832/5000. LR: 0.0429. Data: 0.13s. Batch: 0.26s. S_Loss: 1.0091. T_Loss: 4.7077. Mask: 0.9043. :  31%|███       | 31/100 [00:08<00:16,  4.29it/s]Train Iter: 1833/5000. LR: 0.0429. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0118. T_Loss: 4.7045. Mask: 0.9034. :  32%|███▏      | 32/100 [00:08<00:15,  4.29it/s]Train Iter: 1833/5000. LR: 0.0429. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0118. T_Loss: 4.7045. Mask: 0.9034. :  33%|███▎      | 33/100 [00:08<00:11,  5.83it/s]Train Iter: 1834/5000. LR: 0.0429. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0138. T_Loss: 4.7283. Mask: 0.9035. :  33%|███▎      | 33/100 [00:08<00:11,  5.83it/s]Train Iter: 1835/5000. LR: 0.0429. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0130. T_Loss: 4.7334. Mask: 0.9036. :  34%|███▍      | 34/100 [00:08<00:11,  5.83it/s]Train Iter: 1835/5000. LR: 0.0429. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0130. T_Loss: 4.7334. Mask: 0.9036. :  35%|███▌      | 35/100 [00:08<00:11,  5.62it/s]Train Iter: 1836/5000. LR: 0.0429. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0154. T_Loss: 4.7341. Mask: 0.9028. :  35%|███▌      | 35/100 [00:09<00:11,  5.62it/s]Train Iter: 1836/5000. LR: 0.0429. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0154. T_Loss: 4.7341. Mask: 0.9028. :  36%|███▌      | 36/100 [00:09<00:10,  5.91it/s]Train Iter: 1837/5000. LR: 0.0428. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0146. T_Loss: 4.7408. Mask: 0.9020. :  36%|███▌      | 36/100 [00:09<00:10,  5.91it/s]Train Iter: 1837/5000. LR: 0.0428. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0146. T_Loss: 4.7408. Mask: 0.9020. :  37%|███▋      | 37/100 [00:09<00:10,  6.24it/s]Train Iter: 1838/5000. LR: 0.0428. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0121. T_Loss: 4.7634. Mask: 0.9030. :  37%|███▋      | 37/100 [00:09<00:10,  6.24it/s]Train Iter: 1838/5000. LR: 0.0428. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0121. T_Loss: 4.7634. Mask: 0.9030. :  38%|███▊      | 38/100 [00:09<00:09,  6.54it/s]Train Iter: 1839/5000. LR: 0.0428. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0132. T_Loss: 4.7661. Mask: 0.9030. :  38%|███▊      | 38/100 [00:09<00:09,  6.54it/s]Train Iter: 1839/5000. LR: 0.0428. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0132. T_Loss: 4.7661. Mask: 0.9030. :  39%|███▉      | 39/100 [00:09<00:09,  6.24it/s]Train Iter: 1840/5000. LR: 0.0428. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0167. T_Loss: 4.7762. Mask: 0.9023. :  39%|███▉      | 39/100 [00:09<00:09,  6.24it/s]Train Iter: 1840/5000. LR: 0.0428. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0167. T_Loss: 4.7762. Mask: 0.9023. :  40%|████      | 40/100 [00:09<00:09,  6.66it/s]Train Iter: 1841/5000. LR: 0.0428. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0139. T_Loss: 4.7736. Mask: 0.9032. :  40%|████      | 40/100 [00:09<00:09,  6.66it/s]Train Iter: 1841/5000. LR: 0.0428. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0139. T_Loss: 4.7736. Mask: 0.9032. :  41%|████      | 41/100 [00:09<00:08,  6.75it/s]Train Iter: 1842/5000. LR: 0.0428. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0142. T_Loss: 4.7879. Mask: 0.9033. :  41%|████      | 41/100 [00:09<00:08,  6.75it/s]Train Iter: 1842/5000. LR: 0.0428. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0142. T_Loss: 4.7879. Mask: 0.9033. :  42%|████▏     | 42/100 [00:09<00:07,  7.29it/s]Train Iter: 1843/5000. LR: 0.0428. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0180. T_Loss: 4.7907. Mask: 0.9019. :  42%|████▏     | 42/100 [00:10<00:07,  7.29it/s]Train Iter: 1844/5000. LR: 0.0428. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0200. T_Loss: 4.8237. Mask: 0.9034. :  43%|████▎     | 43/100 [00:10<00:07,  7.29it/s]Train Iter: 1844/5000. LR: 0.0428. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0200. T_Loss: 4.8237. Mask: 0.9034. :  44%|████▍     | 44/100 [00:10<00:07,  8.00it/s]Train Iter: 1845/5000. LR: 0.0427. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0205. T_Loss: 4.8212. Mask: 0.9035. :  44%|████▍     | 44/100 [00:10<00:07,  8.00it/s]Train Iter: 1845/5000. LR: 0.0427. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0205. T_Loss: 4.8212. Mask: 0.9035. :  45%|████▌     | 45/100 [00:10<00:09,  5.93it/s]Train Iter: 1846/5000. LR: 0.0427. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0184. T_Loss: 4.8137. Mask: 0.9035. :  45%|████▌     | 45/100 [00:10<00:09,  5.93it/s]Train Iter: 1846/5000. LR: 0.0427. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0184. T_Loss: 4.8137. Mask: 0.9035. :  46%|████▌     | 46/100 [00:10<00:08,  6.12it/s]Train Iter: 1847/5000. LR: 0.0427. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0189. T_Loss: 4.8350. Mask: 0.9049. :  46%|████▌     | 46/100 [00:10<00:08,  6.12it/s]Train Iter: 1847/5000. LR: 0.0427. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0189. T_Loss: 4.8350. Mask: 0.9049. :  47%|████▋     | 47/100 [00:10<00:08,  6.55it/s]Train Iter: 1848/5000. LR: 0.0427. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0190. T_Loss: 4.8271. Mask: 0.9036. :  47%|████▋     | 47/100 [00:10<00:08,  6.55it/s]Train Iter: 1848/5000. LR: 0.0427. Data: 0.09s. Batch: 0.22s. S_Loss: 1.0190. T_Loss: 4.8271. Mask: 0.9036. :  48%|████▊     | 48/100 [00:10<00:07,  6.79it/s]Train Iter: 1849/5000. LR: 0.0427. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0178. T_Loss: 4.8246. Mask: 0.9043. :  48%|████▊     | 48/100 [00:11<00:07,  6.79it/s]Train Iter: 1849/5000. LR: 0.0427. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0178. T_Loss: 4.8246. Mask: 0.9043. :  49%|████▉     | 49/100 [00:11<00:08,  5.67it/s]Train Iter: 1850/5000. LR: 0.0427. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0173. T_Loss: 4.8050. Mask: 0.9025. :  49%|████▉     | 49/100 [00:11<00:08,  5.67it/s]Train Iter: 1850/5000. LR: 0.0427. Data: 0.08s. Batch: 0.22s. S_Loss: 1.0173. T_Loss: 4.8050. Mask: 0.9025. :  50%|█████     | 50/100 [00:11<00:08,  6.16it/s]total : 5000  current step :  1826
total : 5000  current step :  1827
total : 5000  current step :  1828
total : 5000  current step :  1829
total : 5000  current step :  1830
total : 5000  current step :  1831
total : 5000  current step :  1832
total : 5000  current step :  1833
total : 5000  current step :  1834
total : 5000  current step :  1835
total : 5000  current step :  1836
total : 5000  current step :  1837
total : 5000  current step :  1838
total : 5000  current step :  1839
total : 5000  current step :  1840
total : 5000  current step :  1841
total : 5000  current step :  1842
total : 5000  current step :  1843
total : 5000  current step :  1844
total : 5000  current step :  1845
total : 5000  current step :  1846
total : 5000  current step :  1847
total : 5000  current step :  1848
total : 5000  current step :  1849
total : 5000  current step :  1850
Train Iter: 1851/5000. LR: 0.0427. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0173. T_Loss: 4.8159. Mask: 0.9026. :  50%|█████     | 50/100 [00:13<00:08,  6.16it/s]Train Iter: 1851/5000. LR: 0.0427. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0173. T_Loss: 4.8159. Mask: 0.9026. :  51%|█████     | 51/100 [00:13<00:34,  1.43it/s]Train Iter: 1852/5000. LR: 0.0427. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0185. T_Loss: 4.7950. Mask: 0.9002. :  51%|█████     | 51/100 [00:13<00:34,  1.43it/s]Train Iter: 1852/5000. LR: 0.0427. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0185. T_Loss: 4.7950. Mask: 0.9002. :  52%|█████▏    | 52/100 [00:13<00:25,  1.89it/s]Train Iter: 1853/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0177. T_Loss: 4.8014. Mask: 0.9009. :  52%|█████▏    | 52/100 [00:13<00:25,  1.89it/s]Train Iter: 1853/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0177. T_Loss: 4.8014. Mask: 0.9009. :  53%|█████▎    | 53/100 [00:13<00:19,  2.39it/s]Train Iter: 1854/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0168. T_Loss: 4.7923. Mask: 0.9010. :  53%|█████▎    | 53/100 [00:13<00:19,  2.39it/s]Train Iter: 1854/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0168. T_Loss: 4.7923. Mask: 0.9010. :  54%|█████▍    | 54/100 [00:13<00:15,  3.02it/s]Train Iter: 1855/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0133. T_Loss: 4.7730. Mask: 0.9028. :  54%|█████▍    | 54/100 [00:13<00:15,  3.02it/s]Train Iter: 1855/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0133. T_Loss: 4.7730. Mask: 0.9028. :  55%|█████▌    | 55/100 [00:13<00:12,  3.64it/s]Train Iter: 1856/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0130. T_Loss: 4.7627. Mask: 0.9035. :  55%|█████▌    | 55/100 [00:13<00:12,  3.64it/s]Train Iter: 1856/5000. LR: 0.0426. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0130. T_Loss: 4.7627. Mask: 0.9035. :  56%|█████▌    | 56/100 [00:13<00:10,  4.32it/s]Train Iter: 1857/5000. LR: 0.0426. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0131. T_Loss: 4.7630. Mask: 0.9030. :  56%|█████▌    | 56/100 [00:14<00:10,  4.32it/s]Train Iter: 1857/5000. LR: 0.0426. Data: 0.11s. Batch: 0.24s. S_Loss: 1.0131. T_Loss: 4.7630. Mask: 0.9030. :  57%|█████▋    | 57/100 [00:14<00:08,  4.90it/s]Train Iter: 1858/5000. LR: 0.0426. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0122. T_Loss: 4.7576. Mask: 0.9030. :  57%|█████▋    | 57/100 [00:14<00:08,  4.90it/s]Train Iter: 1858/5000. LR: 0.0426. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0122. T_Loss: 4.7576. Mask: 0.9030. :  58%|█████▊    | 58/100 [00:14<00:07,  5.44it/s]Train Iter: 1859/5000. LR: 0.0426. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0119. T_Loss: 4.7590. Mask: 0.9041. :  58%|█████▊    | 58/100 [00:14<00:07,  5.44it/s]Train Iter: 1859/5000. LR: 0.0426. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0119. T_Loss: 4.7590. Mask: 0.9041. :  59%|█████▉    | 59/100 [00:14<00:08,  4.91it/s]Train Iter: 1860/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0115. T_Loss: 4.7555. Mask: 0.9052. :  59%|█████▉    | 59/100 [00:14<00:08,  4.91it/s]Train Iter: 1860/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0115. T_Loss: 4.7555. Mask: 0.9052. :  60%|██████    | 60/100 [00:14<00:07,  5.47it/s]Train Iter: 1861/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0097. T_Loss: 4.7396. Mask: 0.9052. :  60%|██████    | 60/100 [00:14<00:07,  5.47it/s]Train Iter: 1861/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0097. T_Loss: 4.7396. Mask: 0.9052. :  61%|██████    | 61/100 [00:14<00:06,  6.14it/s]Train Iter: 1862/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0081. T_Loss: 4.7293. Mask: 0.9057. :  61%|██████    | 61/100 [00:14<00:06,  6.14it/s]Train Iter: 1862/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0081. T_Loss: 4.7293. Mask: 0.9057. :  62%|██████▏   | 62/100 [00:14<00:05,  6.61it/s]Train Iter: 1863/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0065. T_Loss: 4.7121. Mask: 0.9058. :  62%|██████▏   | 62/100 [00:14<00:05,  6.61it/s]Train Iter: 1863/5000. LR: 0.0425. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0065. T_Loss: 4.7121. Mask: 0.9058. :  63%|██████▎   | 63/100 [00:14<00:05,  6.81it/s]Train Iter: 1864/5000. LR: 0.0425. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0058. T_Loss: 4.7047. Mask: 0.9072. :  63%|██████▎   | 63/100 [00:15<00:05,  6.81it/s]Train Iter: 1864/5000. LR: 0.0425. Data: 0.10s. Batch: 0.23s. S_Loss: 1.0058. T_Loss: 4.7047. Mask: 0.9072. :  64%|██████▍   | 64/100 [00:15<00:05,  6.87it/s]Train Iter: 1865/5000. LR: 0.0425. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0057. T_Loss: 4.7110. Mask: 0.9077. :  64%|██████▍   | 64/100 [00:15<00:05,  6.87it/s]Train Iter: 1865/5000. LR: 0.0425. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0057. T_Loss: 4.7110. Mask: 0.9077. :  65%|██████▌   | 65/100 [00:15<00:07,  4.89it/s]Train Iter: 1866/5000. LR: 0.0425. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0056. T_Loss: 4.7097. Mask: 0.9086. :  65%|██████▌   | 65/100 [00:15<00:07,  4.89it/s]Train Iter: 1866/5000. LR: 0.0425. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0056. T_Loss: 4.7097. Mask: 0.9086. :  66%|██████▌   | 66/100 [00:15<00:06,  5.40it/s]Train Iter: 1867/5000. LR: 0.0425. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0047. T_Loss: 4.7162. Mask: 0.9086. :  66%|██████▌   | 66/100 [00:15<00:06,  5.40it/s]Train Iter: 1867/5000. LR: 0.0425. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0047. T_Loss: 4.7162. Mask: 0.9086. :  67%|██████▋   | 67/100 [00:15<00:05,  5.99it/s]Train Iter: 1868/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0041. T_Loss: 4.7124. Mask: 0.9081. :  67%|██████▋   | 67/100 [00:15<00:05,  5.99it/s]Train Iter: 1868/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0041. T_Loss: 4.7124. Mask: 0.9081. :  68%|██████▊   | 68/100 [00:15<00:05,  6.40it/s]Train Iter: 1869/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0022. T_Loss: 4.6970. Mask: 0.9094. :  68%|██████▊   | 68/100 [00:16<00:05,  6.40it/s]Train Iter: 1869/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0022. T_Loss: 4.6970. Mask: 0.9094. :  69%|██████▉   | 69/100 [00:16<00:07,  4.38it/s]Train Iter: 1870/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0019. T_Loss: 4.7079. Mask: 0.9094. :  69%|██████▉   | 69/100 [00:16<00:07,  4.38it/s]Train Iter: 1870/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0019. T_Loss: 4.7079. Mask: 0.9094. :  70%|███████   | 70/100 [00:16<00:05,  5.03it/s]Train Iter: 1871/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0003. T_Loss: 4.7141. Mask: 0.9107. :  70%|███████   | 70/100 [00:16<00:05,  5.03it/s]Train Iter: 1871/5000. LR: 0.0424. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0003. T_Loss: 4.7141. Mask: 0.9107. :  71%|███████   | 71/100 [00:16<00:05,  5.67it/s]Train Iter: 1872/5000. LR: 0.0424. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9984. T_Loss: 4.7146. Mask: 0.9110. :  71%|███████   | 71/100 [00:16<00:05,  5.67it/s]Train Iter: 1872/5000. LR: 0.0424. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9984. T_Loss: 4.7146. Mask: 0.9110. :  72%|███████▏  | 72/100 [00:16<00:04,  6.23it/s]Train Iter: 1873/5000. LR: 0.0424. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9971. T_Loss: 4.7039. Mask: 0.9110. :  72%|███████▏  | 72/100 [00:16<00:04,  6.23it/s]Train Iter: 1873/5000. LR: 0.0424. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9971. T_Loss: 4.7039. Mask: 0.9110. :  73%|███████▎  | 73/100 [00:16<00:04,  6.65it/s]Train Iter: 1874/5000. LR: 0.0424. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9965. T_Loss: 4.6959. Mask: 0.9109. :  73%|███████▎  | 73/100 [00:16<00:04,  6.65it/s]Train Iter: 1874/5000. LR: 0.0424. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9965. T_Loss: 4.6959. Mask: 0.9109. :  74%|███████▍  | 74/100 [00:16<00:03,  6.82it/s]Train Iter: 1875/5000. LR: 0.0423. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9962. T_Loss: 4.6956. Mask: 0.9104. :  74%|███████▍  | 74/100 [00:16<00:03,  6.82it/s]Train Iter: 1875/5000. LR: 0.0423. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9962. T_Loss: 4.6956. Mask: 0.9104. :  75%|███████▌  | 75/100 [00:16<00:03,  7.11it/s]total : 5000  current step :  1851
total : 5000  current step :  1852
total : 5000  current step :  1853
total : 5000  current step :  1854
total : 5000  current step :  1855
total : 5000  current step :  1856
total : 5000  current step :  1857
total : 5000  current step :  1858
total : 5000  current step :  1859
total : 5000  current step :  1860
total : 5000  current step :  1861
total : 5000  current step :  1862
total : 5000  current step :  1863
total : 5000  current step :  1864
total : 5000  current step :  1865
total : 5000  current step :  1866
total : 5000  current step :  1867
total : 5000  current step :  1868
total : 5000  current step :  1869
total : 5000  current step :  1870
total : 5000  current step :  1871
total : 5000  current step :  1872
total : 5000  current step :  1873
total : 5000  current step :  1874
total : 5000  current step :  1875
Train Iter: 1876/5000. LR: 0.0423. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9946. T_Loss: 4.6970. Mask: 0.9108. :  75%|███████▌  | 75/100 [00:19<00:03,  7.11it/s]Train Iter: 1876/5000. LR: 0.0423. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9946. T_Loss: 4.6970. Mask: 0.9108. :  76%|███████▌  | 76/100 [00:19<00:19,  1.23it/s]Train Iter: 1877/5000. LR: 0.0423. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9929. T_Loss: 4.6913. Mask: 0.9111. :  76%|███████▌  | 76/100 [00:19<00:19,  1.23it/s]Train Iter: 1877/5000. LR: 0.0423. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9929. T_Loss: 4.6913. Mask: 0.9111. :  77%|███████▋  | 77/100 [00:19<00:13,  1.65it/s]total : 5000  current step :  1876
total : 5000  current step :  1877
Train Iter: 1878/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9917. T_Loss: 4.6906. Mask: 0.9119. :  77%|███████▋  | 77/100 [00:21<00:13,  1.65it/s]Train Iter: 1878/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9917. T_Loss: 4.6906. Mask: 0.9119. :  78%|███████▊  | 78/100 [00:21<00:21,  1.01it/s]Train Iter: 1879/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9908. T_Loss: 4.6870. Mask: 0.9122. :  78%|███████▊  | 78/100 [00:21<00:21,  1.01it/s]Train Iter: 1879/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9908. T_Loss: 4.6870. Mask: 0.9122. :  79%|███████▉  | 79/100 [00:21<00:15,  1.32it/s]Train Iter: 1880/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9899. T_Loss: 4.6855. Mask: 0.9121. :  79%|███████▉  | 79/100 [00:21<00:15,  1.32it/s]Train Iter: 1880/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9899. T_Loss: 4.6855. Mask: 0.9121. :  80%|████████  | 80/100 [00:21<00:11,  1.74it/s]Train Iter: 1881/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9882. T_Loss: 4.6839. Mask: 0.9128. :  80%|████████  | 80/100 [00:21<00:11,  1.74it/s]Train Iter: 1881/5000. LR: 0.0423. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9882. T_Loss: 4.6839. Mask: 0.9128. :  81%|████████  | 81/100 [00:21<00:08,  2.27it/s]Train Iter: 1882/5000. LR: 0.0422. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9866. T_Loss: 4.6749. Mask: 0.9127. :  81%|████████  | 81/100 [00:22<00:08,  2.27it/s]Train Iter: 1882/5000. LR: 0.0422. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9866. T_Loss: 4.6749. Mask: 0.9127. :  82%|████████▏ | 82/100 [00:22<00:06,  2.87it/s]Train Iter: 1883/5000. LR: 0.0422. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9858. T_Loss: 4.6688. Mask: 0.9123. :  82%|████████▏ | 82/100 [00:22<00:06,  2.87it/s]Train Iter: 1883/5000. LR: 0.0422. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9858. T_Loss: 4.6688. Mask: 0.9123. :  83%|████████▎ | 83/100 [00:22<00:04,  3.57it/s]Train Iter: 1884/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9839. T_Loss: 4.6614. Mask: 0.9133. :  83%|████████▎ | 83/100 [00:22<00:04,  3.57it/s]Train Iter: 1884/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9839. T_Loss: 4.6614. Mask: 0.9133. :  84%|████████▍ | 84/100 [00:22<00:03,  4.26it/s]Train Iter: 1885/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9825. T_Loss: 4.6527. Mask: 0.9132. :  84%|████████▍ | 84/100 [00:22<00:03,  4.26it/s]Train Iter: 1885/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9825. T_Loss: 4.6527. Mask: 0.9132. :  85%|████████▌ | 85/100 [00:22<00:03,  4.11it/s]Train Iter: 1886/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9840. T_Loss: 4.6544. Mask: 0.9124. :  85%|████████▌ | 85/100 [00:22<00:03,  4.11it/s]Train Iter: 1886/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9840. T_Loss: 4.6544. Mask: 0.9124. :  86%|████████▌ | 86/100 [00:22<00:02,  4.89it/s]Train Iter: 1887/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9852. T_Loss: 4.6494. Mask: 0.9120. :  86%|████████▌ | 86/100 [00:22<00:02,  4.89it/s]Train Iter: 1887/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9852. T_Loss: 4.6494. Mask: 0.9120. :  87%|████████▋ | 87/100 [00:22<00:02,  5.64it/s]Train Iter: 1888/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9836. T_Loss: 4.6449. Mask: 0.9130. :  87%|████████▋ | 87/100 [00:22<00:02,  5.64it/s]Train Iter: 1888/5000. LR: 0.0422. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9836. T_Loss: 4.6449. Mask: 0.9130. :  88%|████████▊ | 88/100 [00:22<00:01,  6.13it/s]Train Iter: 1889/5000. LR: 0.0422. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9834. T_Loss: 4.6512. Mask: 0.9136. :  88%|████████▊ | 88/100 [00:23<00:01,  6.13it/s]Train Iter: 1889/5000. LR: 0.0422. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9834. T_Loss: 4.6512. Mask: 0.9136. :  89%|████████▉ | 89/100 [00:23<00:02,  5.01it/s]Train Iter: 1890/5000. LR: 0.0421. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9848. T_Loss: 4.6574. Mask: 0.9142. :  89%|████████▉ | 89/100 [00:23<00:02,  5.01it/s]Train Iter: 1890/5000. LR: 0.0421. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9848. T_Loss: 4.6574. Mask: 0.9142. :  90%|█████████ | 90/100 [00:23<00:01,  5.61it/s]Train Iter: 1891/5000. LR: 0.0421. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9838. T_Loss: 4.6470. Mask: 0.9135. :  90%|█████████ | 90/100 [00:23<00:01,  5.61it/s]Train Iter: 1891/5000. LR: 0.0421. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9838. T_Loss: 4.6470. Mask: 0.9135. :  91%|█████████ | 91/100 [00:23<00:01,  6.04it/s]Train Iter: 1892/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9847. T_Loss: 4.6449. Mask: 0.9137. :  91%|█████████ | 91/100 [00:23<00:01,  6.04it/s]Train Iter: 1892/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9847. T_Loss: 4.6449. Mask: 0.9137. :  92%|█████████▏| 92/100 [00:23<00:01,  6.56it/s]Train Iter: 1893/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9850. T_Loss: 4.6502. Mask: 0.9133. :  92%|█████████▏| 92/100 [00:23<00:01,  6.56it/s]Train Iter: 1894/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9831. T_Loss: 4.6380. Mask: 0.9142. :  93%|█████████▎| 93/100 [00:23<00:01,  6.56it/s]Train Iter: 1894/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9831. T_Loss: 4.6380. Mask: 0.9142. :  94%|█████████▍| 94/100 [00:23<00:00,  7.42it/s]Train Iter: 1895/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9833. T_Loss: 4.6409. Mask: 0.9145. :  94%|█████████▍| 94/100 [00:23<00:00,  7.42it/s]Train Iter: 1896/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9821. T_Loss: 4.6333. Mask: 0.9134. :  95%|█████████▌| 95/100 [00:23<00:00,  7.42it/s]Train Iter: 1896/5000. LR: 0.0421. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9821. T_Loss: 4.6333. Mask: 0.9134. :  96%|█████████▌| 96/100 [00:23<00:00,  8.09it/s]Train Iter: 1897/5000. LR: 0.0420. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9821. T_Loss: 4.6253. Mask: 0.9133. :  96%|█████████▌| 96/100 [00:24<00:00,  8.09it/s]Train Iter: 1897/5000. LR: 0.0420. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9821. T_Loss: 4.6253. Mask: 0.9133. :  97%|█████████▋| 97/100 [00:24<00:00,  8.05it/s]Train Iter: 1898/5000. LR: 0.0420. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.6278. Mask: 0.9139. :  97%|█████████▋| 97/100 [00:24<00:00,  8.05it/s]Train Iter: 1898/5000. LR: 0.0420. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.6278. Mask: 0.9139. :  98%|█████████▊| 98/100 [00:24<00:00,  8.16it/s]Train Iter: 1899/5000. LR: 0.0420. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.6182. Mask: 0.9129. :  98%|█████████▊| 98/100 [00:24<00:00,  8.16it/s]Train Iter: 1899/5000. LR: 0.0420. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.6182. Mask: 0.9129. :  99%|█████████▉| 99/100 [00:24<00:00,  5.10it/s]Train Iter: 1900/5000. LR: 0.0420. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.6129. Mask: 0.9122. :  99%|█████████▉| 99/100 [00:24<00:00,  5.10it/s]Train Iter: 1900/5000. LR: 0.0420. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.6129. Mask: 0.9122. : 100%|██████████| 100/100 [00:24<00:00,  5.38it/s]Train Iter: 1900/5000. LR: 0.0420. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.6129. Mask: 0.9122. : 100%|██████████| 100/100 [00:24<00:00,  4.03it/s]
total : 5000  current step :  1878
total : 5000  current step :  1879
total : 5000  current step :  1880
total : 5000  current step :  1881
total : 5000  current step :  1882
total : 5000  current step :  1883
total : 5000  current step :  1884
total : 5000  current step :  1885
total : 5000  current step :  1886
total : 5000  current step :  1887
total : 5000  current step :  1888
total : 5000  current step :  1889
total : 5000  current step :  1890
total : 5000  current step :  1891
total : 5000  current step :  1892
total : 5000  current step :  1893
total : 5000  current step :  1894
total : 5000  current step :  1895
total : 5000  current step :  1896
total : 5000  current step :  1897
total : 5000  current step :  1898
total : 5000  current step :  1899
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.2627. top1: 62.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.2627. top1: 62.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 1.2112. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 1.1366. top1: 76.04. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.1533. top1: 74.22. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 1.1363. top1: 76.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 1.1389. top1: 75.52. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.1546. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.1715. top1: 73.05. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.1715. top1: 73.05. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.1602. top1: 73.96. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.1746. top1: 73.12. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.1519. top1: 74.43. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.1490. top1: 73.70. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.1394. top1: 74.04. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1398. top1: 73.66. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1306. top1: 74.58. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1328. top1: 74.41. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.11it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1328. top1: 74.41. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1250. top1: 74.63. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1241. top1: 73.96. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1245. top1: 74.01. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1211. top1: 74.22. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1334. top1: 73.51. top5: 99.85. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1267. top1: 74.01. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1190. top1: 74.59. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1150. top1: 74.74. top5: 99.87. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1120. top1: 74.75. top5: 99.88. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1193. top1: 74.40. top5: 99.88. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1175. top1: 74.54. top5: 99.88. :  25%|██▌       | 16/63 [00:01<00:03, 13.64it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1175. top1: 74.54. top5: 99.88. :  43%|████▎     | 27/63 [00:01<00:01, 25.79it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1211. top1: 74.33. top5: 99.89. :  43%|████▎     | 27/63 [00:01<00:01, 25.79it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1193. top1: 74.35. top5: 99.89. :  43%|████▎     | 27/63 [00:01<00:01, 25.79it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1182. top1: 74.48. top5: 99.90. :  43%|████▎     | 27/63 [00:01<00:01, 25.79it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1197. top1: 74.19. top5: 99.90. :  43%|████▎     | 27/63 [00:01<00:01, 25.79it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1241. top1: 74.02. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 25.79it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1193. top1: 74.53. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.79it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1186. top1: 74.72. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.79it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1160. top1: 74.82. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.79it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1257. top1: 74.31. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.79it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1257. top1: 74.31. top5: 99.91. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.1218. top1: 74.75. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1187. top1: 74.92. top5: 99.92. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1245. top1: 74.60. top5: 99.84. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1233. top1: 74.77. top5: 99.84. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1219. top1: 75.00. top5: 99.85. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1251. top1: 74.78. top5: 99.85. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1245. top1: 74.85. top5: 99.85. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1203. top1: 75.14. top5: 99.86. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1163. top1: 75.35. top5: 99.86. :  57%|█████▋    | 36/63 [00:02<00:00, 35.62it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1163. top1: 75.35. top5: 99.86. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1162. top1: 75.34. top5: 99.86. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1164. top1: 75.40. top5: 99.87. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1140. top1: 75.46. top5: 99.87. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1148. top1: 75.51. top5: 99.87. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1137. top1: 75.56. top5: 99.88. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1191. top1: 75.25. top5: 99.88. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1176. top1: 75.42. top5: 99.88. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1200. top1: 75.35. top5: 99.88. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1206. top1: 75.29. top5: 99.88. :  71%|███████▏  | 45/63 [00:02<00:00, 44.81it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1206. top1: 75.29. top5: 99.88. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1197. top1: 75.34. top5: 99.89. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1174. top1: 75.45. top5: 99.89. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1196. top1: 75.44. top5: 99.89. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1192. top1: 75.48. top5: 99.89. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1206. top1: 75.48. top5: 99.89. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1171. top1: 75.78. top5: 99.90. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1191. top1: 75.67. top5: 99.90. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1224. top1: 75.45. top5: 99.90. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1217. top1: 75.50. top5: 99.90. :  86%|████████▌ | 54/63 [00:02<00:00, 52.71it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1217. top1: 75.50. top5: 99.90. : 100%|██████████| 63/63 [00:02<00:00, 24.28it/s]
total : 5000  current step :  1900
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 1901/5000. LR: 0.0420. Data: 2.00s. Batch: 2.09s. S_Loss: 0.8753. T_Loss: 4.1563. Mask: 1.0000. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 1901/5000. LR: 0.0420. Data: 2.00s. Batch: 2.09s. S_Loss: 0.8753. T_Loss: 4.1563. Mask: 1.0000. :   1%|          | 1/100 [00:02<03:26,  2.09s/it]Train Iter: 1902/5000. LR: 0.0420. Data: 1.01s. Batch: 1.10s. S_Loss: 0.9400. T_Loss: 4.4282. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:26,  2.09s/it]Train Iter: 1902/5000. LR: 0.0420. Data: 1.01s. Batch: 1.10s. S_Loss: 0.9400. T_Loss: 4.4282. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 1903/5000. LR: 0.0420. Data: 0.67s. Batch: 0.77s. S_Loss: 0.9572. T_Loss: 4.4061. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 1903/5000. LR: 0.0420. Data: 0.67s. Batch: 0.77s. S_Loss: 0.9572. T_Loss: 4.4061. Mask: 0.9167. :   3%|▎         | 3/100 [00:02<00:54,  1.79it/s]Train Iter: 1904/5000. LR: 0.0419. Data: 0.50s. Batch: 0.61s. S_Loss: 0.9218. T_Loss: 4.3182. Mask: 0.9297. :   3%|▎         | 3/100 [00:02<00:54,  1.79it/s]Train Iter: 1904/5000. LR: 0.0419. Data: 0.50s. Batch: 0.61s. S_Loss: 0.9218. T_Loss: 4.3182. Mask: 0.9297. :   4%|▍         | 4/100 [00:02<00:36,  2.60it/s]Train Iter: 1905/5000. LR: 0.0419. Data: 0.40s. Batch: 0.56s. S_Loss: 0.9378. T_Loss: 4.5006. Mask: 0.9375. :   4%|▍         | 4/100 [00:02<00:36,  2.60it/s]Train Iter: 1905/5000. LR: 0.0419. Data: 0.40s. Batch: 0.56s. S_Loss: 0.9378. T_Loss: 4.5006. Mask: 0.9375. :   5%|▌         | 5/100 [00:02<00:36,  2.63it/s]Train Iter: 1906/5000. LR: 0.0419. Data: 0.34s. Batch: 0.48s. S_Loss: 0.9455. T_Loss: 4.6232. Mask: 0.9323. :   5%|▌         | 5/100 [00:02<00:36,  2.63it/s]Train Iter: 1907/5000. LR: 0.0419. Data: 0.29s. Batch: 0.42s. S_Loss: 0.9451. T_Loss: 4.5716. Mask: 0.9241. :   6%|▌         | 6/100 [00:02<00:35,  2.63it/s]Train Iter: 1907/5000. LR: 0.0419. Data: 0.29s. Batch: 0.42s. S_Loss: 0.9451. T_Loss: 4.5716. Mask: 0.9241. :   7%|▋         | 7/100 [00:02<00:20,  4.44it/s]Train Iter: 1908/5000. LR: 0.0419. Data: 0.25s. Batch: 0.38s. S_Loss: 0.9445. T_Loss: 4.5892. Mask: 0.9297. :   7%|▋         | 7/100 [00:03<00:20,  4.44it/s]Train Iter: 1909/5000. LR: 0.0419. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9494. T_Loss: 4.5435. Mask: 0.9271. :   8%|▊         | 8/100 [00:03<00:20,  4.44it/s]Train Iter: 1909/5000. LR: 0.0419. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9494. T_Loss: 4.5435. Mask: 0.9271. :   9%|▉         | 9/100 [00:03<00:17,  5.12it/s]Train Iter: 1910/5000. LR: 0.0419. Data: 0.20s. Batch: 0.33s. S_Loss: 0.9480. T_Loss: 4.4930. Mask: 0.9313. :   9%|▉         | 9/100 [00:03<00:17,  5.12it/s]Train Iter: 1911/5000. LR: 0.0419. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9435. T_Loss: 4.4361. Mask: 0.9290. :  10%|█         | 10/100 [00:03<00:17,  5.12it/s]Train Iter: 1911/5000. LR: 0.0419. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9435. T_Loss: 4.4361. Mask: 0.9290. :  11%|█         | 11/100 [00:03<00:13,  6.61it/s]Train Iter: 1912/5000. LR: 0.0418. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9464. T_Loss: 4.3906. Mask: 0.9219. :  11%|█         | 11/100 [00:03<00:13,  6.61it/s]Train Iter: 1912/5000. LR: 0.0418. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9464. T_Loss: 4.3906. Mask: 0.9219. :  12%|█▏        | 12/100 [00:03<00:13,  6.68it/s]Train Iter: 1913/5000. LR: 0.0418. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9586. T_Loss: 4.4634. Mask: 0.9255. :  12%|█▏        | 12/100 [00:03<00:13,  6.68it/s]Train Iter: 1913/5000. LR: 0.0418. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9586. T_Loss: 4.4634. Mask: 0.9255. :  13%|█▎        | 13/100 [00:03<00:13,  6.69it/s]Train Iter: 1914/5000. LR: 0.0418. Data: 0.15s. Batch: 0.27s. S_Loss: 0.9693. T_Loss: 4.4482. Mask: 0.9152. :  13%|█▎        | 13/100 [00:03<00:13,  6.69it/s]Train Iter: 1914/5000. LR: 0.0418. Data: 0.15s. Batch: 0.27s. S_Loss: 0.9693. T_Loss: 4.4482. Mask: 0.9152. :  14%|█▍        | 14/100 [00:03<00:12,  7.11it/s]Train Iter: 1915/5000. LR: 0.0418. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9765. T_Loss: 4.4861. Mask: 0.9167. :  14%|█▍        | 14/100 [00:04<00:12,  7.11it/s]Train Iter: 1915/5000. LR: 0.0418. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9765. T_Loss: 4.4861. Mask: 0.9167. :  15%|█▌        | 15/100 [00:04<00:16,  5.22it/s]Train Iter: 1916/5000. LR: 0.0418. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9884. T_Loss: 4.6382. Mask: 0.9180. :  15%|█▌        | 15/100 [00:04<00:16,  5.22it/s]Train Iter: 1916/5000. LR: 0.0418. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9884. T_Loss: 4.6382. Mask: 0.9180. :  16%|█▌        | 16/100 [00:04<00:14,  5.74it/s]Train Iter: 1917/5000. LR: 0.0418. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9836. T_Loss: 4.6713. Mask: 0.9191. :  16%|█▌        | 16/100 [00:04<00:14,  5.74it/s]Train Iter: 1917/5000. LR: 0.0418. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9836. T_Loss: 4.6713. Mask: 0.9191. :  17%|█▋        | 17/100 [00:04<00:13,  6.22it/s]Train Iter: 1918/5000. LR: 0.0418. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9853. T_Loss: 4.6880. Mask: 0.9201. :  17%|█▋        | 17/100 [00:04<00:13,  6.22it/s]Train Iter: 1918/5000. LR: 0.0418. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9853. T_Loss: 4.6880. Mask: 0.9201. :  18%|█▊        | 18/100 [00:04<00:12,  6.61it/s]Train Iter: 1919/5000. LR: 0.0417. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9834. T_Loss: 4.7113. Mask: 0.9227. :  18%|█▊        | 18/100 [00:04<00:12,  6.61it/s]Train Iter: 1919/5000. LR: 0.0417. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9834. T_Loss: 4.7113. Mask: 0.9227. :  19%|█▉        | 19/100 [00:04<00:12,  6.53it/s]Train Iter: 1920/5000. LR: 0.0417. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9802. T_Loss: 4.6919. Mask: 0.9203. :  19%|█▉        | 19/100 [00:04<00:12,  6.53it/s]Train Iter: 1920/5000. LR: 0.0417. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9802. T_Loss: 4.6919. Mask: 0.9203. :  20%|██        | 20/100 [00:04<00:12,  6.46it/s]Train Iter: 1921/5000. LR: 0.0417. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9861. T_Loss: 4.7586. Mask: 0.9226. :  20%|██        | 20/100 [00:04<00:12,  6.46it/s]Train Iter: 1921/5000. LR: 0.0417. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9861. T_Loss: 4.7586. Mask: 0.9226. :  21%|██        | 21/100 [00:04<00:11,  6.89it/s]Train Iter: 1922/5000. LR: 0.0417. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9879. T_Loss: 4.7878. Mask: 0.9233. :  21%|██        | 21/100 [00:05<00:11,  6.89it/s]Train Iter: 1922/5000. LR: 0.0417. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9879. T_Loss: 4.7878. Mask: 0.9233. :  22%|██▏       | 22/100 [00:05<00:10,  7.15it/s]Train Iter: 1923/5000. LR: 0.0417. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9911. T_Loss: 4.7632. Mask: 0.9144. :  22%|██▏       | 22/100 [00:05<00:10,  7.15it/s]Train Iter: 1923/5000. LR: 0.0417. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9911. T_Loss: 4.7632. Mask: 0.9144. :  23%|██▎       | 23/100 [00:05<00:10,  7.30it/s]Train Iter: 1924/5000. LR: 0.0417. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9900. T_Loss: 4.7666. Mask: 0.9141. :  23%|██▎       | 23/100 [00:05<00:10,  7.30it/s]Train Iter: 1924/5000. LR: 0.0417. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9900. T_Loss: 4.7666. Mask: 0.9141. :  24%|██▍       | 24/100 [00:05<00:10,  7.56it/s]Train Iter: 1925/5000. LR: 0.0417. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9974. T_Loss: 4.7993. Mask: 0.9150. :  24%|██▍       | 24/100 [00:05<00:10,  7.56it/s]Train Iter: 1925/5000. LR: 0.0417. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9974. T_Loss: 4.7993. Mask: 0.9150. :  25%|██▌       | 25/100 [00:05<00:14,  5.18it/s]total : 5000  current step :  1901
total : 5000  current step :  1902
total : 5000  current step :  1903
total : 5000  current step :  1904
total : 5000  current step :  1905
total : 5000  current step :  1906
total : 5000  current step :  1907
total : 5000  current step :  1908
total : 5000  current step :  1909
total : 5000  current step :  1910
total : 5000  current step :  1911
total : 5000  current step :  1912
total : 5000  current step :  1913
total : 5000  current step :  1914
total : 5000  current step :  1915
total : 5000  current step :  1916
total : 5000  current step :  1917
total : 5000  current step :  1918
total : 5000  current step :  1919
total : 5000  current step :  1920
total : 5000  current step :  1921
total : 5000  current step :  1922
total : 5000  current step :  1923
total : 5000  current step :  1924
total : 5000  current step :  1925
Train Iter: 1926/5000. LR: 0.0416. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9978. T_Loss: 4.8006. Mask: 0.9123. :  25%|██▌       | 25/100 [00:07<00:14,  5.18it/s]Train Iter: 1926/5000. LR: 0.0416. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9978. T_Loss: 4.8006. Mask: 0.9123. :  26%|██▌       | 26/100 [00:07<00:53,  1.38it/s]Train Iter: 1927/5000. LR: 0.0416. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0065. T_Loss: 4.8283. Mask: 0.9086. :  26%|██▌       | 26/100 [00:07<00:53,  1.38it/s]Train Iter: 1927/5000. LR: 0.0416. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0065. T_Loss: 4.8283. Mask: 0.9086. :  27%|██▋       | 27/100 [00:07<00:40,  1.81it/s]Train Iter: 1928/5000. LR: 0.0416. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0071. T_Loss: 4.8621. Mask: 0.9107. :  27%|██▋       | 27/100 [00:07<00:40,  1.81it/s]Train Iter: 1928/5000. LR: 0.0416. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0071. T_Loss: 4.8621. Mask: 0.9107. :  28%|██▊       | 28/100 [00:07<00:30,  2.38it/s]Train Iter: 1929/5000. LR: 0.0416. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0067. T_Loss: 4.8681. Mask: 0.9106. :  28%|██▊       | 28/100 [00:08<00:30,  2.38it/s]Train Iter: 1929/5000. LR: 0.0416. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0067. T_Loss: 4.8681. Mask: 0.9106. :  29%|██▉       | 29/100 [00:08<00:23,  2.96it/s]Train Iter: 1930/5000. LR: 0.0416. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0108. T_Loss: 4.8725. Mask: 0.9073. :  29%|██▉       | 29/100 [00:08<00:23,  2.96it/s]Train Iter: 1930/5000. LR: 0.0416. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0108. T_Loss: 4.8725. Mask: 0.9073. :  30%|███       | 30/100 [00:08<00:19,  3.56it/s]Train Iter: 1931/5000. LR: 0.0416. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0122. T_Loss: 4.8848. Mask: 0.9042. :  30%|███       | 30/100 [00:08<00:19,  3.56it/s]Train Iter: 1931/5000. LR: 0.0416. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0122. T_Loss: 4.8848. Mask: 0.9042. :  31%|███       | 31/100 [00:08<00:16,  4.19it/s]Train Iter: 1932/5000. LR: 0.0416. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0118. T_Loss: 4.9130. Mask: 0.9072. :  31%|███       | 31/100 [00:08<00:16,  4.19it/s]Train Iter: 1932/5000. LR: 0.0416. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0118. T_Loss: 4.9130. Mask: 0.9072. :  32%|███▏      | 32/100 [00:08<00:13,  4.90it/s]Train Iter: 1933/5000. LR: 0.0415. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0131. T_Loss: 4.9323. Mask: 0.9081. :  32%|███▏      | 32/100 [00:08<00:13,  4.90it/s]Train Iter: 1933/5000. LR: 0.0415. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0131. T_Loss: 4.9323. Mask: 0.9081. :  33%|███▎      | 33/100 [00:08<00:11,  5.59it/s]Train Iter: 1934/5000. LR: 0.0415. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0180. T_Loss: 4.9096. Mask: 0.9044. :  33%|███▎      | 33/100 [00:08<00:11,  5.59it/s]Train Iter: 1934/5000. LR: 0.0415. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0180. T_Loss: 4.9096. Mask: 0.9044. :  34%|███▍      | 34/100 [00:08<00:10,  6.12it/s]Train Iter: 1935/5000. LR: 0.0415. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0217. T_Loss: 4.8960. Mask: 0.9027. :  34%|███▍      | 34/100 [00:09<00:10,  6.12it/s]Train Iter: 1935/5000. LR: 0.0415. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0217. T_Loss: 4.8960. Mask: 0.9027. :  35%|███▌      | 35/100 [00:09<00:13,  4.97it/s]Train Iter: 1936/5000. LR: 0.0415. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0261. T_Loss: 4.8901. Mask: 0.9019. :  35%|███▌      | 35/100 [00:09<00:13,  4.97it/s]Train Iter: 1936/5000. LR: 0.0415. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0261. T_Loss: 4.8901. Mask: 0.9019. :  36%|███▌      | 36/100 [00:09<00:11,  5.49it/s]Train Iter: 1937/5000. LR: 0.0415. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0264. T_Loss: 4.8734. Mask: 0.9003. :  36%|███▌      | 36/100 [00:09<00:11,  5.49it/s]Train Iter: 1937/5000. LR: 0.0415. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0264. T_Loss: 4.8734. Mask: 0.9003. :  37%|███▋      | 37/100 [00:09<00:10,  5.84it/s]Train Iter: 1938/5000. LR: 0.0415. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0283. T_Loss: 4.8551. Mask: 0.8988. :  37%|███▋      | 37/100 [00:09<00:10,  5.84it/s]Train Iter: 1938/5000. LR: 0.0415. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0283. T_Loss: 4.8551. Mask: 0.8988. :  38%|███▊      | 38/100 [00:09<00:10,  5.72it/s]Train Iter: 1939/5000. LR: 0.0415. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0266. T_Loss: 4.8677. Mask: 0.9014. :  38%|███▊      | 38/100 [00:09<00:10,  5.72it/s]Train Iter: 1939/5000. LR: 0.0415. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0266. T_Loss: 4.8677. Mask: 0.9014. :  39%|███▉      | 39/100 [00:09<00:13,  4.53it/s]Train Iter: 1940/5000. LR: 0.0414. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0302. T_Loss: 4.8592. Mask: 0.9023. :  39%|███▉      | 39/100 [00:09<00:13,  4.53it/s]Train Iter: 1940/5000. LR: 0.0414. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0302. T_Loss: 4.8592. Mask: 0.9023. :  40%|████      | 40/100 [00:09<00:11,  5.25it/s]Train Iter: 1941/5000. LR: 0.0414. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0306. T_Loss: 4.8560. Mask: 0.9017. :  40%|████      | 40/100 [00:10<00:11,  5.25it/s]Train Iter: 1941/5000. LR: 0.0414. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0306. T_Loss: 4.8560. Mask: 0.9017. :  41%|████      | 41/100 [00:10<00:10,  5.71it/s]Train Iter: 1942/5000. LR: 0.0414. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0309. T_Loss: 4.8350. Mask: 0.9003. :  41%|████      | 41/100 [00:10<00:10,  5.71it/s]Train Iter: 1942/5000. LR: 0.0414. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0309. T_Loss: 4.8350. Mask: 0.9003. :  42%|████▏     | 42/100 [00:10<00:09,  6.29it/s]Train Iter: 1943/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0297. T_Loss: 4.8171. Mask: 0.9004. :  42%|████▏     | 42/100 [00:10<00:09,  6.29it/s]Train Iter: 1943/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0297. T_Loss: 4.8171. Mask: 0.9004. :  43%|████▎     | 43/100 [00:10<00:08,  6.69it/s]Train Iter: 1944/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0292. T_Loss: 4.8151. Mask: 0.9013. :  43%|████▎     | 43/100 [00:10<00:08,  6.69it/s]Train Iter: 1944/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0292. T_Loss: 4.8151. Mask: 0.9013. :  44%|████▍     | 44/100 [00:10<00:08,  6.96it/s]Train Iter: 1945/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0297. T_Loss: 4.8190. Mask: 0.9028. :  44%|████▍     | 44/100 [00:10<00:08,  6.96it/s]Train Iter: 1945/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0297. T_Loss: 4.8190. Mask: 0.9028. :  45%|████▌     | 45/100 [00:10<00:11,  4.74it/s]Train Iter: 1946/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0265. T_Loss: 4.7953. Mask: 0.9022. :  45%|████▌     | 45/100 [00:10<00:11,  4.74it/s]Train Iter: 1946/5000. LR: 0.0414. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0265. T_Loss: 4.7953. Mask: 0.9022. :  46%|████▌     | 46/100 [00:10<00:10,  5.30it/s]Train Iter: 1947/5000. LR: 0.0413. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0256. T_Loss: 4.7762. Mask: 0.9016. :  46%|████▌     | 46/100 [00:11<00:10,  5.30it/s]Train Iter: 1947/5000. LR: 0.0413. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0256. T_Loss: 4.7762. Mask: 0.9016. :  47%|████▋     | 47/100 [00:11<00:08,  5.91it/s]Train Iter: 1948/5000. LR: 0.0413. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0241. T_Loss: 4.7685. Mask: 0.9030. :  47%|████▋     | 47/100 [00:11<00:08,  5.91it/s]Train Iter: 1948/5000. LR: 0.0413. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0241. T_Loss: 4.7685. Mask: 0.9030. :  48%|████▊     | 48/100 [00:11<00:08,  6.36it/s]Train Iter: 1949/5000. LR: 0.0413. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0219. T_Loss: 4.7562. Mask: 0.9043. :  48%|████▊     | 48/100 [00:11<00:08,  6.36it/s]Train Iter: 1949/5000. LR: 0.0413. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0219. T_Loss: 4.7562. Mask: 0.9043. :  49%|████▉     | 49/100 [00:11<00:10,  4.79it/s]Train Iter: 1950/5000. LR: 0.0413. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0230. T_Loss: 4.7614. Mask: 0.9056. :  49%|████▉     | 49/100 [00:11<00:10,  4.79it/s]Train Iter: 1950/5000. LR: 0.0413. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0230. T_Loss: 4.7614. Mask: 0.9056. :  50%|█████     | 50/100 [00:11<00:09,  5.28it/s]total : 5000  current step :  1926
total : 5000  current step :  1927
total : 5000  current step :  1928
total : 5000  current step :  1929
total : 5000  current step :  1930
total : 5000  current step :  1931
total : 5000  current step :  1932
total : 5000  current step :  1933
total : 5000  current step :  1934
total : 5000  current step :  1935
total : 5000  current step :  1936
total : 5000  current step :  1937
total : 5000  current step :  1938
total : 5000  current step :  1939
total : 5000  current step :  1940
total : 5000  current step :  1941
total : 5000  current step :  1942
total : 5000  current step :  1943
total : 5000  current step :  1944
total : 5000  current step :  1945
total : 5000  current step :  1946
total : 5000  current step :  1947
total : 5000  current step :  1948
total : 5000  current step :  1949
total : 5000  current step :  1950
Train Iter: 1951/5000. LR: 0.0413. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0249. T_Loss: 4.7417. Mask: 0.9050. :  50%|█████     | 50/100 [00:13<00:09,  5.28it/s]Train Iter: 1951/5000. LR: 0.0413. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0249. T_Loss: 4.7417. Mask: 0.9050. :  51%|█████     | 51/100 [00:13<00:36,  1.35it/s]Train Iter: 1952/5000. LR: 0.0413. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0259. T_Loss: 4.7417. Mask: 0.9050. :  51%|█████     | 51/100 [00:13<00:36,  1.35it/s]Train Iter: 1952/5000. LR: 0.0413. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0259. T_Loss: 4.7417. Mask: 0.9050. :  52%|█████▏    | 52/100 [00:13<00:26,  1.82it/s]Train Iter: 1953/5000. LR: 0.0413. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0250. T_Loss: 4.7400. Mask: 0.9057. :  52%|█████▏    | 52/100 [00:13<00:26,  1.82it/s]Train Iter: 1953/5000. LR: 0.0413. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0250. T_Loss: 4.7400. Mask: 0.9057. :  53%|█████▎    | 53/100 [00:13<00:19,  2.37it/s]Train Iter: 1954/5000. LR: 0.0413. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0259. T_Loss: 4.7492. Mask: 0.9057. :  53%|█████▎    | 53/100 [00:14<00:19,  2.37it/s]Train Iter: 1954/5000. LR: 0.0413. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0259. T_Loss: 4.7492. Mask: 0.9057. :  54%|█████▍    | 54/100 [00:14<00:15,  3.02it/s]Train Iter: 1955/5000. LR: 0.0412. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0271. T_Loss: 4.7516. Mask: 0.9062. :  54%|█████▍    | 54/100 [00:14<00:15,  3.02it/s]Train Iter: 1955/5000. LR: 0.0412. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0271. T_Loss: 4.7516. Mask: 0.9062. :  55%|█████▌    | 55/100 [00:14<00:14,  3.10it/s]Train Iter: 1956/5000. LR: 0.0412. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0289. T_Loss: 4.7513. Mask: 0.9074. :  55%|█████▌    | 55/100 [00:14<00:14,  3.10it/s]Train Iter: 1956/5000. LR: 0.0412. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0289. T_Loss: 4.7513. Mask: 0.9074. :  56%|█████▌    | 56/100 [00:14<00:11,  3.81it/s]Train Iter: 1957/5000. LR: 0.0412. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0329. T_Loss: 4.7486. Mask: 0.9068. :  56%|█████▌    | 56/100 [00:14<00:11,  3.81it/s]Train Iter: 1957/5000. LR: 0.0412. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0329. T_Loss: 4.7486. Mask: 0.9068. :  57%|█████▋    | 57/100 [00:14<00:09,  4.50it/s]Train Iter: 1958/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0348. T_Loss: 4.7367. Mask: 0.9068. :  57%|█████▋    | 57/100 [00:14<00:09,  4.50it/s]Train Iter: 1958/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0348. T_Loss: 4.7367. Mask: 0.9068. :  58%|█████▊    | 58/100 [00:14<00:08,  5.24it/s]Train Iter: 1959/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0345. T_Loss: 4.7218. Mask: 0.9073. :  58%|█████▊    | 58/100 [00:14<00:08,  5.24it/s]Train Iter: 1959/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0345. T_Loss: 4.7218. Mask: 0.9073. :  59%|█████▉    | 59/100 [00:14<00:07,  5.17it/s]Train Iter: 1960/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0363. T_Loss: 4.7171. Mask: 0.9062. :  59%|█████▉    | 59/100 [00:15<00:07,  5.17it/s]Train Iter: 1960/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0363. T_Loss: 4.7171. Mask: 0.9062. :  60%|██████    | 60/100 [00:15<00:06,  5.97it/s]Train Iter: 1961/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0360. T_Loss: 4.7116. Mask: 0.9078. :  60%|██████    | 60/100 [00:15<00:06,  5.97it/s]Train Iter: 1961/5000. LR: 0.0412. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0360. T_Loss: 4.7116. Mask: 0.9078. :  61%|██████    | 61/100 [00:15<00:05,  6.56it/s]Train Iter: 1962/5000. LR: 0.0411. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0377. T_Loss: 4.7052. Mask: 0.9083. :  61%|██████    | 61/100 [00:15<00:05,  6.56it/s]Train Iter: 1962/5000. LR: 0.0411. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0377. T_Loss: 4.7052. Mask: 0.9083. :  62%|██████▏   | 62/100 [00:15<00:05,  6.91it/s]Train Iter: 1963/5000. LR: 0.0411. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0379. T_Loss: 4.7041. Mask: 0.9092. :  62%|██████▏   | 62/100 [00:15<00:05,  6.91it/s]Train Iter: 1963/5000. LR: 0.0411. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0379. T_Loss: 4.7041. Mask: 0.9092. :  63%|██████▎   | 63/100 [00:15<00:05,  7.26it/s]Train Iter: 1964/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0401. T_Loss: 4.7148. Mask: 0.9087. :  63%|██████▎   | 63/100 [00:15<00:05,  7.26it/s]Train Iter: 1964/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0401. T_Loss: 4.7148. Mask: 0.9087. :  64%|██████▍   | 64/100 [00:15<00:04,  7.77it/s]Train Iter: 1965/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0383. T_Loss: 4.7048. Mask: 0.9067. :  64%|██████▍   | 64/100 [00:15<00:04,  7.77it/s]Train Iter: 1965/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0383. T_Loss: 4.7048. Mask: 0.9067. :  65%|██████▌   | 65/100 [00:15<00:06,  5.15it/s]Train Iter: 1966/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0365. T_Loss: 4.7007. Mask: 0.9072. :  65%|██████▌   | 65/100 [00:16<00:06,  5.15it/s]Train Iter: 1966/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0365. T_Loss: 4.7007. Mask: 0.9072. :  66%|██████▌   | 66/100 [00:16<00:06,  5.48it/s]Train Iter: 1967/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0377. T_Loss: 4.7066. Mask: 0.9072. :  66%|██████▌   | 66/100 [00:16<00:06,  5.48it/s]Train Iter: 1967/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0377. T_Loss: 4.7066. Mask: 0.9072. :  67%|██████▋   | 67/100 [00:16<00:05,  6.20it/s]Train Iter: 1968/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0379. T_Loss: 4.7083. Mask: 0.9076. :  67%|██████▋   | 67/100 [00:16<00:05,  6.20it/s]Train Iter: 1968/5000. LR: 0.0411. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0379. T_Loss: 4.7083. Mask: 0.9076. :  68%|██████▊   | 68/100 [00:16<00:04,  6.89it/s]Train Iter: 1969/5000. LR: 0.0410. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0361. T_Loss: 4.7096. Mask: 0.9085. :  68%|██████▊   | 68/100 [00:16<00:04,  6.89it/s]Train Iter: 1969/5000. LR: 0.0410. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0361. T_Loss: 4.7096. Mask: 0.9085. :  69%|██████▉   | 69/100 [00:16<00:06,  4.71it/s]Train Iter: 1970/5000. LR: 0.0410. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0358. T_Loss: 4.7201. Mask: 0.9085. :  69%|██████▉   | 69/100 [00:16<00:06,  4.71it/s]Train Iter: 1970/5000. LR: 0.0410. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0358. T_Loss: 4.7201. Mask: 0.9085. :  70%|███████   | 70/100 [00:16<00:05,  5.37it/s]Train Iter: 1971/5000. LR: 0.0410. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0342. T_Loss: 4.7154. Mask: 0.9089. :  70%|███████   | 70/100 [00:16<00:05,  5.37it/s]Train Iter: 1971/5000. LR: 0.0410. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0342. T_Loss: 4.7154. Mask: 0.9089. :  71%|███████   | 71/100 [00:16<00:04,  6.06it/s]Train Iter: 1972/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0352. T_Loss: 4.7080. Mask: 0.9084. :  71%|███████   | 71/100 [00:16<00:04,  6.06it/s]Train Iter: 1972/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0352. T_Loss: 4.7080. Mask: 0.9084. :  72%|███████▏  | 72/100 [00:16<00:04,  6.58it/s]Train Iter: 1973/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0342. T_Loss: 4.7050. Mask: 0.9080. :  72%|███████▏  | 72/100 [00:17<00:04,  6.58it/s]Train Iter: 1973/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0342. T_Loss: 4.7050. Mask: 0.9080. :  73%|███████▎  | 73/100 [00:17<00:03,  7.03it/s]Train Iter: 1974/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0330. T_Loss: 4.7038. Mask: 0.9084. :  73%|███████▎  | 73/100 [00:17<00:03,  7.03it/s]Train Iter: 1974/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0330. T_Loss: 4.7038. Mask: 0.9084. :  74%|███████▍  | 74/100 [00:17<00:03,  7.26it/s]Train Iter: 1975/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0344. T_Loss: 4.7056. Mask: 0.9087. :  74%|███████▍  | 74/100 [00:17<00:03,  7.26it/s]Train Iter: 1975/5000. LR: 0.0410. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0344. T_Loss: 4.7056. Mask: 0.9087. :  75%|███████▌  | 75/100 [00:17<00:03,  7.38it/s]total : 5000  current step :  1951
total : 5000  current step :  1952
total : 5000  current step :  1953
total : 5000  current step :  1954
total : 5000  current step :  1955
total : 5000  current step :  1956
total : 5000  current step :  1957
total : 5000  current step :  1958
total : 5000  current step :  1959
total : 5000  current step :  1960
total : 5000  current step :  1961
total : 5000  current step :  1962
total : 5000  current step :  1963
total : 5000  current step :  1964
total : 5000  current step :  1965
total : 5000  current step :  1966
total : 5000  current step :  1967
total : 5000  current step :  1968
total : 5000  current step :  1969
total : 5000  current step :  1970
total : 5000  current step :  1971
total : 5000  current step :  1972
total : 5000  current step :  1973
total : 5000  current step :  1974
total : 5000  current step :  1975
Train Iter: 1976/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0335. T_Loss: 4.7137. Mask: 0.9091. :  75%|███████▌  | 75/100 [00:19<00:03,  7.38it/s]Train Iter: 1976/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0335. T_Loss: 4.7137. Mask: 0.9091. :  76%|███████▌  | 76/100 [00:19<00:16,  1.41it/s]Train Iter: 1977/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0337. T_Loss: 4.7012. Mask: 0.9083. :  76%|███████▌  | 76/100 [00:19<00:16,  1.41it/s]Train Iter: 1978/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0330. T_Loss: 4.7048. Mask: 0.9087. :  77%|███████▋  | 77/100 [00:19<00:16,  1.41it/s]Train Iter: 1978/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0330. T_Loss: 4.7048. Mask: 0.9087. :  78%|███████▊  | 78/100 [00:19<00:09,  2.32it/s]Train Iter: 1979/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0314. T_Loss: 4.7001. Mask: 0.9094. :  78%|███████▊  | 78/100 [00:19<00:09,  2.32it/s]Train Iter: 1979/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0314. T_Loss: 4.7001. Mask: 0.9094. :  79%|███████▉  | 79/100 [00:19<00:08,  2.44it/s]Train Iter: 1980/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0315. T_Loss: 4.7140. Mask: 0.9105. :  79%|███████▉  | 79/100 [00:20<00:08,  2.44it/s]Train Iter: 1980/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0315. T_Loss: 4.7140. Mask: 0.9105. :  80%|████████  | 80/100 [00:20<00:06,  3.02it/s]Train Iter: 1981/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0317. T_Loss: 4.7212. Mask: 0.9117. :  80%|████████  | 80/100 [00:20<00:06,  3.02it/s]Train Iter: 1981/5000. LR: 0.0409. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0317. T_Loss: 4.7212. Mask: 0.9117. :  81%|████████  | 81/100 [00:20<00:05,  3.66it/s]Train Iter: 1982/5000. LR: 0.0408. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0321. T_Loss: 4.7224. Mask: 0.9116. :  81%|████████  | 81/100 [00:20<00:05,  3.66it/s]Train Iter: 1982/5000. LR: 0.0408. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0321. T_Loss: 4.7224. Mask: 0.9116. :  82%|████████▏ | 82/100 [00:20<00:04,  4.23it/s]Train Iter: 1983/5000. LR: 0.0408. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0314. T_Loss: 4.7173. Mask: 0.9115. :  82%|████████▏ | 82/100 [00:20<00:04,  4.23it/s]Train Iter: 1983/5000. LR: 0.0408. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0314. T_Loss: 4.7173. Mask: 0.9115. :  83%|████████▎ | 83/100 [00:20<00:03,  4.75it/s]Train Iter: 1984/5000. LR: 0.0408. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0306. T_Loss: 4.7132. Mask: 0.9111. :  83%|████████▎ | 83/100 [00:20<00:03,  4.75it/s]Train Iter: 1984/5000. LR: 0.0408. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0306. T_Loss: 4.7132. Mask: 0.9111. :  84%|████████▍ | 84/100 [00:20<00:02,  5.41it/s]Train Iter: 1985/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0301. T_Loss: 4.7159. Mask: 0.9107. :  84%|████████▍ | 84/100 [00:20<00:02,  5.41it/s]Train Iter: 1985/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0301. T_Loss: 4.7159. Mask: 0.9107. :  85%|████████▌ | 85/100 [00:20<00:02,  6.11it/s]Train Iter: 1986/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0285. T_Loss: 4.7082. Mask: 0.9106. :  85%|████████▌ | 85/100 [00:20<00:02,  6.11it/s]Train Iter: 1986/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0285. T_Loss: 4.7082. Mask: 0.9106. :  86%|████████▌ | 86/100 [00:20<00:02,  6.82it/s]Train Iter: 1987/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0269. T_Loss: 4.7063. Mask: 0.9109. :  86%|████████▌ | 86/100 [00:20<00:02,  6.82it/s]Train Iter: 1987/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0269. T_Loss: 4.7063. Mask: 0.9109. :  87%|████████▋ | 87/100 [00:20<00:01,  7.45it/s]Train Iter: 1988/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0271. T_Loss: 4.7064. Mask: 0.9109. :  87%|████████▋ | 87/100 [00:21<00:01,  7.45it/s]Train Iter: 1988/5000. LR: 0.0408. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0271. T_Loss: 4.7064. Mask: 0.9109. :  88%|████████▊ | 88/100 [00:21<00:01,  7.53it/s]Train Iter: 1989/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0263. T_Loss: 4.7012. Mask: 0.9105. :  88%|████████▊ | 88/100 [00:21<00:01,  7.53it/s]Train Iter: 1989/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0263. T_Loss: 4.7012. Mask: 0.9105. :  89%|████████▉ | 89/100 [00:21<00:03,  3.47it/s]Train Iter: 1990/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0269. T_Loss: 4.7023. Mask: 0.9104. :  89%|████████▉ | 89/100 [00:21<00:03,  3.47it/s]Train Iter: 1990/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0269. T_Loss: 4.7023. Mask: 0.9104. :  90%|█████████ | 90/100 [00:21<00:02,  4.19it/s]Train Iter: 1991/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0283. T_Loss: 4.7097. Mask: 0.9100. :  90%|█████████ | 90/100 [00:21<00:02,  4.19it/s]Train Iter: 1991/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0283. T_Loss: 4.7097. Mask: 0.9100. :  91%|█████████ | 91/100 [00:21<00:01,  4.77it/s]Train Iter: 1992/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0268. T_Loss: 4.7022. Mask: 0.9100. :  91%|█████████ | 91/100 [00:22<00:01,  4.77it/s]Train Iter: 1992/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0268. T_Loss: 4.7022. Mask: 0.9100. :  92%|█████████▏| 92/100 [00:22<00:01,  5.47it/s]Train Iter: 1993/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0260. T_Loss: 4.7026. Mask: 0.9099. :  92%|█████████▏| 92/100 [00:22<00:01,  5.47it/s]Train Iter: 1993/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0260. T_Loss: 4.7026. Mask: 0.9099. :  93%|█████████▎| 93/100 [00:22<00:01,  6.16it/s]Train Iter: 1994/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0262. T_Loss: 4.7001. Mask: 0.9102. :  93%|█████████▎| 93/100 [00:22<00:01,  6.16it/s]Train Iter: 1994/5000. LR: 0.0407. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0262. T_Loss: 4.7001. Mask: 0.9102. :  94%|█████████▍| 94/100 [00:22<00:00,  6.65it/s]Train Iter: 1995/5000. LR: 0.0407. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0252. T_Loss: 4.7069. Mask: 0.9105. :  94%|█████████▍| 94/100 [00:22<00:00,  6.65it/s]Train Iter: 1995/5000. LR: 0.0407. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0252. T_Loss: 4.7069. Mask: 0.9105. :  95%|█████████▌| 95/100 [00:22<00:01,  3.74it/s]Train Iter: 1996/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0251. T_Loss: 4.7104. Mask: 0.9108. :  95%|█████████▌| 95/100 [00:22<00:01,  3.74it/s]Train Iter: 1996/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0251. T_Loss: 4.7104. Mask: 0.9108. :  96%|█████████▌| 96/100 [00:22<00:00,  4.46it/s]Train Iter: 1997/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0244. T_Loss: 4.7035. Mask: 0.9101. :  96%|█████████▌| 96/100 [00:23<00:00,  4.46it/s]Train Iter: 1997/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0244. T_Loss: 4.7035. Mask: 0.9101. :  97%|█████████▋| 97/100 [00:23<00:00,  5.21it/s]Train Iter: 1998/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0229. T_Loss: 4.7056. Mask: 0.9104. :  97%|█████████▋| 97/100 [00:23<00:00,  5.21it/s]Train Iter: 1998/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0229. T_Loss: 4.7056. Mask: 0.9104. :  98%|█████████▊| 98/100 [00:23<00:00,  5.87it/s]Train Iter: 1999/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0215. T_Loss: 4.7046. Mask: 0.9107. :  98%|█████████▊| 98/100 [00:23<00:00,  5.87it/s]Train Iter: 1999/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0215. T_Loss: 4.7046. Mask: 0.9107. :  99%|█████████▉| 99/100 [00:23<00:00,  4.49it/s]Train Iter: 2000/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0216. T_Loss: 4.7021. Mask: 0.9103. :  99%|█████████▉| 99/100 [00:23<00:00,  4.49it/s]Train Iter: 2000/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0216. T_Loss: 4.7021. Mask: 0.9103. : 100%|██████████| 100/100 [00:23<00:00,  5.35it/s]Train Iter: 2000/5000. LR: 0.0406. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0216. T_Loss: 4.7021. Mask: 0.9103. : 100%|██████████| 100/100 [00:23<00:00,  4.23it/s]
total : 5000  current step :  1976
total : 5000  current step :  1977
total : 5000  current step :  1978
total : 5000  current step :  1979
total : 5000  current step :  1980
total : 5000  current step :  1981
total : 5000  current step :  1982
total : 5000  current step :  1983
total : 5000  current step :  1984
total : 5000  current step :  1985
total : 5000  current step :  1986
total : 5000  current step :  1987
total : 5000  current step :  1988
total : 5000  current step :  1989
total : 5000  current step :  1990
total : 5000  current step :  1991
total : 5000  current step :  1992
total : 5000  current step :  1993
total : 5000  current step :  1994
total : 5000  current step :  1995
total : 5000  current step :  1996
total : 5000  current step :  1997
total : 5000  current step :  1998
total : 5000  current step :  1999
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 1.2097. top1: 62.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 1.2097. top1: 62.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 1.1587. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 1.1013. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.1152. top1: 74.22. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 1.0915. top1: 75.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 1.0958. top1: 75.52. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.1126. top1: 75.45. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.1282. top1: 73.83. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.1165. top1: 74.31. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.1295. top1: 73.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.1295. top1: 73.75. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.57it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.1076. top1: 75.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.57it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.1095. top1: 74.74. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.57it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0989. top1: 75.24. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.57it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0992. top1: 74.78. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.57it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0906. top1: 75.62. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.57it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0930. top1: 75.39. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.57it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0930. top1: 75.39. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0867. top1: 75.74. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0859. top1: 75.52. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0856. top1: 75.66. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0833. top1: 75.94. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0934. top1: 75.45. top5: 99.85. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0874. top1: 75.99. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0799. top1: 76.49. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0758. top1: 76.82. top5: 99.87. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0725. top1: 77.00. top5: 99.88. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0793. top1: 76.56. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0778. top1: 76.62. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0778. top1: 76.62. top5: 99.88. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0828. top1: 76.34. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0811. top1: 76.40. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0802. top1: 76.56. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0811. top1: 76.31. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0883. top1: 76.07. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0851. top1: 76.52. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0870. top1: 76.47. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0855. top1: 76.43. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0973. top1: 75.87. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0951. top1: 76.10. top5: 99.92. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0934. top1: 76.15. top5: 99.92. :  43%|████▎     | 27/63 [00:02<00:01, 24.38it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0934. top1: 76.15. top5: 99.92. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1005. top1: 75.80. top5: 99.76. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1005. top1: 75.78. top5: 99.77. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0996. top1: 75.99. top5: 99.77. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1032. top1: 75.74. top5: 99.78. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1030. top1: 75.87. top5: 99.78. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1001. top1: 76.14. top5: 99.79. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0963. top1: 76.39. top5: 99.79. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0961. top1: 76.36. top5: 99.80. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0971. top1: 76.33. top5: 99.80. :  60%|██████    | 38/63 [00:02<00:00, 36.63it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0971. top1: 76.33. top5: 99.80. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0956. top1: 76.37. top5: 99.80. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0968. top1: 76.47. top5: 99.81. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0969. top1: 76.44. top5: 99.81. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1028. top1: 76.16. top5: 99.82. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1018. top1: 76.26. top5: 99.82. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1049. top1: 76.18. top5: 99.82. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1064. top1: 75.98. top5: 99.83. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1060. top1: 76.02. top5: 99.83. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1044. top1: 76.12. top5: 99.83. :  75%|███████▍  | 47/63 [00:02<00:00, 44.57it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1044. top1: 76.12. top5: 99.83. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1076. top1: 75.99. top5: 99.84. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1081. top1: 76.08. top5: 99.84. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1103. top1: 75.95. top5: 99.84. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1072. top1: 76.20. top5: 99.84. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1101. top1: 76.02. top5: 99.85. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1147. top1: 75.71. top5: 99.85. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1142. top1: 75.80. top5: 99.85. :  89%|████████▉ | 56/63 [00:02<00:00, 53.23it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1142. top1: 75.80. top5: 99.85. : 100%|██████████| 63/63 [00:02<00:00, 24.48it/s]
total : 5000  current step :  2000
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2001/5000. LR: 0.0406. Data: 2.01s. Batch: 2.13s. S_Loss: 0.9168. T_Loss: 4.7102. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2001/5000. LR: 0.0406. Data: 2.01s. Batch: 2.13s. S_Loss: 0.9168. T_Loss: 4.7102. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:30,  2.13s/it]Train Iter: 2002/5000. LR: 0.0406. Data: 1.01s. Batch: 1.11s. S_Loss: 0.9587. T_Loss: 5.0929. Mask: 0.9531. :   1%|          | 1/100 [00:02<03:30,  2.13s/it]Train Iter: 2002/5000. LR: 0.0406. Data: 1.01s. Batch: 1.11s. S_Loss: 0.9587. T_Loss: 5.0929. Mask: 0.9531. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 2003/5000. LR: 0.0405. Data: 0.68s. Batch: 0.79s. S_Loss: 1.0100. T_Loss: 5.2005. Mask: 0.9479. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 2003/5000. LR: 0.0405. Data: 0.68s. Batch: 0.79s. S_Loss: 1.0100. T_Loss: 5.2005. Mask: 0.9479. :   3%|▎         | 3/100 [00:02<00:55,  1.74it/s]Train Iter: 2004/5000. LR: 0.0405. Data: 0.51s. Batch: 0.62s. S_Loss: 0.9713. T_Loss: 5.1308. Mask: 0.9531. :   3%|▎         | 3/100 [00:02<00:55,  1.74it/s]Train Iter: 2004/5000. LR: 0.0405. Data: 0.51s. Batch: 0.62s. S_Loss: 0.9713. T_Loss: 5.1308. Mask: 0.9531. :   4%|▍         | 4/100 [00:02<00:38,  2.51it/s]Train Iter: 2005/5000. LR: 0.0405. Data: 0.41s. Batch: 0.56s. S_Loss: 1.0144. T_Loss: 5.1156. Mask: 0.9437. :   4%|▍         | 4/100 [00:02<00:38,  2.51it/s]Train Iter: 2005/5000. LR: 0.0405. Data: 0.41s. Batch: 0.56s. S_Loss: 1.0144. T_Loss: 5.1156. Mask: 0.9437. :   5%|▌         | 5/100 [00:02<00:34,  2.77it/s]Train Iter: 2006/5000. LR: 0.0405. Data: 0.34s. Batch: 0.48s. S_Loss: 1.0175. T_Loss: 5.0635. Mask: 0.9479. :   5%|▌         | 5/100 [00:02<00:34,  2.77it/s]Train Iter: 2006/5000. LR: 0.0405. Data: 0.34s. Batch: 0.48s. S_Loss: 1.0175. T_Loss: 5.0635. Mask: 0.9479. :   6%|▌         | 6/100 [00:02<00:26,  3.61it/s]Train Iter: 2007/5000. LR: 0.0405. Data: 0.29s. Batch: 0.43s. S_Loss: 1.0042. T_Loss: 4.9682. Mask: 0.9509. :   6%|▌         | 6/100 [00:03<00:26,  3.61it/s]Train Iter: 2007/5000. LR: 0.0405. Data: 0.29s. Batch: 0.43s. S_Loss: 1.0042. T_Loss: 4.9682. Mask: 0.9509. :   7%|▋         | 7/100 [00:03<00:21,  4.42it/s]Train Iter: 2008/5000. LR: 0.0405. Data: 0.26s. Batch: 0.39s. S_Loss: 0.9988. T_Loss: 4.8754. Mask: 0.9453. :   7%|▋         | 7/100 [00:03<00:21,  4.42it/s]Train Iter: 2008/5000. LR: 0.0405. Data: 0.26s. Batch: 0.39s. S_Loss: 0.9988. T_Loss: 4.8754. Mask: 0.9453. :   8%|▊         | 8/100 [00:03<00:17,  5.20it/s]Train Iter: 2009/5000. LR: 0.0405. Data: 0.23s. Batch: 0.38s. S_Loss: 1.0018. T_Loss: 4.8232. Mask: 0.9444. :   8%|▊         | 8/100 [00:03<00:17,  5.20it/s]Train Iter: 2009/5000. LR: 0.0405. Data: 0.23s. Batch: 0.38s. S_Loss: 1.0018. T_Loss: 4.8232. Mask: 0.9444. :   9%|▉         | 9/100 [00:03<00:18,  4.81it/s]Train Iter: 2010/5000. LR: 0.0404. Data: 0.21s. Batch: 0.35s. S_Loss: 1.0031. T_Loss: 4.7947. Mask: 0.9437. :   9%|▉         | 9/100 [00:03<00:18,  4.81it/s]Train Iter: 2010/5000. LR: 0.0404. Data: 0.21s. Batch: 0.35s. S_Loss: 1.0031. T_Loss: 4.7947. Mask: 0.9437. :  10%|█         | 10/100 [00:03<00:16,  5.60it/s]Train Iter: 2011/5000. LR: 0.0404. Data: 0.19s. Batch: 0.33s. S_Loss: 1.0110. T_Loss: 4.9016. Mask: 0.9432. :  10%|█         | 10/100 [00:03<00:16,  5.60it/s]Train Iter: 2011/5000. LR: 0.0404. Data: 0.19s. Batch: 0.33s. S_Loss: 1.0110. T_Loss: 4.9016. Mask: 0.9432. :  11%|█         | 11/100 [00:03<00:14,  6.19it/s]Train Iter: 2012/5000. LR: 0.0404. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0275. T_Loss: 4.9361. Mask: 0.9323. :  11%|█         | 11/100 [00:03<00:14,  6.19it/s]Train Iter: 2012/5000. LR: 0.0404. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0275. T_Loss: 4.9361. Mask: 0.9323. :  12%|█▏        | 12/100 [00:03<00:13,  6.68it/s]Train Iter: 2013/5000. LR: 0.0404. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0231. T_Loss: 4.8613. Mask: 0.9303. :  12%|█▏        | 12/100 [00:03<00:13,  6.68it/s]Train Iter: 2013/5000. LR: 0.0404. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0231. T_Loss: 4.8613. Mask: 0.9303. :  13%|█▎        | 13/100 [00:03<00:12,  6.96it/s]Train Iter: 2014/5000. LR: 0.0404. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0266. T_Loss: 4.8547. Mask: 0.9241. :  13%|█▎        | 13/100 [00:04<00:12,  6.96it/s]Train Iter: 2014/5000. LR: 0.0404. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0266. T_Loss: 4.8547. Mask: 0.9241. :  14%|█▍        | 14/100 [00:04<00:12,  6.97it/s]Train Iter: 2015/5000. LR: 0.0404. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0259. T_Loss: 4.8795. Mask: 0.9250. :  14%|█▍        | 14/100 [00:04<00:12,  6.97it/s]Train Iter: 2015/5000. LR: 0.0404. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0259. T_Loss: 4.8795. Mask: 0.9250. :  15%|█▌        | 15/100 [00:04<00:15,  5.35it/s]Train Iter: 2016/5000. LR: 0.0404. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0249. T_Loss: 4.8483. Mask: 0.9219. :  15%|█▌        | 15/100 [00:04<00:15,  5.35it/s]Train Iter: 2016/5000. LR: 0.0404. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0249. T_Loss: 4.8483. Mask: 0.9219. :  16%|█▌        | 16/100 [00:04<00:13,  6.14it/s]Train Iter: 2017/5000. LR: 0.0403. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0241. T_Loss: 4.8479. Mask: 0.9246. :  16%|█▌        | 16/100 [00:04<00:13,  6.14it/s]Train Iter: 2017/5000. LR: 0.0403. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0241. T_Loss: 4.8479. Mask: 0.9246. :  17%|█▋        | 17/100 [00:04<00:12,  6.88it/s]Train Iter: 2018/5000. LR: 0.0403. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0187. T_Loss: 4.8415. Mask: 0.9236. :  17%|█▋        | 17/100 [00:04<00:12,  6.88it/s]Train Iter: 2018/5000. LR: 0.0403. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0187. T_Loss: 4.8415. Mask: 0.9236. :  18%|█▊        | 18/100 [00:04<00:11,  7.30it/s]Train Iter: 2019/5000. LR: 0.0403. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0172. T_Loss: 4.8183. Mask: 0.9260. :  18%|█▊        | 18/100 [00:04<00:11,  7.30it/s]Train Iter: 2019/5000. LR: 0.0403. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0172. T_Loss: 4.8183. Mask: 0.9260. :  19%|█▉        | 19/100 [00:04<00:16,  5.03it/s]Train Iter: 2020/5000. LR: 0.0403. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0144. T_Loss: 4.7904. Mask: 0.9266. :  19%|█▉        | 19/100 [00:05<00:16,  5.03it/s]Train Iter: 2020/5000. LR: 0.0403. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0144. T_Loss: 4.7904. Mask: 0.9266. :  20%|██        | 20/100 [00:05<00:14,  5.56it/s]Train Iter: 2021/5000. LR: 0.0403. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0110. T_Loss: 4.8128. Mask: 0.9286. :  20%|██        | 20/100 [00:05<00:14,  5.56it/s]Train Iter: 2021/5000. LR: 0.0403. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0110. T_Loss: 4.8128. Mask: 0.9286. :  21%|██        | 21/100 [00:05<00:12,  6.27it/s]Train Iter: 2022/5000. LR: 0.0403. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0080. T_Loss: 4.8144. Mask: 0.9304. :  21%|██        | 21/100 [00:05<00:12,  6.27it/s]Train Iter: 2022/5000. LR: 0.0403. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0080. T_Loss: 4.8144. Mask: 0.9304. :  22%|██▏       | 22/100 [00:05<00:11,  6.77it/s]Train Iter: 2023/5000. LR: 0.0402. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0048. T_Loss: 4.7566. Mask: 0.9293. :  22%|██▏       | 22/100 [00:05<00:11,  6.77it/s]Train Iter: 2023/5000. LR: 0.0402. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0048. T_Loss: 4.7566. Mask: 0.9293. :  23%|██▎       | 23/100 [00:05<00:10,  7.28it/s]Train Iter: 2024/5000. LR: 0.0402. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0068. T_Loss: 4.7448. Mask: 0.9310. :  23%|██▎       | 23/100 [00:05<00:10,  7.28it/s]Train Iter: 2024/5000. LR: 0.0402. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0068. T_Loss: 4.7448. Mask: 0.9310. :  24%|██▍       | 24/100 [00:05<00:10,  7.54it/s]Train Iter: 2025/5000. LR: 0.0402. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0068. T_Loss: 4.7289. Mask: 0.9313. :  24%|██▍       | 24/100 [00:05<00:10,  7.54it/s]Train Iter: 2025/5000. LR: 0.0402. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0068. T_Loss: 4.7289. Mask: 0.9313. :  25%|██▌       | 25/100 [00:05<00:09,  7.72it/s]total : 5000  current step :  2001
total : 5000  current step :  2002
total : 5000  current step :  2003
total : 5000  current step :  2004
total : 5000  current step :  2005
total : 5000  current step :  2006
total : 5000  current step :  2007
total : 5000  current step :  2008
total : 5000  current step :  2009
total : 5000  current step :  2010
total : 5000  current step :  2011
total : 5000  current step :  2012
total : 5000  current step :  2013
total : 5000  current step :  2014
total : 5000  current step :  2015
total : 5000  current step :  2016
total : 5000  current step :  2017
total : 5000  current step :  2018
total : 5000  current step :  2019
total : 5000  current step :  2020
total : 5000  current step :  2021
total : 5000  current step :  2022
total : 5000  current step :  2023
total : 5000  current step :  2024
total : 5000  current step :  2025
Train Iter: 2026/5000. LR: 0.0402. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0053. T_Loss: 4.7200. Mask: 0.9315. :  25%|██▌       | 25/100 [00:07<00:09,  7.72it/s]Train Iter: 2026/5000. LR: 0.0402. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0053. T_Loss: 4.7200. Mask: 0.9315. :  26%|██▌       | 26/100 [00:07<00:48,  1.51it/s]Train Iter: 2027/5000. LR: 0.0402. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0057. T_Loss: 4.7213. Mask: 0.9317. :  26%|██▌       | 26/100 [00:07<00:48,  1.51it/s]Train Iter: 2027/5000. LR: 0.0402. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0057. T_Loss: 4.7213. Mask: 0.9317. :  27%|██▋       | 27/100 [00:07<00:36,  2.01it/s]Train Iter: 2028/5000. LR: 0.0402. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0087. T_Loss: 4.7456. Mask: 0.9319. :  27%|██▋       | 27/100 [00:07<00:36,  2.01it/s]Train Iter: 2028/5000. LR: 0.0402. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0087. T_Loss: 4.7456. Mask: 0.9319. :  28%|██▊       | 28/100 [00:07<00:27,  2.59it/s]Train Iter: 2029/5000. LR: 0.0402. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0091. T_Loss: 4.7494. Mask: 0.9289. :  28%|██▊       | 28/100 [00:08<00:27,  2.59it/s]Train Iter: 2029/5000. LR: 0.0402. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0091. T_Loss: 4.7494. Mask: 0.9289. :  29%|██▉       | 29/100 [00:08<00:23,  3.03it/s]Train Iter: 2030/5000. LR: 0.0401. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0082. T_Loss: 4.7317. Mask: 0.9271. :  29%|██▉       | 29/100 [00:08<00:23,  3.03it/s]Train Iter: 2030/5000. LR: 0.0401. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0082. T_Loss: 4.7317. Mask: 0.9271. :  30%|███       | 30/100 [00:08<00:19,  3.55it/s]Train Iter: 2031/5000. LR: 0.0401. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0109. T_Loss: 4.7589. Mask: 0.9264. :  30%|███       | 30/100 [00:08<00:19,  3.55it/s]Train Iter: 2031/5000. LR: 0.0401. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0109. T_Loss: 4.7589. Mask: 0.9264. :  31%|███       | 31/100 [00:08<00:16,  4.21it/s]Train Iter: 2032/5000. LR: 0.0401. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0067. T_Loss: 4.7441. Mask: 0.9277. :  31%|███       | 31/100 [00:08<00:16,  4.21it/s]Train Iter: 2032/5000. LR: 0.0401. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0067. T_Loss: 4.7441. Mask: 0.9277. :  32%|███▏      | 32/100 [00:08<00:14,  4.84it/s]Train Iter: 2033/5000. LR: 0.0401. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0090. T_Loss: 4.7475. Mask: 0.9280. :  32%|███▏      | 32/100 [00:08<00:14,  4.84it/s]Train Iter: 2033/5000. LR: 0.0401. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0090. T_Loss: 4.7475. Mask: 0.9280. :  33%|███▎      | 33/100 [00:08<00:12,  5.48it/s]Train Iter: 2034/5000. LR: 0.0401. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0087. T_Loss: 4.7666. Mask: 0.9292. :  33%|███▎      | 33/100 [00:08<00:12,  5.48it/s]Train Iter: 2034/5000. LR: 0.0401. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0087. T_Loss: 4.7666. Mask: 0.9292. :  34%|███▍      | 34/100 [00:08<00:11,  5.96it/s]Train Iter: 2035/5000. LR: 0.0401. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0059. T_Loss: 4.7563. Mask: 0.9295. :  34%|███▍      | 34/100 [00:08<00:11,  5.96it/s]Train Iter: 2035/5000. LR: 0.0401. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0059. T_Loss: 4.7563. Mask: 0.9295. :  35%|███▌      | 35/100 [00:08<00:11,  5.43it/s]Train Iter: 2036/5000. LR: 0.0401. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0042. T_Loss: 4.7623. Mask: 0.9306. :  35%|███▌      | 35/100 [00:09<00:11,  5.43it/s]Train Iter: 2036/5000. LR: 0.0401. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0042. T_Loss: 4.7623. Mask: 0.9306. :  36%|███▌      | 36/100 [00:09<00:10,  6.01it/s]Train Iter: 2037/5000. LR: 0.0400. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0022. T_Loss: 4.7304. Mask: 0.9274. :  36%|███▌      | 36/100 [00:09<00:10,  6.01it/s]Train Iter: 2037/5000. LR: 0.0400. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0022. T_Loss: 4.7304. Mask: 0.9274. :  37%|███▋      | 37/100 [00:09<00:09,  6.48it/s]Train Iter: 2038/5000. LR: 0.0400. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0014. T_Loss: 4.7198. Mask: 0.9260. :  37%|███▋      | 37/100 [00:09<00:09,  6.48it/s]Train Iter: 2038/5000. LR: 0.0400. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0014. T_Loss: 4.7198. Mask: 0.9260. :  38%|███▊      | 38/100 [00:09<00:08,  7.11it/s]Train Iter: 2039/5000. LR: 0.0400. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9974. T_Loss: 4.7132. Mask: 0.9271. :  38%|███▊      | 38/100 [00:09<00:08,  7.11it/s]Train Iter: 2039/5000. LR: 0.0400. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9974. T_Loss: 4.7132. Mask: 0.9271. :  39%|███▉      | 39/100 [00:09<00:13,  4.44it/s]Train Iter: 2040/5000. LR: 0.0400. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9974. T_Loss: 4.7370. Mask: 0.9273. :  39%|███▉      | 39/100 [00:09<00:13,  4.44it/s]Train Iter: 2040/5000. LR: 0.0400. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9974. T_Loss: 4.7370. Mask: 0.9273. :  40%|████      | 40/100 [00:09<00:11,  5.12it/s]Train Iter: 2041/5000. LR: 0.0400. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9945. T_Loss: 4.7331. Mask: 0.9276. :  40%|████      | 40/100 [00:10<00:11,  5.12it/s]Train Iter: 2041/5000. LR: 0.0400. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9945. T_Loss: 4.7331. Mask: 0.9276. :  41%|████      | 41/100 [00:10<00:10,  5.61it/s]Train Iter: 2042/5000. LR: 0.0400. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9905. T_Loss: 4.7187. Mask: 0.9286. :  41%|████      | 41/100 [00:10<00:10,  5.61it/s]Train Iter: 2042/5000. LR: 0.0400. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9905. T_Loss: 4.7187. Mask: 0.9286. :  42%|████▏     | 42/100 [00:10<00:09,  6.15it/s]Train Iter: 2043/5000. LR: 0.0400. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9890. T_Loss: 4.7071. Mask: 0.9273. :  42%|████▏     | 42/100 [00:10<00:09,  6.15it/s]Train Iter: 2043/5000. LR: 0.0400. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9890. T_Loss: 4.7071. Mask: 0.9273. :  43%|████▎     | 43/100 [00:10<00:08,  6.72it/s]Train Iter: 2044/5000. LR: 0.0399. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9888. T_Loss: 4.7200. Mask: 0.9268. :  43%|████▎     | 43/100 [00:10<00:08,  6.72it/s]Train Iter: 2044/5000. LR: 0.0399. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9888. T_Loss: 4.7200. Mask: 0.9268. :  44%|████▍     | 44/100 [00:10<00:07,  7.12it/s]Train Iter: 2045/5000. LR: 0.0399. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9892. T_Loss: 4.7300. Mask: 0.9278. :  44%|████▍     | 44/100 [00:10<00:07,  7.12it/s]Train Iter: 2045/5000. LR: 0.0399. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9892. T_Loss: 4.7300. Mask: 0.9278. :  45%|████▌     | 45/100 [00:10<00:11,  4.76it/s]Train Iter: 2046/5000. LR: 0.0399. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9887. T_Loss: 4.7393. Mask: 0.9287. :  45%|████▌     | 45/100 [00:10<00:11,  4.76it/s]Train Iter: 2046/5000. LR: 0.0399. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9887. T_Loss: 4.7393. Mask: 0.9287. :  46%|████▌     | 46/100 [00:10<00:10,  5.38it/s]Train Iter: 2047/5000. LR: 0.0399. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9930. T_Loss: 4.7409. Mask: 0.9282. :  46%|████▌     | 46/100 [00:11<00:10,  5.38it/s]Train Iter: 2047/5000. LR: 0.0399. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9930. T_Loss: 4.7409. Mask: 0.9282. :  47%|████▋     | 47/100 [00:11<00:08,  5.93it/s]Train Iter: 2048/5000. LR: 0.0399. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9925. T_Loss: 4.7445. Mask: 0.9284. :  47%|████▋     | 47/100 [00:11<00:08,  5.93it/s]Train Iter: 2048/5000. LR: 0.0399. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9925. T_Loss: 4.7445. Mask: 0.9284. :  48%|████▊     | 48/100 [00:11<00:08,  6.34it/s]Train Iter: 2049/5000. LR: 0.0399. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9912. T_Loss: 4.7309. Mask: 0.9273. :  48%|████▊     | 48/100 [00:11<00:08,  6.34it/s]Train Iter: 2049/5000. LR: 0.0399. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9912. T_Loss: 4.7309. Mask: 0.9273. :  49%|████▉     | 49/100 [00:11<00:10,  4.81it/s]Train Iter: 2050/5000. LR: 0.0398. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9927. T_Loss: 4.7379. Mask: 0.9269. :  49%|████▉     | 49/100 [00:11<00:10,  4.81it/s]Train Iter: 2050/5000. LR: 0.0398. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9927. T_Loss: 4.7379. Mask: 0.9269. :  50%|█████     | 50/100 [00:11<00:08,  5.56it/s]total : 5000  current step :  2026
total : 5000  current step :  2027
total : 5000  current step :  2028
total : 5000  current step :  2029
total : 5000  current step :  2030
total : 5000  current step :  2031
total : 5000  current step :  2032
total : 5000  current step :  2033
total : 5000  current step :  2034
total : 5000  current step :  2035
total : 5000  current step :  2036
total : 5000  current step :  2037
total : 5000  current step :  2038
total : 5000  current step :  2039
total : 5000  current step :  2040
total : 5000  current step :  2041
total : 5000  current step :  2042
total : 5000  current step :  2043
total : 5000  current step :  2044
total : 5000  current step :  2045
total : 5000  current step :  2046
total : 5000  current step :  2047
total : 5000  current step :  2048
total : 5000  current step :  2049
total : 5000  current step :  2050
Train Iter: 2051/5000. LR: 0.0398. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9910. T_Loss: 4.7362. Mask: 0.9265. :  50%|█████     | 50/100 [00:13<00:08,  5.56it/s]Train Iter: 2051/5000. LR: 0.0398. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9910. T_Loss: 4.7362. Mask: 0.9265. :  51%|█████     | 51/100 [00:13<00:38,  1.26it/s]Train Iter: 2052/5000. LR: 0.0398. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9907. T_Loss: 4.7302. Mask: 0.9267. :  51%|█████     | 51/100 [00:13<00:38,  1.26it/s]Train Iter: 2052/5000. LR: 0.0398. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9907. T_Loss: 4.7302. Mask: 0.9267. :  52%|█████▏    | 52/100 [00:13<00:28,  1.70it/s]Train Iter: 2053/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9896. T_Loss: 4.7238. Mask: 0.9263. :  52%|█████▏    | 52/100 [00:14<00:28,  1.70it/s]Train Iter: 2053/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9896. T_Loss: 4.7238. Mask: 0.9263. :  53%|█████▎    | 53/100 [00:14<00:20,  2.24it/s]Train Iter: 2054/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9900. T_Loss: 4.7200. Mask: 0.9242. :  53%|█████▎    | 53/100 [00:14<00:20,  2.24it/s]Train Iter: 2054/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9900. T_Loss: 4.7200. Mask: 0.9242. :  54%|█████▍    | 54/100 [00:14<00:15,  2.90it/s]Train Iter: 2055/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9892. T_Loss: 4.7234. Mask: 0.9244. :  54%|█████▍    | 54/100 [00:14<00:15,  2.90it/s]Train Iter: 2055/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9892. T_Loss: 4.7234. Mask: 0.9244. :  55%|█████▌    | 55/100 [00:14<00:15,  2.91it/s]Train Iter: 2056/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9889. T_Loss: 4.7267. Mask: 0.9241. :  55%|█████▌    | 55/100 [00:14<00:15,  2.91it/s]Train Iter: 2056/5000. LR: 0.0398. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9889. T_Loss: 4.7267. Mask: 0.9241. :  56%|█████▌    | 56/100 [00:14<00:12,  3.55it/s]Train Iter: 2057/5000. LR: 0.0397. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9893. T_Loss: 4.7307. Mask: 0.9243. :  56%|█████▌    | 56/100 [00:14<00:12,  3.55it/s]Train Iter: 2057/5000. LR: 0.0397. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9893. T_Loss: 4.7307. Mask: 0.9243. :  57%|█████▋    | 57/100 [00:14<00:10,  4.26it/s]Train Iter: 2058/5000. LR: 0.0397. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9904. T_Loss: 4.7294. Mask: 0.9235. :  57%|█████▋    | 57/100 [00:14<00:10,  4.26it/s]Train Iter: 2058/5000. LR: 0.0397. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9904. T_Loss: 4.7294. Mask: 0.9235. :  58%|█████▊    | 58/100 [00:14<00:08,  4.77it/s]Train Iter: 2059/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9886. T_Loss: 4.7282. Mask: 0.9237. :  58%|█████▊    | 58/100 [00:15<00:08,  4.77it/s]Train Iter: 2059/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9886. T_Loss: 4.7282. Mask: 0.9237. :  59%|█████▉    | 59/100 [00:15<00:07,  5.54it/s]Train Iter: 2060/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9892. T_Loss: 4.7338. Mask: 0.9240. :  59%|█████▉    | 59/100 [00:15<00:07,  5.54it/s]Train Iter: 2060/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9892. T_Loss: 4.7338. Mask: 0.9240. :  60%|██████    | 60/100 [00:15<00:06,  5.93it/s]Train Iter: 2061/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9881. T_Loss: 4.7300. Mask: 0.9242. :  60%|██████    | 60/100 [00:15<00:06,  5.93it/s]Train Iter: 2061/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9881. T_Loss: 4.7300. Mask: 0.9242. :  61%|██████    | 61/100 [00:15<00:06,  6.47it/s]Train Iter: 2062/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9869. T_Loss: 4.7234. Mask: 0.9244. :  61%|██████    | 61/100 [00:15<00:06,  6.47it/s]Train Iter: 2062/5000. LR: 0.0397. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9869. T_Loss: 4.7234. Mask: 0.9244. :  62%|██████▏   | 62/100 [00:15<00:05,  6.83it/s]Train Iter: 2063/5000. LR: 0.0396. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9853. T_Loss: 4.7226. Mask: 0.9246. :  62%|██████▏   | 62/100 [00:15<00:05,  6.83it/s]Train Iter: 2063/5000. LR: 0.0396. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9853. T_Loss: 4.7226. Mask: 0.9246. :  63%|██████▎   | 63/100 [00:15<00:05,  7.25it/s]Train Iter: 2064/5000. LR: 0.0396. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9868. T_Loss: 4.7202. Mask: 0.9229. :  63%|██████▎   | 63/100 [00:15<00:05,  7.25it/s]Train Iter: 2064/5000. LR: 0.0396. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9868. T_Loss: 4.7202. Mask: 0.9229. :  64%|██████▍   | 64/100 [00:15<00:04,  7.58it/s]Train Iter: 2065/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9862. T_Loss: 4.7094. Mask: 0.9226. :  64%|██████▍   | 64/100 [00:15<00:04,  7.58it/s]Train Iter: 2065/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9862. T_Loss: 4.7094. Mask: 0.9226. :  65%|██████▌   | 65/100 [00:15<00:06,  5.74it/s]Train Iter: 2066/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9865. T_Loss: 4.7151. Mask: 0.9228. :  65%|██████▌   | 65/100 [00:16<00:06,  5.74it/s]Train Iter: 2066/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9865. T_Loss: 4.7151. Mask: 0.9228. :  66%|██████▌   | 66/100 [00:16<00:05,  6.04it/s]Train Iter: 2067/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9857. T_Loss: 4.7206. Mask: 0.9235. :  66%|██████▌   | 66/100 [00:16<00:05,  6.04it/s]Train Iter: 2067/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9857. T_Loss: 4.7206. Mask: 0.9235. :  67%|██████▋   | 67/100 [00:16<00:05,  6.41it/s]Train Iter: 2068/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9854. T_Loss: 4.7127. Mask: 0.9246. :  67%|██████▋   | 67/100 [00:16<00:05,  6.41it/s]Train Iter: 2068/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9854. T_Loss: 4.7127. Mask: 0.9246. :  68%|██████▊   | 68/100 [00:16<00:04,  6.79it/s]Train Iter: 2069/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9880. T_Loss: 4.7265. Mask: 0.9244. :  68%|██████▊   | 68/100 [00:16<00:04,  6.79it/s]Train Iter: 2069/5000. LR: 0.0396. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9880. T_Loss: 4.7265. Mask: 0.9244. :  69%|██████▉   | 69/100 [00:16<00:06,  5.12it/s]Train Iter: 2070/5000. LR: 0.0395. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9867. T_Loss: 4.7111. Mask: 0.9237. :  69%|██████▉   | 69/100 [00:16<00:06,  5.12it/s]Train Iter: 2070/5000. LR: 0.0395. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9867. T_Loss: 4.7111. Mask: 0.9237. :  70%|███████   | 70/100 [00:16<00:05,  5.76it/s]Train Iter: 2071/5000. LR: 0.0395. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9868. T_Loss: 4.7229. Mask: 0.9239. :  70%|███████   | 70/100 [00:16<00:05,  5.76it/s]Train Iter: 2071/5000. LR: 0.0395. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9868. T_Loss: 4.7229. Mask: 0.9239. :  71%|███████   | 71/100 [00:16<00:04,  6.09it/s]Train Iter: 2072/5000. LR: 0.0395. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9865. T_Loss: 4.7189. Mask: 0.9240. :  71%|███████   | 71/100 [00:17<00:04,  6.09it/s]Train Iter: 2072/5000. LR: 0.0395. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9865. T_Loss: 4.7189. Mask: 0.9240. :  72%|███████▏  | 72/100 [00:17<00:04,  6.53it/s]Train Iter: 2073/5000. LR: 0.0395. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9851. T_Loss: 4.7188. Mask: 0.9242. :  72%|███████▏  | 72/100 [00:17<00:04,  6.53it/s]Train Iter: 2073/5000. LR: 0.0395. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9851. T_Loss: 4.7188. Mask: 0.9242. :  73%|███████▎  | 73/100 [00:17<00:03,  6.90it/s]Train Iter: 2074/5000. LR: 0.0395. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9850. T_Loss: 4.7063. Mask: 0.9231. :  73%|███████▎  | 73/100 [00:17<00:03,  6.90it/s]Train Iter: 2074/5000. LR: 0.0395. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9850. T_Loss: 4.7063. Mask: 0.9231. :  74%|███████▍  | 74/100 [00:17<00:03,  7.09it/s]Train Iter: 2075/5000. LR: 0.0395. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9849. T_Loss: 4.6987. Mask: 0.9233. :  74%|███████▍  | 74/100 [00:17<00:03,  7.09it/s]Train Iter: 2075/5000. LR: 0.0395. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9849. T_Loss: 4.6987. Mask: 0.9233. :  75%|███████▌  | 75/100 [00:17<00:05,  4.67it/s]total : 5000  current step :  2051
total : 5000  current step :  2052
total : 5000  current step :  2053
total : 5000  current step :  2054
total : 5000  current step :  2055
total : 5000  current step :  2056
total : 5000  current step :  2057
total : 5000  current step :  2058
total : 5000  current step :  2059
total : 5000  current step :  2060
total : 5000  current step :  2061
total : 5000  current step :  2062
total : 5000  current step :  2063
total : 5000  current step :  2064
total : 5000  current step :  2065
total : 5000  current step :  2066
total : 5000  current step :  2067
total : 5000  current step :  2068
total : 5000  current step :  2069
total : 5000  current step :  2070
total : 5000  current step :  2071
total : 5000  current step :  2072
total : 5000  current step :  2073
total : 5000  current step :  2074
total : 5000  current step :  2075
Train Iter: 2076/5000. LR: 0.0395. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9854. T_Loss: 4.6943. Mask: 0.9223. :  75%|███████▌  | 75/100 [00:19<00:05,  4.67it/s]Train Iter: 2076/5000. LR: 0.0395. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9854. T_Loss: 4.6943. Mask: 0.9223. :  76%|███████▌  | 76/100 [00:19<00:17,  1.36it/s]Train Iter: 2077/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9863. T_Loss: 4.7005. Mask: 0.9221. :  76%|███████▌  | 76/100 [00:19<00:17,  1.36it/s]Train Iter: 2077/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9863. T_Loss: 4.7005. Mask: 0.9221. :  77%|███████▋  | 77/100 [00:19<00:12,  1.81it/s]Train Iter: 2078/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9858. T_Loss: 4.6888. Mask: 0.9219. :  77%|███████▋  | 77/100 [00:19<00:12,  1.81it/s]Train Iter: 2078/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9858. T_Loss: 4.6888. Mask: 0.9219. :  78%|███████▊  | 78/100 [00:19<00:09,  2.39it/s]Train Iter: 2079/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9852. T_Loss: 4.6857. Mask: 0.9213. :  78%|███████▊  | 78/100 [00:20<00:09,  2.39it/s]Train Iter: 2079/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9852. T_Loss: 4.6857. Mask: 0.9213. :  79%|███████▉  | 79/100 [00:20<00:08,  2.42it/s]Train Iter: 2080/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9845. T_Loss: 4.6884. Mask: 0.9215. :  79%|███████▉  | 79/100 [00:20<00:08,  2.42it/s]Train Iter: 2080/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9845. T_Loss: 4.6884. Mask: 0.9215. :  80%|████████  | 80/100 [00:20<00:06,  3.03it/s]Train Iter: 2081/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9852. T_Loss: 4.6870. Mask: 0.9209. :  80%|████████  | 80/100 [00:20<00:06,  3.03it/s]Train Iter: 2081/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9852. T_Loss: 4.6870. Mask: 0.9209. :  81%|████████  | 81/100 [00:20<00:05,  3.62it/s]Train Iter: 2082/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9848. T_Loss: 4.6851. Mask: 0.9204. :  81%|████████  | 81/100 [00:20<00:05,  3.62it/s]Train Iter: 2082/5000. LR: 0.0394. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9848. T_Loss: 4.6851. Mask: 0.9204. :  82%|████████▏ | 82/100 [00:20<00:04,  4.36it/s]Train Iter: 2083/5000. LR: 0.0393. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9838. T_Loss: 4.6763. Mask: 0.9206. :  82%|████████▏ | 82/100 [00:20<00:04,  4.36it/s]Train Iter: 2083/5000. LR: 0.0393. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9838. T_Loss: 4.6763. Mask: 0.9206. :  83%|████████▎ | 83/100 [00:20<00:03,  5.12it/s]Train Iter: 2084/5000. LR: 0.0393. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9840. T_Loss: 4.6807. Mask: 0.9200. :  83%|████████▎ | 83/100 [00:20<00:03,  5.12it/s]Train Iter: 2084/5000. LR: 0.0393. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9840. T_Loss: 4.6807. Mask: 0.9200. :  84%|████████▍ | 84/100 [00:20<00:02,  5.94it/s]Train Iter: 2085/5000. LR: 0.0393. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9836. T_Loss: 4.6748. Mask: 0.9195. :  84%|████████▍ | 84/100 [00:21<00:02,  5.94it/s]Train Iter: 2085/5000. LR: 0.0393. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9836. T_Loss: 4.6748. Mask: 0.9195. :  85%|████████▌ | 85/100 [00:21<00:03,  4.39it/s]Train Iter: 2086/5000. LR: 0.0393. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9818. T_Loss: 4.6580. Mask: 0.9186. :  85%|████████▌ | 85/100 [00:21<00:03,  4.39it/s]Train Iter: 2086/5000. LR: 0.0393. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9818. T_Loss: 4.6580. Mask: 0.9186. :  86%|████████▌ | 86/100 [00:21<00:02,  5.03it/s]Train Iter: 2087/5000. LR: 0.0393. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.6650. Mask: 0.9185. :  86%|████████▌ | 86/100 [00:21<00:02,  5.03it/s]Train Iter: 2087/5000. LR: 0.0393. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.6650. Mask: 0.9185. :  87%|████████▋ | 87/100 [00:21<00:02,  5.77it/s]Train Iter: 2088/5000. LR: 0.0393. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9824. T_Loss: 4.6640. Mask: 0.9183. :  87%|████████▋ | 87/100 [00:21<00:02,  5.77it/s]Train Iter: 2088/5000. LR: 0.0393. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9824. T_Loss: 4.6640. Mask: 0.9183. :  88%|████████▊ | 88/100 [00:21<00:01,  6.34it/s]Train Iter: 2089/5000. LR: 0.0393. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9814. T_Loss: 4.6706. Mask: 0.9189. :  88%|████████▊ | 88/100 [00:21<00:01,  6.34it/s]Train Iter: 2089/5000. LR: 0.0393. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9814. T_Loss: 4.6706. Mask: 0.9189. :  89%|████████▉ | 89/100 [00:21<00:01,  5.63it/s]Train Iter: 2090/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9842. T_Loss: 4.6872. Mask: 0.9191. :  89%|████████▉ | 89/100 [00:21<00:01,  5.63it/s]Train Iter: 2090/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9842. T_Loss: 4.6872. Mask: 0.9191. :  90%|█████████ | 90/100 [00:21<00:01,  6.11it/s]Train Iter: 2091/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9837. T_Loss: 4.6878. Mask: 0.9190. :  90%|█████████ | 90/100 [00:22<00:01,  6.11it/s]Train Iter: 2091/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9837. T_Loss: 4.6878. Mask: 0.9190. :  91%|█████████ | 91/100 [00:22<00:01,  6.63it/s]Train Iter: 2092/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9836. T_Loss: 4.6841. Mask: 0.9181. :  91%|█████████ | 91/100 [00:22<00:01,  6.63it/s]Train Iter: 2092/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9836. T_Loss: 4.6841. Mask: 0.9181. :  92%|█████████▏| 92/100 [00:22<00:01,  7.03it/s]Train Iter: 2093/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9840. T_Loss: 4.6856. Mask: 0.9177. :  92%|█████████▏| 92/100 [00:22<00:01,  7.03it/s]Train Iter: 2093/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9840. T_Loss: 4.6856. Mask: 0.9177. :  93%|█████████▎| 93/100 [00:22<00:00,  7.30it/s]Train Iter: 2094/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9865. T_Loss: 4.6980. Mask: 0.9182. :  93%|█████████▎| 93/100 [00:22<00:00,  7.30it/s]Train Iter: 2094/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9865. T_Loss: 4.6980. Mask: 0.9182. :  94%|█████████▍| 94/100 [00:22<00:00,  7.58it/s]Train Iter: 2095/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9872. T_Loss: 4.6949. Mask: 0.9171. :  94%|█████████▍| 94/100 [00:22<00:00,  7.58it/s]Train Iter: 2095/5000. LR: 0.0392. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9872. T_Loss: 4.6949. Mask: 0.9171. :  95%|█████████▌| 95/100 [00:22<00:00,  5.53it/s]Train Iter: 2096/5000. LR: 0.0391. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9867. T_Loss: 4.6909. Mask: 0.9163. :  95%|█████████▌| 95/100 [00:22<00:00,  5.53it/s]Train Iter: 2096/5000. LR: 0.0391. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9867. T_Loss: 4.6909. Mask: 0.9163. :  96%|█████████▌| 96/100 [00:22<00:00,  6.02it/s]Train Iter: 2097/5000. LR: 0.0391. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9868. T_Loss: 4.6969. Mask: 0.9162. :  96%|█████████▌| 96/100 [00:22<00:00,  6.02it/s]Train Iter: 2097/5000. LR: 0.0391. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9868. T_Loss: 4.6969. Mask: 0.9162. :  97%|█████████▋| 97/100 [00:22<00:00,  6.53it/s]Train Iter: 2098/5000. LR: 0.0391. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9869. T_Loss: 4.7056. Mask: 0.9171. :  97%|█████████▋| 97/100 [00:23<00:00,  6.53it/s]Train Iter: 2098/5000. LR: 0.0391. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9869. T_Loss: 4.7056. Mask: 0.9171. :  98%|█████████▊| 98/100 [00:23<00:00,  6.95it/s]Train Iter: 2099/5000. LR: 0.0391. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9892. T_Loss: 4.7095. Mask: 0.9170. :  98%|█████████▊| 98/100 [00:23<00:00,  6.95it/s]Train Iter: 2099/5000. LR: 0.0391. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9892. T_Loss: 4.7095. Mask: 0.9170. :  99%|█████████▉| 99/100 [00:23<00:00,  4.71it/s]Train Iter: 2100/5000. LR: 0.0391. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9879. T_Loss: 4.6994. Mask: 0.9175. :  99%|█████████▉| 99/100 [00:23<00:00,  4.71it/s]Train Iter: 2100/5000. LR: 0.0391. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9879. T_Loss: 4.6994. Mask: 0.9175. : 100%|██████████| 100/100 [00:23<00:00,  5.26it/s]Train Iter: 2100/5000. LR: 0.0391. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9879. T_Loss: 4.6994. Mask: 0.9175. : 100%|██████████| 100/100 [00:23<00:00,  4.23it/s]
total : 5000  current step :  2076
total : 5000  current step :  2077
total : 5000  current step :  2078
total : 5000  current step :  2079
total : 5000  current step :  2080
total : 5000  current step :  2081
total : 5000  current step :  2082
total : 5000  current step :  2083
total : 5000  current step :  2084
total : 5000  current step :  2085
total : 5000  current step :  2086
total : 5000  current step :  2087
total : 5000  current step :  2088
total : 5000  current step :  2089
total : 5000  current step :  2090
total : 5000  current step :  2091
total : 5000  current step :  2092
total : 5000  current step :  2093
total : 5000  current step :  2094
total : 5000  current step :  2095
total : 5000  current step :  2096
total : 5000  current step :  2097
total : 5000  current step :  2098
total : 5000  current step :  2099
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 1.0922. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 1.0922. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 1.0611. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 1.0192. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.0296. top1: 78.91. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 1.0077. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 1.0086. top1: 80.73. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.0267. top1: 80.36. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.0358. top1: 78.52. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.0261. top1: 79.17. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.0363. top1: 78.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.0363. top1: 78.75. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.61it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.0176. top1: 79.83. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.61it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0189. top1: 79.17. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.61it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0109. top1: 79.57. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.61it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0098. top1: 79.46. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.61it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0038. top1: 80.21. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.61it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0064. top1: 80.08. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.61it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0064. top1: 80.08. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0009. top1: 80.33. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9995. top1: 80.21. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9991. top1: 80.10. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9976. top1: 80.47. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0056. top1: 80.21. top5: 99.85. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0010. top1: 80.68. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9946. top1: 81.39. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9912. top1: 81.64. top5: 99.87. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9881. top1: 81.88. top5: 99.88. :  25%|██▌       | 16/63 [00:01<00:03, 12.45it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9940. top1: 81.49. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 12.45it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9934. top1: 81.48. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 12.45it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9934. top1: 81.48. top5: 99.88. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9976. top1: 81.47. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9959. top1: 81.47. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9955. top1: 81.56. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9959. top1: 81.35. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0080. top1: 80.96. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0096. top1: 81.06. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0164. top1: 80.70. top5: 99.82. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0193. top1: 80.54. top5: 99.82. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0376. top1: 79.60. top5: 99.74. :  43%|████▎     | 27/63 [00:02<00:01, 24.23it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0376. top1: 79.60. top5: 99.74. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0390. top1: 79.56. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0410. top1: 79.36. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0525. top1: 78.93. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0566. top1: 78.67. top5: 99.53. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0587. top1: 78.81. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0662. top1: 78.35. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0686. top1: 78.20. top5: 99.56. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0681. top1: 78.34. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0668. top1: 78.47. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 33.81it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0668. top1: 78.47. top5: 99.58. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0697. top1: 78.33. top5: 99.59. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0733. top1: 78.12. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0738. top1: 78.12. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0776. top1: 78.12. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0797. top1: 78.00. top5: 99.50. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0888. top1: 77.51. top5: 99.45. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0901. top1: 77.52. top5: 99.46. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0963. top1: 77.30. top5: 99.35. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1004. top1: 77.03. top5: 99.36. :  71%|███████▏  | 45/63 [00:02<00:00, 41.94it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1004. top1: 77.03. top5: 99.36. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1020. top1: 76.99. top5: 99.38. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1021. top1: 77.01. top5: 99.39. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1077. top1: 76.70. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1104. top1: 76.51. top5: 99.41. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1146. top1: 76.32. top5: 99.42. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1123. top1: 76.46. top5: 99.43. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1170. top1: 76.23. top5: 99.44. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1239. top1: 75.76. top5: 99.45. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1240. top1: 75.80. top5: 99.45. :  86%|████████▌ | 54/63 [00:02<00:00, 50.32it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1240. top1: 75.80. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.91it/s]
total : 5000  current step :  2100
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2101/5000. LR: 0.0391. Data: 1.87s. Batch: 2.01s. S_Loss: 0.9611. T_Loss: 5.6164. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2101/5000. LR: 0.0391. Data: 1.87s. Batch: 2.01s. S_Loss: 0.9611. T_Loss: 5.6164. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:19,  2.02s/it]Train Iter: 2102/5000. LR: 0.0391. Data: 0.94s. Batch: 1.07s. S_Loss: 0.9428. T_Loss: 5.0025. Mask: 0.9531. :   1%|          | 1/100 [00:02<03:19,  2.02s/it]Train Iter: 2102/5000. LR: 0.0391. Data: 0.94s. Batch: 1.07s. S_Loss: 0.9428. T_Loss: 5.0025. Mask: 0.9531. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 2103/5000. LR: 0.0390. Data: 0.63s. Batch: 0.75s. S_Loss: 1.0017. T_Loss: 5.0186. Mask: 0.9479. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 2103/5000. LR: 0.0390. Data: 0.63s. Batch: 0.75s. S_Loss: 1.0017. T_Loss: 5.0186. Mask: 0.9479. :   3%|▎         | 3/100 [00:02<00:52,  1.84it/s]Train Iter: 2104/5000. LR: 0.0390. Data: 0.47s. Batch: 0.60s. S_Loss: 1.0108. T_Loss: 4.8690. Mask: 0.9375. :   3%|▎         | 3/100 [00:02<00:52,  1.84it/s]Train Iter: 2104/5000. LR: 0.0390. Data: 0.47s. Batch: 0.60s. S_Loss: 1.0108. T_Loss: 4.8690. Mask: 0.9375. :   4%|▍         | 4/100 [00:02<00:36,  2.62it/s]Train Iter: 2105/5000. LR: 0.0390. Data: 0.38s. Batch: 0.55s. S_Loss: 0.9955. T_Loss: 4.8383. Mask: 0.9375. :   4%|▍         | 4/100 [00:02<00:36,  2.62it/s]Train Iter: 2105/5000. LR: 0.0390. Data: 0.38s. Batch: 0.55s. S_Loss: 0.9955. T_Loss: 4.8383. Mask: 0.9375. :   5%|▌         | 5/100 [00:02<00:36,  2.61it/s]Train Iter: 2106/5000. LR: 0.0390. Data: 0.32s. Batch: 0.48s. S_Loss: 0.9863. T_Loss: 4.8878. Mask: 0.9427. :   5%|▌         | 5/100 [00:02<00:36,  2.61it/s]Train Iter: 2106/5000. LR: 0.0390. Data: 0.32s. Batch: 0.48s. S_Loss: 0.9863. T_Loss: 4.8878. Mask: 0.9427. :   6%|▌         | 6/100 [00:02<00:27,  3.43it/s]Train Iter: 2107/5000. LR: 0.0390. Data: 0.27s. Batch: 0.43s. S_Loss: 0.9760. T_Loss: 4.7472. Mask: 0.9375. :   6%|▌         | 6/100 [00:03<00:27,  3.43it/s]Train Iter: 2107/5000. LR: 0.0390. Data: 0.27s. Batch: 0.43s. S_Loss: 0.9760. T_Loss: 4.7472. Mask: 0.9375. :   7%|▋         | 7/100 [00:03<00:21,  4.27it/s]Train Iter: 2108/5000. LR: 0.0390. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9866. T_Loss: 4.6784. Mask: 0.9258. :   7%|▋         | 7/100 [00:03<00:21,  4.27it/s]Train Iter: 2108/5000. LR: 0.0390. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9866. T_Loss: 4.6784. Mask: 0.9258. :   8%|▊         | 8/100 [00:03<00:18,  5.06it/s]Train Iter: 2109/5000. LR: 0.0389. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9912. T_Loss: 4.6967. Mask: 0.9236. :   8%|▊         | 8/100 [00:03<00:18,  5.06it/s]Train Iter: 2109/5000. LR: 0.0389. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9912. T_Loss: 4.6967. Mask: 0.9236. :   9%|▉         | 9/100 [00:03<00:19,  4.64it/s]Train Iter: 2110/5000. LR: 0.0389. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9873. T_Loss: 4.6343. Mask: 0.9250. :   9%|▉         | 9/100 [00:03<00:19,  4.64it/s]Train Iter: 2110/5000. LR: 0.0389. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9873. T_Loss: 4.6343. Mask: 0.9250. :  10%|█         | 10/100 [00:03<00:16,  5.33it/s]Train Iter: 2111/5000. LR: 0.0389. Data: 0.17s. Batch: 0.33s. S_Loss: 1.0014. T_Loss: 4.6218. Mask: 0.9205. :  10%|█         | 10/100 [00:03<00:16,  5.33it/s]Train Iter: 2111/5000. LR: 0.0389. Data: 0.17s. Batch: 0.33s. S_Loss: 1.0014. T_Loss: 4.6218. Mask: 0.9205. :  11%|█         | 11/100 [00:03<00:15,  5.86it/s]Train Iter: 2112/5000. LR: 0.0389. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9997. T_Loss: 4.5508. Mask: 0.9141. :  11%|█         | 11/100 [00:03<00:15,  5.86it/s]Train Iter: 2112/5000. LR: 0.0389. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9997. T_Loss: 4.5508. Mask: 0.9141. :  12%|█▏        | 12/100 [00:03<00:13,  6.30it/s]Train Iter: 2113/5000. LR: 0.0389. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9964. T_Loss: 4.5643. Mask: 0.9087. :  12%|█▏        | 12/100 [00:03<00:13,  6.30it/s]Train Iter: 2113/5000. LR: 0.0389. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9964. T_Loss: 4.5643. Mask: 0.9087. :  13%|█▎        | 13/100 [00:03<00:12,  6.70it/s]Train Iter: 2114/5000. LR: 0.0389. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0015. T_Loss: 4.5412. Mask: 0.9062. :  13%|█▎        | 13/100 [00:04<00:12,  6.70it/s]Train Iter: 2114/5000. LR: 0.0389. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0015. T_Loss: 4.5412. Mask: 0.9062. :  14%|█▍        | 14/100 [00:04<00:12,  7.06it/s]Train Iter: 2115/5000. LR: 0.0389. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9968. T_Loss: 4.5098. Mask: 0.9042. :  14%|█▍        | 14/100 [00:04<00:12,  7.06it/s]Train Iter: 2115/5000. LR: 0.0389. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9968. T_Loss: 4.5098. Mask: 0.9042. :  15%|█▌        | 15/100 [00:04<00:16,  5.14it/s]Train Iter: 2116/5000. LR: 0.0388. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0003. T_Loss: 4.5019. Mask: 0.9043. :  15%|█▌        | 15/100 [00:04<00:16,  5.14it/s]Train Iter: 2116/5000. LR: 0.0388. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0003. T_Loss: 4.5019. Mask: 0.9043. :  16%|█▌        | 16/100 [00:04<00:14,  5.75it/s]Train Iter: 2117/5000. LR: 0.0388. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9951. T_Loss: 4.4560. Mask: 0.9007. :  16%|█▌        | 16/100 [00:04<00:14,  5.75it/s]Train Iter: 2117/5000. LR: 0.0388. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9951. T_Loss: 4.4560. Mask: 0.9007. :  17%|█▋        | 17/100 [00:04<00:12,  6.44it/s]Train Iter: 2118/5000. LR: 0.0388. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9899. T_Loss: 4.4715. Mask: 0.9062. :  17%|█▋        | 17/100 [00:04<00:12,  6.44it/s]Train Iter: 2118/5000. LR: 0.0388. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9899. T_Loss: 4.4715. Mask: 0.9062. :  18%|█▊        | 18/100 [00:04<00:11,  6.95it/s]Train Iter: 2119/5000. LR: 0.0388. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9851. T_Loss: 4.4975. Mask: 0.9079. :  18%|█▊        | 18/100 [00:05<00:11,  6.95it/s]Train Iter: 2119/5000. LR: 0.0388. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9851. T_Loss: 4.4975. Mask: 0.9079. :  19%|█▉        | 19/100 [00:05<00:17,  4.69it/s]Train Iter: 2120/5000. LR: 0.0388. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9914. T_Loss: 4.5202. Mask: 0.9031. :  19%|█▉        | 19/100 [00:05<00:17,  4.69it/s]Train Iter: 2120/5000. LR: 0.0388. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9914. T_Loss: 4.5202. Mask: 0.9031. :  20%|██        | 20/100 [00:05<00:14,  5.38it/s]Train Iter: 2121/5000. LR: 0.0388. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9858. T_Loss: 4.5305. Mask: 0.9033. :  20%|██        | 20/100 [00:05<00:14,  5.38it/s]Train Iter: 2121/5000. LR: 0.0388. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9858. T_Loss: 4.5305. Mask: 0.9033. :  21%|██        | 21/100 [00:05<00:13,  5.97it/s]Train Iter: 2122/5000. LR: 0.0387. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9825. T_Loss: 4.5275. Mask: 0.9020. :  21%|██        | 21/100 [00:05<00:13,  5.97it/s]Train Iter: 2122/5000. LR: 0.0387. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9825. T_Loss: 4.5275. Mask: 0.9020. :  22%|██▏       | 22/100 [00:05<00:11,  6.56it/s]Train Iter: 2123/5000. LR: 0.0387. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9848. T_Loss: 4.5549. Mask: 0.9035. :  22%|██▏       | 22/100 [00:05<00:11,  6.56it/s]Train Iter: 2123/5000. LR: 0.0387. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9848. T_Loss: 4.5549. Mask: 0.9035. :  23%|██▎       | 23/100 [00:05<00:11,  6.99it/s]Train Iter: 2124/5000. LR: 0.0387. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9806. T_Loss: 4.5397. Mask: 0.9023. :  23%|██▎       | 23/100 [00:05<00:11,  6.99it/s]Train Iter: 2124/5000. LR: 0.0387. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9806. T_Loss: 4.5397. Mask: 0.9023. :  24%|██▍       | 24/100 [00:05<00:10,  7.31it/s]Train Iter: 2125/5000. LR: 0.0387. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9805. T_Loss: 4.5299. Mask: 0.9012. :  24%|██▍       | 24/100 [00:05<00:10,  7.31it/s]Train Iter: 2125/5000. LR: 0.0387. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9805. T_Loss: 4.5299. Mask: 0.9012. :  25%|██▌       | 25/100 [00:05<00:09,  7.53it/s]total : 5000  current step :  2101
total : 5000  current step :  2102
total : 5000  current step :  2103
total : 5000  current step :  2104
total : 5000  current step :  2105
total : 5000  current step :  2106
total : 5000  current step :  2107
total : 5000  current step :  2108
total : 5000  current step :  2109
total : 5000  current step :  2110
total : 5000  current step :  2111
total : 5000  current step :  2112
total : 5000  current step :  2113
total : 5000  current step :  2114
total : 5000  current step :  2115
total : 5000  current step :  2116
total : 5000  current step :  2117
total : 5000  current step :  2118
total : 5000  current step :  2119
total : 5000  current step :  2120
total : 5000  current step :  2121
total : 5000  current step :  2122
total : 5000  current step :  2123
total : 5000  current step :  2124
total : 5000  current step :  2125
Train Iter: 2126/5000. LR: 0.0387. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9862. T_Loss: 4.5547. Mask: 0.9002. :  25%|██▌       | 25/100 [00:07<00:09,  7.53it/s]Train Iter: 2126/5000. LR: 0.0387. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9862. T_Loss: 4.5547. Mask: 0.9002. :  26%|██▌       | 26/100 [00:07<00:50,  1.47it/s]Train Iter: 2127/5000. LR: 0.0387. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9882. T_Loss: 4.5547. Mask: 0.8993. :  26%|██▌       | 26/100 [00:07<00:50,  1.47it/s]Train Iter: 2127/5000. LR: 0.0387. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9882. T_Loss: 4.5547. Mask: 0.8993. :  27%|██▋       | 27/100 [00:07<00:37,  1.97it/s]Train Iter: 2128/5000. LR: 0.0386. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9847. T_Loss: 4.5780. Mask: 0.9018. :  27%|██▋       | 27/100 [00:07<00:37,  1.97it/s]Train Iter: 2128/5000. LR: 0.0386. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9847. T_Loss: 4.5780. Mask: 0.9018. :  28%|██▊       | 28/100 [00:07<00:28,  2.53it/s]Train Iter: 2129/5000. LR: 0.0386. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9791. T_Loss: 4.5706. Mask: 0.9030. :  28%|██▊       | 28/100 [00:08<00:28,  2.53it/s]Train Iter: 2129/5000. LR: 0.0386. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9791. T_Loss: 4.5706. Mask: 0.9030. :  29%|██▉       | 29/100 [00:08<00:21,  3.23it/s]Train Iter: 2130/5000. LR: 0.0386. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9847. T_Loss: 4.5948. Mask: 0.9031. :  29%|██▉       | 29/100 [00:08<00:21,  3.23it/s]Train Iter: 2130/5000. LR: 0.0386. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9847. T_Loss: 4.5948. Mask: 0.9031. :  30%|███       | 30/100 [00:08<00:18,  3.84it/s]Train Iter: 2131/5000. LR: 0.0386. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9854. T_Loss: 4.5721. Mask: 0.9002. :  30%|███       | 30/100 [00:08<00:18,  3.84it/s]Train Iter: 2132/5000. LR: 0.0386. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9830. T_Loss: 4.5702. Mask: 0.9014. :  31%|███       | 31/100 [00:08<00:17,  3.84it/s]Train Iter: 2132/5000. LR: 0.0386. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9830. T_Loss: 4.5702. Mask: 0.9014. :  32%|███▏      | 32/100 [00:08<00:12,  5.35it/s]Train Iter: 2133/5000. LR: 0.0386. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9837. T_Loss: 4.5480. Mask: 0.9006. :  32%|███▏      | 32/100 [00:08<00:12,  5.35it/s]Train Iter: 2133/5000. LR: 0.0386. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9837. T_Loss: 4.5480. Mask: 0.9006. :  33%|███▎      | 33/100 [00:08<00:11,  5.80it/s]Train Iter: 2134/5000. LR: 0.0386. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9842. T_Loss: 4.5549. Mask: 0.8989. :  33%|███▎      | 33/100 [00:08<00:11,  5.80it/s]Train Iter: 2134/5000. LR: 0.0386. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9842. T_Loss: 4.5549. Mask: 0.8989. :  34%|███▍      | 34/100 [00:08<00:10,  6.14it/s]Train Iter: 2135/5000. LR: 0.0385. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9835. T_Loss: 4.5531. Mask: 0.8973. :  34%|███▍      | 34/100 [00:09<00:10,  6.14it/s]Train Iter: 2135/5000. LR: 0.0385. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9835. T_Loss: 4.5531. Mask: 0.8973. :  35%|███▌      | 35/100 [00:09<00:13,  4.96it/s]Train Iter: 2136/5000. LR: 0.0385. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9808. T_Loss: 4.5491. Mask: 0.8967. :  35%|███▌      | 35/100 [00:09<00:13,  4.96it/s]Train Iter: 2136/5000. LR: 0.0385. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9808. T_Loss: 4.5491. Mask: 0.8967. :  36%|███▌      | 36/100 [00:09<00:11,  5.45it/s]Train Iter: 2137/5000. LR: 0.0385. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9813. T_Loss: 4.5492. Mask: 0.8961. :  36%|███▌      | 36/100 [00:09<00:11,  5.45it/s]Train Iter: 2137/5000. LR: 0.0385. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9813. T_Loss: 4.5492. Mask: 0.8961. :  37%|███▋      | 37/100 [00:09<00:10,  6.00it/s]Train Iter: 2138/5000. LR: 0.0385. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9837. T_Loss: 4.5662. Mask: 0.8972. :  37%|███▋      | 37/100 [00:09<00:10,  6.00it/s]Train Iter: 2138/5000. LR: 0.0385. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9837. T_Loss: 4.5662. Mask: 0.8972. :  38%|███▊      | 38/100 [00:09<00:09,  6.51it/s]Train Iter: 2139/5000. LR: 0.0385. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9832. T_Loss: 4.5766. Mask: 0.8974. :  38%|███▊      | 38/100 [00:09<00:09,  6.51it/s]Train Iter: 2139/5000. LR: 0.0385. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9832. T_Loss: 4.5766. Mask: 0.8974. :  39%|███▉      | 39/100 [00:09<00:11,  5.23it/s]Train Iter: 2140/5000. LR: 0.0385. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9828. T_Loss: 4.5563. Mask: 0.8945. :  39%|███▉      | 39/100 [00:09<00:11,  5.23it/s]Train Iter: 2140/5000. LR: 0.0385. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9828. T_Loss: 4.5563. Mask: 0.8945. :  40%|████      | 40/100 [00:09<00:10,  5.82it/s]Train Iter: 2141/5000. LR: 0.0384. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9819. T_Loss: 4.5683. Mask: 0.8963. :  40%|████      | 40/100 [00:09<00:10,  5.82it/s]Train Iter: 2141/5000. LR: 0.0384. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9819. T_Loss: 4.5683. Mask: 0.8963. :  41%|████      | 41/100 [00:09<00:09,  6.14it/s]Train Iter: 2142/5000. LR: 0.0384. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9810. T_Loss: 4.5560. Mask: 0.8958. :  41%|████      | 41/100 [00:10<00:09,  6.14it/s]Train Iter: 2142/5000. LR: 0.0384. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9810. T_Loss: 4.5560. Mask: 0.8958. :  42%|████▏     | 42/100 [00:10<00:08,  6.71it/s]Train Iter: 2143/5000. LR: 0.0384. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9777. T_Loss: 4.5344. Mask: 0.8968. :  42%|████▏     | 42/100 [00:10<00:08,  6.71it/s]Train Iter: 2143/5000. LR: 0.0384. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9777. T_Loss: 4.5344. Mask: 0.8968. :  43%|████▎     | 43/100 [00:10<00:07,  7.18it/s]Train Iter: 2144/5000. LR: 0.0384. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9775. T_Loss: 4.5389. Mask: 0.8984. :  43%|████▎     | 43/100 [00:10<00:07,  7.18it/s]Train Iter: 2144/5000. LR: 0.0384. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9775. T_Loss: 4.5389. Mask: 0.8984. :  44%|████▍     | 44/100 [00:10<00:07,  7.46it/s]Train Iter: 2145/5000. LR: 0.0384. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9780. T_Loss: 4.5227. Mask: 0.8972. :  44%|████▍     | 44/100 [00:10<00:07,  7.46it/s]Train Iter: 2145/5000. LR: 0.0384. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9780. T_Loss: 4.5227. Mask: 0.8972. :  45%|████▌     | 45/100 [00:10<00:07,  7.53it/s]Train Iter: 2146/5000. LR: 0.0384. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9817. T_Loss: 4.5237. Mask: 0.8954. :  45%|████▌     | 45/100 [00:10<00:07,  7.53it/s]Train Iter: 2146/5000. LR: 0.0384. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9817. T_Loss: 4.5237. Mask: 0.8954. :  46%|████▌     | 46/100 [00:10<00:07,  7.67it/s]Train Iter: 2147/5000. LR: 0.0383. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9839. T_Loss: 4.5095. Mask: 0.8943. :  46%|████▌     | 46/100 [00:10<00:07,  7.67it/s]Train Iter: 2147/5000. LR: 0.0383. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9839. T_Loss: 4.5095. Mask: 0.8943. :  47%|████▋     | 47/100 [00:10<00:06,  7.83it/s]Train Iter: 2148/5000. LR: 0.0383. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9821. T_Loss: 4.5108. Mask: 0.8965. :  47%|████▋     | 47/100 [00:10<00:06,  7.83it/s]Train Iter: 2148/5000. LR: 0.0383. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9821. T_Loss: 4.5108. Mask: 0.8965. :  48%|████▊     | 48/100 [00:10<00:06,  7.73it/s]Train Iter: 2149/5000. LR: 0.0383. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9834. T_Loss: 4.5155. Mask: 0.8967. :  48%|████▊     | 48/100 [00:11<00:06,  7.73it/s]Train Iter: 2149/5000. LR: 0.0383. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9834. T_Loss: 4.5155. Mask: 0.8967. :  49%|████▉     | 49/100 [00:11<00:09,  5.49it/s]Train Iter: 2150/5000. LR: 0.0383. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9837. T_Loss: 4.5253. Mask: 0.8962. :  49%|████▉     | 49/100 [00:11<00:09,  5.49it/s]Train Iter: 2150/5000. LR: 0.0383. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9837. T_Loss: 4.5253. Mask: 0.8962. :  50%|█████     | 50/100 [00:11<00:08,  6.13it/s]total : 5000  current step :  2126
total : 5000  current step :  2127
total : 5000  current step :  2128
total : 5000  current step :  2129
total : 5000  current step :  2130
total : 5000  current step :  2131
total : 5000  current step :  2132
total : 5000  current step :  2133
total : 5000  current step :  2134
total : 5000  current step :  2135
total : 5000  current step :  2136
total : 5000  current step :  2137
total : 5000  current step :  2138
total : 5000  current step :  2139
total : 5000  current step :  2140
total : 5000  current step :  2141
total : 5000  current step :  2142
total : 5000  current step :  2143
total : 5000  current step :  2144
total : 5000  current step :  2145
total : 5000  current step :  2146
total : 5000  current step :  2147
total : 5000  current step :  2148
total : 5000  current step :  2149
total : 5000  current step :  2150
Train Iter: 2151/5000. LR: 0.0383. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9830. T_Loss: 4.5169. Mask: 0.8952. :  50%|█████     | 50/100 [00:13<00:08,  6.13it/s]Train Iter: 2151/5000. LR: 0.0383. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9830. T_Loss: 4.5169. Mask: 0.8952. :  51%|█████     | 51/100 [00:13<00:34,  1.40it/s]Train Iter: 2152/5000. LR: 0.0383. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9824. T_Loss: 4.4905. Mask: 0.8954. :  51%|█████     | 51/100 [00:13<00:34,  1.40it/s]Train Iter: 2152/5000. LR: 0.0383. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9824. T_Loss: 4.4905. Mask: 0.8954. :  52%|█████▏    | 52/100 [00:13<00:26,  1.85it/s]Train Iter: 2153/5000. LR: 0.0383. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9831. T_Loss: 4.4904. Mask: 0.8950. :  52%|█████▏    | 52/100 [00:13<00:26,  1.85it/s]Train Iter: 2153/5000. LR: 0.0383. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9831. T_Loss: 4.4904. Mask: 0.8950. :  53%|█████▎    | 53/100 [00:13<00:19,  2.43it/s]Train Iter: 2154/5000. LR: 0.0382. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9812. T_Loss: 4.4903. Mask: 0.8970. :  53%|█████▎    | 53/100 [00:13<00:19,  2.43it/s]Train Iter: 2154/5000. LR: 0.0382. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9812. T_Loss: 4.4903. Mask: 0.8970. :  54%|█████▍    | 54/100 [00:13<00:15,  3.06it/s]Train Iter: 2155/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9847. T_Loss: 4.5071. Mask: 0.8977. :  54%|█████▍    | 54/100 [00:13<00:15,  3.06it/s]Train Iter: 2155/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9847. T_Loss: 4.5071. Mask: 0.8977. :  55%|█████▌    | 55/100 [00:13<00:14,  3.14it/s]Train Iter: 2156/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9832. T_Loss: 4.5011. Mask: 0.8979. :  55%|█████▌    | 55/100 [00:14<00:14,  3.14it/s]Train Iter: 2156/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9832. T_Loss: 4.5011. Mask: 0.8979. :  56%|█████▌    | 56/100 [00:14<00:11,  3.88it/s]Train Iter: 2157/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.4924. Mask: 0.8986. :  56%|█████▌    | 56/100 [00:14<00:11,  3.88it/s]Train Iter: 2157/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.4924. Mask: 0.8986. :  57%|█████▋    | 57/100 [00:14<00:09,  4.58it/s]Train Iter: 2158/5000. LR: 0.0382. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9817. T_Loss: 4.4936. Mask: 0.8992. :  57%|█████▋    | 57/100 [00:14<00:09,  4.58it/s]Train Iter: 2158/5000. LR: 0.0382. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9817. T_Loss: 4.4936. Mask: 0.8992. :  58%|█████▊    | 58/100 [00:14<00:07,  5.25it/s]Train Iter: 2159/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9828. T_Loss: 4.4869. Mask: 0.8988. :  58%|█████▊    | 58/100 [00:14<00:07,  5.25it/s]Train Iter: 2159/5000. LR: 0.0382. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9828. T_Loss: 4.4869. Mask: 0.8988. :  59%|█████▉    | 59/100 [00:14<00:09,  4.20it/s]Train Iter: 2160/5000. LR: 0.0381. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9832. T_Loss: 4.4906. Mask: 0.8995. :  59%|█████▉    | 59/100 [00:14<00:09,  4.20it/s]Train Iter: 2160/5000. LR: 0.0381. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9832. T_Loss: 4.4906. Mask: 0.8995. :  60%|██████    | 60/100 [00:14<00:08,  4.88it/s]Train Iter: 2161/5000. LR: 0.0381. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9815. T_Loss: 4.4881. Mask: 0.9006. :  60%|██████    | 60/100 [00:14<00:08,  4.88it/s]Train Iter: 2161/5000. LR: 0.0381. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9815. T_Loss: 4.4881. Mask: 0.9006. :  61%|██████    | 61/100 [00:14<00:07,  5.44it/s]Train Iter: 2162/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9817. T_Loss: 4.4933. Mask: 0.9002. :  61%|██████    | 61/100 [00:15<00:07,  5.44it/s]Train Iter: 2162/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9817. T_Loss: 4.4933. Mask: 0.9002. :  62%|██████▏   | 62/100 [00:15<00:06,  5.98it/s]Train Iter: 2163/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9822. T_Loss: 4.5009. Mask: 0.9008. :  62%|██████▏   | 62/100 [00:15<00:06,  5.98it/s]Train Iter: 2163/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9822. T_Loss: 4.5009. Mask: 0.9008. :  63%|██████▎   | 63/100 [00:15<00:05,  6.41it/s]Train Iter: 2164/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9827. T_Loss: 4.5081. Mask: 0.9009. :  63%|██████▎   | 63/100 [00:15<00:05,  6.41it/s]Train Iter: 2164/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9827. T_Loss: 4.5081. Mask: 0.9009. :  64%|██████▍   | 64/100 [00:15<00:05,  6.93it/s]Train Iter: 2165/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9864. T_Loss: 4.5281. Mask: 0.9014. :  64%|██████▍   | 64/100 [00:15<00:05,  6.93it/s]Train Iter: 2165/5000. LR: 0.0381. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9864. T_Loss: 4.5281. Mask: 0.9014. :  65%|██████▌   | 65/100 [00:15<00:06,  5.09it/s]Train Iter: 2166/5000. LR: 0.0380. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9860. T_Loss: 4.5137. Mask: 0.9015. :  65%|██████▌   | 65/100 [00:15<00:06,  5.09it/s]Train Iter: 2166/5000. LR: 0.0380. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9860. T_Loss: 4.5137. Mask: 0.9015. :  66%|██████▌   | 66/100 [00:15<00:05,  5.70it/s]Train Iter: 2167/5000. LR: 0.0380. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9863. T_Loss: 4.5238. Mask: 0.9021. :  66%|██████▌   | 66/100 [00:15<00:05,  5.70it/s]Train Iter: 2167/5000. LR: 0.0380. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9863. T_Loss: 4.5238. Mask: 0.9021. :  67%|██████▋   | 67/100 [00:15<00:05,  6.28it/s]Train Iter: 2168/5000. LR: 0.0380. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9864. T_Loss: 4.5164. Mask: 0.9003. :  67%|██████▋   | 67/100 [00:15<00:05,  6.28it/s]Train Iter: 2168/5000. LR: 0.0380. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9864. T_Loss: 4.5164. Mask: 0.9003. :  68%|██████▊   | 68/100 [00:15<00:04,  6.75it/s]Train Iter: 2169/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9877. T_Loss: 4.5252. Mask: 0.9013. :  68%|██████▊   | 68/100 [00:16<00:04,  6.75it/s]Train Iter: 2169/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9877. T_Loss: 4.5252. Mask: 0.9013. :  69%|██████▉   | 69/100 [00:16<00:05,  5.96it/s]Train Iter: 2170/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9878. T_Loss: 4.5332. Mask: 0.9022. :  69%|██████▉   | 69/100 [00:16<00:05,  5.96it/s]Train Iter: 2170/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9878. T_Loss: 4.5332. Mask: 0.9022. :  70%|███████   | 70/100 [00:16<00:04,  6.50it/s]Train Iter: 2171/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9866. T_Loss: 4.5431. Mask: 0.9032. :  70%|███████   | 70/100 [00:16<00:04,  6.50it/s]Train Iter: 2171/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9866. T_Loss: 4.5431. Mask: 0.9032. :  71%|███████   | 71/100 [00:16<00:04,  6.90it/s]Train Iter: 2172/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9863. T_Loss: 4.5432. Mask: 0.9041. :  71%|███████   | 71/100 [00:16<00:04,  6.90it/s]Train Iter: 2172/5000. LR: 0.0380. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9863. T_Loss: 4.5432. Mask: 0.9041. :  72%|███████▏  | 72/100 [00:16<00:03,  7.48it/s]Train Iter: 2173/5000. LR: 0.0379. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9851. T_Loss: 4.5407. Mask: 0.9045. :  72%|███████▏  | 72/100 [00:16<00:03,  7.48it/s]Train Iter: 2173/5000. LR: 0.0379. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9851. T_Loss: 4.5407. Mask: 0.9045. :  73%|███████▎  | 73/100 [00:16<00:03,  7.64it/s]Train Iter: 2174/5000. LR: 0.0379. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9841. T_Loss: 4.5415. Mask: 0.9041. :  73%|███████▎  | 73/100 [00:16<00:03,  7.64it/s]Train Iter: 2174/5000. LR: 0.0379. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9841. T_Loss: 4.5415. Mask: 0.9041. :  74%|███████▍  | 74/100 [00:16<00:03,  7.77it/s]Train Iter: 2175/5000. LR: 0.0379. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9851. T_Loss: 4.5359. Mask: 0.9025. :  74%|███████▍  | 74/100 [00:17<00:03,  7.77it/s]Train Iter: 2175/5000. LR: 0.0379. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9851. T_Loss: 4.5359. Mask: 0.9025. :  75%|███████▌  | 75/100 [00:17<00:04,  5.27it/s]total : 5000  current step :  2151
total : 5000  current step :  2152
total : 5000  current step :  2153
total : 5000  current step :  2154
total : 5000  current step :  2155
total : 5000  current step :  2156
total : 5000  current step :  2157
total : 5000  current step :  2158
total : 5000  current step :  2159
total : 5000  current step :  2160
total : 5000  current step :  2161
total : 5000  current step :  2162
total : 5000  current step :  2163
total : 5000  current step :  2164
total : 5000  current step :  2165
total : 5000  current step :  2166
total : 5000  current step :  2167
total : 5000  current step :  2168
total : 5000  current step :  2169
total : 5000  current step :  2170
total : 5000  current step :  2171
total : 5000  current step :  2172
total : 5000  current step :  2173
total : 5000  current step :  2174
total : 5000  current step :  2175
Train Iter: 2176/5000. LR: 0.0379. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9869. T_Loss: 4.5357. Mask: 0.9025. :  75%|███████▌  | 75/100 [00:19<00:04,  5.27it/s]Train Iter: 2176/5000. LR: 0.0379. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9869. T_Loss: 4.5357. Mask: 0.9025. :  76%|███████▌  | 76/100 [00:19<00:18,  1.28it/s]Train Iter: 2177/5000. LR: 0.0379. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9857. T_Loss: 4.5359. Mask: 0.9034. :  76%|███████▌  | 76/100 [00:19<00:18,  1.28it/s]Train Iter: 2177/5000. LR: 0.0379. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9857. T_Loss: 4.5359. Mask: 0.9034. :  77%|███████▋  | 77/100 [00:19<00:13,  1.69it/s]Train Iter: 2178/5000. LR: 0.0379. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9863. T_Loss: 4.5474. Mask: 0.9042. :  77%|███████▋  | 77/100 [00:19<00:13,  1.69it/s]Train Iter: 2178/5000. LR: 0.0379. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9863. T_Loss: 4.5474. Mask: 0.9042. :  78%|███████▊  | 78/100 [00:19<00:10,  2.19it/s]Train Iter: 2179/5000. LR: 0.0378. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9857. T_Loss: 4.5483. Mask: 0.9043. :  78%|███████▊  | 78/100 [00:19<00:10,  2.19it/s]Train Iter: 2179/5000. LR: 0.0378. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9857. T_Loss: 4.5483. Mask: 0.9043. :  79%|███████▉  | 79/100 [00:19<00:07,  2.84it/s]Train Iter: 2180/5000. LR: 0.0378. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9854. T_Loss: 4.5398. Mask: 0.9039. :  79%|███████▉  | 79/100 [00:19<00:07,  2.84it/s]Train Iter: 2180/5000. LR: 0.0378. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9854. T_Loss: 4.5398. Mask: 0.9039. :  80%|████████  | 80/100 [00:19<00:05,  3.54it/s]Train Iter: 2181/5000. LR: 0.0378. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9850. T_Loss: 4.5326. Mask: 0.9043. :  80%|████████  | 80/100 [00:19<00:05,  3.54it/s]Train Iter: 2181/5000. LR: 0.0378. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9850. T_Loss: 4.5326. Mask: 0.9043. :  81%|████████  | 81/100 [00:19<00:04,  4.24it/s]Train Iter: 2182/5000. LR: 0.0378. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9854. T_Loss: 4.5451. Mask: 0.9055. :  81%|████████  | 81/100 [00:20<00:04,  4.24it/s]Train Iter: 2182/5000. LR: 0.0378. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9854. T_Loss: 4.5451. Mask: 0.9055. :  82%|████████▏ | 82/100 [00:20<00:03,  4.84it/s]Train Iter: 2183/5000. LR: 0.0378. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9853. T_Loss: 4.5326. Mask: 0.9051. :  82%|████████▏ | 82/100 [00:20<00:03,  4.84it/s]Train Iter: 2183/5000. LR: 0.0378. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9853. T_Loss: 4.5326. Mask: 0.9051. :  83%|████████▎ | 83/100 [00:20<00:03,  5.37it/s]Train Iter: 2184/5000. LR: 0.0378. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9846. T_Loss: 4.5355. Mask: 0.9059. :  83%|████████▎ | 83/100 [00:20<00:03,  5.37it/s]Train Iter: 2184/5000. LR: 0.0378. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9846. T_Loss: 4.5355. Mask: 0.9059. :  84%|████████▍ | 84/100 [00:20<00:02,  5.94it/s]Train Iter: 2185/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9850. T_Loss: 4.5338. Mask: 0.9062. :  84%|████████▍ | 84/100 [00:20<00:02,  5.94it/s]Train Iter: 2185/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9850. T_Loss: 4.5338. Mask: 0.9062. :  85%|████████▌ | 85/100 [00:20<00:03,  4.55it/s]Train Iter: 2186/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9863. T_Loss: 4.5372. Mask: 0.9062. :  85%|████████▌ | 85/100 [00:20<00:03,  4.55it/s]Train Iter: 2186/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9863. T_Loss: 4.5372. Mask: 0.9062. :  86%|████████▌ | 86/100 [00:20<00:02,  5.31it/s]Train Iter: 2187/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9864. T_Loss: 4.5358. Mask: 0.9062. :  86%|████████▌ | 86/100 [00:20<00:02,  5.31it/s]Train Iter: 2187/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9864. T_Loss: 4.5358. Mask: 0.9062. :  87%|████████▋ | 87/100 [00:20<00:02,  5.82it/s]Train Iter: 2188/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9853. T_Loss: 4.5240. Mask: 0.9070. :  87%|████████▋ | 87/100 [00:21<00:02,  5.82it/s]Train Iter: 2188/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9853. T_Loss: 4.5240. Mask: 0.9070. :  88%|████████▊ | 88/100 [00:21<00:01,  6.15it/s]Train Iter: 2189/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9845. T_Loss: 4.5244. Mask: 0.9073. :  88%|████████▊ | 88/100 [00:21<00:01,  6.15it/s]Train Iter: 2189/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9845. T_Loss: 4.5244. Mask: 0.9073. :  89%|████████▉ | 89/100 [00:21<00:02,  5.09it/s]Train Iter: 2190/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9847. T_Loss: 4.5187. Mask: 0.9073. :  89%|████████▉ | 89/100 [00:21<00:02,  5.09it/s]Train Iter: 2190/5000. LR: 0.0377. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9847. T_Loss: 4.5187. Mask: 0.9073. :  90%|█████████ | 90/100 [00:21<00:01,  5.86it/s]total : 5000  current step :  2176
total : 5000  current step :  2177
total : 5000  current step :  2178
total : 5000  current step :  2179
total : 5000  current step :  2180
total : 5000  current step :  2181
total : 5000  current step :  2182
total : 5000  current step :  2183
total : 5000  current step :  2184
total : 5000  current step :  2185
total : 5000  current step :  2186
total : 5000  current step :  2187
total : 5000  current step :  2188
total : 5000  current step :  2189
total : 5000  current step :  2190
Train Iter: 2191/5000. LR: 0.0376. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9845. T_Loss: 4.5128. Mask: 0.9076. :  90%|█████████ | 90/100 [00:23<00:01,  5.86it/s]Train Iter: 2191/5000. LR: 0.0376. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9845. T_Loss: 4.5128. Mask: 0.9076. :  91%|█████████ | 91/100 [00:23<00:06,  1.33it/s]Train Iter: 2192/5000. LR: 0.0376. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9848. T_Loss: 4.5109. Mask: 0.9083. :  91%|█████████ | 91/100 [00:23<00:06,  1.33it/s]Train Iter: 2192/5000. LR: 0.0376. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9848. T_Loss: 4.5109. Mask: 0.9083. :  92%|█████████▏| 92/100 [00:23<00:04,  1.77it/s]Train Iter: 2193/5000. LR: 0.0376. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9841. T_Loss: 4.5038. Mask: 0.9079. :  92%|█████████▏| 92/100 [00:23<00:04,  1.77it/s]Train Iter: 2193/5000. LR: 0.0376. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9841. T_Loss: 4.5038. Mask: 0.9079. :  93%|█████████▎| 93/100 [00:23<00:03,  2.30it/s]Train Iter: 2194/5000. LR: 0.0376. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9837. T_Loss: 4.4957. Mask: 0.9076. :  93%|█████████▎| 93/100 [00:23<00:03,  2.30it/s]Train Iter: 2194/5000. LR: 0.0376. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9837. T_Loss: 4.4957. Mask: 0.9076. :  94%|█████████▍| 94/100 [00:23<00:02,  2.93it/s]Train Iter: 2195/5000. LR: 0.0376. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9832. T_Loss: 4.4894. Mask: 0.9072. :  94%|█████████▍| 94/100 [00:24<00:02,  2.93it/s]Train Iter: 2195/5000. LR: 0.0376. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9832. T_Loss: 4.4894. Mask: 0.9072. :  95%|█████████▌| 95/100 [00:24<00:01,  3.61it/s]Train Iter: 2196/5000. LR: 0.0376. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.4773. Mask: 0.9076. :  95%|█████████▌| 95/100 [00:24<00:01,  3.61it/s]Train Iter: 2196/5000. LR: 0.0376. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.4773. Mask: 0.9076. :  96%|█████████▌| 96/100 [00:24<00:00,  4.32it/s]Train Iter: 2197/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9814. T_Loss: 4.4724. Mask: 0.9075. :  96%|█████████▌| 96/100 [00:24<00:00,  4.32it/s]Train Iter: 2197/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9814. T_Loss: 4.4724. Mask: 0.9075. :  97%|█████████▋| 97/100 [00:24<00:00,  4.97it/s]Train Iter: 2198/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9812. T_Loss: 4.4693. Mask: 0.9082. :  97%|█████████▋| 97/100 [00:24<00:00,  4.97it/s]Train Iter: 2198/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9812. T_Loss: 4.4693. Mask: 0.9082. :  98%|█████████▊| 98/100 [00:24<00:00,  5.58it/s]Train Iter: 2199/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.4670. Mask: 0.9088. :  98%|█████████▊| 98/100 [00:24<00:00,  5.58it/s]Train Iter: 2199/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.4670. Mask: 0.9088. :  99%|█████████▉| 99/100 [00:24<00:00,  4.23it/s]Train Iter: 2200/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.4694. Mask: 0.9094. :  99%|█████████▉| 99/100 [00:24<00:00,  4.23it/s]Train Iter: 2200/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.4694. Mask: 0.9094. : 100%|██████████| 100/100 [00:24<00:00,  5.00it/s]Train Iter: 2200/5000. LR: 0.0375. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9816. T_Loss: 4.4694. Mask: 0.9094. : 100%|██████████| 100/100 [00:24<00:00,  4.01it/s]
total : 5000  current step :  2191
total : 5000  current step :  2192
total : 5000  current step :  2193
total : 5000  current step :  2194
total : 5000  current step :  2195
total : 5000  current step :  2196
total : 5000  current step :  2197
total : 5000  current step :  2198
total : 5000  current step :  2199
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 1.0314. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 1.0314. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 1.0134. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.9721. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.9820. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 0.9644. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9647. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9647. top1: 83.33. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:14,  4.07it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9815. top1: 82.59. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:14,  4.07it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9883. top1: 80.86. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:14,  4.07it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9802. top1: 81.60. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:14,  4.07it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9904. top1: 81.25. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:14,  4.07it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9745. top1: 82.10. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:14,  4.07it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9737. top1: 82.29. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:14,  4.07it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9677. top1: 82.69. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:14,  4.07it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9677. top1: 82.69. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.06it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9654. top1: 82.59. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.06it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9610. top1: 83.12. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.06it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9640. top1: 82.81. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.06it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9590. top1: 83.09. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.06it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9581. top1: 83.16. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.06it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9581. top1: 83.16. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9578. top1: 83.06. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9562. top1: 83.44. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9636. top1: 83.04. top5: 99.85. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9595. top1: 83.52. top5: 99.86. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9543. top1: 84.10. top5: 99.86. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9511. top1: 84.38. top5: 99.87. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9481. top1: 84.62. top5: 99.88. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9539. top1: 84.13. top5: 99.88. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9536. top1: 83.91. top5: 99.88. :  29%|██▊       | 18/63 [00:02<00:03, 14.58it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9536. top1: 83.91. top5: 99.88. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9566. top1: 83.82. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9550. top1: 83.94. top5: 99.89. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9548. top1: 83.96. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9554. top1: 83.87. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9686. top1: 83.40. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9727. top1: 83.33. top5: 99.81. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9811. top1: 82.90. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9868. top1: 82.68. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0075. top1: 81.68. top5: 99.57. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0101. top1: 81.50. top5: 99.58. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0141. top1: 81.17. top5: 99.59. :  43%|████▎     | 27/63 [00:02<00:01, 24.95it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0141. top1: 81.17. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0276. top1: 80.69. top5: 99.44. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0338. top1: 80.39. top5: 99.38. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0375. top1: 80.34. top5: 99.31. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0476. top1: 79.84. top5: 99.33. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0516. top1: 79.58. top5: 99.35. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0523. top1: 79.69. top5: 99.36. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0527. top1: 79.65. top5: 99.38. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0576. top1: 79.28. top5: 99.39. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0626. top1: 79.06. top5: 99.34. :  60%|██████    | 38/63 [00:02<00:00, 38.36it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0626. top1: 79.06. top5: 99.34. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0641. top1: 79.04. top5: 99.35. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0693. top1: 79.02. top5: 99.30. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0720. top1: 78.88. top5: 99.31. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0824. top1: 78.19. top5: 99.26. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0849. top1: 78.19. top5: 99.22. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0926. top1: 77.95. top5: 99.12. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0981. top1: 77.60. top5: 99.13. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1005. top1: 77.56. top5: 99.15. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1015. top1: 77.46. top5: 99.16. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1081. top1: 77.08. top5: 99.18. :  75%|███████▍  | 47/63 [00:02<00:00, 47.32it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1081. top1: 77.08. top5: 99.18. :  90%|█████████ | 57/63 [00:02<00:00, 56.61it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1119. top1: 76.89. top5: 99.19. :  90%|█████████ | 57/63 [00:02<00:00, 56.61it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1166. top1: 76.69. top5: 99.21. :  90%|█████████ | 57/63 [00:02<00:00, 56.61it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1148. top1: 76.82. top5: 99.22. :  90%|█████████ | 57/63 [00:02<00:00, 56.61it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1203. top1: 76.49. top5: 99.23. :  90%|█████████ | 57/63 [00:02<00:00, 56.61it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1280. top1: 76.06. top5: 99.24. :  90%|█████████ | 57/63 [00:02<00:00, 56.61it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1283. top1: 76.10. top5: 99.25. :  90%|█████████ | 57/63 [00:02<00:00, 56.61it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1283. top1: 76.10. top5: 99.25. : 100%|██████████| 63/63 [00:02<00:00, 21.76it/s]
total : 5000  current step :  2200
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2201/5000. LR: 0.0375. Data: 2.03s. Batch: 2.13s. S_Loss: 0.9976. T_Loss: 3.1491. Mask: 0.8750. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2201/5000. LR: 0.0375. Data: 2.03s. Batch: 2.13s. S_Loss: 0.9976. T_Loss: 3.1491. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:31,  2.13s/it]Train Iter: 2202/5000. LR: 0.0375. Data: 1.02s. Batch: 1.13s. S_Loss: 1.0405. T_Loss: 3.9443. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:31,  2.13s/it]Train Iter: 2202/5000. LR: 0.0375. Data: 1.02s. Batch: 1.13s. S_Loss: 1.0405. T_Loss: 3.9443. Mask: 0.8750. :   2%|▏         | 2/100 [00:02<01:33,  1.04it/s]Train Iter: 2203/5000. LR: 0.0375. Data: 0.68s. Batch: 0.79s. S_Loss: 1.0223. T_Loss: 4.0279. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:33,  1.04it/s]Train Iter: 2203/5000. LR: 0.0375. Data: 0.68s. Batch: 0.79s. S_Loss: 1.0223. T_Loss: 4.0279. Mask: 0.9167. :   3%|▎         | 3/100 [00:02<00:54,  1.77it/s]Train Iter: 2204/5000. LR: 0.0374. Data: 0.51s. Batch: 0.62s. S_Loss: 0.9948. T_Loss: 4.1802. Mask: 0.9375. :   3%|▎         | 3/100 [00:02<00:54,  1.77it/s]Train Iter: 2204/5000. LR: 0.0374. Data: 0.51s. Batch: 0.62s. S_Loss: 0.9948. T_Loss: 4.1802. Mask: 0.9375. :   4%|▍         | 4/100 [00:02<00:36,  2.61it/s]Train Iter: 2205/5000. LR: 0.0374. Data: 0.41s. Batch: 0.53s. S_Loss: 1.0157. T_Loss: 4.4043. Mask: 0.9500. :   4%|▍         | 4/100 [00:02<00:36,  2.61it/s]Train Iter: 2205/5000. LR: 0.0374. Data: 0.41s. Batch: 0.53s. S_Loss: 1.0157. T_Loss: 4.4043. Mask: 0.9500. :   5%|▌         | 5/100 [00:02<00:30,  3.15it/s]Train Iter: 2206/5000. LR: 0.0374. Data: 0.34s. Batch: 0.46s. S_Loss: 1.0030. T_Loss: 4.3906. Mask: 0.9583. :   5%|▌         | 5/100 [00:02<00:30,  3.15it/s]Train Iter: 2207/5000. LR: 0.0374. Data: 0.30s. Batch: 0.41s. S_Loss: 1.0118. T_Loss: 4.4773. Mask: 0.9643. :   6%|▌         | 6/100 [00:02<00:29,  3.15it/s]Train Iter: 2207/5000. LR: 0.0374. Data: 0.30s. Batch: 0.41s. S_Loss: 1.0118. T_Loss: 4.4773. Mask: 0.9643. :   7%|▋         | 7/100 [00:02<00:19,  4.76it/s]Train Iter: 2208/5000. LR: 0.0374. Data: 0.26s. Batch: 0.37s. S_Loss: 1.0261. T_Loss: 4.6074. Mask: 0.9570. :   7%|▋         | 7/100 [00:02<00:19,  4.76it/s]Train Iter: 2209/5000. LR: 0.0374. Data: 0.23s. Batch: 0.37s. S_Loss: 1.0119. T_Loss: 4.6069. Mask: 0.9618. :   8%|▊         | 8/100 [00:03<00:19,  4.76it/s]Train Iter: 2209/5000. LR: 0.0374. Data: 0.23s. Batch: 0.37s. S_Loss: 1.0119. T_Loss: 4.6069. Mask: 0.9618. :   9%|▉         | 9/100 [00:03<00:19,  4.76it/s]Train Iter: 2210/5000. LR: 0.0373. Data: 0.21s. Batch: 0.34s. S_Loss: 1.0132. T_Loss: 4.5696. Mask: 0.9594. :   9%|▉         | 9/100 [00:03<00:19,  4.76it/s]Train Iter: 2210/5000. LR: 0.0373. Data: 0.21s. Batch: 0.34s. S_Loss: 1.0132. T_Loss: 4.5696. Mask: 0.9594. :  10%|█         | 10/100 [00:03<00:17,  5.22it/s]Train Iter: 2211/5000. LR: 0.0373. Data: 0.19s. Batch: 0.32s. S_Loss: 1.0020. T_Loss: 4.5786. Mask: 0.9574. :  10%|█         | 10/100 [00:03<00:17,  5.22it/s]Train Iter: 2211/5000. LR: 0.0373. Data: 0.19s. Batch: 0.32s. S_Loss: 1.0020. T_Loss: 4.5786. Mask: 0.9574. :  11%|█         | 11/100 [00:03<00:15,  5.70it/s]Train Iter: 2212/5000. LR: 0.0373. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0057. T_Loss: 4.5944. Mask: 0.9479. :  11%|█         | 11/100 [00:03<00:15,  5.70it/s]Train Iter: 2212/5000. LR: 0.0373. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0057. T_Loss: 4.5944. Mask: 0.9479. :  12%|█▏        | 12/100 [00:03<00:14,  6.13it/s]Train Iter: 2213/5000. LR: 0.0373. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9976. T_Loss: 4.6235. Mask: 0.9471. :  12%|█▏        | 12/100 [00:03<00:14,  6.13it/s]Train Iter: 2213/5000. LR: 0.0373. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9976. T_Loss: 4.6235. Mask: 0.9471. :  13%|█▎        | 13/100 [00:03<00:12,  6.71it/s]Train Iter: 2214/5000. LR: 0.0373. Data: 0.15s. Batch: 0.28s. S_Loss: 0.9986. T_Loss: 4.6411. Mask: 0.9442. :  13%|█▎        | 13/100 [00:03<00:12,  6.71it/s]Train Iter: 2215/5000. LR: 0.0373. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0103. T_Loss: 4.6780. Mask: 0.9458. :  14%|█▍        | 14/100 [00:04<00:12,  6.71it/s]Train Iter: 2215/5000. LR: 0.0373. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0103. T_Loss: 4.6780. Mask: 0.9458. :  15%|█▌        | 15/100 [00:04<00:15,  5.64it/s]Train Iter: 2216/5000. LR: 0.0372. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0107. T_Loss: 4.6933. Mask: 0.9473. :  15%|█▌        | 15/100 [00:04<00:15,  5.64it/s]Train Iter: 2216/5000. LR: 0.0372. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0107. T_Loss: 4.6933. Mask: 0.9473. :  16%|█▌        | 16/100 [00:04<00:14,  5.88it/s]Train Iter: 2217/5000. LR: 0.0372. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0141. T_Loss: 4.7081. Mask: 0.9430. :  16%|█▌        | 16/100 [00:04<00:14,  5.88it/s]Train Iter: 2217/5000. LR: 0.0372. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0141. T_Loss: 4.7081. Mask: 0.9430. :  17%|█▋        | 17/100 [00:04<00:12,  6.52it/s]Train Iter: 2218/5000. LR: 0.0372. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0137. T_Loss: 4.7178. Mask: 0.9427. :  17%|█▋        | 17/100 [00:04<00:12,  6.52it/s]Train Iter: 2218/5000. LR: 0.0372. Data: 0.12s. Batch: 0.25s. S_Loss: 1.0137. T_Loss: 4.7178. Mask: 0.9427. :  18%|█▊        | 18/100 [00:04<00:11,  7.01it/s]Train Iter: 2219/5000. LR: 0.0372. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0257. T_Loss: 4.7336. Mask: 0.9391. :  18%|█▊        | 18/100 [00:04<00:11,  7.01it/s]Train Iter: 2219/5000. LR: 0.0372. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0257. T_Loss: 4.7336. Mask: 0.9391. :  19%|█▉        | 19/100 [00:04<00:13,  6.17it/s]Train Iter: 2220/5000. LR: 0.0372. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0236. T_Loss: 4.7043. Mask: 0.9375. :  19%|█▉        | 19/100 [00:04<00:13,  6.17it/s]Train Iter: 2220/5000. LR: 0.0372. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0236. T_Loss: 4.7043. Mask: 0.9375. :  20%|██        | 20/100 [00:04<00:12,  6.62it/s]Train Iter: 2221/5000. LR: 0.0372. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0249. T_Loss: 4.6968. Mask: 0.9360. :  20%|██        | 20/100 [00:05<00:12,  6.62it/s]Train Iter: 2221/5000. LR: 0.0372. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0249. T_Loss: 4.6968. Mask: 0.9360. :  21%|██        | 21/100 [00:05<00:11,  6.79it/s]Train Iter: 2222/5000. LR: 0.0371. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0226. T_Loss: 4.6604. Mask: 0.9332. :  21%|██        | 21/100 [00:05<00:11,  6.79it/s]Train Iter: 2222/5000. LR: 0.0371. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0226. T_Loss: 4.6604. Mask: 0.9332. :  22%|██▏       | 22/100 [00:05<00:11,  6.88it/s]Train Iter: 2223/5000. LR: 0.0371. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0262. T_Loss: 4.6536. Mask: 0.9334. :  22%|██▏       | 22/100 [00:05<00:11,  6.88it/s]Train Iter: 2223/5000. LR: 0.0371. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0262. T_Loss: 4.6536. Mask: 0.9334. :  23%|██▎       | 23/100 [00:05<00:10,  7.03it/s]Train Iter: 2224/5000. LR: 0.0371. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0266. T_Loss: 4.6310. Mask: 0.9349. :  23%|██▎       | 23/100 [00:05<00:10,  7.03it/s]Train Iter: 2224/5000. LR: 0.0371. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0266. T_Loss: 4.6310. Mask: 0.9349. :  24%|██▍       | 24/100 [00:05<00:10,  7.19it/s]Train Iter: 2225/5000. LR: 0.0371. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0253. T_Loss: 4.6276. Mask: 0.9363. :  24%|██▍       | 24/100 [00:05<00:10,  7.19it/s]Train Iter: 2225/5000. LR: 0.0371. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0253. T_Loss: 4.6276. Mask: 0.9363. :  25%|██▌       | 25/100 [00:05<00:12,  6.07it/s]total : 5000  current step :  2201
total : 5000  current step :  2202
total : 5000  current step :  2203
total : 5000  current step :  2204
total : 5000  current step :  2205
total : 5000  current step :  2206
total : 5000  current step :  2207
total : 5000  current step :  2208
total : 5000  current step :  2209
total : 5000  current step :  2210
total : 5000  current step :  2211
total : 5000  current step :  2212
total : 5000  current step :  2213
total : 5000  current step :  2214
total : 5000  current step :  2215
total : 5000  current step :  2216
total : 5000  current step :  2217
total : 5000  current step :  2218
total : 5000  current step :  2219
total : 5000  current step :  2220
total : 5000  current step :  2221
total : 5000  current step :  2222
total : 5000  current step :  2223
total : 5000  current step :  2224
total : 5000  current step :  2225
Train Iter: 2226/5000. LR: 0.0371. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0275. T_Loss: 4.6499. Mask: 0.9375. :  25%|██▌       | 25/100 [00:08<00:12,  6.07it/s]Train Iter: 2226/5000. LR: 0.0371. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0275. T_Loss: 4.6499. Mask: 0.9375. :  26%|██▌       | 26/100 [00:08<01:00,  1.23it/s]Train Iter: 2227/5000. LR: 0.0371. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0290. T_Loss: 4.6232. Mask: 0.9340. :  26%|██▌       | 26/100 [00:08<01:00,  1.23it/s]Train Iter: 2227/5000. LR: 0.0371. Data: 0.16s. Batch: 0.30s. S_Loss: 1.0290. T_Loss: 4.6232. Mask: 0.9340. :  27%|██▋       | 27/100 [00:08<00:44,  1.64it/s]Train Iter: 2228/5000. LR: 0.0370. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0243. T_Loss: 4.5999. Mask: 0.9330. :  27%|██▋       | 27/100 [00:08<00:44,  1.64it/s]Train Iter: 2228/5000. LR: 0.0370. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0243. T_Loss: 4.5999. Mask: 0.9330. :  28%|██▊       | 28/100 [00:08<00:33,  2.14it/s]Train Iter: 2229/5000. LR: 0.0370. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0248. T_Loss: 4.5794. Mask: 0.9332. :  28%|██▊       | 28/100 [00:08<00:33,  2.14it/s]Train Iter: 2229/5000. LR: 0.0370. Data: 0.15s. Batch: 0.29s. S_Loss: 1.0248. T_Loss: 4.5794. Mask: 0.9332. :  29%|██▉       | 29/100 [00:08<00:29,  2.40it/s]Train Iter: 2230/5000. LR: 0.0370. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0230. T_Loss: 4.5815. Mask: 0.9344. :  29%|██▉       | 29/100 [00:08<00:29,  2.40it/s]Train Iter: 2230/5000. LR: 0.0370. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0230. T_Loss: 4.5815. Mask: 0.9344. :  30%|███       | 30/100 [00:08<00:23,  3.02it/s]Train Iter: 2231/5000. LR: 0.0370. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0207. T_Loss: 4.5922. Mask: 0.9345. :  30%|███       | 30/100 [00:08<00:23,  3.02it/s]Train Iter: 2231/5000. LR: 0.0370. Data: 0.14s. Batch: 0.28s. S_Loss: 1.0207. T_Loss: 4.5922. Mask: 0.9345. :  31%|███       | 31/100 [00:08<00:18,  3.76it/s]Train Iter: 2232/5000. LR: 0.0370. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0200. T_Loss: 4.5917. Mask: 0.9355. :  31%|███       | 31/100 [00:08<00:18,  3.76it/s]Train Iter: 2232/5000. LR: 0.0370. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0200. T_Loss: 4.5917. Mask: 0.9355. :  32%|███▏      | 32/100 [00:08<00:15,  4.48it/s]Train Iter: 2233/5000. LR: 0.0370. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0143. T_Loss: 4.5712. Mask: 0.9356. :  32%|███▏      | 32/100 [00:09<00:15,  4.48it/s]Train Iter: 2233/5000. LR: 0.0370. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0143. T_Loss: 4.5712. Mask: 0.9356. :  33%|███▎      | 33/100 [00:09<00:12,  5.22it/s]Train Iter: 2234/5000. LR: 0.0369. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0128. T_Loss: 4.5501. Mask: 0.9357. :  33%|███▎      | 33/100 [00:09<00:12,  5.22it/s]Train Iter: 2234/5000. LR: 0.0369. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0128. T_Loss: 4.5501. Mask: 0.9357. :  34%|███▍      | 34/100 [00:09<00:11,  5.74it/s]Train Iter: 2235/5000. LR: 0.0369. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0119. T_Loss: 4.5766. Mask: 0.9366. :  34%|███▍      | 34/100 [00:09<00:11,  5.74it/s]Train Iter: 2235/5000. LR: 0.0369. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0119. T_Loss: 4.5766. Mask: 0.9366. :  35%|███▌      | 35/100 [00:09<00:13,  4.86it/s]Train Iter: 2236/5000. LR: 0.0369. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0120. T_Loss: 4.5814. Mask: 0.9375. :  35%|███▌      | 35/100 [00:09<00:13,  4.86it/s]Train Iter: 2236/5000. LR: 0.0369. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0120. T_Loss: 4.5814. Mask: 0.9375. :  36%|███▌      | 36/100 [00:09<00:12,  5.33it/s]Train Iter: 2237/5000. LR: 0.0369. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0084. T_Loss: 4.5912. Mask: 0.9383. :  36%|███▌      | 36/100 [00:09<00:12,  5.33it/s]Train Iter: 2237/5000. LR: 0.0369. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0084. T_Loss: 4.5912. Mask: 0.9383. :  37%|███▋      | 37/100 [00:09<00:10,  5.94it/s]Train Iter: 2238/5000. LR: 0.0369. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0057. T_Loss: 4.6078. Mask: 0.9375. :  37%|███▋      | 37/100 [00:09<00:10,  5.94it/s]Train Iter: 2238/5000. LR: 0.0369. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0057. T_Loss: 4.6078. Mask: 0.9375. :  38%|███▊      | 38/100 [00:09<00:10,  6.17it/s]Train Iter: 2239/5000. LR: 0.0369. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0054. T_Loss: 4.6102. Mask: 0.9383. :  38%|███▊      | 38/100 [00:10<00:10,  6.17it/s]Train Iter: 2239/5000. LR: 0.0369. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0054. T_Loss: 4.6102. Mask: 0.9383. :  39%|███▉      | 39/100 [00:10<00:10,  6.10it/s]Train Iter: 2240/5000. LR: 0.0368. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0046. T_Loss: 4.5954. Mask: 0.9383. :  39%|███▉      | 39/100 [00:10<00:10,  6.10it/s]Train Iter: 2240/5000. LR: 0.0368. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0046. T_Loss: 4.5954. Mask: 0.9383. :  40%|████      | 40/100 [00:10<00:09,  6.38it/s]Train Iter: 2241/5000. LR: 0.0368. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0047. T_Loss: 4.6134. Mask: 0.9367. :  40%|████      | 40/100 [00:10<00:09,  6.38it/s]Train Iter: 2241/5000. LR: 0.0368. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0047. T_Loss: 4.6134. Mask: 0.9367. :  41%|████      | 41/100 [00:10<00:09,  6.34it/s]Train Iter: 2242/5000. LR: 0.0368. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0064. T_Loss: 4.6156. Mask: 0.9345. :  41%|████      | 41/100 [00:10<00:09,  6.34it/s]Train Iter: 2242/5000. LR: 0.0368. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0064. T_Loss: 4.6156. Mask: 0.9345. :  42%|████▏     | 42/100 [00:10<00:08,  6.80it/s]Train Iter: 2243/5000. LR: 0.0368. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0049. T_Loss: 4.6248. Mask: 0.9353. :  42%|████▏     | 42/100 [00:10<00:08,  6.80it/s]Train Iter: 2243/5000. LR: 0.0368. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0049. T_Loss: 4.6248. Mask: 0.9353. :  43%|████▎     | 43/100 [00:10<00:08,  6.85it/s]Train Iter: 2244/5000. LR: 0.0368. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0028. T_Loss: 4.6264. Mask: 0.9368. :  43%|████▎     | 43/100 [00:10<00:08,  6.85it/s]Train Iter: 2245/5000. LR: 0.0368. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0040. T_Loss: 4.6313. Mask: 0.9354. :  44%|████▍     | 44/100 [00:11<00:08,  6.85it/s]Train Iter: 2245/5000. LR: 0.0368. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0040. T_Loss: 4.6313. Mask: 0.9354. :  45%|████▌     | 45/100 [00:11<00:09,  5.75it/s]Train Iter: 2246/5000. LR: 0.0367. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0038. T_Loss: 4.6446. Mask: 0.9355. :  45%|████▌     | 45/100 [00:11<00:09,  5.75it/s]Train Iter: 2246/5000. LR: 0.0367. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0038. T_Loss: 4.6446. Mask: 0.9355. :  46%|████▌     | 46/100 [00:11<00:08,  6.17it/s]Train Iter: 2247/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0028. T_Loss: 4.6337. Mask: 0.9335. :  46%|████▌     | 46/100 [00:11<00:08,  6.17it/s]Train Iter: 2247/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0028. T_Loss: 4.6337. Mask: 0.9335. :  47%|████▋     | 47/100 [00:11<00:08,  6.48it/s]Train Iter: 2248/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0036. T_Loss: 4.6417. Mask: 0.9342. :  47%|████▋     | 47/100 [00:11<00:08,  6.48it/s]Train Iter: 2249/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0074. T_Loss: 4.6638. Mask: 0.9337. :  48%|████▊     | 48/100 [00:11<00:08,  6.48it/s]Train Iter: 2249/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0074. T_Loss: 4.6638. Mask: 0.9337. :  49%|████▉     | 49/100 [00:11<00:09,  5.58it/s]Train Iter: 2250/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0092. T_Loss: 4.6722. Mask: 0.9325. :  49%|████▉     | 49/100 [00:11<00:09,  5.58it/s]Train Iter: 2250/5000. LR: 0.0367. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0092. T_Loss: 4.6722. Mask: 0.9325. :  50%|█████     | 50/100 [00:11<00:08,  5.96it/s]total : 5000  current step :  2226
total : 5000  current step :  2227
total : 5000  current step :  2228
total : 5000  current step :  2229
total : 5000  current step :  2230
total : 5000  current step :  2231
total : 5000  current step :  2232
total : 5000  current step :  2233
total : 5000  current step :  2234
total : 5000  current step :  2235
total : 5000  current step :  2236
total : 5000  current step :  2237
total : 5000  current step :  2238
total : 5000  current step :  2239
total : 5000  current step :  2240
total : 5000  current step :  2241
total : 5000  current step :  2242
total : 5000  current step :  2243
total : 5000  current step :  2244
total : 5000  current step :  2245
total : 5000  current step :  2246
total : 5000  current step :  2247
total : 5000  current step :  2248
total : 5000  current step :  2249
total : 5000  current step :  2250
Train Iter: 2251/5000. LR: 0.0367. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0121. T_Loss: 4.7039. Mask: 0.9332. :  50%|█████     | 50/100 [00:14<00:08,  5.96it/s]Train Iter: 2251/5000. LR: 0.0367. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0121. T_Loss: 4.7039. Mask: 0.9332. :  51%|█████     | 51/100 [00:14<00:33,  1.47it/s]Train Iter: 2252/5000. LR: 0.0366. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0131. T_Loss: 4.7074. Mask: 0.9309. :  51%|█████     | 51/100 [00:14<00:33,  1.47it/s]Train Iter: 2252/5000. LR: 0.0366. Data: 0.13s. Batch: 0.27s. S_Loss: 1.0131. T_Loss: 4.7074. Mask: 0.9309. :  52%|█████▏    | 52/100 [00:14<00:25,  1.89it/s]Train Iter: 2253/5000. LR: 0.0366. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0138. T_Loss: 4.7074. Mask: 0.9304. :  52%|█████▏    | 52/100 [00:14<00:25,  1.89it/s]Train Iter: 2253/5000. LR: 0.0366. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0138. T_Loss: 4.7074. Mask: 0.9304. :  53%|█████▎    | 53/100 [00:14<00:19,  2.41it/s]Train Iter: 2254/5000. LR: 0.0366. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0115. T_Loss: 4.7113. Mask: 0.9311. :  53%|█████▎    | 53/100 [00:14<00:19,  2.41it/s]Train Iter: 2254/5000. LR: 0.0366. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0115. T_Loss: 4.7113. Mask: 0.9311. :  54%|█████▍    | 54/100 [00:14<00:15,  3.03it/s]Train Iter: 2255/5000. LR: 0.0366. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0092. T_Loss: 4.7140. Mask: 0.9301. :  54%|█████▍    | 54/100 [00:14<00:15,  3.03it/s]Train Iter: 2255/5000. LR: 0.0366. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0092. T_Loss: 4.7140. Mask: 0.9301. :  55%|█████▌    | 55/100 [00:14<00:15,  2.97it/s]Train Iter: 2256/5000. LR: 0.0366. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0075. T_Loss: 4.7101. Mask: 0.9297. :  55%|█████▌    | 55/100 [00:14<00:15,  2.97it/s]Train Iter: 2256/5000. LR: 0.0366. Data: 0.12s. Batch: 0.26s. S_Loss: 1.0075. T_Loss: 4.7101. Mask: 0.9297. :  56%|█████▌    | 56/100 [00:14<00:12,  3.61it/s]Train Iter: 2257/5000. LR: 0.0366. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0070. T_Loss: 4.7070. Mask: 0.9304. :  56%|█████▌    | 56/100 [00:15<00:12,  3.61it/s]Train Iter: 2257/5000. LR: 0.0366. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0070. T_Loss: 4.7070. Mask: 0.9304. :  57%|█████▋    | 57/100 [00:15<00:10,  4.14it/s]Train Iter: 2258/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0056. T_Loss: 4.6990. Mask: 0.9289. :  57%|█████▋    | 57/100 [00:15<00:10,  4.14it/s]Train Iter: 2258/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0056. T_Loss: 4.6990. Mask: 0.9289. :  58%|█████▊    | 58/100 [00:15<00:08,  4.76it/s]Train Iter: 2259/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0040. T_Loss: 4.6830. Mask: 0.9274. :  58%|█████▊    | 58/100 [00:15<00:08,  4.76it/s]Train Iter: 2259/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0040. T_Loss: 4.6830. Mask: 0.9274. :  59%|█████▉    | 59/100 [00:15<00:11,  3.70it/s]Train Iter: 2260/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0031. T_Loss: 4.6866. Mask: 0.9276. :  59%|█████▉    | 59/100 [00:15<00:11,  3.70it/s]Train Iter: 2260/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0031. T_Loss: 4.6866. Mask: 0.9276. :  60%|██████    | 60/100 [00:15<00:09,  4.38it/s]Train Iter: 2261/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0021. T_Loss: 4.6804. Mask: 0.9283. :  60%|██████    | 60/100 [00:15<00:09,  4.38it/s]Train Iter: 2261/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0021. T_Loss: 4.6804. Mask: 0.9283. :  61%|██████    | 61/100 [00:15<00:07,  5.07it/s]Train Iter: 2262/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0005. T_Loss: 4.6801. Mask: 0.9284. :  61%|██████    | 61/100 [00:16<00:07,  5.07it/s]Train Iter: 2262/5000. LR: 0.0365. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0005. T_Loss: 4.6801. Mask: 0.9284. :  62%|██████▏   | 62/100 [00:16<00:06,  5.58it/s]Train Iter: 2263/5000. LR: 0.0365. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0001. T_Loss: 4.6707. Mask: 0.9286. :  62%|██████▏   | 62/100 [00:16<00:06,  5.58it/s]Train Iter: 2263/5000. LR: 0.0365. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0001. T_Loss: 4.6707. Mask: 0.9286. :  63%|██████▎   | 63/100 [00:16<00:06,  6.10it/s]Train Iter: 2264/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9995. T_Loss: 4.6508. Mask: 0.9263. :  63%|██████▎   | 63/100 [00:16<00:06,  6.10it/s]Train Iter: 2264/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9995. T_Loss: 4.6508. Mask: 0.9263. :  64%|██████▍   | 64/100 [00:16<00:05,  6.52it/s]Train Iter: 2265/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9997. T_Loss: 4.6456. Mask: 0.9274. :  64%|██████▍   | 64/100 [00:16<00:05,  6.52it/s]Train Iter: 2265/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9997. T_Loss: 4.6456. Mask: 0.9274. :  65%|██████▌   | 65/100 [00:16<00:07,  4.85it/s]Train Iter: 2266/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9991. T_Loss: 4.6321. Mask: 0.9280. :  65%|██████▌   | 65/100 [00:16<00:07,  4.85it/s]Train Iter: 2267/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9989. T_Loss: 4.6184. Mask: 0.9272. :  66%|██████▌   | 66/100 [00:16<00:07,  4.85it/s]Train Iter: 2267/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9989. T_Loss: 4.6184. Mask: 0.9272. :  67%|██████▋   | 67/100 [00:16<00:04,  6.73it/s]Train Iter: 2268/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9999. T_Loss: 4.6235. Mask: 0.9269. :  67%|██████▋   | 67/100 [00:16<00:04,  6.73it/s]Train Iter: 2269/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9995. T_Loss: 4.6117. Mask: 0.9271. :  68%|██████▊   | 68/100 [00:17<00:04,  6.73it/s]Train Iter: 2269/5000. LR: 0.0364. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9995. T_Loss: 4.6117. Mask: 0.9271. :  69%|██████▉   | 69/100 [00:17<00:04,  6.83it/s]Train Iter: 2270/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9994. T_Loss: 4.6044. Mask: 0.9272. :  69%|██████▉   | 69/100 [00:17<00:04,  6.83it/s]Train Iter: 2271/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9999. T_Loss: 4.6071. Mask: 0.9261. :  70%|███████   | 70/100 [00:17<00:04,  6.83it/s]Train Iter: 2271/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9999. T_Loss: 4.6071. Mask: 0.9261. :  71%|███████   | 71/100 [00:17<00:03,  8.25it/s]Train Iter: 2272/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0013. T_Loss: 4.6154. Mask: 0.9245. :  71%|███████   | 71/100 [00:17<00:03,  8.25it/s]Train Iter: 2273/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0005. T_Loss: 4.6092. Mask: 0.9251. :  72%|███████▏  | 72/100 [00:17<00:03,  8.25it/s]Train Iter: 2273/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0005. T_Loss: 4.6092. Mask: 0.9251. :  73%|███████▎  | 73/100 [00:17<00:02,  9.42it/s]Train Iter: 2274/5000. LR: 0.0363. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0010. T_Loss: 4.6157. Mask: 0.9244. :  73%|███████▎  | 73/100 [00:17<00:02,  9.42it/s]Train Iter: 2275/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0016. T_Loss: 4.6164. Mask: 0.9237. :  74%|███████▍  | 74/100 [00:17<00:02,  9.42it/s]Train Iter: 2275/5000. LR: 0.0363. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0016. T_Loss: 4.6164. Mask: 0.9237. :  75%|███████▌  | 75/100 [00:17<00:03,  7.09it/s]total : 5000  current step :  2251
total : 5000  current step :  2252
total : 5000  current step :  2253
total : 5000  current step :  2254
total : 5000  current step :  2255
total : 5000  current step :  2256
total : 5000  current step :  2257
total : 5000  current step :  2258
total : 5000  current step :  2259
total : 5000  current step :  2260
total : 5000  current step :  2261
total : 5000  current step :  2262
total : 5000  current step :  2263
total : 5000  current step :  2264
total : 5000  current step :  2265
total : 5000  current step :  2266
total : 5000  current step :  2267
total : 5000  current step :  2268
total : 5000  current step :  2269
total : 5000  current step :  2270
total : 5000  current step :  2271
total : 5000  current step :  2272
total : 5000  current step :  2273
total : 5000  current step :  2274
total : 5000  current step :  2275
Train Iter: 2276/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0014. T_Loss: 4.6162. Mask: 0.9239. :  75%|███████▌  | 75/100 [00:19<00:03,  7.09it/s]Train Iter: 2276/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0014. T_Loss: 4.6162. Mask: 0.9239. :  76%|███████▌  | 76/100 [00:19<00:12,  1.94it/s]Train Iter: 2277/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0013. T_Loss: 4.6224. Mask: 0.9237. :  76%|███████▌  | 76/100 [00:20<00:12,  1.94it/s]Train Iter: 2277/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0013. T_Loss: 4.6224. Mask: 0.9237. :  77%|███████▋  | 77/100 [00:20<00:09,  2.32it/s]Train Iter: 2278/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0007. T_Loss: 4.6215. Mask: 0.9235. :  77%|███████▋  | 77/100 [00:20<00:09,  2.32it/s]Train Iter: 2278/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0007. T_Loss: 4.6215. Mask: 0.9235. :  78%|███████▊  | 78/100 [00:20<00:07,  2.79it/s]Train Iter: 2279/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0013. T_Loss: 4.6301. Mask: 0.9225. :  78%|███████▊  | 78/100 [00:20<00:07,  2.79it/s]Train Iter: 2279/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0013. T_Loss: 4.6301. Mask: 0.9225. :  79%|███████▉  | 79/100 [00:20<00:07,  2.90it/s]Train Iter: 2280/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0022. T_Loss: 4.6296. Mask: 0.9223. :  79%|███████▉  | 79/100 [00:20<00:07,  2.90it/s]Train Iter: 2280/5000. LR: 0.0362. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0022. T_Loss: 4.6296. Mask: 0.9223. :  80%|████████  | 80/100 [00:20<00:05,  3.46it/s]Train Iter: 2281/5000. LR: 0.0362. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0009. T_Loss: 4.6274. Mask: 0.9225. :  80%|████████  | 80/100 [00:20<00:05,  3.46it/s]Train Iter: 2281/5000. LR: 0.0362. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0009. T_Loss: 4.6274. Mask: 0.9225. :  81%|████████  | 81/100 [00:20<00:04,  4.09it/s]Train Iter: 2282/5000. LR: 0.0361. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0005. T_Loss: 4.6253. Mask: 0.9226. :  81%|████████  | 81/100 [00:20<00:04,  4.09it/s]Train Iter: 2282/5000. LR: 0.0361. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0005. T_Loss: 4.6253. Mask: 0.9226. :  82%|████████▏ | 82/100 [00:20<00:03,  4.78it/s]Train Iter: 2283/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0003. T_Loss: 4.6248. Mask: 0.9224. :  82%|████████▏ | 82/100 [00:20<00:03,  4.78it/s]Train Iter: 2283/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0003. T_Loss: 4.6248. Mask: 0.9224. :  83%|████████▎ | 83/100 [00:20<00:03,  5.36it/s]Train Iter: 2284/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0027. T_Loss: 4.6308. Mask: 0.9215. :  83%|████████▎ | 83/100 [00:21<00:03,  5.36it/s]Train Iter: 2284/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0027. T_Loss: 4.6308. Mask: 0.9215. :  84%|████████▍ | 84/100 [00:21<00:02,  5.99it/s]Train Iter: 2285/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0031. T_Loss: 4.6378. Mask: 0.9217. :  84%|████████▍ | 84/100 [00:21<00:02,  5.99it/s]Train Iter: 2285/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0031. T_Loss: 4.6378. Mask: 0.9217. :  85%|████████▌ | 85/100 [00:21<00:03,  4.63it/s]Train Iter: 2286/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0058. T_Loss: 4.6545. Mask: 0.9215. :  85%|████████▌ | 85/100 [00:21<00:03,  4.63it/s]Train Iter: 2286/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0058. T_Loss: 4.6545. Mask: 0.9215. :  86%|████████▌ | 86/100 [00:21<00:02,  5.25it/s]Train Iter: 2287/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0061. T_Loss: 4.6484. Mask: 0.9203. :  86%|████████▌ | 86/100 [00:21<00:02,  5.25it/s]Train Iter: 2287/5000. LR: 0.0361. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0061. T_Loss: 4.6484. Mask: 0.9203. :  87%|████████▋ | 87/100 [00:21<00:02,  5.78it/s]Train Iter: 2288/5000. LR: 0.0360. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0050. T_Loss: 4.6365. Mask: 0.9190. :  87%|████████▋ | 87/100 [00:21<00:02,  5.78it/s]Train Iter: 2288/5000. LR: 0.0360. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0050. T_Loss: 4.6365. Mask: 0.9190. :  88%|████████▊ | 88/100 [00:21<00:01,  6.33it/s]Train Iter: 2289/5000. LR: 0.0360. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0064. T_Loss: 4.6498. Mask: 0.9196. :  88%|████████▊ | 88/100 [00:22<00:01,  6.33it/s]Train Iter: 2289/5000. LR: 0.0360. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0064. T_Loss: 4.6498. Mask: 0.9196. :  89%|████████▉ | 89/100 [00:22<00:02,  4.52it/s]Train Iter: 2290/5000. LR: 0.0360. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0070. T_Loss: 4.6517. Mask: 0.9194. :  89%|████████▉ | 89/100 [00:22<00:02,  4.52it/s]Train Iter: 2290/5000. LR: 0.0360. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0070. T_Loss: 4.6517. Mask: 0.9194. :  90%|█████████ | 90/100 [00:22<00:01,  5.22it/s]Train Iter: 2291/5000. LR: 0.0360. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0073. T_Loss: 4.6580. Mask: 0.9196. :  90%|█████████ | 90/100 [00:22<00:01,  5.22it/s]Train Iter: 2291/5000. LR: 0.0360. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0073. T_Loss: 4.6580. Mask: 0.9196. :  91%|█████████ | 91/100 [00:22<00:01,  5.76it/s]Train Iter: 2292/5000. LR: 0.0360. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0070. T_Loss: 4.6558. Mask: 0.9192. :  91%|█████████ | 91/100 [00:22<00:01,  5.76it/s]Train Iter: 2292/5000. LR: 0.0360. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0070. T_Loss: 4.6558. Mask: 0.9192. :  92%|█████████▏| 92/100 [00:22<00:01,  6.21it/s]Train Iter: 2293/5000. LR: 0.0360. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0086. T_Loss: 4.6581. Mask: 0.9187. :  92%|█████████▏| 92/100 [00:22<00:01,  6.21it/s]Train Iter: 2293/5000. LR: 0.0360. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0086. T_Loss: 4.6581. Mask: 0.9187. :  93%|█████████▎| 93/100 [00:22<00:01,  6.65it/s]Train Iter: 2294/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0082. T_Loss: 4.6611. Mask: 0.9179. :  93%|█████████▎| 93/100 [00:22<00:01,  6.65it/s]Train Iter: 2294/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0082. T_Loss: 4.6611. Mask: 0.9179. :  94%|█████████▍| 94/100 [00:22<00:00,  7.07it/s]Train Iter: 2295/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0075. T_Loss: 4.6538. Mask: 0.9171. :  94%|█████████▍| 94/100 [00:23<00:00,  7.07it/s]Train Iter: 2295/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0075. T_Loss: 4.6538. Mask: 0.9171. :  95%|█████████▌| 95/100 [00:23<00:01,  4.83it/s]Train Iter: 2296/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0070. T_Loss: 4.6558. Mask: 0.9167. :  95%|█████████▌| 95/100 [00:23<00:01,  4.83it/s]Train Iter: 2296/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0070. T_Loss: 4.6558. Mask: 0.9167. :  96%|█████████▌| 96/100 [00:23<00:00,  5.33it/s]Train Iter: 2297/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0067. T_Loss: 4.6569. Mask: 0.9162. :  96%|█████████▌| 96/100 [00:23<00:00,  5.33it/s]Train Iter: 2297/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0067. T_Loss: 4.6569. Mask: 0.9162. :  97%|█████████▋| 97/100 [00:23<00:00,  5.83it/s]Train Iter: 2298/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0074. T_Loss: 4.6620. Mask: 0.9158. :  97%|█████████▋| 97/100 [00:23<00:00,  5.83it/s]Train Iter: 2298/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0074. T_Loss: 4.6620. Mask: 0.9158. :  98%|█████████▊| 98/100 [00:23<00:00,  6.30it/s]Train Iter: 2299/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0076. T_Loss: 4.6660. Mask: 0.9160. :  98%|█████████▊| 98/100 [00:23<00:00,  6.30it/s]Train Iter: 2299/5000. LR: 0.0359. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0076. T_Loss: 4.6660. Mask: 0.9160. :  99%|█████████▉| 99/100 [00:23<00:00,  4.93it/s]Train Iter: 2300/5000. LR: 0.0358. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0078. T_Loss: 4.6617. Mask: 0.9153. :  99%|█████████▉| 99/100 [00:23<00:00,  4.93it/s]Train Iter: 2300/5000. LR: 0.0358. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0078. T_Loss: 4.6617. Mask: 0.9153. : 100%|██████████| 100/100 [00:23<00:00,  5.53it/s]Train Iter: 2300/5000. LR: 0.0358. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0078. T_Loss: 4.6617. Mask: 0.9153. : 100%|██████████| 100/100 [00:23<00:00,  4.17it/s]
total : 5000  current step :  2276
total : 5000  current step :  2277
total : 5000  current step :  2278
total : 5000  current step :  2279
total : 5000  current step :  2280
total : 5000  current step :  2281
total : 5000  current step :  2282
total : 5000  current step :  2283
total : 5000  current step :  2284
total : 5000  current step :  2285
total : 5000  current step :  2286
total : 5000  current step :  2287
total : 5000  current step :  2288
total : 5000  current step :  2289
total : 5000  current step :  2290
total : 5000  current step :  2291
total : 5000  current step :  2292
total : 5000  current step :  2293
total : 5000  current step :  2294
total : 5000  current step :  2295
total : 5000  current step :  2296
total : 5000  current step :  2297
total : 5000  current step :  2298
total : 5000  current step :  2299
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9882. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9882. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.86s. Loss: 0.9756. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.9391. top1: 85.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9500. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9342. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9342. top1: 86.25. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9348. top1: 84.90. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9511. top1: 84.38. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9569. top1: 83.98. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9503. top1: 84.38. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9606. top1: 83.75. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9462. top1: 84.66. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9465. top1: 84.90. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9410. top1: 85.34. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9382. top1: 85.49. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9347. top1: 85.83. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.73it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9347. top1: 85.83. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9377. top1: 85.55. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9332. top1: 85.66. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9322. top1: 85.76. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9313. top1: 85.86. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9302. top1: 86.09. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9369. top1: 85.57. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9334. top1: 85.94. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9286. top1: 86.41. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9252. top1: 86.59. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.50it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9252. top1: 86.59. top5: 100.00. :  38%|███▊      | 24/63 [00:01<00:01, 23.01it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9221. top1: 86.75. top5: 100.00. :  38%|███▊      | 24/63 [00:01<00:01, 23.01it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9279. top1: 86.18. top5: 100.00. :  38%|███▊      | 24/63 [00:01<00:01, 23.01it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9277. top1: 86.11. top5: 100.00. :  38%|███▊      | 24/63 [00:01<00:01, 23.01it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9304. top1: 85.94. top5: 100.00. :  38%|███▊      | 24/63 [00:01<00:01, 23.01it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9291. top1: 86.10. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 23.01it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9288. top1: 86.15. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 23.01it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9294. top1: 85.99. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 23.01it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9441. top1: 85.35. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 23.01it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9500. top1: 85.23. top5: 99.91. :  38%|███▊      | 24/63 [00:02<00:01, 23.01it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9597. top1: 84.65. top5: 99.82. :  38%|███▊      | 24/63 [00:02<00:01, 23.01it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9597. top1: 84.65. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9674. top1: 84.38. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9900. top1: 83.33. top5: 99.65. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9942. top1: 83.11. top5: 99.66. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0000. top1: 82.65. top5: 99.67. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0142. top1: 82.13. top5: 99.52. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0215. top1: 81.80. top5: 99.45. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0263. top1: 81.63. top5: 99.39. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0376. top1: 81.03. top5: 99.40. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0427. top1: 80.74. top5: 99.42. :  54%|█████▍    | 34/63 [00:02<00:00, 34.45it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0427. top1: 80.74. top5: 99.42. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0442. top1: 80.75. top5: 99.43. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0456. top1: 80.56. top5: 99.44. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0515. top1: 80.10. top5: 99.46. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0571. top1: 79.85. top5: 99.40. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0595. top1: 79.69. top5: 99.41. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0652. top1: 79.53. top5: 99.43. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0688. top1: 79.31. top5: 99.44. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0802. top1: 78.62. top5: 99.39. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0832. top1: 78.49. top5: 99.34. :  68%|██████▊   | 43/63 [00:02<00:00, 44.17it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0832. top1: 78.49. top5: 99.34. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0916. top1: 78.12. top5: 99.23. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0981. top1: 77.78. top5: 99.25. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1011. top1: 77.67. top5: 99.26. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1027. top1: 77.51. top5: 99.27. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1101. top1: 77.08. top5: 99.29. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1149. top1: 76.78. top5: 99.30. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1203. top1: 76.59. top5: 99.31. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1191. top1: 76.67. top5: 99.32. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1251. top1: 76.28. top5: 99.33. :  83%|████████▎ | 52/63 [00:02<00:00, 52.31it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1251. top1: 76.28. top5: 99.33. :  97%|█████████▋| 61/63 [00:02<00:00, 59.13it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1334. top1: 75.76. top5: 99.34. :  97%|█████████▋| 61/63 [00:02<00:00, 59.13it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1340. top1: 75.70. top5: 99.35. :  97%|█████████▋| 61/63 [00:02<00:00, 59.13it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1340. top1: 75.70. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 24.28it/s]
total : 5000  current step :  2300
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2301/5000. LR: 0.0358. Data: 2.19s. Batch: 2.30s. S_Loss: 0.9698. T_Loss: 5.5923. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2301/5000. LR: 0.0358. Data: 2.19s. Batch: 2.30s. S_Loss: 0.9698. T_Loss: 5.5923. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:48,  2.30s/it]Train Iter: 2302/5000. LR: 0.0358. Data: 1.10s. Batch: 1.21s. S_Loss: 0.9366. T_Loss: 4.7178. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:48,  2.30s/it]Train Iter: 2302/5000. LR: 0.0358. Data: 1.10s. Batch: 1.21s. S_Loss: 0.9366. T_Loss: 4.7178. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:40,  1.02s/it]Train Iter: 2303/5000. LR: 0.0358. Data: 0.74s. Batch: 0.84s. S_Loss: 0.9636. T_Loss: 4.8247. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:40,  1.02s/it]Train Iter: 2304/5000. LR: 0.0358. Data: 0.55s. Batch: 0.66s. S_Loss: 0.9647. T_Loss: 4.6671. Mask: 0.8984. :   3%|▎         | 3/100 [00:02<01:39,  1.02s/it]Train Iter: 2304/5000. LR: 0.0358. Data: 0.55s. Batch: 0.66s. S_Loss: 0.9647. T_Loss: 4.6671. Mask: 0.8984. :   4%|▍         | 4/100 [00:02<00:43,  2.20it/s]Train Iter: 2305/5000. LR: 0.0358. Data: 0.44s. Batch: 0.59s. S_Loss: 0.9641. T_Loss: 4.8275. Mask: 0.9187. :   4%|▍         | 4/100 [00:02<00:43,  2.20it/s]Train Iter: 2305/5000. LR: 0.0358. Data: 0.44s. Batch: 0.59s. S_Loss: 0.9641. T_Loss: 4.8275. Mask: 0.9187. :   5%|▌         | 5/100 [00:02<00:37,  2.52it/s]Train Iter: 2306/5000. LR: 0.0357. Data: 0.37s. Batch: 0.51s. S_Loss: 0.9787. T_Loss: 4.9049. Mask: 0.9219. :   5%|▌         | 5/100 [00:03<00:37,  2.52it/s]Train Iter: 2306/5000. LR: 0.0357. Data: 0.37s. Batch: 0.51s. S_Loss: 0.9787. T_Loss: 4.9049. Mask: 0.9219. :   6%|▌         | 6/100 [00:03<00:29,  3.18it/s]Train Iter: 2307/5000. LR: 0.0357. Data: 0.32s. Batch: 0.45s. S_Loss: 1.0004. T_Loss: 5.0987. Mask: 0.9286. :   6%|▌         | 6/100 [00:03<00:29,  3.18it/s]Train Iter: 2307/5000. LR: 0.0357. Data: 0.32s. Batch: 0.45s. S_Loss: 1.0004. T_Loss: 5.0987. Mask: 0.9286. :   7%|▋         | 7/100 [00:03<00:23,  3.89it/s]Train Iter: 2308/5000. LR: 0.0357. Data: 0.28s. Batch: 0.41s. S_Loss: 1.0154. T_Loss: 5.0097. Mask: 0.9102. :   7%|▋         | 7/100 [00:03<00:23,  3.89it/s]Train Iter: 2308/5000. LR: 0.0357. Data: 0.28s. Batch: 0.41s. S_Loss: 1.0154. T_Loss: 5.0097. Mask: 0.9102. :   8%|▊         | 8/100 [00:03<00:20,  4.51it/s]Train Iter: 2309/5000. LR: 0.0357. Data: 0.25s. Batch: 0.42s. S_Loss: 1.0250. T_Loss: 4.9466. Mask: 0.9062. :   8%|▊         | 8/100 [00:03<00:20,  4.51it/s]Train Iter: 2309/5000. LR: 0.0357. Data: 0.25s. Batch: 0.42s. S_Loss: 1.0250. T_Loss: 4.9466. Mask: 0.9062. :   9%|▉         | 9/100 [00:03<00:26,  3.49it/s]Train Iter: 2310/5000. LR: 0.0357. Data: 0.22s. Batch: 0.39s. S_Loss: 1.0242. T_Loss: 4.8176. Mask: 0.9031. :   9%|▉         | 9/100 [00:03<00:26,  3.49it/s]Train Iter: 2310/5000. LR: 0.0357. Data: 0.22s. Batch: 0.39s. S_Loss: 1.0242. T_Loss: 4.8176. Mask: 0.9031. :  10%|█         | 10/100 [00:03<00:21,  4.17it/s]Train Iter: 2311/5000. LR: 0.0357. Data: 0.20s. Batch: 0.37s. S_Loss: 1.0287. T_Loss: 4.7430. Mask: 0.9006. :  10%|█         | 10/100 [00:04<00:21,  4.17it/s]Train Iter: 2311/5000. LR: 0.0357. Data: 0.20s. Batch: 0.37s. S_Loss: 1.0287. T_Loss: 4.7430. Mask: 0.9006. :  11%|█         | 11/100 [00:04<00:18,  4.75it/s]Train Iter: 2312/5000. LR: 0.0356. Data: 0.19s. Batch: 0.35s. S_Loss: 1.0200. T_Loss: 4.6989. Mask: 0.8984. :  11%|█         | 11/100 [00:04<00:18,  4.75it/s]Train Iter: 2312/5000. LR: 0.0356. Data: 0.19s. Batch: 0.35s. S_Loss: 1.0200. T_Loss: 4.6989. Mask: 0.8984. :  12%|█▏        | 12/100 [00:04<00:16,  5.40it/s]Train Iter: 2313/5000. LR: 0.0356. Data: 0.17s. Batch: 0.33s. S_Loss: 1.0116. T_Loss: 4.6833. Mask: 0.9014. :  12%|█▏        | 12/100 [00:04<00:16,  5.40it/s]Train Iter: 2313/5000. LR: 0.0356. Data: 0.17s. Batch: 0.33s. S_Loss: 1.0116. T_Loss: 4.6833. Mask: 0.9014. :  13%|█▎        | 13/100 [00:04<00:14,  6.00it/s]Train Iter: 2314/5000. LR: 0.0356. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0045. T_Loss: 4.6089. Mask: 0.8996. :  13%|█▎        | 13/100 [00:04<00:14,  6.00it/s]Train Iter: 2314/5000. LR: 0.0356. Data: 0.16s. Batch: 0.31s. S_Loss: 1.0045. T_Loss: 4.6089. Mask: 0.8996. :  14%|█▍        | 14/100 [00:04<00:12,  6.68it/s]Train Iter: 2315/5000. LR: 0.0356. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0115. T_Loss: 4.6249. Mask: 0.8979. :  14%|█▍        | 14/100 [00:04<00:12,  6.68it/s]Train Iter: 2315/5000. LR: 0.0356. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0115. T_Loss: 4.6249. Mask: 0.8979. :  15%|█▌        | 15/100 [00:04<00:16,  5.24it/s]Train Iter: 2316/5000. LR: 0.0356. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0092. T_Loss: 4.6029. Mask: 0.8984. :  15%|█▌        | 15/100 [00:04<00:16,  5.24it/s]Train Iter: 2316/5000. LR: 0.0356. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0092. T_Loss: 4.6029. Mask: 0.8984. :  16%|█▌        | 16/100 [00:04<00:13,  6.02it/s]Train Iter: 2317/5000. LR: 0.0356. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0041. T_Loss: 4.5830. Mask: 0.8989. :  16%|█▌        | 16/100 [00:04<00:13,  6.02it/s]Train Iter: 2317/5000. LR: 0.0356. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0041. T_Loss: 4.5830. Mask: 0.8989. :  17%|█▋        | 17/100 [00:04<00:12,  6.57it/s]Train Iter: 2318/5000. LR: 0.0355. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0141. T_Loss: 4.6154. Mask: 0.9010. :  17%|█▋        | 17/100 [00:05<00:12,  6.57it/s]Train Iter: 2318/5000. LR: 0.0355. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0141. T_Loss: 4.6154. Mask: 0.9010. :  18%|█▊        | 18/100 [00:05<00:11,  7.03it/s]Train Iter: 2319/5000. LR: 0.0355. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0178. T_Loss: 4.6786. Mask: 0.9046. :  18%|█▊        | 18/100 [00:05<00:11,  7.03it/s]Train Iter: 2319/5000. LR: 0.0355. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0178. T_Loss: 4.6786. Mask: 0.9046. :  19%|█▉        | 19/100 [00:05<00:15,  5.13it/s]Train Iter: 2320/5000. LR: 0.0355. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0311. T_Loss: 4.6903. Mask: 0.9047. :  19%|█▉        | 19/100 [00:05<00:15,  5.13it/s]Train Iter: 2320/5000. LR: 0.0355. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0311. T_Loss: 4.6903. Mask: 0.9047. :  20%|██        | 20/100 [00:05<00:14,  5.57it/s]Train Iter: 2321/5000. LR: 0.0355. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0270. T_Loss: 4.6756. Mask: 0.9062. :  20%|██        | 20/100 [00:05<00:14,  5.57it/s]Train Iter: 2321/5000. LR: 0.0355. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0270. T_Loss: 4.6756. Mask: 0.9062. :  21%|██        | 21/100 [00:05<00:12,  6.12it/s]Train Iter: 2322/5000. LR: 0.0355. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0330. T_Loss: 4.7330. Mask: 0.9077. :  21%|██        | 21/100 [00:05<00:12,  6.12it/s]Train Iter: 2322/5000. LR: 0.0355. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0330. T_Loss: 4.7330. Mask: 0.9077. :  22%|██▏       | 22/100 [00:05<00:11,  6.54it/s]Train Iter: 2323/5000. LR: 0.0355. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0296. T_Loss: 4.7421. Mask: 0.9076. :  22%|██▏       | 22/100 [00:05<00:11,  6.54it/s]Train Iter: 2323/5000. LR: 0.0355. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0296. T_Loss: 4.7421. Mask: 0.9076. :  23%|██▎       | 23/100 [00:05<00:10,  7.26it/s]Train Iter: 2324/5000. LR: 0.0354. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0267. T_Loss: 4.7381. Mask: 0.9062. :  23%|██▎       | 23/100 [00:05<00:10,  7.26it/s]Train Iter: 2324/5000. LR: 0.0354. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0267. T_Loss: 4.7381. Mask: 0.9062. :  24%|██▍       | 24/100 [00:05<00:09,  7.63it/s]Train Iter: 2325/5000. LR: 0.0354. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0286. T_Loss: 4.7963. Mask: 0.9087. :  24%|██▍       | 24/100 [00:06<00:09,  7.63it/s]Train Iter: 2325/5000. LR: 0.0354. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0286. T_Loss: 4.7963. Mask: 0.9087. :  25%|██▌       | 25/100 [00:06<00:15,  4.95it/s]total : 5000  current step :  2301
total : 5000  current step :  2302
total : 5000  current step :  2303
total : 5000  current step :  2304
total : 5000  current step :  2305
total : 5000  current step :  2306
total : 5000  current step :  2307
total : 5000  current step :  2308
total : 5000  current step :  2309
total : 5000  current step :  2310
total : 5000  current step :  2311
total : 5000  current step :  2312
total : 5000  current step :  2313
total : 5000  current step :  2314
total : 5000  current step :  2315
total : 5000  current step :  2316
total : 5000  current step :  2317
total : 5000  current step :  2318
total : 5000  current step :  2319
total : 5000  current step :  2320
total : 5000  current step :  2321
total : 5000  current step :  2322
total : 5000  current step :  2323
total : 5000  current step :  2324
total : 5000  current step :  2325
Train Iter: 2326/5000. LR: 0.0354. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0238. T_Loss: 4.8151. Mask: 0.9087. :  25%|██▌       | 25/100 [00:08<00:15,  4.95it/s]Train Iter: 2326/5000. LR: 0.0354. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0238. T_Loss: 4.8151. Mask: 0.9087. :  26%|██▌       | 26/100 [00:08<00:53,  1.37it/s]Train Iter: 2327/5000. LR: 0.0354. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0230. T_Loss: 4.8295. Mask: 0.9097. :  26%|██▌       | 26/100 [00:08<00:53,  1.37it/s]Train Iter: 2327/5000. LR: 0.0354. Data: 0.15s. Batch: 0.31s. S_Loss: 1.0230. T_Loss: 4.8295. Mask: 0.9097. :  27%|██▋       | 27/100 [00:08<00:40,  1.82it/s]Train Iter: 2328/5000. LR: 0.0354. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0196. T_Loss: 4.8132. Mask: 0.9096. :  27%|██▋       | 27/100 [00:08<00:40,  1.82it/s]Train Iter: 2328/5000. LR: 0.0354. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0196. T_Loss: 4.8132. Mask: 0.9096. :  28%|██▊       | 28/100 [00:08<00:30,  2.35it/s]Train Iter: 2329/5000. LR: 0.0354. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0192. T_Loss: 4.8050. Mask: 0.9073. :  28%|██▊       | 28/100 [00:08<00:30,  2.35it/s]Train Iter: 2329/5000. LR: 0.0354. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0192. T_Loss: 4.8050. Mask: 0.9073. :  29%|██▉       | 29/100 [00:08<00:27,  2.60it/s]Train Iter: 2330/5000. LR: 0.0353. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0206. T_Loss: 4.8152. Mask: 0.9062. :  29%|██▉       | 29/100 [00:08<00:27,  2.60it/s]Train Iter: 2330/5000. LR: 0.0353. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0206. T_Loss: 4.8152. Mask: 0.9062. :  30%|███       | 30/100 [00:08<00:20,  3.34it/s]Train Iter: 2331/5000. LR: 0.0353. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0237. T_Loss: 4.8345. Mask: 0.9062. :  30%|███       | 30/100 [00:09<00:20,  3.34it/s]Train Iter: 2331/5000. LR: 0.0353. Data: 0.13s. Batch: 0.29s. S_Loss: 1.0237. T_Loss: 4.8345. Mask: 0.9062. :  31%|███       | 31/100 [00:09<00:16,  4.12it/s]Train Iter: 2332/5000. LR: 0.0353. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0244. T_Loss: 4.8471. Mask: 0.9062. :  31%|███       | 31/100 [00:09<00:16,  4.12it/s]Train Iter: 2332/5000. LR: 0.0353. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0244. T_Loss: 4.8471. Mask: 0.9062. :  32%|███▏      | 32/100 [00:09<00:13,  5.00it/s]Train Iter: 2333/5000. LR: 0.0353. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0322. T_Loss: 4.8640. Mask: 0.9072. :  32%|███▏      | 32/100 [00:09<00:13,  5.00it/s]Train Iter: 2333/5000. LR: 0.0353. Data: 0.13s. Batch: 0.28s. S_Loss: 1.0322. T_Loss: 4.8640. Mask: 0.9072. :  33%|███▎      | 33/100 [00:09<00:12,  5.58it/s]Train Iter: 2334/5000. LR: 0.0353. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0330. T_Loss: 4.8508. Mask: 0.9072. :  33%|███▎      | 33/100 [00:09<00:12,  5.58it/s]Train Iter: 2334/5000. LR: 0.0353. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0330. T_Loss: 4.8508. Mask: 0.9072. :  34%|███▍      | 34/100 [00:09<00:10,  6.27it/s]Train Iter: 2335/5000. LR: 0.0353. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0356. T_Loss: 4.8596. Mask: 0.9054. :  34%|███▍      | 34/100 [00:09<00:10,  6.27it/s]Train Iter: 2335/5000. LR: 0.0353. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0356. T_Loss: 4.8596. Mask: 0.9054. :  35%|███▌      | 35/100 [00:09<00:14,  4.43it/s]Train Iter: 2336/5000. LR: 0.0352. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0379. T_Loss: 4.8794. Mask: 0.9062. :  35%|███▌      | 35/100 [00:09<00:14,  4.43it/s]Train Iter: 2337/5000. LR: 0.0352. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0404. T_Loss: 4.8812. Mask: 0.9071. :  36%|███▌      | 36/100 [00:10<00:14,  4.43it/s]Train Iter: 2337/5000. LR: 0.0352. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0404. T_Loss: 4.8812. Mask: 0.9071. :  37%|███▋      | 37/100 [00:10<00:10,  5.76it/s]Train Iter: 2338/5000. LR: 0.0352. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0388. T_Loss: 4.8739. Mask: 0.9071. :  37%|███▋      | 37/100 [00:10<00:10,  5.76it/s]Train Iter: 2338/5000. LR: 0.0352. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0388. T_Loss: 4.8739. Mask: 0.9071. :  38%|███▊      | 38/100 [00:10<00:09,  6.23it/s]Train Iter: 2339/5000. LR: 0.0352. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0355. T_Loss: 4.8770. Mask: 0.9095. :  38%|███▊      | 38/100 [00:10<00:09,  6.23it/s]Train Iter: 2339/5000. LR: 0.0352. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0355. T_Loss: 4.8770. Mask: 0.9095. :  39%|███▉      | 39/100 [00:10<00:13,  4.48it/s]Train Iter: 2340/5000. LR: 0.0352. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0331. T_Loss: 4.8600. Mask: 0.9109. :  39%|███▉      | 39/100 [00:10<00:13,  4.48it/s]Train Iter: 2340/5000. LR: 0.0352. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0331. T_Loss: 4.8600. Mask: 0.9109. :  40%|████      | 40/100 [00:10<00:11,  5.12it/s]Train Iter: 2341/5000. LR: 0.0352. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0335. T_Loss: 4.8715. Mask: 0.9108. :  40%|████      | 40/100 [00:10<00:11,  5.12it/s]Train Iter: 2341/5000. LR: 0.0352. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0335. T_Loss: 4.8715. Mask: 0.9108. :  41%|████      | 41/100 [00:10<00:10,  5.71it/s]Train Iter: 2342/5000. LR: 0.0351. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0349. T_Loss: 4.8583. Mask: 0.9092. :  41%|████      | 41/100 [00:10<00:10,  5.71it/s]Train Iter: 2342/5000. LR: 0.0351. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0349. T_Loss: 4.8583. Mask: 0.9092. :  42%|████▏     | 42/100 [00:10<00:09,  6.23it/s]Train Iter: 2343/5000. LR: 0.0351. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0348. T_Loss: 4.8516. Mask: 0.9077. :  42%|████▏     | 42/100 [00:11<00:09,  6.23it/s]Train Iter: 2343/5000. LR: 0.0351. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0348. T_Loss: 4.8516. Mask: 0.9077. :  43%|████▎     | 43/100 [00:11<00:08,  6.64it/s]Train Iter: 2344/5000. LR: 0.0351. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0336. T_Loss: 4.8440. Mask: 0.9084. :  43%|████▎     | 43/100 [00:11<00:08,  6.64it/s]Train Iter: 2344/5000. LR: 0.0351. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0336. T_Loss: 4.8440. Mask: 0.9084. :  44%|████▍     | 44/100 [00:11<00:07,  7.05it/s]Train Iter: 2345/5000. LR: 0.0351. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0334. T_Loss: 4.8705. Mask: 0.9097. :  44%|████▍     | 44/100 [00:11<00:07,  7.05it/s]Train Iter: 2345/5000. LR: 0.0351. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0334. T_Loss: 4.8705. Mask: 0.9097. :  45%|████▌     | 45/100 [00:11<00:07,  7.41it/s]Train Iter: 2346/5000. LR: 0.0351. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0318. T_Loss: 4.8589. Mask: 0.9103. :  45%|████▌     | 45/100 [00:11<00:07,  7.41it/s]Train Iter: 2346/5000. LR: 0.0351. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0318. T_Loss: 4.8589. Mask: 0.9103. :  46%|████▌     | 46/100 [00:11<00:06,  7.79it/s]Train Iter: 2347/5000. LR: 0.0350. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0288. T_Loss: 4.8499. Mask: 0.9116. :  46%|████▌     | 46/100 [00:11<00:06,  7.79it/s]Train Iter: 2347/5000. LR: 0.0350. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0288. T_Loss: 4.8499. Mask: 0.9116. :  47%|████▋     | 47/100 [00:11<00:06,  7.72it/s]Train Iter: 2348/5000. LR: 0.0350. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0278. T_Loss: 4.8443. Mask: 0.9115. :  47%|████▋     | 47/100 [00:11<00:06,  7.72it/s]Train Iter: 2348/5000. LR: 0.0350. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0278. T_Loss: 4.8443. Mask: 0.9115. :  48%|████▊     | 48/100 [00:11<00:06,  7.91it/s]Train Iter: 2349/5000. LR: 0.0350. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0249. T_Loss: 4.8222. Mask: 0.9114. :  48%|████▊     | 48/100 [00:11<00:06,  7.91it/s]Train Iter: 2349/5000. LR: 0.0350. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0249. T_Loss: 4.8222. Mask: 0.9114. :  49%|████▉     | 49/100 [00:11<00:09,  5.48it/s]Train Iter: 2350/5000. LR: 0.0350. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0242. T_Loss: 4.8261. Mask: 0.9131. :  49%|████▉     | 49/100 [00:12<00:09,  5.48it/s]Train Iter: 2350/5000. LR: 0.0350. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0242. T_Loss: 4.8261. Mask: 0.9131. :  50%|█████     | 50/100 [00:12<00:08,  6.13it/s]total : 5000  current step :  2326
total : 5000  current step :  2327
total : 5000  current step :  2328
total : 5000  current step :  2329
total : 5000  current step :  2330
total : 5000  current step :  2331
total : 5000  current step :  2332
total : 5000  current step :  2333
total : 5000  current step :  2334
total : 5000  current step :  2335
total : 5000  current step :  2336
total : 5000  current step :  2337
total : 5000  current step :  2338
total : 5000  current step :  2339
total : 5000  current step :  2340
total : 5000  current step :  2341
total : 5000  current step :  2342
total : 5000  current step :  2343
total : 5000  current step :  2344
total : 5000  current step :  2345
total : 5000  current step :  2346
total : 5000  current step :  2347
total : 5000  current step :  2348
total : 5000  current step :  2349
total : 5000  current step :  2350
Train Iter: 2351/5000. LR: 0.0350. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0230. T_Loss: 4.8162. Mask: 0.9142. :  50%|█████     | 50/100 [00:14<00:08,  6.13it/s]Train Iter: 2351/5000. LR: 0.0350. Data: 0.12s. Batch: 0.28s. S_Loss: 1.0230. T_Loss: 4.8162. Mask: 0.9142. :  51%|█████     | 51/100 [00:14<00:36,  1.34it/s]Train Iter: 2352/5000. LR: 0.0350. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0223. T_Loss: 4.8031. Mask: 0.9129. :  51%|█████     | 51/100 [00:14<00:36,  1.34it/s]Train Iter: 2353/5000. LR: 0.0349. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0201. T_Loss: 4.7985. Mask: 0.9121. :  52%|█████▏    | 52/100 [00:14<00:35,  1.34it/s]Train Iter: 2353/5000. LR: 0.0349. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0201. T_Loss: 4.7985. Mask: 0.9121. :  53%|█████▎    | 53/100 [00:14<00:20,  2.28it/s]Train Iter: 2354/5000. LR: 0.0349. Data: 0.12s. Batch: 0.27s. S_Loss: 1.0198. T_Loss: 4.7761. Mask: 0.9126. :  53%|█████▎    | 53/100 [00:14<00:20,  2.28it/s]Train Iter: 2355/5000. LR: 0.0349. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0238. T_Loss: 4.7820. Mask: 0.9108. :  54%|█████▍    | 54/100 [00:14<00:20,  2.28it/s]Train Iter: 2355/5000. LR: 0.0349. Data: 0.11s. Batch: 0.27s. S_Loss: 1.0238. T_Loss: 4.7820. Mask: 0.9108. :  55%|█████▌    | 55/100 [00:14<00:15,  2.95it/s]Train Iter: 2356/5000. LR: 0.0349. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0271. T_Loss: 4.7716. Mask: 0.9090. :  55%|█████▌    | 55/100 [00:14<00:15,  2.95it/s]Train Iter: 2357/5000. LR: 0.0349. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0284. T_Loss: 4.7594. Mask: 0.9079. :  56%|█████▌    | 56/100 [00:14<00:14,  2.95it/s]Train Iter: 2357/5000. LR: 0.0349. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0284. T_Loss: 4.7594. Mask: 0.9079. :  57%|█████▋    | 57/100 [00:14<00:10,  4.08it/s]Train Iter: 2358/5000. LR: 0.0349. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0286. T_Loss: 4.7626. Mask: 0.9084. :  57%|█████▋    | 57/100 [00:14<00:10,  4.08it/s]Train Iter: 2359/5000. LR: 0.0348. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0278. T_Loss: 4.7499. Mask: 0.9084. :  58%|█████▊    | 58/100 [00:15<00:10,  4.08it/s]Train Iter: 2359/5000. LR: 0.0348. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0278. T_Loss: 4.7499. Mask: 0.9084. :  59%|█████▉    | 59/100 [00:15<00:09,  4.19it/s]Train Iter: 2360/5000. LR: 0.0348. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0312. T_Loss: 4.7478. Mask: 0.9078. :  59%|█████▉    | 59/100 [00:15<00:09,  4.19it/s]Train Iter: 2360/5000. LR: 0.0348. Data: 0.10s. Batch: 0.26s. S_Loss: 1.0312. T_Loss: 4.7478. Mask: 0.9078. :  60%|██████    | 60/100 [00:15<00:08,  4.60it/s]Train Iter: 2361/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0318. T_Loss: 4.7461. Mask: 0.9078. :  60%|██████    | 60/100 [00:15<00:08,  4.60it/s]Train Iter: 2361/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0318. T_Loss: 4.7461. Mask: 0.9078. :  61%|██████    | 61/100 [00:15<00:07,  5.07it/s]Train Iter: 2362/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0302. T_Loss: 4.7539. Mask: 0.9088. :  61%|██████    | 61/100 [00:15<00:07,  5.07it/s]Train Iter: 2362/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0302. T_Loss: 4.7539. Mask: 0.9088. :  62%|██████▏   | 62/100 [00:15<00:06,  5.53it/s]Train Iter: 2363/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0293. T_Loss: 4.7422. Mask: 0.9092. :  62%|██████▏   | 62/100 [00:15<00:06,  5.53it/s]Train Iter: 2363/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0293. T_Loss: 4.7422. Mask: 0.9092. :  63%|██████▎   | 63/100 [00:15<00:06,  5.97it/s]Train Iter: 2364/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0287. T_Loss: 4.7380. Mask: 0.9092. :  63%|██████▎   | 63/100 [00:15<00:06,  5.97it/s]Train Iter: 2364/5000. LR: 0.0348. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0287. T_Loss: 4.7380. Mask: 0.9092. :  64%|██████▍   | 64/100 [00:15<00:05,  6.40it/s]Train Iter: 2365/5000. LR: 0.0347. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0271. T_Loss: 4.7294. Mask: 0.9091. :  64%|██████▍   | 64/100 [00:16<00:05,  6.40it/s]Train Iter: 2365/5000. LR: 0.0347. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0271. T_Loss: 4.7294. Mask: 0.9091. :  65%|██████▌   | 65/100 [00:16<00:07,  4.92it/s]Train Iter: 2366/5000. LR: 0.0347. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0269. T_Loss: 4.7261. Mask: 0.9091. :  65%|██████▌   | 65/100 [00:16<00:07,  4.92it/s]Train Iter: 2366/5000. LR: 0.0347. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0269. T_Loss: 4.7261. Mask: 0.9091. :  66%|██████▌   | 66/100 [00:16<00:06,  5.06it/s]Train Iter: 2367/5000. LR: 0.0347. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0264. T_Loss: 4.7363. Mask: 0.9100. :  66%|██████▌   | 66/100 [00:16<00:06,  5.06it/s]Train Iter: 2367/5000. LR: 0.0347. Data: 0.09s. Batch: 0.25s. S_Loss: 1.0264. T_Loss: 4.7363. Mask: 0.9100. :  67%|██████▋   | 67/100 [00:16<00:05,  5.76it/s]Train Iter: 2368/5000. LR: 0.0347. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0252. T_Loss: 4.7317. Mask: 0.9104. :  67%|██████▋   | 67/100 [00:16<00:05,  5.76it/s]Train Iter: 2368/5000. LR: 0.0347. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0252. T_Loss: 4.7317. Mask: 0.9104. :  68%|██████▊   | 68/100 [00:16<00:05,  6.36it/s]Train Iter: 2369/5000. LR: 0.0347. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0244. T_Loss: 4.7218. Mask: 0.9099. :  68%|██████▊   | 68/100 [00:16<00:05,  6.36it/s]Train Iter: 2369/5000. LR: 0.0347. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0244. T_Loss: 4.7218. Mask: 0.9099. :  69%|██████▉   | 69/100 [00:16<00:06,  5.05it/s]Train Iter: 2370/5000. LR: 0.0347. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0236. T_Loss: 4.7314. Mask: 0.9103. :  69%|██████▉   | 69/100 [00:17<00:06,  5.05it/s]Train Iter: 2370/5000. LR: 0.0347. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0236. T_Loss: 4.7314. Mask: 0.9103. :  70%|███████   | 70/100 [00:17<00:05,  5.71it/s]Train Iter: 2371/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0211. T_Loss: 4.7156. Mask: 0.9098. :  70%|███████   | 70/100 [00:17<00:05,  5.71it/s]Train Iter: 2371/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0211. T_Loss: 4.7156. Mask: 0.9098. :  71%|███████   | 71/100 [00:17<00:04,  6.33it/s]Train Iter: 2372/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0205. T_Loss: 4.7190. Mask: 0.9106. :  71%|███████   | 71/100 [00:17<00:04,  6.33it/s]Train Iter: 2372/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0205. T_Loss: 4.7190. Mask: 0.9106. :  72%|███████▏  | 72/100 [00:17<00:04,  6.85it/s]Train Iter: 2373/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0198. T_Loss: 4.7162. Mask: 0.9110. :  72%|███████▏  | 72/100 [00:17<00:04,  6.85it/s]Train Iter: 2373/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0198. T_Loss: 4.7162. Mask: 0.9110. :  73%|███████▎  | 73/100 [00:17<00:03,  7.21it/s]Train Iter: 2374/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0176. T_Loss: 4.7129. Mask: 0.9113. :  73%|███████▎  | 73/100 [00:17<00:03,  7.21it/s]Train Iter: 2374/5000. LR: 0.0346. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0176. T_Loss: 4.7129. Mask: 0.9113. :  74%|███████▍  | 74/100 [00:17<00:03,  7.51it/s]Train Iter: 2375/5000. LR: 0.0346. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0166. T_Loss: 4.7070. Mask: 0.9113. :  74%|███████▍  | 74/100 [00:17<00:03,  7.51it/s]Train Iter: 2375/5000. LR: 0.0346. Data: 0.08s. Batch: 0.24s. S_Loss: 1.0166. T_Loss: 4.7070. Mask: 0.9113. :  75%|███████▌  | 75/100 [00:17<00:04,  5.32it/s]total : 5000  current step :  2351
total : 5000  current step :  2352
total : 5000  current step :  2353
total : 5000  current step :  2354
total : 5000  current step :  2355
total : 5000  current step :  2356
total : 5000  current step :  2357
total : 5000  current step :  2358
total : 5000  current step :  2359
total : 5000  current step :  2360
total : 5000  current step :  2361
total : 5000  current step :  2362
total : 5000  current step :  2363
total : 5000  current step :  2364
total : 5000  current step :  2365
total : 5000  current step :  2366
total : 5000  current step :  2367
total : 5000  current step :  2368
total : 5000  current step :  2369
total : 5000  current step :  2370
total : 5000  current step :  2371
total : 5000  current step :  2372
total : 5000  current step :  2373
total : 5000  current step :  2374
total : 5000  current step :  2375
Train Iter: 2376/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0143. T_Loss: 4.7010. Mask: 0.9116. :  75%|███████▌  | 75/100 [00:20<00:04,  5.32it/s]Train Iter: 2376/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0143. T_Loss: 4.7010. Mask: 0.9116. :  76%|███████▌  | 76/100 [00:20<00:19,  1.25it/s]Train Iter: 2377/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0147. T_Loss: 4.7049. Mask: 0.9123. :  76%|███████▌  | 76/100 [00:20<00:19,  1.25it/s]Train Iter: 2377/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0147. T_Loss: 4.7049. Mask: 0.9123. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 2378/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0137. T_Loss: 4.7018. Mask: 0.9131. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 2378/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0137. T_Loss: 4.7018. Mask: 0.9131. :  78%|███████▊  | 78/100 [00:20<00:09,  2.24it/s]Train Iter: 2379/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0131. T_Loss: 4.6996. Mask: 0.9134. :  78%|███████▊  | 78/100 [00:20<00:09,  2.24it/s]Train Iter: 2379/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0131. T_Loss: 4.6996. Mask: 0.9134. :  79%|███████▉  | 79/100 [00:20<00:07,  2.86it/s]Train Iter: 2380/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0126. T_Loss: 4.6972. Mask: 0.9133. :  79%|███████▉  | 79/100 [00:20<00:07,  2.86it/s]Train Iter: 2380/5000. LR: 0.0345. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0126. T_Loss: 4.6972. Mask: 0.9133. :  80%|████████  | 80/100 [00:20<00:05,  3.56it/s]Train Iter: 2381/5000. LR: 0.0345. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0142. T_Loss: 4.7038. Mask: 0.9132. :  80%|████████  | 80/100 [00:20<00:05,  3.56it/s]Train Iter: 2381/5000. LR: 0.0345. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0142. T_Loss: 4.7038. Mask: 0.9132. :  81%|████████  | 81/100 [00:20<00:04,  4.25it/s]Train Iter: 2382/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0123. T_Loss: 4.6996. Mask: 0.9139. :  81%|████████  | 81/100 [00:20<00:04,  4.25it/s]Train Iter: 2382/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0123. T_Loss: 4.6996. Mask: 0.9139. :  82%|████████▏ | 82/100 [00:20<00:03,  4.94it/s]Train Iter: 2383/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0120. T_Loss: 4.7020. Mask: 0.9142. :  82%|████████▏ | 82/100 [00:20<00:03,  4.94it/s]Train Iter: 2383/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0120. T_Loss: 4.7020. Mask: 0.9142. :  83%|████████▎ | 83/100 [00:20<00:03,  5.50it/s]Train Iter: 2384/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0111. T_Loss: 4.7010. Mask: 0.9144. :  83%|████████▎ | 83/100 [00:21<00:03,  5.50it/s]Train Iter: 2384/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0111. T_Loss: 4.7010. Mask: 0.9144. :  84%|████████▍ | 84/100 [00:21<00:02,  6.14it/s]Train Iter: 2385/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0116. T_Loss: 4.6988. Mask: 0.9147. :  84%|████████▍ | 84/100 [00:21<00:02,  6.14it/s]Train Iter: 2385/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0116. T_Loss: 4.6988. Mask: 0.9147. :  85%|████████▌ | 85/100 [00:21<00:03,  4.94it/s]Train Iter: 2386/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0113. T_Loss: 4.6940. Mask: 0.9142. :  85%|████████▌ | 85/100 [00:21<00:03,  4.94it/s]Train Iter: 2387/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0108. T_Loss: 4.6935. Mask: 0.9149. :  86%|████████▌ | 86/100 [00:21<00:02,  4.94it/s]Train Iter: 2387/5000. LR: 0.0344. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0108. T_Loss: 4.6935. Mask: 0.9149. :  87%|████████▋ | 87/100 [00:21<00:01,  6.74it/s]Train Iter: 2388/5000. LR: 0.0343. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0089. T_Loss: 4.6883. Mask: 0.9155. :  87%|████████▋ | 87/100 [00:21<00:01,  6.74it/s]Train Iter: 2389/5000. LR: 0.0343. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0092. T_Loss: 4.6812. Mask: 0.9154. :  88%|████████▊ | 88/100 [00:21<00:01,  6.74it/s]Train Iter: 2389/5000. LR: 0.0343. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0092. T_Loss: 4.6812. Mask: 0.9154. :  89%|████████▉ | 89/100 [00:21<00:01,  8.25it/s]Train Iter: 2390/5000. LR: 0.0343. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0101. T_Loss: 4.6915. Mask: 0.9163. :  89%|████████▉ | 89/100 [00:21<00:01,  8.25it/s]Train Iter: 2391/5000. LR: 0.0343. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0101. T_Loss: 4.6895. Mask: 0.9169. :  90%|█████████ | 90/100 [00:21<00:01,  8.25it/s]Train Iter: 2391/5000. LR: 0.0343. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0101. T_Loss: 4.6895. Mask: 0.9169. :  91%|█████████ | 91/100 [00:21<00:01,  8.67it/s]Train Iter: 2392/5000. LR: 0.0343. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0108. T_Loss: 4.6835. Mask: 0.9164. :  91%|█████████ | 91/100 [00:22<00:01,  8.67it/s]Train Iter: 2392/5000. LR: 0.0343. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0108. T_Loss: 4.6835. Mask: 0.9164. :  92%|█████████▏| 92/100 [00:22<00:00,  8.42it/s]Train Iter: 2393/5000. LR: 0.0343. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0134. T_Loss: 4.6893. Mask: 0.9167. :  92%|█████████▏| 92/100 [00:22<00:00,  8.42it/s]Train Iter: 2393/5000. LR: 0.0343. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0134. T_Loss: 4.6893. Mask: 0.9167. :  93%|█████████▎| 93/100 [00:22<00:00,  8.36it/s]Train Iter: 2394/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0125. T_Loss: 4.7015. Mask: 0.9169. :  93%|█████████▎| 93/100 [00:22<00:00,  8.36it/s]Train Iter: 2394/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0125. T_Loss: 4.7015. Mask: 0.9169. :  94%|█████████▍| 94/100 [00:22<00:00,  8.67it/s]Train Iter: 2395/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0120. T_Loss: 4.6921. Mask: 0.9168. :  94%|█████████▍| 94/100 [00:22<00:00,  8.67it/s]Train Iter: 2395/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0120. T_Loss: 4.6921. Mask: 0.9168. :  95%|█████████▌| 95/100 [00:22<00:00,  5.65it/s]Train Iter: 2396/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0136. T_Loss: 4.7053. Mask: 0.9173. :  95%|█████████▌| 95/100 [00:22<00:00,  5.65it/s]Train Iter: 2396/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0136. T_Loss: 4.7053. Mask: 0.9173. :  96%|█████████▌| 96/100 [00:22<00:00,  6.20it/s]Train Iter: 2397/5000. LR: 0.0342. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0130. T_Loss: 4.7107. Mask: 0.9172. :  96%|█████████▌| 96/100 [00:22<00:00,  6.20it/s]Train Iter: 2397/5000. LR: 0.0342. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0130. T_Loss: 4.7107. Mask: 0.9172. :  97%|█████████▋| 97/100 [00:22<00:00,  6.74it/s]Train Iter: 2398/5000. LR: 0.0342. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0133. T_Loss: 4.7201. Mask: 0.9180. :  97%|█████████▋| 97/100 [00:23<00:00,  6.74it/s]Train Iter: 2398/5000. LR: 0.0342. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0133. T_Loss: 4.7201. Mask: 0.9180. :  98%|█████████▊| 98/100 [00:23<00:00,  6.93it/s]Train Iter: 2399/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0134. T_Loss: 4.7231. Mask: 0.9182. :  98%|█████████▊| 98/100 [00:23<00:00,  6.93it/s]Train Iter: 2399/5000. LR: 0.0342. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0134. T_Loss: 4.7231. Mask: 0.9182. :  99%|█████████▉| 99/100 [00:23<00:00,  4.62it/s]Train Iter: 2400/5000. LR: 0.0341. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0122. T_Loss: 4.7155. Mask: 0.9181. :  99%|█████████▉| 99/100 [00:23<00:00,  4.62it/s]Train Iter: 2400/5000. LR: 0.0341. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0122. T_Loss: 4.7155. Mask: 0.9181. : 100%|██████████| 100/100 [00:23<00:00,  5.32it/s]Train Iter: 2400/5000. LR: 0.0341. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0122. T_Loss: 4.7155. Mask: 0.9181. : 100%|██████████| 100/100 [00:23<00:00,  4.25it/s]
total : 5000  current step :  2376
total : 5000  current step :  2377
total : 5000  current step :  2378
total : 5000  current step :  2379
total : 5000  current step :  2380
total : 5000  current step :  2381
total : 5000  current step :  2382
total : 5000  current step :  2383
total : 5000  current step :  2384
total : 5000  current step :  2385
total : 5000  current step :  2386
total : 5000  current step :  2387
total : 5000  current step :  2388
total : 5000  current step :  2389
total : 5000  current step :  2390
total : 5000  current step :  2391
total : 5000  current step :  2392
total : 5000  current step :  2393
total : 5000  current step :  2394
total : 5000  current step :  2395
total : 5000  current step :  2396
total : 5000  current step :  2397
total : 5000  current step :  2398
total : 5000  current step :  2399
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.66s. Loss: 0.9912. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.66s. Loss: 0.9912. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 0.9746. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9414. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9520. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9351. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9332. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9480. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9537. top1: 85.16. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9465. top1: 85.76. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.66s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9465. top1: 85.76. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9556. top1: 85.31. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9415. top1: 86.08. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9412. top1: 86.46. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9356. top1: 86.30. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9325. top1: 85.94. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9288. top1: 86.25. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9310. top1: 86.13. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.84it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9310. top1: 86.13. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9268. top1: 86.21. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9259. top1: 86.28. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9249. top1: 86.35. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9240. top1: 86.56. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9297. top1: 86.16. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9264. top1: 86.51. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9217. top1: 86.96. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9182. top1: 87.11. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9155. top1: 87.25. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9212. top1: 86.78. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9211. top1: 86.57. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.16it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9211. top1: 86.57. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.11it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9240. top1: 86.50. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.11it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9223. top1: 86.64. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9220. top1: 86.67. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9227. top1: 86.49. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9371. top1: 86.04. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9428. top1: 85.98. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9522. top1: 85.39. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9601. top1: 85.00. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9818. top1: 83.94. top5: 99.74. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9858. top1: 83.70. top5: 99.75. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9912. top1: 83.31. top5: 99.75. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9912. top1: 83.31. top5: 99.75. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0047. top1: 82.77. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0119. top1: 82.34. top5: 99.53. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0165. top1: 82.32. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0276. top1: 81.70. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0327. top1: 81.40. top5: 99.56. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0344. top1: 81.39. top5: 99.57. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0353. top1: 81.32. top5: 99.58. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0409. top1: 80.91. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0460. top1: 80.65. top5: 99.53. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0482. top1: 80.60. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 37.62it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0482. top1: 80.60. top5: 99.54. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0536. top1: 80.42. top5: 99.55. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0567. top1: 80.25. top5: 99.56. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0674. top1: 79.53. top5: 99.51. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0702. top1: 79.45. top5: 99.52. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0783. top1: 79.07. top5: 99.41. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0846. top1: 78.70. top5: 99.42. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0875. top1: 78.52. top5: 99.43. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0891. top1: 78.40. top5: 99.44. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0965. top1: 77.96. top5: 99.45. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1015. top1: 77.53. top5: 99.46. :  76%|███████▌  | 48/63 [00:02<00:00, 48.49it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1015. top1: 77.53. top5: 99.46. :  92%|█████████▏| 58/63 [00:02<00:00, 58.35it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1066. top1: 77.28. top5: 99.47. :  92%|█████████▏| 58/63 [00:02<00:00, 58.35it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1054. top1: 77.34. top5: 99.48. :  92%|█████████▏| 58/63 [00:02<00:00, 58.35it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1113. top1: 76.90. top5: 99.49. :  92%|█████████▏| 58/63 [00:02<00:00, 58.35it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1197. top1: 76.41. top5: 99.50. :  92%|█████████▏| 58/63 [00:02<00:00, 58.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1203. top1: 76.40. top5: 99.50. :  92%|█████████▏| 58/63 [00:02<00:00, 58.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1203. top1: 76.40. top5: 99.50. : 100%|██████████| 63/63 [00:02<00:00, 24.47it/s]
total : 5000  current step :  2400
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2401/5000. LR: 0.0341. Data: 2.00s. Batch: 2.13s. S_Loss: 0.9881. T_Loss: 5.7250. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2401/5000. LR: 0.0341. Data: 2.00s. Batch: 2.13s. S_Loss: 0.9881. T_Loss: 5.7250. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:31,  2.14s/it]Train Iter: 2402/5000. LR: 0.0341. Data: 1.13s. Batch: 1.26s. S_Loss: 0.9787. T_Loss: 5.5851. Mask: 0.9531. :   1%|          | 1/100 [00:02<03:31,  2.14s/it]Train Iter: 2402/5000. LR: 0.0341. Data: 1.13s. Batch: 1.26s. S_Loss: 0.9787. T_Loss: 5.5851. Mask: 0.9531. :   2%|▏         | 2/100 [00:02<01:48,  1.10s/it]Train Iter: 2403/5000. LR: 0.0341. Data: 0.75s. Batch: 0.88s. S_Loss: 1.0127. T_Loss: 5.2525. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:48,  1.10s/it]Train Iter: 2403/5000. LR: 0.0341. Data: 0.75s. Batch: 0.88s. S_Loss: 1.0127. T_Loss: 5.2525. Mask: 0.9375. :   3%|▎         | 3/100 [00:02<01:03,  1.52it/s]Train Iter: 2404/5000. LR: 0.0341. Data: 0.57s. Batch: 0.69s. S_Loss: 1.0401. T_Loss: 5.3761. Mask: 0.9297. :   3%|▎         | 3/100 [00:02<01:03,  1.52it/s]Train Iter: 2404/5000. LR: 0.0341. Data: 0.57s. Batch: 0.69s. S_Loss: 1.0401. T_Loss: 5.3761. Mask: 0.9297. :   4%|▍         | 4/100 [00:02<00:42,  2.23it/s]Train Iter: 2405/5000. LR: 0.0340. Data: 0.45s. Batch: 0.61s. S_Loss: 1.0411. T_Loss: 5.3699. Mask: 0.9187. :   4%|▍         | 4/100 [00:03<00:42,  2.23it/s]Train Iter: 2405/5000. LR: 0.0340. Data: 0.45s. Batch: 0.61s. S_Loss: 1.0411. T_Loss: 5.3699. Mask: 0.9187. :   5%|▌         | 5/100 [00:03<00:36,  2.59it/s]Train Iter: 2406/5000. LR: 0.0340. Data: 0.38s. Batch: 0.53s. S_Loss: 1.0312. T_Loss: 5.3382. Mask: 0.9115. :   5%|▌         | 5/100 [00:03<00:36,  2.59it/s]Train Iter: 2406/5000. LR: 0.0340. Data: 0.38s. Batch: 0.53s. S_Loss: 1.0312. T_Loss: 5.3382. Mask: 0.9115. :   6%|▌         | 6/100 [00:03<00:28,  3.34it/s]Train Iter: 2407/5000. LR: 0.0340. Data: 0.32s. Batch: 0.47s. S_Loss: 1.0341. T_Loss: 5.2099. Mask: 0.9062. :   6%|▌         | 6/100 [00:03<00:28,  3.34it/s]Train Iter: 2407/5000. LR: 0.0340. Data: 0.32s. Batch: 0.47s. S_Loss: 1.0341. T_Loss: 5.2099. Mask: 0.9062. :   7%|▋         | 7/100 [00:03<00:22,  4.08it/s]Train Iter: 2408/5000. LR: 0.0340. Data: 0.28s. Batch: 0.43s. S_Loss: 1.0202. T_Loss: 5.2231. Mask: 0.9102. :   7%|▋         | 7/100 [00:03<00:22,  4.08it/s]Train Iter: 2408/5000. LR: 0.0340. Data: 0.28s. Batch: 0.43s. S_Loss: 1.0202. T_Loss: 5.2231. Mask: 0.9102. :   8%|▊         | 8/100 [00:03<00:19,  4.79it/s]Train Iter: 2409/5000. LR: 0.0340. Data: 0.25s. Batch: 0.41s. S_Loss: 1.0140. T_Loss: 5.2668. Mask: 0.9097. :   8%|▊         | 8/100 [00:03<00:19,  4.79it/s]Train Iter: 2409/5000. LR: 0.0340. Data: 0.25s. Batch: 0.41s. S_Loss: 1.0140. T_Loss: 5.2668. Mask: 0.9097. :   9%|▉         | 9/100 [00:03<00:21,  4.25it/s]Train Iter: 2410/5000. LR: 0.0340. Data: 0.23s. Batch: 0.38s. S_Loss: 1.0075. T_Loss: 5.2152. Mask: 0.9062. :   9%|▉         | 9/100 [00:03<00:21,  4.25it/s]Train Iter: 2410/5000. LR: 0.0340. Data: 0.23s. Batch: 0.38s. S_Loss: 1.0075. T_Loss: 5.2152. Mask: 0.9062. :  10%|█         | 10/100 [00:03<00:17,  5.07it/s]Train Iter: 2411/5000. LR: 0.0339. Data: 0.21s. Batch: 0.36s. S_Loss: 1.0029. T_Loss: 5.1353. Mask: 0.9034. :  10%|█         | 10/100 [00:03<00:17,  5.07it/s]Train Iter: 2412/5000. LR: 0.0339. Data: 0.19s. Batch: 0.34s. S_Loss: 1.0017. T_Loss: 5.1755. Mask: 0.9010. :  11%|█         | 11/100 [00:04<00:17,  5.07it/s]Train Iter: 2412/5000. LR: 0.0339. Data: 0.19s. Batch: 0.34s. S_Loss: 1.0017. T_Loss: 5.1755. Mask: 0.9010. :  12%|█▏        | 12/100 [00:04<00:13,  6.69it/s]Train Iter: 2413/5000. LR: 0.0339. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9981. T_Loss: 5.1563. Mask: 0.9014. :  12%|█▏        | 12/100 [00:04<00:13,  6.69it/s]Train Iter: 2414/5000. LR: 0.0339. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9894. T_Loss: 5.1586. Mask: 0.9085. :  13%|█▎        | 13/100 [00:04<00:13,  6.69it/s]Train Iter: 2414/5000. LR: 0.0339. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9894. T_Loss: 5.1586. Mask: 0.9085. :  14%|█▍        | 14/100 [00:04<00:10,  7.89it/s]Train Iter: 2415/5000. LR: 0.0339. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9887. T_Loss: 5.1602. Mask: 0.9104. :  14%|█▍        | 14/100 [00:04<00:10,  7.89it/s]Train Iter: 2415/5000. LR: 0.0339. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9887. T_Loss: 5.1602. Mask: 0.9104. :  15%|█▌        | 15/100 [00:04<00:11,  7.25it/s]Train Iter: 2416/5000. LR: 0.0339. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9887. T_Loss: 5.1012. Mask: 0.9062. :  15%|█▌        | 15/100 [00:04<00:11,  7.25it/s]Train Iter: 2416/5000. LR: 0.0339. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9887. T_Loss: 5.1012. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:11,  7.56it/s]Train Iter: 2417/5000. LR: 0.0338. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9787. T_Loss: 5.0594. Mask: 0.9099. :  16%|█▌        | 16/100 [00:04<00:11,  7.56it/s]Train Iter: 2417/5000. LR: 0.0338. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9787. T_Loss: 5.0594. Mask: 0.9099. :  17%|█▋        | 17/100 [00:04<00:10,  7.81it/s]Train Iter: 2418/5000. LR: 0.0338. Data: 0.13s. Batch: 0.26s. S_Loss: 0.9812. T_Loss: 5.0793. Mask: 0.9132. :  17%|█▋        | 17/100 [00:04<00:10,  7.81it/s]Train Iter: 2418/5000. LR: 0.0338. Data: 0.13s. Batch: 0.26s. S_Loss: 0.9812. T_Loss: 5.0793. Mask: 0.9132. :  18%|█▊        | 18/100 [00:04<00:10,  7.57it/s]Train Iter: 2419/5000. LR: 0.0338. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9766. T_Loss: 5.0802. Mask: 0.9161. :  18%|█▊        | 18/100 [00:05<00:10,  7.57it/s]Train Iter: 2419/5000. LR: 0.0338. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9766. T_Loss: 5.0802. Mask: 0.9161. :  19%|█▉        | 19/100 [00:05<00:13,  5.86it/s]Train Iter: 2420/5000. LR: 0.0338. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9783. T_Loss: 5.0594. Mask: 0.9141. :  19%|█▉        | 19/100 [00:05<00:13,  5.86it/s]Train Iter: 2420/5000. LR: 0.0338. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9783. T_Loss: 5.0594. Mask: 0.9141. :  20%|██        | 20/100 [00:05<00:12,  6.44it/s]Train Iter: 2421/5000. LR: 0.0338. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9795. T_Loss: 5.0875. Mask: 0.9152. :  20%|██        | 20/100 [00:05<00:12,  6.44it/s]Train Iter: 2421/5000. LR: 0.0338. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9795. T_Loss: 5.0875. Mask: 0.9152. :  21%|██        | 21/100 [00:05<00:11,  6.72it/s]Train Iter: 2422/5000. LR: 0.0337. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9829. T_Loss: 5.0768. Mask: 0.9134. :  21%|██        | 21/100 [00:05<00:11,  6.72it/s]Train Iter: 2422/5000. LR: 0.0337. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9829. T_Loss: 5.0768. Mask: 0.9134. :  22%|██▏       | 22/100 [00:05<00:11,  7.03it/s]Train Iter: 2423/5000. LR: 0.0337. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9848. T_Loss: 5.0945. Mask: 0.9171. :  22%|██▏       | 22/100 [00:05<00:11,  7.03it/s]Train Iter: 2423/5000. LR: 0.0337. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9848. T_Loss: 5.0945. Mask: 0.9171. :  23%|██▎       | 23/100 [00:05<00:10,  7.18it/s]Train Iter: 2424/5000. LR: 0.0337. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9854. T_Loss: 5.0782. Mask: 0.9180. :  23%|██▎       | 23/100 [00:05<00:10,  7.18it/s]Train Iter: 2424/5000. LR: 0.0337. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9854. T_Loss: 5.0782. Mask: 0.9180. :  24%|██▍       | 24/100 [00:05<00:10,  7.25it/s]Train Iter: 2425/5000. LR: 0.0337. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9848. T_Loss: 5.0703. Mask: 0.9187. :  24%|██▍       | 24/100 [00:05<00:10,  7.25it/s]Train Iter: 2425/5000. LR: 0.0337. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9848. T_Loss: 5.0703. Mask: 0.9187. :  25%|██▌       | 25/100 [00:05<00:13,  5.36it/s]total : 5000  current step :  2401
total : 5000  current step :  2402
total : 5000  current step :  2403
total : 5000  current step :  2404
total : 5000  current step :  2405
total : 5000  current step :  2406
total : 5000  current step :  2407
total : 5000  current step :  2408
total : 5000  current step :  2409
total : 5000  current step :  2410
total : 5000  current step :  2411
total : 5000  current step :  2412
total : 5000  current step :  2413
total : 5000  current step :  2414
total : 5000  current step :  2415
total : 5000  current step :  2416
total : 5000  current step :  2417
total : 5000  current step :  2418
total : 5000  current step :  2419
total : 5000  current step :  2420
total : 5000  current step :  2421
total : 5000  current step :  2422
total : 5000  current step :  2423
total : 5000  current step :  2424
total : 5000  current step :  2425
Train Iter: 2426/5000. LR: 0.0337. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9851. T_Loss: 5.0417. Mask: 0.9135. :  25%|██▌       | 25/100 [00:07<00:13,  5.36it/s]Train Iter: 2426/5000. LR: 0.0337. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9851. T_Loss: 5.0417. Mask: 0.9135. :  26%|██▌       | 26/100 [00:07<00:51,  1.44it/s]Train Iter: 2427/5000. LR: 0.0337. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9879. T_Loss: 5.0417. Mask: 0.9132. :  26%|██▌       | 26/100 [00:08<00:51,  1.44it/s]Train Iter: 2427/5000. LR: 0.0337. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9879. T_Loss: 5.0417. Mask: 0.9132. :  27%|██▋       | 27/100 [00:08<00:38,  1.90it/s]Train Iter: 2428/5000. LR: 0.0336. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9874. T_Loss: 5.0145. Mask: 0.9141. :  27%|██▋       | 27/100 [00:08<00:38,  1.90it/s]Train Iter: 2428/5000. LR: 0.0336. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9874. T_Loss: 5.0145. Mask: 0.9141. :  28%|██▊       | 28/100 [00:08<00:29,  2.40it/s]Train Iter: 2429/5000. LR: 0.0336. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9895. T_Loss: 4.9886. Mask: 0.9127. :  28%|██▊       | 28/100 [00:08<00:29,  2.40it/s]Train Iter: 2429/5000. LR: 0.0336. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9895. T_Loss: 4.9886. Mask: 0.9127. :  29%|██▉       | 29/100 [00:08<00:29,  2.39it/s]Train Iter: 2430/5000. LR: 0.0336. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9943. T_Loss: 4.9779. Mask: 0.9125. :  29%|██▉       | 29/100 [00:08<00:29,  2.39it/s]Train Iter: 2430/5000. LR: 0.0336. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9943. T_Loss: 4.9779. Mask: 0.9125. :  30%|███       | 30/100 [00:08<00:23,  3.02it/s]Train Iter: 2431/5000. LR: 0.0336. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9889. T_Loss: 4.9363. Mask: 0.9153. :  30%|███       | 30/100 [00:08<00:23,  3.02it/s]Train Iter: 2431/5000. LR: 0.0336. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9889. T_Loss: 4.9363. Mask: 0.9153. :  31%|███       | 31/100 [00:08<00:18,  3.68it/s]Train Iter: 2432/5000. LR: 0.0336. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9902. T_Loss: 4.9471. Mask: 0.9170. :  31%|███       | 31/100 [00:08<00:18,  3.68it/s]Train Iter: 2432/5000. LR: 0.0336. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9902. T_Loss: 4.9471. Mask: 0.9170. :  32%|███▏      | 32/100 [00:08<00:15,  4.40it/s]Train Iter: 2433/5000. LR: 0.0336. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9886. T_Loss: 4.9244. Mask: 0.9176. :  32%|███▏      | 32/100 [00:09<00:15,  4.40it/s]Train Iter: 2433/5000. LR: 0.0336. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9886. T_Loss: 4.9244. Mask: 0.9176. :  33%|███▎      | 33/100 [00:09<00:13,  5.06it/s]Train Iter: 2434/5000. LR: 0.0335. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9910. T_Loss: 4.9310. Mask: 0.9173. :  33%|███▎      | 33/100 [00:09<00:13,  5.06it/s]Train Iter: 2434/5000. LR: 0.0335. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9910. T_Loss: 4.9310. Mask: 0.9173. :  34%|███▍      | 34/100 [00:09<00:11,  5.78it/s]Train Iter: 2435/5000. LR: 0.0335. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9918. T_Loss: 4.9298. Mask: 0.9161. :  34%|███▍      | 34/100 [00:09<00:11,  5.78it/s]Train Iter: 2435/5000. LR: 0.0335. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9918. T_Loss: 4.9298. Mask: 0.9161. :  35%|███▌      | 35/100 [00:09<00:13,  4.92it/s]Train Iter: 2436/5000. LR: 0.0335. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9911. T_Loss: 4.9243. Mask: 0.9167. :  35%|███▌      | 35/100 [00:09<00:13,  4.92it/s]Train Iter: 2436/5000. LR: 0.0335. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9911. T_Loss: 4.9243. Mask: 0.9167. :  36%|███▌      | 36/100 [00:09<00:11,  5.61it/s]Train Iter: 2437/5000. LR: 0.0335. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9953. T_Loss: 4.9171. Mask: 0.9130. :  36%|███▌      | 36/100 [00:09<00:11,  5.61it/s]Train Iter: 2437/5000. LR: 0.0335. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9953. T_Loss: 4.9171. Mask: 0.9130. :  37%|███▋      | 37/100 [00:09<00:10,  6.07it/s]Train Iter: 2438/5000. LR: 0.0335. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9952. T_Loss: 4.9208. Mask: 0.9120. :  37%|███▋      | 37/100 [00:09<00:10,  6.07it/s]Train Iter: 2438/5000. LR: 0.0335. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9952. T_Loss: 4.9208. Mask: 0.9120. :  38%|███▊      | 38/100 [00:09<00:09,  6.48it/s]Train Iter: 2439/5000. LR: 0.0335. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9930. T_Loss: 4.9192. Mask: 0.9143. :  38%|███▊      | 38/100 [00:10<00:09,  6.48it/s]Train Iter: 2439/5000. LR: 0.0335. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9930. T_Loss: 4.9192. Mask: 0.9143. :  39%|███▉      | 39/100 [00:10<00:11,  5.11it/s]Train Iter: 2440/5000. LR: 0.0334. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9913. T_Loss: 4.9018. Mask: 0.9164. :  39%|███▉      | 39/100 [00:10<00:11,  5.11it/s]Train Iter: 2440/5000. LR: 0.0334. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9913. T_Loss: 4.9018. Mask: 0.9164. :  40%|████      | 40/100 [00:10<00:10,  5.84it/s]Train Iter: 2441/5000. LR: 0.0334. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9926. T_Loss: 4.9102. Mask: 0.9162. :  40%|████      | 40/100 [00:10<00:10,  5.84it/s]Train Iter: 2441/5000. LR: 0.0334. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9926. T_Loss: 4.9102. Mask: 0.9162. :  41%|████      | 41/100 [00:10<00:09,  6.27it/s]Train Iter: 2442/5000. LR: 0.0334. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9915. T_Loss: 4.8797. Mask: 0.9159. :  41%|████      | 41/100 [00:10<00:09,  6.27it/s]Train Iter: 2442/5000. LR: 0.0334. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9915. T_Loss: 4.8797. Mask: 0.9159. :  42%|████▏     | 42/100 [00:10<00:08,  6.97it/s]Train Iter: 2443/5000. LR: 0.0334. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9896. T_Loss: 4.8632. Mask: 0.9164. :  42%|████▏     | 42/100 [00:10<00:08,  6.97it/s]Train Iter: 2443/5000. LR: 0.0334. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9896. T_Loss: 4.8632. Mask: 0.9164. :  43%|████▎     | 43/100 [00:10<00:07,  7.31it/s]Train Iter: 2444/5000. LR: 0.0334. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9918. T_Loss: 4.8583. Mask: 0.9162. :  43%|████▎     | 43/100 [00:10<00:07,  7.31it/s]Train Iter: 2444/5000. LR: 0.0334. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9918. T_Loss: 4.8583. Mask: 0.9162. :  44%|████▍     | 44/100 [00:10<00:07,  7.93it/s]Train Iter: 2445/5000. LR: 0.0333. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9913. T_Loss: 4.8553. Mask: 0.9160. :  44%|████▍     | 44/100 [00:10<00:07,  7.93it/s]Train Iter: 2445/5000. LR: 0.0333. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9913. T_Loss: 4.8553. Mask: 0.9160. :  45%|████▌     | 45/100 [00:10<00:06,  8.22it/s]Train Iter: 2446/5000. LR: 0.0333. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9904. T_Loss: 4.8471. Mask: 0.9158. :  45%|████▌     | 45/100 [00:10<00:06,  8.22it/s]Train Iter: 2446/5000. LR: 0.0333. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9904. T_Loss: 4.8471. Mask: 0.9158. :  46%|████▌     | 46/100 [00:10<00:06,  8.19it/s]Train Iter: 2447/5000. LR: 0.0333. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9909. T_Loss: 4.8366. Mask: 0.9149. :  46%|████▌     | 46/100 [00:11<00:06,  8.19it/s]Train Iter: 2447/5000. LR: 0.0333. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9909. T_Loss: 4.8366. Mask: 0.9149. :  47%|████▋     | 47/100 [00:11<00:06,  8.29it/s]Train Iter: 2448/5000. LR: 0.0333. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9910. T_Loss: 4.8395. Mask: 0.9160. :  47%|████▋     | 47/100 [00:11<00:06,  8.29it/s]Train Iter: 2448/5000. LR: 0.0333. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9910. T_Loss: 4.8395. Mask: 0.9160. :  48%|████▊     | 48/100 [00:11<00:06,  7.80it/s]Train Iter: 2449/5000. LR: 0.0333. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9938. T_Loss: 4.8306. Mask: 0.9165. :  48%|████▊     | 48/100 [00:11<00:06,  7.80it/s]Train Iter: 2449/5000. LR: 0.0333. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9938. T_Loss: 4.8306. Mask: 0.9165. :  49%|████▉     | 49/100 [00:11<00:09,  5.22it/s]Train Iter: 2450/5000. LR: 0.0333. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9947. T_Loss: 4.8258. Mask: 0.9175. :  49%|████▉     | 49/100 [00:11<00:09,  5.22it/s]Train Iter: 2450/5000. LR: 0.0333. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9947. T_Loss: 4.8258. Mask: 0.9175. :  50%|█████     | 50/100 [00:11<00:08,  5.94it/s]total : 5000  current step :  2426
total : 5000  current step :  2427
total : 5000  current step :  2428
total : 5000  current step :  2429
total : 5000  current step :  2430
total : 5000  current step :  2431
total : 5000  current step :  2432
total : 5000  current step :  2433
total : 5000  current step :  2434
total : 5000  current step :  2435
total : 5000  current step :  2436
total : 5000  current step :  2437
total : 5000  current step :  2438
total : 5000  current step :  2439
total : 5000  current step :  2440
total : 5000  current step :  2441
total : 5000  current step :  2442
total : 5000  current step :  2443
total : 5000  current step :  2444
total : 5000  current step :  2445
total : 5000  current step :  2446
total : 5000  current step :  2447
total : 5000  current step :  2448
total : 5000  current step :  2449
total : 5000  current step :  2450
Train Iter: 2451/5000. LR: 0.0332. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9984. T_Loss: 4.8328. Mask: 0.9179. :  50%|█████     | 50/100 [00:13<00:08,  5.94it/s]Train Iter: 2451/5000. LR: 0.0332. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9984. T_Loss: 4.8328. Mask: 0.9179. :  51%|█████     | 51/100 [00:13<00:33,  1.48it/s]Train Iter: 2452/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9995. T_Loss: 4.8381. Mask: 0.9177. :  51%|█████     | 51/100 [00:13<00:33,  1.48it/s]Train Iter: 2452/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9995. T_Loss: 4.8381. Mask: 0.9177. :  52%|█████▏    | 52/100 [00:13<00:24,  1.96it/s]Train Iter: 2453/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0035. T_Loss: 4.8327. Mask: 0.9180. :  52%|█████▏    | 52/100 [00:13<00:24,  1.96it/s]Train Iter: 2453/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0035. T_Loss: 4.8327. Mask: 0.9180. :  53%|█████▎    | 53/100 [00:13<00:18,  2.54it/s]Train Iter: 2454/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0042. T_Loss: 4.8503. Mask: 0.9178. :  53%|█████▎    | 53/100 [00:13<00:18,  2.54it/s]Train Iter: 2454/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0042. T_Loss: 4.8503. Mask: 0.9178. :  54%|█████▍    | 54/100 [00:13<00:14,  3.17it/s]Train Iter: 2455/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0033. T_Loss: 4.8361. Mask: 0.9187. :  54%|█████▍    | 54/100 [00:14<00:14,  3.17it/s]Train Iter: 2455/5000. LR: 0.0332. Data: 0.11s. Batch: 0.26s. S_Loss: 1.0033. T_Loss: 4.8361. Mask: 0.9187. :  55%|█████▌    | 55/100 [00:14<00:14,  3.21it/s]Train Iter: 2456/5000. LR: 0.0332. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0016. T_Loss: 4.8356. Mask: 0.9196. :  55%|█████▌    | 55/100 [00:14<00:14,  3.21it/s]Train Iter: 2456/5000. LR: 0.0332. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0016. T_Loss: 4.8356. Mask: 0.9196. :  56%|█████▌    | 56/100 [00:14<00:11,  3.98it/s]Train Iter: 2457/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9992. T_Loss: 4.8190. Mask: 0.9189. :  56%|█████▌    | 56/100 [00:14<00:11,  3.98it/s]Train Iter: 2457/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9992. T_Loss: 4.8190. Mask: 0.9189. :  57%|█████▋    | 57/100 [00:14<00:09,  4.58it/s]Train Iter: 2458/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9990. T_Loss: 4.8101. Mask: 0.9197. :  57%|█████▋    | 57/100 [00:14<00:09,  4.58it/s]Train Iter: 2458/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9990. T_Loss: 4.8101. Mask: 0.9197. :  58%|█████▊    | 58/100 [00:14<00:08,  5.00it/s]Train Iter: 2459/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9977. T_Loss: 4.8026. Mask: 0.9195. :  58%|█████▊    | 58/100 [00:14<00:08,  5.00it/s]Train Iter: 2459/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9977. T_Loss: 4.8026. Mask: 0.9195. :  59%|█████▉    | 59/100 [00:14<00:09,  4.29it/s]Train Iter: 2460/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9965. T_Loss: 4.7827. Mask: 0.9193. :  59%|█████▉    | 59/100 [00:15<00:09,  4.29it/s]Train Iter: 2460/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9965. T_Loss: 4.7827. Mask: 0.9193. :  60%|██████    | 60/100 [00:15<00:07,  5.01it/s]Train Iter: 2461/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9962. T_Loss: 4.7823. Mask: 0.9191. :  60%|██████    | 60/100 [00:15<00:07,  5.01it/s]Train Iter: 2461/5000. LR: 0.0331. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9962. T_Loss: 4.7823. Mask: 0.9191. :  61%|██████    | 61/100 [00:15<00:06,  5.62it/s]Train Iter: 2462/5000. LR: 0.0330. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9958. T_Loss: 4.7661. Mask: 0.9189. :  61%|██████    | 61/100 [00:15<00:06,  5.62it/s]Train Iter: 2462/5000. LR: 0.0330. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9958. T_Loss: 4.7661. Mask: 0.9189. :  62%|██████▏   | 62/100 [00:15<00:06,  6.19it/s]Train Iter: 2463/5000. LR: 0.0330. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9964. T_Loss: 4.7753. Mask: 0.9187. :  62%|██████▏   | 62/100 [00:15<00:06,  6.19it/s]Train Iter: 2463/5000. LR: 0.0330. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9964. T_Loss: 4.7753. Mask: 0.9187. :  63%|██████▎   | 63/100 [00:15<00:05,  6.77it/s]Train Iter: 2464/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9964. T_Loss: 4.7656. Mask: 0.9189. :  63%|██████▎   | 63/100 [00:15<00:05,  6.77it/s]Train Iter: 2464/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9964. T_Loss: 4.7656. Mask: 0.9189. :  64%|██████▍   | 64/100 [00:15<00:04,  7.24it/s]Train Iter: 2465/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9974. T_Loss: 4.7542. Mask: 0.9187. :  64%|██████▍   | 64/100 [00:15<00:04,  7.24it/s]Train Iter: 2465/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9974. T_Loss: 4.7542. Mask: 0.9187. :  65%|██████▌   | 65/100 [00:15<00:07,  4.67it/s]Train Iter: 2466/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9977. T_Loss: 4.7454. Mask: 0.9186. :  65%|██████▌   | 65/100 [00:16<00:07,  4.67it/s]Train Iter: 2466/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9977. T_Loss: 4.7454. Mask: 0.9186. :  66%|██████▌   | 66/100 [00:16<00:06,  5.31it/s]Train Iter: 2467/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9995. T_Loss: 4.7524. Mask: 0.9184. :  66%|██████▌   | 66/100 [00:16<00:06,  5.31it/s]Train Iter: 2467/5000. LR: 0.0330. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9995. T_Loss: 4.7524. Mask: 0.9184. :  67%|██████▋   | 67/100 [00:16<00:05,  6.15it/s]Train Iter: 2468/5000. LR: 0.0329. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0009. T_Loss: 4.7388. Mask: 0.9173. :  67%|██████▋   | 67/100 [00:16<00:05,  6.15it/s]Train Iter: 2469/5000. LR: 0.0329. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0012. T_Loss: 4.7291. Mask: 0.9185. :  68%|██████▊   | 68/100 [00:16<00:05,  6.15it/s]Train Iter: 2469/5000. LR: 0.0329. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0012. T_Loss: 4.7291. Mask: 0.9185. :  69%|██████▉   | 69/100 [00:16<00:05,  6.04it/s]Train Iter: 2470/5000. LR: 0.0329. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0006. T_Loss: 4.7186. Mask: 0.9183. :  69%|██████▉   | 69/100 [00:16<00:05,  6.04it/s]Train Iter: 2470/5000. LR: 0.0329. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0006. T_Loss: 4.7186. Mask: 0.9183. :  70%|███████   | 70/100 [00:16<00:04,  6.40it/s]Train Iter: 2471/5000. LR: 0.0329. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0019. T_Loss: 4.7259. Mask: 0.9177. :  70%|███████   | 70/100 [00:16<00:04,  6.40it/s]Train Iter: 2471/5000. LR: 0.0329. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0019. T_Loss: 4.7259. Mask: 0.9177. :  71%|███████   | 71/100 [00:16<00:04,  6.88it/s]Train Iter: 2472/5000. LR: 0.0329. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0029. T_Loss: 4.7084. Mask: 0.9167. :  71%|███████   | 71/100 [00:16<00:04,  6.88it/s]Train Iter: 2472/5000. LR: 0.0329. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0029. T_Loss: 4.7084. Mask: 0.9167. :  72%|███████▏  | 72/100 [00:16<00:03,  7.20it/s]Train Iter: 2473/5000. LR: 0.0328. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0035. T_Loss: 4.6991. Mask: 0.9161. :  72%|███████▏  | 72/100 [00:17<00:03,  7.20it/s]Train Iter: 2473/5000. LR: 0.0328. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0035. T_Loss: 4.6991. Mask: 0.9161. :  73%|███████▎  | 73/100 [00:17<00:03,  7.46it/s]Train Iter: 2474/5000. LR: 0.0328. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0030. T_Loss: 4.6975. Mask: 0.9160. :  73%|███████▎  | 73/100 [00:17<00:03,  7.46it/s]Train Iter: 2474/5000. LR: 0.0328. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0030. T_Loss: 4.6975. Mask: 0.9160. :  74%|███████▍  | 74/100 [00:17<00:03,  7.69it/s]Train Iter: 2475/5000. LR: 0.0328. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0041. T_Loss: 4.7080. Mask: 0.9167. :  74%|███████▍  | 74/100 [00:17<00:03,  7.69it/s]Train Iter: 2475/5000. LR: 0.0328. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0041. T_Loss: 4.7080. Mask: 0.9167. :  75%|███████▌  | 75/100 [00:17<00:04,  5.63it/s]total : 5000  current step :  2451
total : 5000  current step :  2452
total : 5000  current step :  2453
total : 5000  current step :  2454
total : 5000  current step :  2455
total : 5000  current step :  2456
total : 5000  current step :  2457
total : 5000  current step :  2458
total : 5000  current step :  2459
total : 5000  current step :  2460
total : 5000  current step :  2461
total : 5000  current step :  2462
total : 5000  current step :  2463
total : 5000  current step :  2464
total : 5000  current step :  2465
total : 5000  current step :  2466
total : 5000  current step :  2467
total : 5000  current step :  2468
total : 5000  current step :  2469
total : 5000  current step :  2470
total : 5000  current step :  2471
total : 5000  current step :  2472
total : 5000  current step :  2473
total : 5000  current step :  2474
total : 5000  current step :  2475
Train Iter: 2476/5000. LR: 0.0328. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0052. T_Loss: 4.7186. Mask: 0.9165. :  75%|███████▌  | 75/100 [00:19<00:04,  5.63it/s]Train Iter: 2476/5000. LR: 0.0328. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0052. T_Loss: 4.7186. Mask: 0.9165. :  76%|███████▌  | 76/100 [00:19<00:16,  1.47it/s]Train Iter: 2477/5000. LR: 0.0328. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0043. T_Loss: 4.7233. Mask: 0.9168. :  76%|███████▌  | 76/100 [00:19<00:16,  1.47it/s]Train Iter: 2477/5000. LR: 0.0328. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0043. T_Loss: 4.7233. Mask: 0.9168. :  77%|███████▋  | 77/100 [00:19<00:11,  1.95it/s]Train Iter: 2478/5000. LR: 0.0328. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0035. T_Loss: 4.7218. Mask: 0.9167. :  77%|███████▋  | 77/100 [00:19<00:11,  1.95it/s]Train Iter: 2478/5000. LR: 0.0328. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0035. T_Loss: 4.7218. Mask: 0.9167. :  78%|███████▊  | 78/100 [00:19<00:08,  2.53it/s]Train Iter: 2479/5000. LR: 0.0327. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0029. T_Loss: 4.7149. Mask: 0.9165. :  78%|███████▊  | 78/100 [00:19<00:08,  2.53it/s]Train Iter: 2479/5000. LR: 0.0327. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0029. T_Loss: 4.7149. Mask: 0.9165. :  79%|███████▉  | 79/100 [00:19<00:07,  2.86it/s]Train Iter: 2480/5000. LR: 0.0327. Data: 0.10s. Batch: 0.25s. S_Loss: 1.0029. T_Loss: 4.7171. Mask: 0.9164. :  79%|███████▉  | 79/100 [00:19<00:07,  2.86it/s]Train Iter: 2481/5000. LR: 0.0327. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0020. T_Loss: 4.7130. Mask: 0.9163. :  80%|████████  | 80/100 [00:19<00:06,  2.86it/s]Train Iter: 2481/5000. LR: 0.0327. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0020. T_Loss: 4.7130. Mask: 0.9163. :  81%|████████  | 81/100 [00:19<00:04,  4.48it/s]Train Iter: 2482/5000. LR: 0.0327. Data: 0.10s. Batch: 0.24s. S_Loss: 1.0020. T_Loss: 4.7107. Mask: 0.9165. :  81%|████████  | 81/100 [00:20<00:04,  4.48it/s]Train Iter: 2483/5000. LR: 0.0327. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0006. T_Loss: 4.7094. Mask: 0.9172. :  82%|████████▏ | 82/100 [00:20<00:04,  4.48it/s]Train Iter: 2483/5000. LR: 0.0327. Data: 0.09s. Batch: 0.24s. S_Loss: 1.0006. T_Loss: 4.7094. Mask: 0.9172. :  83%|████████▎ | 83/100 [00:20<00:02,  6.09it/s]Train Iter: 2484/5000. LR: 0.0327. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9988. T_Loss: 4.7039. Mask: 0.9178. :  83%|████████▎ | 83/100 [00:20<00:02,  6.09it/s]Train Iter: 2485/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9982. T_Loss: 4.6965. Mask: 0.9180. :  84%|████████▍ | 84/100 [00:20<00:02,  6.09it/s]Train Iter: 2485/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9982. T_Loss: 4.6965. Mask: 0.9180. :  85%|████████▌ | 85/100 [00:20<00:02,  5.75it/s]Train Iter: 2486/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9992. T_Loss: 4.6919. Mask: 0.9175. :  85%|████████▌ | 85/100 [00:20<00:02,  5.75it/s]Train Iter: 2486/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9992. T_Loss: 4.6919. Mask: 0.9175. :  86%|████████▌ | 86/100 [00:20<00:02,  6.10it/s]Train Iter: 2487/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9989. T_Loss: 4.7178. Mask: 0.9181. :  86%|████████▌ | 86/100 [00:20<00:02,  6.10it/s]Train Iter: 2487/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9989. T_Loss: 4.7178. Mask: 0.9181. :  87%|████████▋ | 87/100 [00:20<00:01,  6.53it/s]Train Iter: 2488/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9988. T_Loss: 4.7230. Mask: 0.9183. :  87%|████████▋ | 87/100 [00:20<00:01,  6.53it/s]Train Iter: 2488/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9988. T_Loss: 4.7230. Mask: 0.9183. :  88%|████████▊ | 88/100 [00:20<00:01,  6.75it/s]Train Iter: 2489/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9974. T_Loss: 4.7167. Mask: 0.9185. :  88%|████████▊ | 88/100 [00:21<00:01,  6.75it/s]Train Iter: 2489/5000. LR: 0.0326. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9974. T_Loss: 4.7167. Mask: 0.9185. :  89%|████████▉ | 89/100 [00:21<00:02,  4.88it/s]Train Iter: 2490/5000. LR: 0.0325. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9964. T_Loss: 4.7038. Mask: 0.9181. :  89%|████████▉ | 89/100 [00:21<00:02,  4.88it/s]Train Iter: 2490/5000. LR: 0.0325. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9964. T_Loss: 4.7038. Mask: 0.9181. :  90%|█████████ | 90/100 [00:21<00:01,  5.51it/s]Train Iter: 2491/5000. LR: 0.0325. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9962. T_Loss: 4.7100. Mask: 0.9186. :  90%|█████████ | 90/100 [00:21<00:01,  5.51it/s]Train Iter: 2491/5000. LR: 0.0325. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9962. T_Loss: 4.7100. Mask: 0.9186. :  91%|█████████ | 91/100 [00:21<00:01,  5.86it/s]Train Iter: 2492/5000. LR: 0.0325. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9953. T_Loss: 4.7089. Mask: 0.9192. :  91%|█████████ | 91/100 [00:21<00:01,  5.86it/s]Train Iter: 2492/5000. LR: 0.0325. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9953. T_Loss: 4.7089. Mask: 0.9192. :  92%|█████████▏| 92/100 [00:21<00:01,  6.51it/s]Train Iter: 2493/5000. LR: 0.0325. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9941. T_Loss: 4.7097. Mask: 0.9200. :  92%|█████████▏| 92/100 [00:21<00:01,  6.51it/s]Train Iter: 2493/5000. LR: 0.0325. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9941. T_Loss: 4.7097. Mask: 0.9200. :  93%|█████████▎| 93/100 [00:21<00:00,  7.09it/s]Train Iter: 2494/5000. LR: 0.0325. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9926. T_Loss: 4.7036. Mask: 0.9209. :  93%|█████████▎| 93/100 [00:21<00:00,  7.09it/s]Train Iter: 2494/5000. LR: 0.0325. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9926. T_Loss: 4.7036. Mask: 0.9209. :  94%|█████████▍| 94/100 [00:21<00:00,  7.55it/s]Train Iter: 2495/5000. LR: 0.0325. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9923. T_Loss: 4.6993. Mask: 0.9211. :  94%|█████████▍| 94/100 [00:21<00:00,  7.55it/s]Train Iter: 2495/5000. LR: 0.0325. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9923. T_Loss: 4.6993. Mask: 0.9211. :  95%|█████████▌| 95/100 [00:21<00:00,  8.03it/s]Train Iter: 2496/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9913. T_Loss: 4.6975. Mask: 0.9209. :  95%|█████████▌| 95/100 [00:22<00:00,  8.03it/s]Train Iter: 2496/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9913. T_Loss: 4.6975. Mask: 0.9209. :  96%|█████████▌| 96/100 [00:22<00:00,  8.40it/s]Train Iter: 2497/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9908. T_Loss: 4.6928. Mask: 0.9204. :  96%|█████████▌| 96/100 [00:22<00:00,  8.40it/s]Train Iter: 2498/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9902. T_Loss: 4.6878. Mask: 0.9206. :  97%|█████████▋| 97/100 [00:22<00:00,  8.40it/s]Train Iter: 2498/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9902. T_Loss: 4.6878. Mask: 0.9206. :  98%|█████████▊| 98/100 [00:22<00:00,  9.36it/s]Train Iter: 2499/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9908. T_Loss: 4.6860. Mask: 0.9201. :  98%|█████████▊| 98/100 [00:22<00:00,  9.36it/s]Train Iter: 2499/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9908. T_Loss: 4.6860. Mask: 0.9201. :  99%|█████████▉| 99/100 [00:22<00:00,  6.29it/s]Train Iter: 2500/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9916. T_Loss: 4.6927. Mask: 0.9206. :  99%|█████████▉| 99/100 [00:22<00:00,  6.29it/s]Train Iter: 2500/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9916. T_Loss: 4.6927. Mask: 0.9206. : 100%|██████████| 100/100 [00:22<00:00,  6.60it/s]Train Iter: 2500/5000. LR: 0.0324. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9916. T_Loss: 4.6927. Mask: 0.9206. : 100%|██████████| 100/100 [00:22<00:00,  4.41it/s]
total : 5000  current step :  2476
total : 5000  current step :  2477
total : 5000  current step :  2478
total : 5000  current step :  2479
total : 5000  current step :  2480
total : 5000  current step :  2481
total : 5000  current step :  2482
total : 5000  current step :  2483
total : 5000  current step :  2484
total : 5000  current step :  2485
total : 5000  current step :  2486
total : 5000  current step :  2487
total : 5000  current step :  2488
total : 5000  current step :  2489
total : 5000  current step :  2490
total : 5000  current step :  2491
total : 5000  current step :  2492
total : 5000  current step :  2493
total : 5000  current step :  2494
total : 5000  current step :  2495
total : 5000  current step :  2496
total : 5000  current step :  2497
total : 5000  current step :  2498
total : 5000  current step :  2499
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.9868. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.9868. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 0.9700. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9427. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9527. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9339. top1: 85.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9305. top1: 85.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9455. top1: 84.82. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9500. top1: 83.98. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9500. top1: 83.98. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9434. top1: 84.72. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9531. top1: 84.06. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9391. top1: 84.94. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9393. top1: 85.16. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9337. top1: 85.58. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9303. top1: 85.49. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9263. top1: 85.83. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9286. top1: 85.74. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9247. top1: 85.85. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9245. top1: 85.76. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9233. top1: 85.69. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.99it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9233. top1: 85.69. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9226. top1: 85.94. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9284. top1: 85.71. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9249. top1: 86.08. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9203. top1: 86.55. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9168. top1: 86.72. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9138. top1: 87.00. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9196. top1: 86.30. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9195. top1: 86.11. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9230. top1: 86.05. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9211. top1: 86.10. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9209. top1: 86.15. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9213. top1: 85.89. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 16.25it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9213. top1: 85.89. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9353. top1: 85.45. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9408. top1: 85.42. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9494. top1: 84.93. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9571. top1: 84.38. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9778. top1: 83.33. top5: 99.91. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s] Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9816. top1: 83.11. top5: 99.92. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9872. top1: 82.65. top5: 99.92. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0000. top1: 82.13. top5: 99.76. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0068. top1: 81.80. top5: 99.77. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0112. top1: 81.71. top5: 99.77. :  49%|████▉     | 31/63 [00:02<00:01, 28.87it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0112. top1: 81.71. top5: 99.77. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0221. top1: 81.03. top5: 99.78. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0274. top1: 80.74. top5: 99.78. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0293. top1: 80.68. top5: 99.79. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0300. top1: 80.56. top5: 99.79. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0350. top1: 80.10. top5: 99.80. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0395. top1: 79.85. top5: 99.73. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0418. top1: 79.75. top5: 99.74. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0469. top1: 79.59. top5: 99.74. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0498. top1: 79.44. top5: 99.75. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0603. top1: 78.80. top5: 99.75. :  65%|██████▌   | 41/63 [00:02<00:00, 39.05it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0603. top1: 78.80. top5: 99.75. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0628. top1: 78.73. top5: 99.76. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0706. top1: 78.42. top5: 99.76. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0769. top1: 78.07. top5: 99.77. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0794. top1: 77.90. top5: 99.77. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0808. top1: 77.79. top5: 99.78. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0881. top1: 77.36. top5: 99.78. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0933. top1: 76.83. top5: 99.78. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0981. top1: 76.59. top5: 99.79. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0970. top1: 76.67. top5: 99.79. :  81%|████████  | 51/63 [00:02<00:00, 48.92it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0970. top1: 76.67. top5: 99.79. :  95%|█████████▌| 60/63 [00:02<00:00, 55.29it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1028. top1: 76.23. top5: 99.80. :  95%|█████████▌| 60/63 [00:02<00:00, 55.29it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1109. top1: 75.76. top5: 99.80. :  95%|█████████▌| 60/63 [00:02<00:00, 55.29it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1114. top1: 75.75. top5: 99.80. :  95%|█████████▌| 60/63 [00:02<00:00, 55.29it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1114. top1: 75.75. top5: 99.80. : 100%|██████████| 63/63 [00:02<00:00, 24.64it/s]
total : 5000  current step :  2500
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2501/5000. LR: 0.0324. Data: 1.86s. Batch: 1.96s. S_Loss: 0.9666. T_Loss: 3.3121. Mask: 0.8750. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 2501/5000. LR: 0.0324. Data: 1.86s. Batch: 1.96s. S_Loss: 0.9666. T_Loss: 3.3121. Mask: 0.8750. :   1%|          | 1/100 [00:01<03:14,  1.97s/it]Train Iter: 2502/5000. LR: 0.0323. Data: 0.94s. Batch: 1.04s. S_Loss: 0.9018. T_Loss: 4.0767. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:14,  1.97s/it]Train Iter: 2502/5000. LR: 0.0323. Data: 0.94s. Batch: 1.04s. S_Loss: 0.9018. T_Loss: 4.0767. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:26,  1.13it/s]Train Iter: 2503/5000. LR: 0.0323. Data: 0.63s. Batch: 0.73s. S_Loss: 0.9494. T_Loss: 4.2549. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:26,  1.13it/s]Train Iter: 2503/5000. LR: 0.0323. Data: 0.63s. Batch: 0.73s. S_Loss: 0.9494. T_Loss: 4.2549. Mask: 0.9167. :   3%|▎         | 3/100 [00:02<00:51,  1.89it/s]total : 5000  current step :  2501
total : 5000  current step :  2502
total : 5000  current step :  2503
Train Iter: 2504/5000. LR: 0.0323. Data: 1.01s. Batch: 1.12s. S_Loss: 0.9490. T_Loss: 4.1511. Mask: 0.9141. :   3%|▎         | 3/100 [00:04<00:51,  1.89it/s]Train Iter: 2504/5000. LR: 0.0323. Data: 1.01s. Batch: 1.12s. S_Loss: 0.9490. T_Loss: 4.1511. Mask: 0.9141. :   4%|▍         | 4/100 [00:04<01:57,  1.22s/it]Train Iter: 2505/5000. LR: 0.0323. Data: 0.81s. Batch: 0.96s. S_Loss: 0.9414. T_Loss: 4.4064. Mask: 0.9250. :   4%|▍         | 4/100 [00:04<01:57,  1.22s/it]Train Iter: 2505/5000. LR: 0.0323. Data: 0.81s. Batch: 0.96s. S_Loss: 0.9414. T_Loss: 4.4064. Mask: 0.9250. :   5%|▌         | 5/100 [00:04<01:25,  1.11it/s]Train Iter: 2506/5000. LR: 0.0323. Data: 0.68s. Batch: 0.82s. S_Loss: 0.9402. T_Loss: 4.4209. Mask: 0.9167. :   5%|▌         | 5/100 [00:04<01:25,  1.11it/s]Train Iter: 2506/5000. LR: 0.0323. Data: 0.68s. Batch: 0.82s. S_Loss: 0.9402. T_Loss: 4.4209. Mask: 0.9167. :   6%|▌         | 6/100 [00:04<01:00,  1.57it/s]Train Iter: 2507/5000. LR: 0.0322. Data: 0.58s. Batch: 0.72s. S_Loss: 0.9434. T_Loss: 4.4465. Mask: 0.9286. :   6%|▌         | 6/100 [00:05<01:00,  1.57it/s]Train Iter: 2507/5000. LR: 0.0322. Data: 0.58s. Batch: 0.72s. S_Loss: 0.9434. T_Loss: 4.4465. Mask: 0.9286. :   7%|▋         | 7/100 [00:05<00:44,  2.10it/s]Train Iter: 2508/5000. LR: 0.0322. Data: 0.51s. Batch: 0.65s. S_Loss: 0.9409. T_Loss: 4.4559. Mask: 0.9336. :   7%|▋         | 7/100 [00:05<00:44,  2.10it/s]Train Iter: 2508/5000. LR: 0.0322. Data: 0.51s. Batch: 0.65s. S_Loss: 0.9409. T_Loss: 4.4559. Mask: 0.9336. :   8%|▊         | 8/100 [00:05<00:33,  2.72it/s]Train Iter: 2509/5000. LR: 0.0322. Data: 0.45s. Batch: 0.59s. S_Loss: 0.9370. T_Loss: 4.4158. Mask: 0.9306. :   8%|▊         | 8/100 [00:05<00:33,  2.72it/s]Train Iter: 2509/5000. LR: 0.0322. Data: 0.45s. Batch: 0.59s. S_Loss: 0.9370. T_Loss: 4.4158. Mask: 0.9306. :   9%|▉         | 9/100 [00:05<00:27,  3.35it/s]Train Iter: 2510/5000. LR: 0.0322. Data: 0.41s. Batch: 0.55s. S_Loss: 0.9337. T_Loss: 4.4411. Mask: 0.9344. :   9%|▉         | 9/100 [00:05<00:27,  3.35it/s]Train Iter: 2510/5000. LR: 0.0322. Data: 0.41s. Batch: 0.55s. S_Loss: 0.9337. T_Loss: 4.4411. Mask: 0.9344. :  10%|█         | 10/100 [00:05<00:22,  4.00it/s]Train Iter: 2511/5000. LR: 0.0322. Data: 0.37s. Batch: 0.51s. S_Loss: 0.9279. T_Loss: 4.3998. Mask: 0.9347. :  10%|█         | 10/100 [00:05<00:22,  4.00it/s]Train Iter: 2511/5000. LR: 0.0322. Data: 0.37s. Batch: 0.51s. S_Loss: 0.9279. T_Loss: 4.3998. Mask: 0.9347. :  11%|█         | 11/100 [00:05<00:18,  4.71it/s]Train Iter: 2512/5000. LR: 0.0322. Data: 0.34s. Batch: 0.48s. S_Loss: 0.9396. T_Loss: 4.5131. Mask: 0.9349. :  11%|█         | 11/100 [00:05<00:18,  4.71it/s]Train Iter: 2512/5000. LR: 0.0322. Data: 0.34s. Batch: 0.48s. S_Loss: 0.9396. T_Loss: 4.5131. Mask: 0.9349. :  12%|█▏        | 12/100 [00:05<00:15,  5.55it/s]Train Iter: 2513/5000. LR: 0.0321. Data: 0.31s. Batch: 0.45s. S_Loss: 0.9438. T_Loss: 4.5273. Mask: 0.9375. :  12%|█▏        | 12/100 [00:05<00:15,  5.55it/s]Train Iter: 2514/5000. LR: 0.0321. Data: 0.29s. Batch: 0.42s. S_Loss: 0.9396. T_Loss: 4.4906. Mask: 0.9353. :  13%|█▎        | 13/100 [00:05<00:15,  5.55it/s]Train Iter: 2514/5000. LR: 0.0321. Data: 0.29s. Batch: 0.42s. S_Loss: 0.9396. T_Loss: 4.4906. Mask: 0.9353. :  14%|█▍        | 14/100 [00:05<00:12,  7.01it/s]Train Iter: 2515/5000. LR: 0.0321. Data: 0.27s. Batch: 0.42s. S_Loss: 0.9434. T_Loss: 4.5595. Mask: 0.9313. :  14%|█▍        | 14/100 [00:06<00:12,  7.01it/s]Train Iter: 2515/5000. LR: 0.0321. Data: 0.27s. Batch: 0.42s. S_Loss: 0.9434. T_Loss: 4.5595. Mask: 0.9313. :  15%|█▌        | 15/100 [00:06<00:15,  5.40it/s]Train Iter: 2516/5000. LR: 0.0321. Data: 0.26s. Batch: 0.40s. S_Loss: 0.9386. T_Loss: 4.5517. Mask: 0.9297. :  15%|█▌        | 15/100 [00:06<00:15,  5.40it/s]Train Iter: 2516/5000. LR: 0.0321. Data: 0.26s. Batch: 0.40s. S_Loss: 0.9386. T_Loss: 4.5517. Mask: 0.9297. :  16%|█▌        | 16/100 [00:06<00:14,  5.84it/s]Train Iter: 2517/5000. LR: 0.0321. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9356. T_Loss: 4.5465. Mask: 0.9265. :  16%|█▌        | 16/100 [00:06<00:14,  5.84it/s]Train Iter: 2517/5000. LR: 0.0321. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9356. T_Loss: 4.5465. Mask: 0.9265. :  17%|█▋        | 17/100 [00:06<00:13,  6.23it/s]Train Iter: 2518/5000. LR: 0.0320. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9405. T_Loss: 4.5470. Mask: 0.9219. :  17%|█▋        | 17/100 [00:06<00:13,  6.23it/s]Train Iter: 2518/5000. LR: 0.0320. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9405. T_Loss: 4.5470. Mask: 0.9219. :  18%|█▊        | 18/100 [00:06<00:12,  6.50it/s]Train Iter: 2519/5000. LR: 0.0320. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9371. T_Loss: 4.5326. Mask: 0.9194. :  18%|█▊        | 18/100 [00:06<00:12,  6.50it/s]Train Iter: 2519/5000. LR: 0.0320. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9371. T_Loss: 4.5326. Mask: 0.9194. :  19%|█▉        | 19/100 [00:06<00:13,  5.84it/s]Train Iter: 2520/5000. LR: 0.0320. Data: 0.21s. Batch: 0.35s. S_Loss: 0.9452. T_Loss: 4.5804. Mask: 0.9219. :  19%|█▉        | 19/100 [00:07<00:13,  5.84it/s]Train Iter: 2520/5000. LR: 0.0320. Data: 0.21s. Batch: 0.35s. S_Loss: 0.9452. T_Loss: 4.5804. Mask: 0.9219. :  20%|██        | 20/100 [00:07<00:13,  5.76it/s]Train Iter: 2521/5000. LR: 0.0320. Data: 0.20s. Batch: 0.34s. S_Loss: 0.9495. T_Loss: 4.6191. Mask: 0.9226. :  20%|██        | 20/100 [00:07<00:13,  5.76it/s]Train Iter: 2521/5000. LR: 0.0320. Data: 0.20s. Batch: 0.34s. S_Loss: 0.9495. T_Loss: 4.6191. Mask: 0.9226. :  21%|██        | 21/100 [00:07<00:12,  6.49it/s]Train Iter: 2522/5000. LR: 0.0320. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9450. T_Loss: 4.6221. Mask: 0.9219. :  21%|██        | 21/100 [00:07<00:12,  6.49it/s]Train Iter: 2522/5000. LR: 0.0320. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9450. T_Loss: 4.6221. Mask: 0.9219. :  22%|██▏       | 22/100 [00:07<00:10,  7.10it/s]Train Iter: 2523/5000. LR: 0.0320. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9426. T_Loss: 4.6215. Mask: 0.9226. :  22%|██▏       | 22/100 [00:07<00:10,  7.10it/s]Train Iter: 2523/5000. LR: 0.0320. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9426. T_Loss: 4.6215. Mask: 0.9226. :  23%|██▎       | 23/100 [00:07<00:10,  7.34it/s]Train Iter: 2524/5000. LR: 0.0319. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9446. T_Loss: 4.6850. Mask: 0.9232. :  23%|██▎       | 23/100 [00:07<00:10,  7.34it/s]Train Iter: 2524/5000. LR: 0.0319. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9446. T_Loss: 4.6850. Mask: 0.9232. :  24%|██▍       | 24/100 [00:07<00:10,  7.43it/s]Train Iter: 2525/5000. LR: 0.0319. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9487. T_Loss: 4.7322. Mask: 0.9250. :  24%|██▍       | 24/100 [00:07<00:10,  7.43it/s]Train Iter: 2525/5000. LR: 0.0319. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9487. T_Loss: 4.7322. Mask: 0.9250. :  25%|██▌       | 25/100 [00:07<00:13,  5.63it/s]total : 5000  current step :  2504
total : 5000  current step :  2505
total : 5000  current step :  2506
total : 5000  current step :  2507
total : 5000  current step :  2508
total : 5000  current step :  2509
total : 5000  current step :  2510
total : 5000  current step :  2511
total : 5000  current step :  2512
total : 5000  current step :  2513
total : 5000  current step :  2514
total : 5000  current step :  2515
total : 5000  current step :  2516
total : 5000  current step :  2517
total : 5000  current step :  2518
total : 5000  current step :  2519
total : 5000  current step :  2520
total : 5000  current step :  2521
total : 5000  current step :  2522
total : 5000  current step :  2523
total : 5000  current step :  2524
total : 5000  current step :  2525
Train Iter: 2526/5000. LR: 0.0319. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9516. T_Loss: 4.7395. Mask: 0.9255. :  25%|██▌       | 25/100 [00:09<00:13,  5.63it/s]Train Iter: 2526/5000. LR: 0.0319. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9516. T_Loss: 4.7395. Mask: 0.9255. :  26%|██▌       | 26/100 [00:09<00:57,  1.29it/s]Train Iter: 2527/5000. LR: 0.0319. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9508. T_Loss: 4.7472. Mask: 0.9259. :  26%|██▌       | 26/100 [00:10<00:57,  1.29it/s]Train Iter: 2527/5000. LR: 0.0319. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9508. T_Loss: 4.7472. Mask: 0.9259. :  27%|██▋       | 27/100 [00:10<00:42,  1.72it/s]Train Iter: 2528/5000. LR: 0.0319. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9502. T_Loss: 4.7424. Mask: 0.9252. :  27%|██▋       | 27/100 [00:10<00:42,  1.72it/s]Train Iter: 2528/5000. LR: 0.0319. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9502. T_Loss: 4.7424. Mask: 0.9252. :  28%|██▊       | 28/100 [00:10<00:31,  2.26it/s]Train Iter: 2529/5000. LR: 0.0318. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9503. T_Loss: 4.7680. Mask: 0.9246. :  28%|██▊       | 28/100 [00:10<00:31,  2.26it/s]Train Iter: 2529/5000. LR: 0.0318. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9503. T_Loss: 4.7680. Mask: 0.9246. :  29%|██▉       | 29/100 [00:10<00:24,  2.88it/s]Train Iter: 2530/5000. LR: 0.0318. Data: 0.21s. Batch: 0.35s. S_Loss: 0.9518. T_Loss: 4.8038. Mask: 0.9219. :  29%|██▉       | 29/100 [00:10<00:24,  2.88it/s]Train Iter: 2530/5000. LR: 0.0318. Data: 0.21s. Batch: 0.35s. S_Loss: 0.9518. T_Loss: 4.8038. Mask: 0.9219. :  30%|███       | 30/100 [00:10<00:19,  3.59it/s]Train Iter: 2531/5000. LR: 0.0318. Data: 0.20s. Batch: 0.34s. S_Loss: 0.9519. T_Loss: 4.8200. Mask: 0.9214. :  30%|███       | 30/100 [00:10<00:19,  3.59it/s]Train Iter: 2531/5000. LR: 0.0318. Data: 0.20s. Batch: 0.34s. S_Loss: 0.9519. T_Loss: 4.8200. Mask: 0.9214. :  31%|███       | 31/100 [00:10<00:16,  4.30it/s]Train Iter: 2532/5000. LR: 0.0318. Data: 0.20s. Batch: 0.33s. S_Loss: 0.9554. T_Loss: 4.8377. Mask: 0.9229. :  31%|███       | 31/100 [00:10<00:16,  4.30it/s]Train Iter: 2532/5000. LR: 0.0318. Data: 0.20s. Batch: 0.33s. S_Loss: 0.9554. T_Loss: 4.8377. Mask: 0.9229. :  32%|███▏      | 32/100 [00:10<00:14,  4.81it/s]Train Iter: 2533/5000. LR: 0.0318. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9523. T_Loss: 4.8257. Mask: 0.9233. :  32%|███▏      | 32/100 [00:10<00:14,  4.81it/s]Train Iter: 2533/5000. LR: 0.0318. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9523. T_Loss: 4.8257. Mask: 0.9233. :  33%|███▎      | 33/100 [00:10<00:12,  5.39it/s]Train Iter: 2534/5000. LR: 0.0318. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9576. T_Loss: 4.8663. Mask: 0.9246. :  33%|███▎      | 33/100 [00:11<00:12,  5.39it/s]Train Iter: 2534/5000. LR: 0.0318. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9576. T_Loss: 4.8663. Mask: 0.9246. :  34%|███▍      | 34/100 [00:11<00:11,  5.91it/s]Train Iter: 2535/5000. LR: 0.0317. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9608. T_Loss: 4.8631. Mask: 0.9241. :  34%|███▍      | 34/100 [00:11<00:11,  5.91it/s]Train Iter: 2535/5000. LR: 0.0317. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9608. T_Loss: 4.8631. Mask: 0.9241. :  35%|███▌      | 35/100 [00:11<00:14,  4.50it/s]Train Iter: 2536/5000. LR: 0.0317. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9613. T_Loss: 4.8407. Mask: 0.9219. :  35%|███▌      | 35/100 [00:11<00:14,  4.50it/s]Train Iter: 2536/5000. LR: 0.0317. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9613. T_Loss: 4.8407. Mask: 0.9219. :  36%|███▌      | 36/100 [00:11<00:12,  5.14it/s]Train Iter: 2537/5000. LR: 0.0317. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9630. T_Loss: 4.8586. Mask: 0.9215. :  36%|███▌      | 36/100 [00:11<00:12,  5.14it/s]Train Iter: 2537/5000. LR: 0.0317. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9630. T_Loss: 4.8586. Mask: 0.9215. :  37%|███▋      | 37/100 [00:11<00:11,  5.71it/s]Train Iter: 2538/5000. LR: 0.0317. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9653. T_Loss: 4.8640. Mask: 0.9202. :  37%|███▋      | 37/100 [00:11<00:11,  5.71it/s]Train Iter: 2538/5000. LR: 0.0317. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9653. T_Loss: 4.8640. Mask: 0.9202. :  38%|███▊      | 38/100 [00:11<00:09,  6.23it/s]Train Iter: 2539/5000. LR: 0.0317. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9654. T_Loss: 4.8743. Mask: 0.9207. :  38%|███▊      | 38/100 [00:11<00:09,  6.23it/s]Train Iter: 2539/5000. LR: 0.0317. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9654. T_Loss: 4.8743. Mask: 0.9207. :  39%|███▉      | 39/100 [00:11<00:11,  5.54it/s]Train Iter: 2540/5000. LR: 0.0317. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9689. T_Loss: 4.8794. Mask: 0.9203. :  39%|███▉      | 39/100 [00:12<00:11,  5.54it/s]Train Iter: 2540/5000. LR: 0.0317. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9689. T_Loss: 4.8794. Mask: 0.9203. :  40%|████      | 40/100 [00:12<00:09,  6.39it/s]Train Iter: 2541/5000. LR: 0.0316. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9668. T_Loss: 4.8779. Mask: 0.9207. :  40%|████      | 40/100 [00:12<00:09,  6.39it/s]Train Iter: 2541/5000. LR: 0.0316. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9668. T_Loss: 4.8779. Mask: 0.9207. :  41%|████      | 41/100 [00:12<00:08,  6.73it/s]Train Iter: 2542/5000. LR: 0.0316. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9698. T_Loss: 4.8764. Mask: 0.9182. :  41%|████      | 41/100 [00:12<00:08,  6.73it/s]Train Iter: 2542/5000. LR: 0.0316. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9698. T_Loss: 4.8764. Mask: 0.9182. :  42%|████▏     | 42/100 [00:12<00:08,  7.15it/s]Train Iter: 2543/5000. LR: 0.0316. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9691. T_Loss: 4.8865. Mask: 0.9186. :  42%|████▏     | 42/100 [00:12<00:08,  7.15it/s]Train Iter: 2543/5000. LR: 0.0316. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9691. T_Loss: 4.8865. Mask: 0.9186. :  43%|████▎     | 43/100 [00:12<00:07,  7.27it/s]Train Iter: 2544/5000. LR: 0.0316. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9684. T_Loss: 4.8738. Mask: 0.9183. :  43%|████▎     | 43/100 [00:12<00:07,  7.27it/s]Train Iter: 2544/5000. LR: 0.0316. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9684. T_Loss: 4.8738. Mask: 0.9183. :  44%|████▍     | 44/100 [00:12<00:07,  7.21it/s]Train Iter: 2545/5000. LR: 0.0316. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9710. T_Loss: 4.8955. Mask: 0.9194. :  44%|████▍     | 44/100 [00:12<00:07,  7.21it/s]Train Iter: 2545/5000. LR: 0.0316. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9710. T_Loss: 4.8955. Mask: 0.9194. :  45%|████▌     | 45/100 [00:12<00:09,  5.97it/s]Train Iter: 2546/5000. LR: 0.0315. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9706. T_Loss: 4.8765. Mask: 0.9185. :  45%|████▌     | 45/100 [00:12<00:09,  5.97it/s]Train Iter: 2546/5000. LR: 0.0315. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9706. T_Loss: 4.8765. Mask: 0.9185. :  46%|████▌     | 46/100 [00:12<00:08,  6.67it/s]Train Iter: 2547/5000. LR: 0.0315. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9724. T_Loss: 4.8821. Mask: 0.9182. :  46%|████▌     | 46/100 [00:13<00:08,  6.67it/s]Train Iter: 2547/5000. LR: 0.0315. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9724. T_Loss: 4.8821. Mask: 0.9182. :  47%|████▋     | 47/100 [00:13<00:07,  7.25it/s]Train Iter: 2548/5000. LR: 0.0315. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9729. T_Loss: 4.8736. Mask: 0.9167. :  47%|████▋     | 47/100 [00:13<00:07,  7.25it/s]Train Iter: 2548/5000. LR: 0.0315. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9729. T_Loss: 4.8736. Mask: 0.9167. :  48%|████▊     | 48/100 [00:13<00:06,  7.87it/s]Train Iter: 2549/5000. LR: 0.0315. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9739. T_Loss: 4.8724. Mask: 0.9152. :  48%|████▊     | 48/100 [00:13<00:06,  7.87it/s]Train Iter: 2549/5000. LR: 0.0315. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9739. T_Loss: 4.8724. Mask: 0.9152. :  49%|████▉     | 49/100 [00:13<00:09,  5.43it/s]Train Iter: 2550/5000. LR: 0.0315. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9757. T_Loss: 4.8639. Mask: 0.9137. :  49%|████▉     | 49/100 [00:13<00:09,  5.43it/s]Train Iter: 2550/5000. LR: 0.0315. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9757. T_Loss: 4.8639. Mask: 0.9137. :  50%|█████     | 50/100 [00:13<00:08,  6.00it/s]total : 5000  current step :  2526
total : 5000  current step :  2527
total : 5000  current step :  2528
total : 5000  current step :  2529
total : 5000  current step :  2530
total : 5000  current step :  2531
total : 5000  current step :  2532
total : 5000  current step :  2533
total : 5000  current step :  2534
total : 5000  current step :  2535
total : 5000  current step :  2536
total : 5000  current step :  2537
total : 5000  current step :  2538
total : 5000  current step :  2539
total : 5000  current step :  2540
total : 5000  current step :  2541
total : 5000  current step :  2542
total : 5000  current step :  2543
total : 5000  current step :  2544
total : 5000  current step :  2545
total : 5000  current step :  2546
total : 5000  current step :  2547
total : 5000  current step :  2548
total : 5000  current step :  2549
total : 5000  current step :  2550
Train Iter: 2551/5000. LR: 0.0315. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9759. T_Loss: 4.8513. Mask: 0.9112. :  50%|█████     | 50/100 [00:15<00:08,  6.00it/s]Train Iter: 2551/5000. LR: 0.0315. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9759. T_Loss: 4.8513. Mask: 0.9112. :  51%|█████     | 51/100 [00:15<00:36,  1.34it/s]Train Iter: 2552/5000. LR: 0.0314. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9774. T_Loss: 4.8576. Mask: 0.9111. :  51%|█████     | 51/100 [00:15<00:36,  1.34it/s]Train Iter: 2552/5000. LR: 0.0314. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9774. T_Loss: 4.8576. Mask: 0.9111. :  52%|█████▏    | 52/100 [00:15<00:27,  1.77it/s]Train Iter: 2553/5000. LR: 0.0314. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9802. T_Loss: 4.8698. Mask: 0.9104. :  52%|█████▏    | 52/100 [00:15<00:27,  1.77it/s]Train Iter: 2553/5000. LR: 0.0314. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9802. T_Loss: 4.8698. Mask: 0.9104. :  53%|█████▎    | 53/100 [00:15<00:20,  2.26it/s]Train Iter: 2554/5000. LR: 0.0314. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9817. T_Loss: 4.8620. Mask: 0.9091. :  53%|█████▎    | 53/100 [00:16<00:20,  2.26it/s]Train Iter: 2554/5000. LR: 0.0314. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9817. T_Loss: 4.8620. Mask: 0.9091. :  54%|█████▍    | 54/100 [00:16<00:16,  2.83it/s]Train Iter: 2555/5000. LR: 0.0314. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9821. T_Loss: 4.8512. Mask: 0.9085. :  54%|█████▍    | 54/100 [00:16<00:16,  2.83it/s]Train Iter: 2555/5000. LR: 0.0314. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9821. T_Loss: 4.8512. Mask: 0.9085. :  55%|█████▌    | 55/100 [00:16<00:15,  2.89it/s]Train Iter: 2556/5000. LR: 0.0314. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9821. T_Loss: 4.8489. Mask: 0.9090. :  55%|█████▌    | 55/100 [00:16<00:15,  2.89it/s]Train Iter: 2556/5000. LR: 0.0314. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9821. T_Loss: 4.8489. Mask: 0.9090. :  56%|█████▌    | 56/100 [00:16<00:12,  3.55it/s]Train Iter: 2557/5000. LR: 0.0313. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9825. T_Loss: 4.8535. Mask: 0.9090. :  56%|█████▌    | 56/100 [00:16<00:12,  3.55it/s]Train Iter: 2557/5000. LR: 0.0313. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9825. T_Loss: 4.8535. Mask: 0.9090. :  57%|█████▋    | 57/100 [00:16<00:10,  4.25it/s]Train Iter: 2558/5000. LR: 0.0313. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9828. T_Loss: 4.8576. Mask: 0.9084. :  57%|█████▋    | 57/100 [00:16<00:10,  4.25it/s]Train Iter: 2559/5000. LR: 0.0313. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9808. T_Loss: 4.8448. Mask: 0.9089. :  58%|█████▊    | 58/100 [00:17<00:09,  4.25it/s]Train Iter: 2559/5000. LR: 0.0313. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9808. T_Loss: 4.8448. Mask: 0.9089. :  59%|█████▉    | 59/100 [00:17<00:09,  4.36it/s]Train Iter: 2560/5000. LR: 0.0313. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9814. T_Loss: 4.8652. Mask: 0.9094. :  59%|█████▉    | 59/100 [00:17<00:09,  4.36it/s]Train Iter: 2560/5000. LR: 0.0313. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9814. T_Loss: 4.8652. Mask: 0.9094. :  60%|██████    | 60/100 [00:17<00:08,  4.80it/s]Train Iter: 2561/5000. LR: 0.0313. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9795. T_Loss: 4.8507. Mask: 0.9088. :  60%|██████    | 60/100 [00:17<00:08,  4.80it/s]Train Iter: 2561/5000. LR: 0.0313. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9795. T_Loss: 4.8507. Mask: 0.9088. :  61%|██████    | 61/100 [00:17<00:07,  5.31it/s]Train Iter: 2562/5000. LR: 0.0313. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9810. T_Loss: 4.8571. Mask: 0.9098. :  61%|██████    | 61/100 [00:17<00:07,  5.31it/s]Train Iter: 2562/5000. LR: 0.0313. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9810. T_Loss: 4.8571. Mask: 0.9098. :  62%|██████▏   | 62/100 [00:17<00:06,  5.75it/s]Train Iter: 2563/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9808. T_Loss: 4.8669. Mask: 0.9102. :  62%|██████▏   | 62/100 [00:17<00:06,  5.75it/s]Train Iter: 2563/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9808. T_Loss: 4.8669. Mask: 0.9102. :  63%|██████▎   | 63/100 [00:17<00:05,  6.28it/s]Train Iter: 2564/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9820. T_Loss: 4.8701. Mask: 0.9102. :  63%|██████▎   | 63/100 [00:17<00:05,  6.28it/s]Train Iter: 2564/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9820. T_Loss: 4.8701. Mask: 0.9102. :  64%|██████▍   | 64/100 [00:17<00:05,  6.41it/s]Train Iter: 2565/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9831. T_Loss: 4.8767. Mask: 0.9082. :  64%|██████▍   | 64/100 [00:18<00:05,  6.41it/s]Train Iter: 2565/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9831. T_Loss: 4.8767. Mask: 0.9082. :  65%|██████▌   | 65/100 [00:18<00:07,  4.46it/s]Train Iter: 2566/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9818. T_Loss: 4.8671. Mask: 0.9072. :  65%|██████▌   | 65/100 [00:18<00:07,  4.46it/s]Train Iter: 2566/5000. LR: 0.0312. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9818. T_Loss: 4.8671. Mask: 0.9072. :  66%|██████▌   | 66/100 [00:18<00:06,  5.15it/s]Train Iter: 2567/5000. LR: 0.0312. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9799. T_Loss: 4.8528. Mask: 0.9076. :  66%|██████▌   | 66/100 [00:18<00:06,  5.15it/s]Train Iter: 2568/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9788. T_Loss: 4.8421. Mask: 0.9081. :  67%|██████▋   | 67/100 [00:18<00:06,  5.15it/s]Train Iter: 2568/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9788. T_Loss: 4.8421. Mask: 0.9081. :  68%|██████▊   | 68/100 [00:18<00:04,  6.81it/s]Train Iter: 2569/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9791. T_Loss: 4.8300. Mask: 0.9081. :  68%|██████▊   | 68/100 [00:18<00:04,  6.81it/s]Train Iter: 2569/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9791. T_Loss: 4.8300. Mask: 0.9081. :  69%|██████▉   | 69/100 [00:18<00:05,  5.33it/s]Train Iter: 2570/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9793. T_Loss: 4.8314. Mask: 0.9080. :  69%|██████▉   | 69/100 [00:18<00:05,  5.33it/s]Train Iter: 2570/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9793. T_Loss: 4.8314. Mask: 0.9080. :  70%|███████   | 70/100 [00:18<00:05,  5.81it/s]Train Iter: 2571/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9798. T_Loss: 4.8257. Mask: 0.9080. :  70%|███████   | 70/100 [00:19<00:05,  5.81it/s]Train Iter: 2571/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9798. T_Loss: 4.8257. Mask: 0.9080. :  71%|███████   | 71/100 [00:19<00:04,  6.30it/s]Train Iter: 2572/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9797. T_Loss: 4.8256. Mask: 0.9084. :  71%|███████   | 71/100 [00:19<00:04,  6.30it/s]Train Iter: 2572/5000. LR: 0.0311. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9797. T_Loss: 4.8256. Mask: 0.9084. :  72%|███████▏  | 72/100 [00:19<00:04,  6.72it/s]Train Iter: 2573/5000. LR: 0.0311. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9793. T_Loss: 4.8153. Mask: 0.9092. :  72%|███████▏  | 72/100 [00:19<00:04,  6.72it/s]Train Iter: 2573/5000. LR: 0.0311. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9793. T_Loss: 4.8153. Mask: 0.9092. :  73%|███████▎  | 73/100 [00:19<00:03,  7.09it/s]Train Iter: 2574/5000. LR: 0.0310. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9774. T_Loss: 4.8030. Mask: 0.9092. :  73%|███████▎  | 73/100 [00:19<00:03,  7.09it/s]Train Iter: 2574/5000. LR: 0.0310. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9774. T_Loss: 4.8030. Mask: 0.9092. :  74%|███████▍  | 74/100 [00:19<00:03,  7.36it/s]Train Iter: 2575/5000. LR: 0.0310. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9771. T_Loss: 4.7927. Mask: 0.9096. :  74%|███████▍  | 74/100 [00:19<00:03,  7.36it/s]Train Iter: 2575/5000. LR: 0.0310. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9771. T_Loss: 4.7927. Mask: 0.9096. :  75%|███████▌  | 75/100 [00:19<00:04,  5.25it/s]total : 5000  current step :  2551
total : 5000  current step :  2552
total : 5000  current step :  2553
total : 5000  current step :  2554
total : 5000  current step :  2555
total : 5000  current step :  2556
total : 5000  current step :  2557
total : 5000  current step :  2558
total : 5000  current step :  2559
total : 5000  current step :  2560
total : 5000  current step :  2561
total : 5000  current step :  2562
total : 5000  current step :  2563
total : 5000  current step :  2564
total : 5000  current step :  2565
total : 5000  current step :  2566
total : 5000  current step :  2567
total : 5000  current step :  2568
total : 5000  current step :  2569
total : 5000  current step :  2570
total : 5000  current step :  2571
total : 5000  current step :  2572
total : 5000  current step :  2573
total : 5000  current step :  2574
total : 5000  current step :  2575
Train Iter: 2576/5000. LR: 0.0310. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9752. T_Loss: 4.7754. Mask: 0.9095. :  75%|███████▌  | 75/100 [00:21<00:04,  5.25it/s]Train Iter: 2576/5000. LR: 0.0310. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9752. T_Loss: 4.7754. Mask: 0.9095. :  76%|███████▌  | 76/100 [00:21<00:18,  1.31it/s]Train Iter: 2577/5000. LR: 0.0310. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9763. T_Loss: 4.7687. Mask: 0.9095. :  76%|███████▌  | 76/100 [00:22<00:18,  1.31it/s]Train Iter: 2577/5000. LR: 0.0310. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9763. T_Loss: 4.7687. Mask: 0.9095. :  77%|███████▋  | 77/100 [00:22<00:13,  1.73it/s]Train Iter: 2578/5000. LR: 0.0310. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9749. T_Loss: 4.7663. Mask: 0.9107. :  77%|███████▋  | 77/100 [00:22<00:13,  1.73it/s]Train Iter: 2578/5000. LR: 0.0310. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9749. T_Loss: 4.7663. Mask: 0.9107. :  78%|███████▊  | 78/100 [00:22<00:09,  2.28it/s]Train Iter: 2579/5000. LR: 0.0309. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9734. T_Loss: 4.7522. Mask: 0.9106. :  78%|███████▊  | 78/100 [00:22<00:09,  2.28it/s]Train Iter: 2579/5000. LR: 0.0309. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9734. T_Loss: 4.7522. Mask: 0.9106. :  79%|███████▉  | 79/100 [00:22<00:07,  2.76it/s]Train Iter: 2580/5000. LR: 0.0309. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9728. T_Loss: 4.7527. Mask: 0.9113. :  79%|███████▉  | 79/100 [00:22<00:07,  2.76it/s]Train Iter: 2580/5000. LR: 0.0309. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9728. T_Loss: 4.7527. Mask: 0.9113. :  80%|████████  | 80/100 [00:22<00:05,  3.48it/s]Train Iter: 2581/5000. LR: 0.0309. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9735. T_Loss: 4.7564. Mask: 0.9120. :  80%|████████  | 80/100 [00:22<00:05,  3.48it/s]Train Iter: 2581/5000. LR: 0.0309. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9735. T_Loss: 4.7564. Mask: 0.9120. :  81%|████████  | 81/100 [00:22<00:04,  4.32it/s]Train Iter: 2582/5000. LR: 0.0309. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9747. T_Loss: 4.7495. Mask: 0.9120. :  81%|████████  | 81/100 [00:22<00:04,  4.32it/s]Train Iter: 2583/5000. LR: 0.0309. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9744. T_Loss: 4.7465. Mask: 0.9130. :  82%|████████▏ | 82/100 [00:22<00:04,  4.32it/s]Train Iter: 2583/5000. LR: 0.0309. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9744. T_Loss: 4.7465. Mask: 0.9130. :  83%|████████▎ | 83/100 [00:22<00:02,  5.78it/s]Train Iter: 2584/5000. LR: 0.0309. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9735. T_Loss: 4.7419. Mask: 0.9133. :  83%|████████▎ | 83/100 [00:22<00:02,  5.78it/s]Train Iter: 2584/5000. LR: 0.0309. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9735. T_Loss: 4.7419. Mask: 0.9133. :  84%|████████▍ | 84/100 [00:22<00:02,  6.24it/s]Train Iter: 2585/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9727. T_Loss: 4.7329. Mask: 0.9132. :  84%|████████▍ | 84/100 [00:23<00:02,  6.24it/s]Train Iter: 2585/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9727. T_Loss: 4.7329. Mask: 0.9132. :  85%|████████▌ | 85/100 [00:23<00:03,  4.79it/s]Train Iter: 2586/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9720. T_Loss: 4.7204. Mask: 0.9135. :  85%|████████▌ | 85/100 [00:23<00:03,  4.79it/s]Train Iter: 2586/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9720. T_Loss: 4.7204. Mask: 0.9135. :  86%|████████▌ | 86/100 [00:23<00:02,  5.27it/s]Train Iter: 2587/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9712. T_Loss: 4.7085. Mask: 0.9127. :  86%|████████▌ | 86/100 [00:23<00:02,  5.27it/s]Train Iter: 2587/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9712. T_Loss: 4.7085. Mask: 0.9127. :  87%|████████▋ | 87/100 [00:23<00:02,  6.02it/s]Train Iter: 2588/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9725. T_Loss: 4.6994. Mask: 0.9116. :  87%|████████▋ | 87/100 [00:23<00:02,  6.02it/s]Train Iter: 2588/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9725. T_Loss: 4.6994. Mask: 0.9116. :  88%|████████▊ | 88/100 [00:23<00:01,  6.49it/s]Train Iter: 2589/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9716. T_Loss: 4.7031. Mask: 0.9122. :  88%|████████▊ | 88/100 [00:23<00:01,  6.49it/s]Train Iter: 2589/5000. LR: 0.0308. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9716. T_Loss: 4.7031. Mask: 0.9122. :  89%|████████▉ | 89/100 [00:23<00:02,  4.66it/s]Train Iter: 2590/5000. LR: 0.0307. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9724. T_Loss: 4.6974. Mask: 0.9111. :  89%|████████▉ | 89/100 [00:24<00:02,  4.66it/s]Train Iter: 2590/5000. LR: 0.0307. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9724. T_Loss: 4.6974. Mask: 0.9111. :  90%|█████████ | 90/100 [00:24<00:01,  5.33it/s]Train Iter: 2591/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9717. T_Loss: 4.6889. Mask: 0.9117. :  90%|█████████ | 90/100 [00:24<00:01,  5.33it/s]Train Iter: 2591/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9717. T_Loss: 4.6889. Mask: 0.9117. :  91%|█████████ | 91/100 [00:24<00:01,  5.98it/s]Train Iter: 2592/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9706. T_Loss: 4.6908. Mask: 0.9127. :  91%|█████████ | 91/100 [00:24<00:01,  5.98it/s]Train Iter: 2593/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9705. T_Loss: 4.6886. Mask: 0.9130. :  92%|█████████▏| 92/100 [00:24<00:01,  5.98it/s]Train Iter: 2593/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9705. T_Loss: 4.6886. Mask: 0.9130. :  93%|█████████▎| 93/100 [00:24<00:00,  7.38it/s]Train Iter: 2594/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9704. T_Loss: 4.6811. Mask: 0.9122. :  93%|█████████▎| 93/100 [00:24<00:00,  7.38it/s]Train Iter: 2594/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9704. T_Loss: 4.6811. Mask: 0.9122. :  94%|█████████▍| 94/100 [00:24<00:00,  7.61it/s]Train Iter: 2595/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9728. T_Loss: 4.6922. Mask: 0.9132. :  94%|█████████▍| 94/100 [00:24<00:00,  7.61it/s]Train Iter: 2595/5000. LR: 0.0307. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9728. T_Loss: 4.6922. Mask: 0.9132. :  95%|█████████▌| 95/100 [00:24<00:00,  7.22it/s]Train Iter: 2596/5000. LR: 0.0306. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9730. T_Loss: 4.6927. Mask: 0.9131. :  95%|█████████▌| 95/100 [00:24<00:00,  7.22it/s]Train Iter: 2596/5000. LR: 0.0306. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9730. T_Loss: 4.6927. Mask: 0.9131. :  96%|█████████▌| 96/100 [00:24<00:00,  7.76it/s]Train Iter: 2597/5000. LR: 0.0306. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9732. T_Loss: 4.6920. Mask: 0.9137. :  96%|█████████▌| 96/100 [00:24<00:00,  7.76it/s]Train Iter: 2597/5000. LR: 0.0306. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9732. T_Loss: 4.6920. Mask: 0.9137. :  97%|█████████▋| 97/100 [00:24<00:00,  7.81it/s]Train Iter: 2598/5000. LR: 0.0306. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9743. T_Loss: 4.6909. Mask: 0.9133. :  97%|█████████▋| 97/100 [00:25<00:00,  7.81it/s]Train Iter: 2598/5000. LR: 0.0306. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9743. T_Loss: 4.6909. Mask: 0.9133. :  98%|█████████▊| 98/100 [00:25<00:00,  7.74it/s]Train Iter: 2599/5000. LR: 0.0306. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9741. T_Loss: 4.6879. Mask: 0.9138. :  98%|█████████▊| 98/100 [00:25<00:00,  7.74it/s]Train Iter: 2599/5000. LR: 0.0306. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9741. T_Loss: 4.6879. Mask: 0.9138. :  99%|█████████▉| 99/100 [00:25<00:00,  4.92it/s]Train Iter: 2600/5000. LR: 0.0306. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9753. T_Loss: 4.6965. Mask: 0.9137. :  99%|█████████▉| 99/100 [00:25<00:00,  4.92it/s]Train Iter: 2600/5000. LR: 0.0306. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9753. T_Loss: 4.6965. Mask: 0.9137. : 100%|██████████| 100/100 [00:25<00:00,  3.92it/s]
total : 5000  current step :  2576
total : 5000  current step :  2577
total : 5000  current step :  2578
total : 5000  current step :  2579
total : 5000  current step :  2580
total : 5000  current step :  2581
total : 5000  current step :  2582
total : 5000  current step :  2583
total : 5000  current step :  2584
total : 5000  current step :  2585
total : 5000  current step :  2586
total : 5000  current step :  2587
total : 5000  current step :  2588
total : 5000  current step :  2589
total : 5000  current step :  2590
total : 5000  current step :  2591
total : 5000  current step :  2592
total : 5000  current step :  2593
total : 5000  current step :  2594
total : 5000  current step :  2595
total : 5000  current step :  2596
total : 5000  current step :  2597
total : 5000  current step :  2598
total : 5000  current step :  2599
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.76s. Loss: 0.9425. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.76s. Loss: 0.9425. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 0.9299. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.9042. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.9145. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.9145. top1: 85.94. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.8973. top1: 88.12. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8946. top1: 88.02. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9077. top1: 87.05. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9108. top1: 86.33. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9046. top1: 86.81. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9123. top1: 86.56. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8998. top1: 87.22. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9002. top1: 87.50. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8950. top1: 87.98. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.78it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8950. top1: 87.98. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.19it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8918. top1: 88.17. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.19it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8886. top1: 88.33. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.19it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8902. top1: 88.09. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 11.19it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8872. top1: 88.05. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 11.19it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8865. top1: 88.37. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 11.19it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8858. top1: 88.49. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 11.19it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8858. top1: 88.49. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8853. top1: 88.59. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8899. top1: 88.69. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8869. top1: 89.06. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8830. top1: 89.40. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8800. top1: 89.45. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8773. top1: 89.62. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8821. top1: 89.06. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8822. top1: 89.00. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8855. top1: 88.84. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8836. top1: 89.12. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 17.09it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8836. top1: 89.12. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8835. top1: 89.06. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8836. top1: 88.91. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9002. top1: 88.18. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9089. top1: 87.97. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9207. top1: 87.13. top5: 99.82. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9311. top1: 86.52. top5: 99.82. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9549. top1: 85.33. top5: 99.65. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9610. top1: 84.97. top5: 99.66. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9690. top1: 84.46. top5: 99.67. :  46%|████▌     | 29/63 [00:02<00:01, 29.26it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9690. top1: 84.46. top5: 99.67. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9837. top1: 83.89. top5: 99.52. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9928. top1: 83.36. top5: 99.45. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9990. top1: 83.00. top5: 99.39. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0127. top1: 82.29. top5: 99.40. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0196. top1: 81.98. top5: 99.42. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0230. top1: 81.82. top5: 99.43. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0254. top1: 81.53. top5: 99.44. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0320. top1: 80.98. top5: 99.46. :  60%|██████    | 38/63 [00:02<00:00, 39.75it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0320. top1: 80.98. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0382. top1: 80.65. top5: 99.40. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0420. top1: 80.40. top5: 99.41. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0485. top1: 80.10. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0525. top1: 79.75. top5: 99.44. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0654. top1: 78.98. top5: 99.39. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0690. top1: 78.91. top5: 99.40. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0779. top1: 78.54. top5: 99.41. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0859. top1: 78.18. top5: 99.36. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0893. top1: 77.95. top5: 99.38. :  73%|███████▎  | 46/63 [00:02<00:00, 45.75it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0893. top1: 77.95. top5: 99.38. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0914. top1: 77.79. top5: 99.39. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1003. top1: 77.14. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1067. top1: 76.62. top5: 99.41. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1124. top1: 76.32. top5: 99.42. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1118. top1: 76.30. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1186. top1: 75.87. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1282. top1: 75.35. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1290. top1: 75.25. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 54.25it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1290. top1: 75.25. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 57.67it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1290. top1: 75.25. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 22.38it/s]
total : 5000  current step :  2600
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2601/5000. LR: 0.0305. Data: 2.10s. Batch: 2.23s. S_Loss: 1.0426. T_Loss: 4.6853. Mask: 0.9062. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2601/5000. LR: 0.0305. Data: 2.10s. Batch: 2.23s. S_Loss: 1.0426. T_Loss: 4.6853. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:40,  2.23s/it]Train Iter: 2602/5000. LR: 0.0305. Data: 1.06s. Batch: 1.18s. S_Loss: 0.9667. T_Loss: 4.3299. Mask: 0.8906. :   1%|          | 1/100 [00:02<03:40,  2.23s/it]Train Iter: 2602/5000. LR: 0.0305. Data: 1.06s. Batch: 1.18s. S_Loss: 0.9667. T_Loss: 4.3299. Mask: 0.8906. :   2%|▏         | 2/100 [00:02<01:38,  1.00s/it]Train Iter: 2603/5000. LR: 0.0305. Data: 0.71s. Batch: 0.83s. S_Loss: 0.9695. T_Loss: 5.0204. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:38,  1.00s/it]Train Iter: 2603/5000. LR: 0.0305. Data: 0.71s. Batch: 0.83s. S_Loss: 0.9695. T_Loss: 5.0204. Mask: 0.9167. :   3%|▎         | 3/100 [00:02<00:58,  1.65it/s]Train Iter: 2604/5000. LR: 0.0305. Data: 0.53s. Batch: 0.66s. S_Loss: 0.9639. T_Loss: 5.2287. Mask: 0.9297. :   3%|▎         | 3/100 [00:02<00:58,  1.65it/s]Train Iter: 2604/5000. LR: 0.0305. Data: 0.53s. Batch: 0.66s. S_Loss: 0.9639. T_Loss: 5.2287. Mask: 0.9297. :   4%|▍         | 4/100 [00:02<00:40,  2.39it/s]Train Iter: 2605/5000. LR: 0.0305. Data: 0.43s. Batch: 0.60s. S_Loss: 0.9676. T_Loss: 5.1350. Mask: 0.9313. :   4%|▍         | 4/100 [00:02<00:40,  2.39it/s]Train Iter: 2605/5000. LR: 0.0305. Data: 0.43s. Batch: 0.60s. S_Loss: 0.9676. T_Loss: 5.1350. Mask: 0.9313. :   5%|▌         | 5/100 [00:02<00:37,  2.52it/s]Train Iter: 2606/5000. LR: 0.0305. Data: 0.36s. Batch: 0.52s. S_Loss: 0.9708. T_Loss: 5.0905. Mask: 0.9323. :   5%|▌         | 5/100 [00:03<00:37,  2.52it/s]Train Iter: 2606/5000. LR: 0.0305. Data: 0.36s. Batch: 0.52s. S_Loss: 0.9708. T_Loss: 5.0905. Mask: 0.9323. :   6%|▌         | 6/100 [00:03<00:28,  3.30it/s]Train Iter: 2607/5000. LR: 0.0304. Data: 0.31s. Batch: 0.46s. S_Loss: 0.9757. T_Loss: 5.1670. Mask: 0.9330. :   6%|▌         | 6/100 [00:03<00:28,  3.30it/s]Train Iter: 2608/5000. LR: 0.0304. Data: 0.27s. Batch: 0.41s. S_Loss: 0.9674. T_Loss: 5.0484. Mask: 0.9297. :   7%|▋         | 7/100 [00:03<00:28,  3.30it/s]Train Iter: 2608/5000. LR: 0.0304. Data: 0.27s. Batch: 0.41s. S_Loss: 0.9674. T_Loss: 5.0484. Mask: 0.9297. :   8%|▊         | 8/100 [00:03<00:18,  4.92it/s]Train Iter: 2609/5000. LR: 0.0304. Data: 0.24s. Batch: 0.40s. S_Loss: 0.9624. T_Loss: 5.0210. Mask: 0.9306. :   8%|▊         | 8/100 [00:03<00:18,  4.92it/s]Train Iter: 2609/5000. LR: 0.0304. Data: 0.24s. Batch: 0.40s. S_Loss: 0.9624. T_Loss: 5.0210. Mask: 0.9306. :   9%|▉         | 9/100 [00:03<00:21,  4.31it/s]Train Iter: 2610/5000. LR: 0.0304. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9596. T_Loss: 5.0679. Mask: 0.9313. :   9%|▉         | 9/100 [00:03<00:21,  4.31it/s]Train Iter: 2610/5000. LR: 0.0304. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9596. T_Loss: 5.0679. Mask: 0.9313. :  10%|█         | 10/100 [00:03<00:18,  4.88it/s]Train Iter: 2611/5000. LR: 0.0304. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9642. T_Loss: 4.9836. Mask: 0.9290. :  10%|█         | 10/100 [00:03<00:18,  4.88it/s]Train Iter: 2611/5000. LR: 0.0304. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9642. T_Loss: 4.9836. Mask: 0.9290. :  11%|█         | 11/100 [00:03<00:16,  5.47it/s]Train Iter: 2612/5000. LR: 0.0303. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9634. T_Loss: 4.9589. Mask: 0.9245. :  11%|█         | 11/100 [00:04<00:16,  5.47it/s]Train Iter: 2612/5000. LR: 0.0303. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9634. T_Loss: 4.9589. Mask: 0.9245. :  12%|█▏        | 12/100 [00:04<00:14,  6.01it/s]Train Iter: 2613/5000. LR: 0.0303. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9556. T_Loss: 4.9038. Mask: 0.9231. :  12%|█▏        | 12/100 [00:04<00:14,  6.01it/s]Train Iter: 2613/5000. LR: 0.0303. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9556. T_Loss: 4.9038. Mask: 0.9231. :  13%|█▎        | 13/100 [00:04<00:13,  6.34it/s]Train Iter: 2614/5000. LR: 0.0303. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9634. T_Loss: 4.9025. Mask: 0.9196. :  13%|█▎        | 13/100 [00:04<00:13,  6.34it/s]Train Iter: 2614/5000. LR: 0.0303. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9634. T_Loss: 4.9025. Mask: 0.9196. :  14%|█▍        | 14/100 [00:04<00:13,  6.55it/s]Train Iter: 2615/5000. LR: 0.0303. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9604. T_Loss: 4.8489. Mask: 0.9167. :  14%|█▍        | 14/100 [00:04<00:13,  6.55it/s]Train Iter: 2615/5000. LR: 0.0303. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9604. T_Loss: 4.8489. Mask: 0.9167. :  15%|█▌        | 15/100 [00:04<00:12,  6.97it/s]Train Iter: 2616/5000. LR: 0.0303. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9666. T_Loss: 4.8475. Mask: 0.9180. :  15%|█▌        | 15/100 [00:04<00:12,  6.97it/s]Train Iter: 2616/5000. LR: 0.0303. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9666. T_Loss: 4.8475. Mask: 0.9180. :  16%|█▌        | 16/100 [00:04<00:11,  7.10it/s]Train Iter: 2617/5000. LR: 0.0303. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9579. T_Loss: 4.8330. Mask: 0.9210. :  16%|█▌        | 16/100 [00:04<00:11,  7.10it/s]Train Iter: 2617/5000. LR: 0.0303. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9579. T_Loss: 4.8330. Mask: 0.9210. :  17%|█▋        | 17/100 [00:04<00:11,  7.28it/s]Train Iter: 2618/5000. LR: 0.0302. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9562. T_Loss: 4.8235. Mask: 0.9236. :  17%|█▋        | 17/100 [00:04<00:11,  7.28it/s]Train Iter: 2618/5000. LR: 0.0302. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9562. T_Loss: 4.8235. Mask: 0.9236. :  18%|█▊        | 18/100 [00:04<00:11,  7.34it/s]Train Iter: 2619/5000. LR: 0.0302. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9629. T_Loss: 4.8226. Mask: 0.9227. :  18%|█▊        | 18/100 [00:05<00:11,  7.34it/s]Train Iter: 2619/5000. LR: 0.0302. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9629. T_Loss: 4.8226. Mask: 0.9227. :  19%|█▉        | 19/100 [00:05<00:15,  5.13it/s]Train Iter: 2620/5000. LR: 0.0302. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9618. T_Loss: 4.8752. Mask: 0.9234. :  19%|█▉        | 19/100 [00:05<00:15,  5.13it/s]Train Iter: 2620/5000. LR: 0.0302. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9618. T_Loss: 4.8752. Mask: 0.9234. :  20%|██        | 20/100 [00:05<00:14,  5.57it/s]Train Iter: 2621/5000. LR: 0.0302. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9668. T_Loss: 4.8943. Mask: 0.9226. :  20%|██        | 20/100 [00:05<00:14,  5.57it/s]Train Iter: 2621/5000. LR: 0.0302. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9668. T_Loss: 4.8943. Mask: 0.9226. :  21%|██        | 21/100 [00:05<00:13,  6.03it/s]Train Iter: 2622/5000. LR: 0.0302. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.8832. Mask: 0.9233. :  21%|██        | 21/100 [00:05<00:13,  6.03it/s]Train Iter: 2622/5000. LR: 0.0302. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.8832. Mask: 0.9233. :  22%|██▏       | 22/100 [00:05<00:11,  6.62it/s]Train Iter: 2623/5000. LR: 0.0301. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9677. T_Loss: 4.8953. Mask: 0.9226. :  22%|██▏       | 22/100 [00:05<00:11,  6.62it/s]Train Iter: 2623/5000. LR: 0.0301. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9677. T_Loss: 4.8953. Mask: 0.9226. :  23%|██▎       | 23/100 [00:05<00:11,  6.86it/s]Train Iter: 2624/5000. LR: 0.0301. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9665. T_Loss: 4.8809. Mask: 0.9219. :  23%|██▎       | 23/100 [00:05<00:11,  6.86it/s]Train Iter: 2624/5000. LR: 0.0301. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9665. T_Loss: 4.8809. Mask: 0.9219. :  24%|██▍       | 24/100 [00:05<00:10,  7.11it/s]Train Iter: 2625/5000. LR: 0.0301. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9690. T_Loss: 4.8873. Mask: 0.9213. :  24%|██▍       | 24/100 [00:06<00:10,  7.11it/s]Train Iter: 2625/5000. LR: 0.0301. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9690. T_Loss: 4.8873. Mask: 0.9213. :  25%|██▌       | 25/100 [00:06<00:15,  4.88it/s]total : 5000  current step :  2601
total : 5000  current step :  2602
total : 5000  current step :  2603
total : 5000  current step :  2604
total : 5000  current step :  2605
total : 5000  current step :  2606
total : 5000  current step :  2607
total : 5000  current step :  2608
total : 5000  current step :  2609
total : 5000  current step :  2610
total : 5000  current step :  2611
total : 5000  current step :  2612
total : 5000  current step :  2613
total : 5000  current step :  2614
total : 5000  current step :  2615
total : 5000  current step :  2616
total : 5000  current step :  2617
total : 5000  current step :  2618
total : 5000  current step :  2619
total : 5000  current step :  2620
total : 5000  current step :  2621
total : 5000  current step :  2622
total : 5000  current step :  2623
total : 5000  current step :  2624
total : 5000  current step :  2625
Train Iter: 2626/5000. LR: 0.0301. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9663. T_Loss: 4.8685. Mask: 0.9219. :  25%|██▌       | 25/100 [00:08<00:15,  4.88it/s]Train Iter: 2626/5000. LR: 0.0301. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9663. T_Loss: 4.8685. Mask: 0.9219. :  26%|██▌       | 26/100 [00:08<01:09,  1.06it/s]Train Iter: 2627/5000. LR: 0.0301. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9689. T_Loss: 4.8770. Mask: 0.9225. :  26%|██▌       | 26/100 [00:08<01:09,  1.06it/s]Train Iter: 2627/5000. LR: 0.0301. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9689. T_Loss: 4.8770. Mask: 0.9225. :  27%|██▋       | 27/100 [00:08<00:51,  1.43it/s]Train Iter: 2628/5000. LR: 0.0301. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9719. T_Loss: 4.8861. Mask: 0.9196. :  27%|██▋       | 27/100 [00:09<00:51,  1.43it/s]Train Iter: 2628/5000. LR: 0.0301. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9719. T_Loss: 4.8861. Mask: 0.9196. :  28%|██▊       | 28/100 [00:09<00:37,  1.92it/s]Train Iter: 2629/5000. LR: 0.0300. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9684. T_Loss: 4.8857. Mask: 0.9213. :  28%|██▊       | 28/100 [00:09<00:37,  1.92it/s]Train Iter: 2629/5000. LR: 0.0300. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9684. T_Loss: 4.8857. Mask: 0.9213. :  29%|██▉       | 29/100 [00:09<00:31,  2.23it/s]Train Iter: 2630/5000. LR: 0.0300. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9721. T_Loss: 4.9041. Mask: 0.9187. :  29%|██▉       | 29/100 [00:09<00:31,  2.23it/s]Train Iter: 2630/5000. LR: 0.0300. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9721. T_Loss: 4.9041. Mask: 0.9187. :  30%|███       | 30/100 [00:09<00:24,  2.84it/s]Train Iter: 2631/5000. LR: 0.0300. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9733. T_Loss: 4.8867. Mask: 0.9173. :  30%|███       | 30/100 [00:09<00:24,  2.84it/s]Train Iter: 2631/5000. LR: 0.0300. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9733. T_Loss: 4.8867. Mask: 0.9173. :  31%|███       | 31/100 [00:09<00:19,  3.47it/s]Train Iter: 2632/5000. LR: 0.0300. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9749. T_Loss: 4.8680. Mask: 0.9141. :  31%|███       | 31/100 [00:09<00:19,  3.47it/s]Train Iter: 2632/5000. LR: 0.0300. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9749. T_Loss: 4.8680. Mask: 0.9141. :  32%|███▏      | 32/100 [00:09<00:16,  4.15it/s]Train Iter: 2633/5000. LR: 0.0300. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9749. T_Loss: 4.8565. Mask: 0.9148. :  32%|███▏      | 32/100 [00:09<00:16,  4.15it/s]Train Iter: 2633/5000. LR: 0.0300. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9749. T_Loss: 4.8565. Mask: 0.9148. :  33%|███▎      | 33/100 [00:09<00:13,  4.83it/s]Train Iter: 2634/5000. LR: 0.0299. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9775. T_Loss: 4.8330. Mask: 0.9136. :  33%|███▎      | 33/100 [00:09<00:13,  4.83it/s]Train Iter: 2634/5000. LR: 0.0299. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9775. T_Loss: 4.8330. Mask: 0.9136. :  34%|███▍      | 34/100 [00:09<00:12,  5.43it/s]Train Iter: 2635/5000. LR: 0.0299. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9767. T_Loss: 4.8214. Mask: 0.9152. :  34%|███▍      | 34/100 [00:10<00:12,  5.43it/s]Train Iter: 2635/5000. LR: 0.0299. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9767. T_Loss: 4.8214. Mask: 0.9152. :  35%|███▌      | 35/100 [00:10<00:15,  4.19it/s]Train Iter: 2636/5000. LR: 0.0299. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9793. T_Loss: 4.8133. Mask: 0.9149. :  35%|███▌      | 35/100 [00:10<00:15,  4.19it/s]Train Iter: 2636/5000. LR: 0.0299. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9793. T_Loss: 4.8133. Mask: 0.9149. :  36%|███▌      | 36/100 [00:10<00:12,  5.05it/s]Train Iter: 2637/5000. LR: 0.0299. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9786. T_Loss: 4.7980. Mask: 0.9130. :  36%|███▌      | 36/100 [00:10<00:12,  5.05it/s]Train Iter: 2638/5000. LR: 0.0299. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9778. T_Loss: 4.7971. Mask: 0.9145. :  37%|███▋      | 37/100 [00:10<00:12,  5.05it/s]Train Iter: 2638/5000. LR: 0.0299. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9778. T_Loss: 4.7971. Mask: 0.9145. :  38%|███▊      | 38/100 [00:10<00:08,  7.01it/s]Train Iter: 2639/5000. LR: 0.0298. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9785. T_Loss: 4.8107. Mask: 0.9151. :  38%|███▊      | 38/100 [00:10<00:08,  7.01it/s]Train Iter: 2639/5000. LR: 0.0298. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9785. T_Loss: 4.8107. Mask: 0.9151. :  39%|███▉      | 39/100 [00:10<00:09,  6.39it/s]Train Iter: 2640/5000. LR: 0.0298. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9776. T_Loss: 4.8124. Mask: 0.9148. :  39%|███▉      | 39/100 [00:10<00:09,  6.39it/s]Train Iter: 2641/5000. LR: 0.0298. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9779. T_Loss: 4.7934. Mask: 0.9146. :  40%|████      | 40/100 [00:11<00:09,  6.39it/s]Train Iter: 2641/5000. LR: 0.0298. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9779. T_Loss: 4.7934. Mask: 0.9146. :  41%|████      | 41/100 [00:11<00:08,  7.17it/s]Train Iter: 2642/5000. LR: 0.0298. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9784. T_Loss: 4.8077. Mask: 0.9167. :  41%|████      | 41/100 [00:11<00:08,  7.17it/s]Train Iter: 2642/5000. LR: 0.0298. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9784. T_Loss: 4.8077. Mask: 0.9167. :  42%|████▏     | 42/100 [00:11<00:07,  7.43it/s]Train Iter: 2643/5000. LR: 0.0298. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9792. T_Loss: 4.7973. Mask: 0.9157. :  42%|████▏     | 42/100 [00:11<00:07,  7.43it/s]Train Iter: 2643/5000. LR: 0.0298. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9792. T_Loss: 4.7973. Mask: 0.9157. :  43%|████▎     | 43/100 [00:11<00:07,  7.66it/s]Train Iter: 2644/5000. LR: 0.0298. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9785. T_Loss: 4.7985. Mask: 0.9162. :  43%|████▎     | 43/100 [00:11<00:07,  7.66it/s]Train Iter: 2644/5000. LR: 0.0298. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9785. T_Loss: 4.7985. Mask: 0.9162. :  44%|████▍     | 44/100 [00:11<00:07,  7.84it/s]Train Iter: 2645/5000. LR: 0.0297. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9775. T_Loss: 4.7802. Mask: 0.9167. :  44%|████▍     | 44/100 [00:11<00:07,  7.84it/s]Train Iter: 2645/5000. LR: 0.0297. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9775. T_Loss: 4.7802. Mask: 0.9167. :  45%|████▌     | 45/100 [00:11<00:10,  5.18it/s]Train Iter: 2646/5000. LR: 0.0297. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9770. T_Loss: 4.7802. Mask: 0.9178. :  45%|████▌     | 45/100 [00:11<00:10,  5.18it/s]Train Iter: 2646/5000. LR: 0.0297. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9770. T_Loss: 4.7802. Mask: 0.9178. :  46%|████▌     | 46/100 [00:11<00:09,  5.68it/s]Train Iter: 2647/5000. LR: 0.0297. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9751. T_Loss: 4.7774. Mask: 0.9182. :  46%|████▌     | 46/100 [00:12<00:09,  5.68it/s]Train Iter: 2647/5000. LR: 0.0297. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9751. T_Loss: 4.7774. Mask: 0.9182. :  47%|████▋     | 47/100 [00:12<00:08,  6.09it/s]Train Iter: 2648/5000. LR: 0.0297. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9729. T_Loss: 4.7601. Mask: 0.9186. :  47%|████▋     | 47/100 [00:12<00:08,  6.09it/s]Train Iter: 2648/5000. LR: 0.0297. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9729. T_Loss: 4.7601. Mask: 0.9186. :  48%|████▊     | 48/100 [00:12<00:08,  6.46it/s]Train Iter: 2649/5000. LR: 0.0297. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9711. T_Loss: 4.7468. Mask: 0.9196. :  48%|████▊     | 48/100 [00:12<00:08,  6.46it/s]Train Iter: 2649/5000. LR: 0.0297. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9711. T_Loss: 4.7468. Mask: 0.9196. :  49%|████▉     | 49/100 [00:12<00:07,  6.78it/s]Train Iter: 2650/5000. LR: 0.0296. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9709. T_Loss: 4.7367. Mask: 0.9200. :  49%|████▉     | 49/100 [00:12<00:07,  6.78it/s]Train Iter: 2650/5000. LR: 0.0296. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9709. T_Loss: 4.7367. Mask: 0.9200. :  50%|█████     | 50/100 [00:12<00:07,  7.02it/s]total : 5000  current step :  2626
total : 5000  current step :  2627
total : 5000  current step :  2628
total : 5000  current step :  2629
total : 5000  current step :  2630
total : 5000  current step :  2631
total : 5000  current step :  2632
total : 5000  current step :  2633
total : 5000  current step :  2634
total : 5000  current step :  2635
total : 5000  current step :  2636
total : 5000  current step :  2637
total : 5000  current step :  2638
total : 5000  current step :  2639
total : 5000  current step :  2640
total : 5000  current step :  2641
total : 5000  current step :  2642
total : 5000  current step :  2643
total : 5000  current step :  2644
total : 5000  current step :  2645
total : 5000  current step :  2646
total : 5000  current step :  2647
total : 5000  current step :  2648
total : 5000  current step :  2649
total : 5000  current step :  2650
Train Iter: 2651/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9728. T_Loss: 4.7543. Mask: 0.9197. :  50%|█████     | 50/100 [00:14<00:07,  7.02it/s]Train Iter: 2651/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9728. T_Loss: 4.7543. Mask: 0.9197. :  51%|█████     | 51/100 [00:14<00:36,  1.35it/s]Train Iter: 2652/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9709. T_Loss: 4.7360. Mask: 0.9201. :  51%|█████     | 51/100 [00:14<00:36,  1.35it/s]Train Iter: 2652/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9709. T_Loss: 4.7360. Mask: 0.9201. :  52%|█████▏    | 52/100 [00:14<00:27,  1.77it/s]Train Iter: 2653/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9688. T_Loss: 4.7230. Mask: 0.9210. :  52%|█████▏    | 52/100 [00:14<00:27,  1.77it/s]Train Iter: 2653/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9688. T_Loss: 4.7230. Mask: 0.9210. :  53%|█████▎    | 53/100 [00:14<00:20,  2.29it/s]Train Iter: 2654/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9683. T_Loss: 4.7216. Mask: 0.9207. :  53%|█████▎    | 53/100 [00:15<00:20,  2.29it/s]Train Iter: 2654/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9683. T_Loss: 4.7216. Mask: 0.9207. :  54%|█████▍    | 54/100 [00:15<00:16,  2.87it/s]Train Iter: 2655/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9669. T_Loss: 4.7264. Mask: 0.9222. :  54%|█████▍    | 54/100 [00:15<00:16,  2.87it/s]Train Iter: 2655/5000. LR: 0.0296. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9669. T_Loss: 4.7264. Mask: 0.9222. :  55%|█████▌    | 55/100 [00:15<00:15,  2.84it/s]Train Iter: 2656/5000. LR: 0.0295. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9654. T_Loss: 4.7246. Mask: 0.9224. :  55%|█████▌    | 55/100 [00:15<00:15,  2.84it/s]Train Iter: 2656/5000. LR: 0.0295. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9654. T_Loss: 4.7246. Mask: 0.9224. :  56%|█████▌    | 56/100 [00:15<00:12,  3.56it/s]Train Iter: 2657/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9647. T_Loss: 4.7268. Mask: 0.9232. :  56%|█████▌    | 56/100 [00:15<00:12,  3.56it/s]Train Iter: 2657/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9647. T_Loss: 4.7268. Mask: 0.9232. :  57%|█████▋    | 57/100 [00:15<00:10,  4.25it/s]Train Iter: 2658/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9633. T_Loss: 4.7125. Mask: 0.9240. :  57%|█████▋    | 57/100 [00:15<00:10,  4.25it/s]Train Iter: 2658/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9633. T_Loss: 4.7125. Mask: 0.9240. :  58%|█████▊    | 58/100 [00:15<00:08,  4.91it/s]Train Iter: 2659/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9642. T_Loss: 4.7223. Mask: 0.9243. :  58%|█████▊    | 58/100 [00:15<00:08,  4.91it/s]Train Iter: 2659/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9642. T_Loss: 4.7223. Mask: 0.9243. :  59%|█████▉    | 59/100 [00:15<00:07,  5.49it/s]Train Iter: 2660/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9625. T_Loss: 4.7103. Mask: 0.9245. :  59%|█████▉    | 59/100 [00:16<00:07,  5.49it/s]Train Iter: 2660/5000. LR: 0.0295. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9625. T_Loss: 4.7103. Mask: 0.9245. :  60%|██████    | 60/100 [00:16<00:06,  6.10it/s]Train Iter: 2661/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9621. T_Loss: 4.6928. Mask: 0.9237. :  60%|██████    | 60/100 [00:16<00:06,  6.10it/s]Train Iter: 2662/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9633. T_Loss: 4.6840. Mask: 0.9239. :  61%|██████    | 61/100 [00:16<00:06,  6.10it/s]Train Iter: 2662/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9633. T_Loss: 4.6840. Mask: 0.9239. :  62%|██████▏   | 62/100 [00:16<00:05,  7.23it/s]Train Iter: 2663/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9631. T_Loss: 4.6732. Mask: 0.9236. :  62%|██████▏   | 62/100 [00:16<00:05,  7.23it/s]Train Iter: 2663/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9631. T_Loss: 4.6732. Mask: 0.9236. :  63%|██████▎   | 63/100 [00:16<00:05,  7.36it/s]Train Iter: 2664/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9616. T_Loss: 4.6685. Mask: 0.9238. :  63%|██████▎   | 63/100 [00:16<00:05,  7.36it/s]Train Iter: 2664/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9616. T_Loss: 4.6685. Mask: 0.9238. :  64%|██████▍   | 64/100 [00:16<00:04,  7.53it/s]Train Iter: 2665/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9603. T_Loss: 4.6595. Mask: 0.9226. :  64%|██████▍   | 64/100 [00:16<00:04,  7.53it/s]Train Iter: 2665/5000. LR: 0.0294. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9603. T_Loss: 4.6595. Mask: 0.9226. :  65%|██████▌   | 65/100 [00:16<00:05,  6.06it/s]Train Iter: 2666/5000. LR: 0.0294. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9617. T_Loss: 4.6653. Mask: 0.9228. :  65%|██████▌   | 65/100 [00:16<00:05,  6.06it/s]Train Iter: 2666/5000. LR: 0.0294. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9617. T_Loss: 4.6653. Mask: 0.9228. :  66%|██████▌   | 66/100 [00:16<00:05,  6.31it/s]Train Iter: 2667/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9609. T_Loss: 4.6647. Mask: 0.9235. :  66%|██████▌   | 66/100 [00:16<00:05,  6.31it/s]Train Iter: 2667/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9609. T_Loss: 4.6647. Mask: 0.9235. :  67%|██████▋   | 67/100 [00:16<00:04,  6.64it/s]Train Iter: 2668/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9612. T_Loss: 4.6558. Mask: 0.9237. :  67%|██████▋   | 67/100 [00:17<00:04,  6.64it/s]Train Iter: 2669/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9623. T_Loss: 4.6411. Mask: 0.9226. :  68%|██████▊   | 68/100 [00:17<00:04,  6.64it/s]Train Iter: 2669/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9623. T_Loss: 4.6411. Mask: 0.9226. :  69%|██████▉   | 69/100 [00:17<00:05,  5.60it/s]Train Iter: 2670/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9626. T_Loss: 4.6535. Mask: 0.9228. :  69%|██████▉   | 69/100 [00:17<00:05,  5.60it/s]Train Iter: 2670/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9626. T_Loss: 4.6535. Mask: 0.9228. :  70%|███████   | 70/100 [00:17<00:04,  6.04it/s]Train Iter: 2671/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9622. T_Loss: 4.6598. Mask: 0.9239. :  70%|███████   | 70/100 [00:17<00:04,  6.04it/s]Train Iter: 2671/5000. LR: 0.0293. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9622. T_Loss: 4.6598. Mask: 0.9239. :  71%|███████   | 71/100 [00:17<00:04,  6.39it/s]Train Iter: 2672/5000. LR: 0.0292. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9626. T_Loss: 4.6674. Mask: 0.9249. :  71%|███████   | 71/100 [00:17<00:04,  6.39it/s]Train Iter: 2672/5000. LR: 0.0292. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9626. T_Loss: 4.6674. Mask: 0.9249. :  72%|███████▏  | 72/100 [00:17<00:03,  7.03it/s]Train Iter: 2673/5000. LR: 0.0292. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.6624. Mask: 0.9242. :  72%|███████▏  | 72/100 [00:17<00:03,  7.03it/s]Train Iter: 2673/5000. LR: 0.0292. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.6624. Mask: 0.9242. :  73%|███████▎  | 73/100 [00:17<00:03,  7.14it/s]Train Iter: 2674/5000. LR: 0.0292. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9621. T_Loss: 4.6676. Mask: 0.9248. :  73%|███████▎  | 73/100 [00:18<00:03,  7.14it/s]Train Iter: 2674/5000. LR: 0.0292. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9621. T_Loss: 4.6676. Mask: 0.9248. :  74%|███████▍  | 74/100 [00:18<00:03,  7.55it/s]Train Iter: 2675/5000. LR: 0.0292. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9633. T_Loss: 4.6604. Mask: 0.9254. :  74%|███████▍  | 74/100 [00:18<00:03,  7.55it/s]Train Iter: 2675/5000. LR: 0.0292. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9633. T_Loss: 4.6604. Mask: 0.9254. :  75%|███████▌  | 75/100 [00:18<00:03,  7.66it/s]total : 5000  current step :  2651
total : 5000  current step :  2652
total : 5000  current step :  2653
total : 5000  current step :  2654
total : 5000  current step :  2655
total : 5000  current step :  2656
total : 5000  current step :  2657
total : 5000  current step :  2658
total : 5000  current step :  2659
total : 5000  current step :  2660
total : 5000  current step :  2661
total : 5000  current step :  2662
total : 5000  current step :  2663
total : 5000  current step :  2664
total : 5000  current step :  2665
total : 5000  current step :  2666
total : 5000  current step :  2667
total : 5000  current step :  2668
total : 5000  current step :  2669
total : 5000  current step :  2670
total : 5000  current step :  2671
total : 5000  current step :  2672
total : 5000  current step :  2673
total : 5000  current step :  2674
total : 5000  current step :  2675
Train Iter: 2676/5000. LR: 0.0292. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9639. T_Loss: 4.6716. Mask: 0.9256. :  75%|███████▌  | 75/100 [00:20<00:03,  7.66it/s]Train Iter: 2676/5000. LR: 0.0292. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9639. T_Loss: 4.6716. Mask: 0.9256. :  76%|███████▌  | 76/100 [00:20<00:17,  1.38it/s]Train Iter: 2677/5000. LR: 0.0292. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9641. T_Loss: 4.6813. Mask: 0.9257. :  76%|███████▌  | 76/100 [00:20<00:17,  1.38it/s]Train Iter: 2677/5000. LR: 0.0292. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9641. T_Loss: 4.6813. Mask: 0.9257. :  77%|███████▋  | 77/100 [00:20<00:12,  1.83it/s]Train Iter: 2678/5000. LR: 0.0291. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9637. T_Loss: 4.6734. Mask: 0.9243. :  77%|███████▋  | 77/100 [00:20<00:12,  1.83it/s]Train Iter: 2678/5000. LR: 0.0291. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9637. T_Loss: 4.6734. Mask: 0.9243. :  78%|███████▊  | 78/100 [00:20<00:09,  2.36it/s]Train Iter: 2679/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9637. T_Loss: 4.6751. Mask: 0.9252. :  78%|███████▊  | 78/100 [00:20<00:09,  2.36it/s]Train Iter: 2679/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9637. T_Loss: 4.6751. Mask: 0.9252. :  79%|███████▉  | 79/100 [00:20<00:08,  2.46it/s]Train Iter: 2680/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9622. T_Loss: 4.6694. Mask: 0.9262. :  79%|███████▉  | 79/100 [00:21<00:08,  2.46it/s]Train Iter: 2680/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9622. T_Loss: 4.6694. Mask: 0.9262. :  80%|████████  | 80/100 [00:21<00:06,  3.11it/s]Train Iter: 2681/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9622. T_Loss: 4.6809. Mask: 0.9267. :  80%|████████  | 80/100 [00:21<00:06,  3.11it/s]Train Iter: 2681/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9622. T_Loss: 4.6809. Mask: 0.9267. :  81%|████████  | 81/100 [00:21<00:05,  3.80it/s]Train Iter: 2682/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9627. T_Loss: 4.6744. Mask: 0.9253. :  81%|████████  | 81/100 [00:21<00:05,  3.80it/s]Train Iter: 2682/5000. LR: 0.0291. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9627. T_Loss: 4.6744. Mask: 0.9253. :  82%|████████▏ | 82/100 [00:21<00:04,  4.42it/s]Train Iter: 2683/5000. LR: 0.0290. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9616. T_Loss: 4.6679. Mask: 0.9258. :  82%|████████▏ | 82/100 [00:21<00:04,  4.42it/s]Train Iter: 2683/5000. LR: 0.0290. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9616. T_Loss: 4.6679. Mask: 0.9258. :  83%|████████▎ | 83/100 [00:21<00:03,  5.27it/s]Train Iter: 2684/5000. LR: 0.0290. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9610. T_Loss: 4.6644. Mask: 0.9263. :  83%|████████▎ | 83/100 [00:21<00:03,  5.27it/s]Train Iter: 2684/5000. LR: 0.0290. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9610. T_Loss: 4.6644. Mask: 0.9263. :  84%|████████▍ | 84/100 [00:21<00:02,  5.90it/s]Train Iter: 2685/5000. LR: 0.0290. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9608. T_Loss: 4.6541. Mask: 0.9265. :  84%|████████▍ | 84/100 [00:21<00:02,  5.90it/s]Train Iter: 2685/5000. LR: 0.0290. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9608. T_Loss: 4.6541. Mask: 0.9265. :  85%|████████▌ | 85/100 [00:21<00:03,  4.38it/s]Train Iter: 2686/5000. LR: 0.0290. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9618. T_Loss: 4.6549. Mask: 0.9262. :  85%|████████▌ | 85/100 [00:22<00:03,  4.38it/s]Train Iter: 2686/5000. LR: 0.0290. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9618. T_Loss: 4.6549. Mask: 0.9262. :  86%|████████▌ | 86/100 [00:22<00:02,  4.98it/s]Train Iter: 2687/5000. LR: 0.0290. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9612. T_Loss: 4.6459. Mask: 0.9271. :  86%|████████▌ | 86/100 [00:22<00:02,  4.98it/s]Train Iter: 2687/5000. LR: 0.0290. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9612. T_Loss: 4.6459. Mask: 0.9271. :  87%|████████▋ | 87/100 [00:22<00:02,  5.58it/s]Train Iter: 2688/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9624. T_Loss: 4.6405. Mask: 0.9254. :  87%|████████▋ | 87/100 [00:22<00:02,  5.58it/s]Train Iter: 2688/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9624. T_Loss: 4.6405. Mask: 0.9254. :  88%|████████▊ | 88/100 [00:22<00:01,  6.15it/s]Train Iter: 2689/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9619. T_Loss: 4.6369. Mask: 0.9256. :  88%|████████▊ | 88/100 [00:22<00:01,  6.15it/s]Train Iter: 2689/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9619. T_Loss: 4.6369. Mask: 0.9256. :  89%|████████▉ | 89/100 [00:22<00:02,  4.56it/s]Train Iter: 2690/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9624. T_Loss: 4.6397. Mask: 0.9257. :  89%|████████▉ | 89/100 [00:22<00:02,  4.56it/s]Train Iter: 2690/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9624. T_Loss: 4.6397. Mask: 0.9257. :  90%|█████████ | 90/100 [00:22<00:01,  5.14it/s]Train Iter: 2691/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9640. T_Loss: 4.6433. Mask: 0.9258. :  90%|█████████ | 90/100 [00:22<00:01,  5.14it/s]Train Iter: 2691/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9640. T_Loss: 4.6433. Mask: 0.9258. :  91%|█████████ | 91/100 [00:22<00:01,  5.46it/s]Train Iter: 2692/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6430. Mask: 0.9260. :  91%|█████████ | 91/100 [00:23<00:01,  5.46it/s]Train Iter: 2692/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6430. Mask: 0.9260. :  92%|█████████▏| 92/100 [00:23<00:01,  5.93it/s]Train Iter: 2693/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9624. T_Loss: 4.6450. Mask: 0.9267. :  92%|█████████▏| 92/100 [00:23<00:01,  5.93it/s]Train Iter: 2693/5000. LR: 0.0289. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9624. T_Loss: 4.6450. Mask: 0.9267. :  93%|█████████▎| 93/100 [00:23<00:01,  6.50it/s]Train Iter: 2694/5000. LR: 0.0288. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9618. T_Loss: 4.6439. Mask: 0.9265. :  93%|█████████▎| 93/100 [00:23<00:01,  6.50it/s]Train Iter: 2694/5000. LR: 0.0288. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9618. T_Loss: 4.6439. Mask: 0.9265. :  94%|█████████▍| 94/100 [00:23<00:00,  6.62it/s]Train Iter: 2695/5000. LR: 0.0288. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6521. Mask: 0.9263. :  94%|█████████▍| 94/100 [00:23<00:00,  6.62it/s]Train Iter: 2695/5000. LR: 0.0288. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6521. Mask: 0.9263. :  95%|█████████▌| 95/100 [00:23<00:00,  5.44it/s]Train Iter: 2696/5000. LR: 0.0288. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9645. T_Loss: 4.6392. Mask: 0.9248. :  95%|█████████▌| 95/100 [00:23<00:00,  5.44it/s]Train Iter: 2696/5000. LR: 0.0288. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9645. T_Loss: 4.6392. Mask: 0.9248. :  96%|█████████▌| 96/100 [00:23<00:00,  5.87it/s]Train Iter: 2697/5000. LR: 0.0288. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9644. T_Loss: 4.6337. Mask: 0.9240. :  96%|█████████▌| 96/100 [00:23<00:00,  5.87it/s]Train Iter: 2697/5000. LR: 0.0288. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9644. T_Loss: 4.6337. Mask: 0.9240. :  97%|█████████▋| 97/100 [00:23<00:00,  6.18it/s]Train Iter: 2698/5000. LR: 0.0288. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9649. T_Loss: 4.6356. Mask: 0.9238. :  97%|█████████▋| 97/100 [00:24<00:00,  6.18it/s]Train Iter: 2698/5000. LR: 0.0288. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9649. T_Loss: 4.6356. Mask: 0.9238. :  98%|█████████▊| 98/100 [00:24<00:00,  6.75it/s]Train Iter: 2699/5000. LR: 0.0287. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9652. T_Loss: 4.6319. Mask: 0.9233. :  98%|█████████▊| 98/100 [00:24<00:00,  6.75it/s]Train Iter: 2699/5000. LR: 0.0287. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9652. T_Loss: 4.6319. Mask: 0.9233. :  99%|█████████▉| 99/100 [00:24<00:00,  4.61it/s]Train Iter: 2700/5000. LR: 0.0287. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9649. T_Loss: 4.6329. Mask: 0.9234. :  99%|█████████▉| 99/100 [00:24<00:00,  4.61it/s]Train Iter: 2700/5000. LR: 0.0287. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9649. T_Loss: 4.6329. Mask: 0.9234. : 100%|██████████| 100/100 [00:24<00:00,  5.30it/s]Train Iter: 2700/5000. LR: 0.0287. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9649. T_Loss: 4.6329. Mask: 0.9234. : 100%|██████████| 100/100 [00:24<00:00,  4.08it/s]
total : 5000  current step :  2676
total : 5000  current step :  2677
total : 5000  current step :  2678
total : 5000  current step :  2679
total : 5000  current step :  2680
total : 5000  current step :  2681
total : 5000  current step :  2682
total : 5000  current step :  2683
total : 5000  current step :  2684
total : 5000  current step :  2685
total : 5000  current step :  2686
total : 5000  current step :  2687
total : 5000  current step :  2688
total : 5000  current step :  2689
total : 5000  current step :  2690
total : 5000  current step :  2691
total : 5000  current step :  2692
total : 5000  current step :  2693
total : 5000  current step :  2694
total : 5000  current step :  2695
total : 5000  current step :  2696
total : 5000  current step :  2697
total : 5000  current step :  2698
total : 5000  current step :  2699
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 0.9561. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 0.9561. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.90s. Loss: 0.9410. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.9134. top1: 85.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.9232. top1: 85.16. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9078. top1: 86.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9054. top1: 86.98. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9054. top1: 86.98. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9194. top1: 86.16. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9231. top1: 85.55. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9156. top1: 86.11. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9239. top1: 85.94. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9121. top1: 86.93. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9106. top1: 86.98. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9045. top1: 87.26. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9011. top1: 87.28. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8977. top1: 87.50. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8994. top1: 87.50. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.29it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8994. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.09it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8959. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8953. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8957. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8953. top1: 87.66. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9005. top1: 87.65. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8975. top1: 87.93. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8931. top1: 88.32. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8901. top1: 88.41. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8875. top1: 88.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8923. top1: 88.10. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.09it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8923. top1: 88.10. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8919. top1: 88.08. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8943. top1: 87.95. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8924. top1: 88.15. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8922. top1: 88.12. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8921. top1: 88.10. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9076. top1: 87.60. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9152. top1: 87.31. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9254. top1: 86.58. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9357. top1: 85.89. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9357. top1: 85.89. top5: 99.91. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9585. top1: 84.72. top5: 99.74. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9636. top1: 84.46. top5: 99.75. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9705. top1: 83.96. top5: 99.75. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9840. top1: 83.33. top5: 99.68. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9924. top1: 82.89. top5: 99.69. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9983. top1: 82.62. top5: 99.62. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0123. top1: 81.92. top5: 99.55. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0196. top1: 81.54. top5: 99.56. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0224. top1: 81.46. top5: 99.57. :  56%|█████▌    | 35/63 [00:02<00:00, 32.52it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0224. top1: 81.46. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0243. top1: 81.18. top5: 99.58. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0310. top1: 80.64. top5: 99.59. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0366. top1: 80.39. top5: 99.60. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0399. top1: 80.08. top5: 99.61. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0458. top1: 79.85. top5: 99.62. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0492. top1: 79.62. top5: 99.56. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0616. top1: 78.86. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0652. top1: 78.79. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 40.51it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0652. top1: 78.79. top5: 99.52. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0734. top1: 78.48. top5: 99.53. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0810. top1: 78.12. top5: 99.48. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0838. top1: 78.01. top5: 99.49. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0858. top1: 77.90. top5: 99.50. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0935. top1: 77.47. top5: 99.51. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0998. top1: 76.94. top5: 99.52. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1046. top1: 76.64. top5: 99.52. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1036. top1: 76.72. top5: 99.53. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1099. top1: 76.23. top5: 99.54. :  83%|████████▎ | 52/63 [00:02<00:00, 47.57it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1099. top1: 76.23. top5: 99.54. :  97%|█████████▋| 61/63 [00:02<00:00, 56.30it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1185. top1: 75.71. top5: 99.55. :  97%|█████████▋| 61/63 [00:02<00:00, 56.30it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1190. top1: 75.70. top5: 99.55. :  97%|█████████▋| 61/63 [00:02<00:00, 56.30it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1190. top1: 75.70. top5: 99.55. : 100%|██████████| 63/63 [00:02<00:00, 22.96it/s]
total : 5000  current step :  2700
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2701/5000. LR: 0.0287. Data: 2.13s. Batch: 2.24s. S_Loss: 0.8471. T_Loss: 3.9293. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2701/5000. LR: 0.0287. Data: 2.13s. Batch: 2.24s. S_Loss: 0.8471. T_Loss: 3.9293. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:42,  2.24s/it]Train Iter: 2702/5000. LR: 0.0287. Data: 1.06s. Batch: 1.17s. S_Loss: 0.9268. T_Loss: 4.5750. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:42,  2.24s/it]Train Iter: 2702/5000. LR: 0.0287. Data: 1.06s. Batch: 1.17s. S_Loss: 0.9268. T_Loss: 4.5750. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 2703/5000. LR: 0.0287. Data: 0.72s. Batch: 0.83s. S_Loss: 0.9344. T_Loss: 4.6221. Mask: 0.9479. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 2703/5000. LR: 0.0287. Data: 0.72s. Batch: 0.83s. S_Loss: 0.9344. T_Loss: 4.6221. Mask: 0.9479. :   3%|▎         | 3/100 [00:02<00:58,  1.66it/s]Train Iter: 2704/5000. LR: 0.0287. Data: 0.54s. Batch: 0.65s. S_Loss: 0.9773. T_Loss: 5.0111. Mask: 0.9609. :   3%|▎         | 3/100 [00:02<00:58,  1.66it/s]Train Iter: 2704/5000. LR: 0.0287. Data: 0.54s. Batch: 0.65s. S_Loss: 0.9773. T_Loss: 5.0111. Mask: 0.9609. :   4%|▍         | 4/100 [00:02<00:39,  2.41it/s]Train Iter: 2705/5000. LR: 0.0286. Data: 0.43s. Batch: 0.64s. S_Loss: 1.0158. T_Loss: 5.1581. Mask: 0.9563. :   4%|▍         | 4/100 [00:03<00:39,  2.41it/s]Train Iter: 2705/5000. LR: 0.0286. Data: 0.43s. Batch: 0.64s. S_Loss: 1.0158. T_Loss: 5.1581. Mask: 0.9563. :   5%|▌         | 5/100 [00:03<00:46,  2.06it/s]Train Iter: 2706/5000. LR: 0.0286. Data: 0.36s. Batch: 0.56s. S_Loss: 0.9959. T_Loss: 5.1203. Mask: 0.9583. :   5%|▌         | 5/100 [00:03<00:46,  2.06it/s]Train Iter: 2706/5000. LR: 0.0286. Data: 0.36s. Batch: 0.56s. S_Loss: 0.9959. T_Loss: 5.1203. Mask: 0.9583. :   6%|▌         | 6/100 [00:03<00:34,  2.74it/s]Train Iter: 2707/5000. LR: 0.0286. Data: 0.31s. Batch: 0.50s. S_Loss: 0.9860. T_Loss: 5.0197. Mask: 0.9420. :   6%|▌         | 6/100 [00:03<00:34,  2.74it/s]Train Iter: 2707/5000. LR: 0.0286. Data: 0.31s. Batch: 0.50s. S_Loss: 0.9860. T_Loss: 5.0197. Mask: 0.9420. :   7%|▋         | 7/100 [00:03<00:26,  3.47it/s]Train Iter: 2708/5000. LR: 0.0286. Data: 0.27s. Batch: 0.45s. S_Loss: 0.9816. T_Loss: 4.9988. Mask: 0.9297. :   7%|▋         | 7/100 [00:03<00:26,  3.47it/s]Train Iter: 2708/5000. LR: 0.0286. Data: 0.27s. Batch: 0.45s. S_Loss: 0.9816. T_Loss: 4.9988. Mask: 0.9297. :   8%|▊         | 8/100 [00:03<00:21,  4.20it/s]Train Iter: 2709/5000. LR: 0.0286. Data: 0.24s. Batch: 0.46s. S_Loss: 0.9785. T_Loss: 4.9369. Mask: 0.9201. :   8%|▊         | 8/100 [00:04<00:21,  4.20it/s]Train Iter: 2709/5000. LR: 0.0286. Data: 0.24s. Batch: 0.46s. S_Loss: 0.9785. T_Loss: 4.9369. Mask: 0.9201. :   9%|▉         | 9/100 [00:04<00:30,  3.02it/s]Train Iter: 2710/5000. LR: 0.0285. Data: 0.22s. Batch: 0.43s. S_Loss: 0.9802. T_Loss: 4.9669. Mask: 0.9250. :   9%|▉         | 9/100 [00:04<00:30,  3.02it/s]Train Iter: 2710/5000. LR: 0.0285. Data: 0.22s. Batch: 0.43s. S_Loss: 0.9802. T_Loss: 4.9669. Mask: 0.9250. :  10%|█         | 10/100 [00:04<00:24,  3.68it/s]Train Iter: 2711/5000. LR: 0.0285. Data: 0.20s. Batch: 0.40s. S_Loss: 0.9777. T_Loss: 4.9235. Mask: 0.9205. :  10%|█         | 10/100 [00:04<00:24,  3.68it/s]Train Iter: 2711/5000. LR: 0.0285. Data: 0.20s. Batch: 0.40s. S_Loss: 0.9777. T_Loss: 4.9235. Mask: 0.9205. :  11%|█         | 11/100 [00:04<00:20,  4.43it/s]Train Iter: 2712/5000. LR: 0.0285. Data: 0.18s. Batch: 0.38s. S_Loss: 0.9897. T_Loss: 4.8727. Mask: 0.9089. :  11%|█         | 11/100 [00:04<00:20,  4.43it/s]Train Iter: 2712/5000. LR: 0.0285. Data: 0.18s. Batch: 0.38s. S_Loss: 0.9897. T_Loss: 4.8727. Mask: 0.9089. :  12%|█▏        | 12/100 [00:04<00:17,  5.12it/s]Train Iter: 2713/5000. LR: 0.0285. Data: 0.17s. Batch: 0.36s. S_Loss: 0.9883. T_Loss: 4.8337. Mask: 0.9087. :  12%|█▏        | 12/100 [00:04<00:17,  5.12it/s]Train Iter: 2713/5000. LR: 0.0285. Data: 0.17s. Batch: 0.36s. S_Loss: 0.9883. T_Loss: 4.8337. Mask: 0.9087. :  13%|█▎        | 13/100 [00:04<00:15,  5.58it/s]Train Iter: 2714/5000. LR: 0.0285. Data: 0.16s. Batch: 0.34s. S_Loss: 0.9887. T_Loss: 4.8638. Mask: 0.9129. :  13%|█▎        | 13/100 [00:04<00:15,  5.58it/s]Train Iter: 2714/5000. LR: 0.0285. Data: 0.16s. Batch: 0.34s. S_Loss: 0.9887. T_Loss: 4.8638. Mask: 0.9129. :  14%|█▍        | 14/100 [00:04<00:13,  6.37it/s]Train Iter: 2715/5000. LR: 0.0284. Data: 0.15s. Batch: 0.34s. S_Loss: 0.9838. T_Loss: 4.8547. Mask: 0.9125. :  14%|█▍        | 14/100 [00:05<00:13,  6.37it/s]Train Iter: 2715/5000. LR: 0.0284. Data: 0.15s. Batch: 0.34s. S_Loss: 0.9838. T_Loss: 4.8547. Mask: 0.9125. :  15%|█▌        | 15/100 [00:05<00:19,  4.34it/s]Train Iter: 2716/5000. LR: 0.0284. Data: 0.14s. Batch: 0.33s. S_Loss: 0.9820. T_Loss: 4.8338. Mask: 0.9082. :  15%|█▌        | 15/100 [00:05<00:19,  4.34it/s]Train Iter: 2716/5000. LR: 0.0284. Data: 0.14s. Batch: 0.33s. S_Loss: 0.9820. T_Loss: 4.8338. Mask: 0.9082. :  16%|█▌        | 16/100 [00:05<00:17,  4.83it/s]Train Iter: 2717/5000. LR: 0.0284. Data: 0.13s. Batch: 0.32s. S_Loss: 0.9830. T_Loss: 4.8652. Mask: 0.9099. :  16%|█▌        | 16/100 [00:05<00:17,  4.83it/s]Train Iter: 2717/5000. LR: 0.0284. Data: 0.13s. Batch: 0.32s. S_Loss: 0.9830. T_Loss: 4.8652. Mask: 0.9099. :  17%|█▋        | 17/100 [00:05<00:15,  5.40it/s]Train Iter: 2718/5000. LR: 0.0284. Data: 0.12s. Batch: 0.31s. S_Loss: 0.9806. T_Loss: 4.8798. Mask: 0.9132. :  17%|█▋        | 17/100 [00:05<00:15,  5.40it/s]Train Iter: 2718/5000. LR: 0.0284. Data: 0.12s. Batch: 0.31s. S_Loss: 0.9806. T_Loss: 4.8798. Mask: 0.9132. :  18%|█▊        | 18/100 [00:05<00:13,  6.14it/s]Train Iter: 2719/5000. LR: 0.0284. Data: 0.12s. Batch: 0.30s. S_Loss: 0.9798. T_Loss: 4.8826. Mask: 0.9128. :  18%|█▊        | 18/100 [00:05<00:13,  6.14it/s]Train Iter: 2719/5000. LR: 0.0284. Data: 0.12s. Batch: 0.30s. S_Loss: 0.9798. T_Loss: 4.8826. Mask: 0.9128. :  19%|█▉        | 19/100 [00:05<00:12,  6.54it/s]Train Iter: 2720/5000. LR: 0.0284. Data: 0.11s. Batch: 0.29s. S_Loss: 0.9808. T_Loss: 4.8936. Mask: 0.9141. :  19%|█▉        | 19/100 [00:05<00:12,  6.54it/s]Train Iter: 2720/5000. LR: 0.0284. Data: 0.11s. Batch: 0.29s. S_Loss: 0.9808. T_Loss: 4.8936. Mask: 0.9141. :  20%|██        | 20/100 [00:05<00:11,  7.17it/s]Train Iter: 2721/5000. LR: 0.0283. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9756. T_Loss: 4.8422. Mask: 0.9122. :  20%|██        | 20/100 [00:05<00:11,  7.17it/s]Train Iter: 2721/5000. LR: 0.0283. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9756. T_Loss: 4.8422. Mask: 0.9122. :  21%|██        | 21/100 [00:05<00:10,  7.38it/s]Train Iter: 2722/5000. LR: 0.0283. Data: 0.10s. Batch: 0.28s. S_Loss: 0.9760. T_Loss: 4.7840. Mask: 0.9091. :  21%|██        | 21/100 [00:06<00:10,  7.38it/s]Train Iter: 2722/5000. LR: 0.0283. Data: 0.10s. Batch: 0.28s. S_Loss: 0.9760. T_Loss: 4.7840. Mask: 0.9091. :  22%|██▏       | 22/100 [00:06<00:10,  7.33it/s]Train Iter: 2723/5000. LR: 0.0283. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9836. T_Loss: 4.8099. Mask: 0.9076. :  22%|██▏       | 22/100 [00:06<00:10,  7.33it/s]Train Iter: 2723/5000. LR: 0.0283. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9836. T_Loss: 4.8099. Mask: 0.9076. :  23%|██▎       | 23/100 [00:06<00:10,  7.52it/s]Train Iter: 2724/5000. LR: 0.0283. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9867. T_Loss: 4.8040. Mask: 0.9036. :  23%|██▎       | 23/100 [00:06<00:10,  7.52it/s]Train Iter: 2724/5000. LR: 0.0283. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9867. T_Loss: 4.8040. Mask: 0.9036. :  24%|██▍       | 24/100 [00:06<00:09,  7.73it/s]Train Iter: 2725/5000. LR: 0.0283. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9867. T_Loss: 4.8157. Mask: 0.9038. :  24%|██▍       | 24/100 [00:06<00:09,  7.73it/s]Train Iter: 2725/5000. LR: 0.0283. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9867. T_Loss: 4.8157. Mask: 0.9038. :  25%|██▌       | 25/100 [00:06<00:11,  6.25it/s]total : 5000  current step :  2701
total : 5000  current step :  2702
total : 5000  current step :  2703
total : 5000  current step :  2704
total : 5000  current step :  2705
total : 5000  current step :  2706
total : 5000  current step :  2707
total : 5000  current step :  2708
total : 5000  current step :  2709
total : 5000  current step :  2710
total : 5000  current step :  2711
total : 5000  current step :  2712
total : 5000  current step :  2713
total : 5000  current step :  2714
total : 5000  current step :  2715
total : 5000  current step :  2716
total : 5000  current step :  2717
total : 5000  current step :  2718
total : 5000  current step :  2719
total : 5000  current step :  2720
total : 5000  current step :  2721
total : 5000  current step :  2722
total : 5000  current step :  2723
total : 5000  current step :  2724
total : 5000  current step :  2725
Train Iter: 2726/5000. LR: 0.0282. Data: 0.16s. Batch: 0.33s. S_Loss: 0.9872. T_Loss: 4.7885. Mask: 0.9038. :  25%|██▌       | 25/100 [00:08<00:11,  6.25it/s]Train Iter: 2726/5000. LR: 0.0282. Data: 0.16s. Batch: 0.33s. S_Loss: 0.9872. T_Loss: 4.7885. Mask: 0.9038. :  26%|██▌       | 26/100 [00:08<00:54,  1.37it/s]Train Iter: 2727/5000. LR: 0.0282. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9848. T_Loss: 4.7864. Mask: 0.9051. :  26%|██▌       | 26/100 [00:08<00:54,  1.37it/s]Train Iter: 2727/5000. LR: 0.0282. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9848. T_Loss: 4.7864. Mask: 0.9051. :  27%|██▋       | 27/100 [00:08<00:40,  1.82it/s]Train Iter: 2728/5000. LR: 0.0282. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9855. T_Loss: 4.7581. Mask: 0.9029. :  27%|██▋       | 27/100 [00:08<00:40,  1.82it/s]Train Iter: 2729/5000. LR: 0.0282. Data: 0.14s. Batch: 0.31s. S_Loss: 0.9867. T_Loss: 4.7700. Mask: 0.9041. :  28%|██▊       | 28/100 [00:09<00:39,  1.82it/s]Train Iter: 2729/5000. LR: 0.0282. Data: 0.14s. Batch: 0.31s. S_Loss: 0.9867. T_Loss: 4.7700. Mask: 0.9041. :  29%|██▉       | 29/100 [00:09<00:27,  2.62it/s]Train Iter: 2730/5000. LR: 0.0282. Data: 0.14s. Batch: 0.31s. S_Loss: 0.9833. T_Loss: 4.7559. Mask: 0.9052. :  29%|██▉       | 29/100 [00:09<00:27,  2.62it/s]Train Iter: 2731/5000. LR: 0.0282. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9822. T_Loss: 4.7295. Mask: 0.9052. :  30%|███       | 30/100 [00:09<00:26,  2.62it/s]Train Iter: 2731/5000. LR: 0.0282. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9822. T_Loss: 4.7295. Mask: 0.9052. :  31%|███       | 31/100 [00:09<00:18,  3.82it/s]Train Iter: 2732/5000. LR: 0.0281. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9834. T_Loss: 4.7279. Mask: 0.9062. :  31%|███       | 31/100 [00:09<00:18,  3.82it/s]Train Iter: 2732/5000. LR: 0.0281. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9834. T_Loss: 4.7279. Mask: 0.9062. :  32%|███▏      | 32/100 [00:09<00:15,  4.34it/s]Train Iter: 2733/5000. LR: 0.0281. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9807. T_Loss: 4.7195. Mask: 0.9053. :  32%|███▏      | 32/100 [00:09<00:15,  4.34it/s]Train Iter: 2733/5000. LR: 0.0281. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9807. T_Loss: 4.7195. Mask: 0.9053. :  33%|███▎      | 33/100 [00:09<00:13,  4.85it/s]Train Iter: 2734/5000. LR: 0.0281. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9869. T_Loss: 4.7641. Mask: 0.9072. :  33%|███▎      | 33/100 [00:09<00:13,  4.85it/s]Train Iter: 2734/5000. LR: 0.0281. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9869. T_Loss: 4.7641. Mask: 0.9072. :  34%|███▍      | 34/100 [00:09<00:12,  5.36it/s]Train Iter: 2735/5000. LR: 0.0281. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9883. T_Loss: 4.7806. Mask: 0.9080. :  34%|███▍      | 34/100 [00:10<00:12,  5.36it/s]Train Iter: 2735/5000. LR: 0.0281. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9883. T_Loss: 4.7806. Mask: 0.9080. :  35%|███▌      | 35/100 [00:10<00:16,  4.06it/s]Train Iter: 2736/5000. LR: 0.0281. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9911. T_Loss: 4.8110. Mask: 0.9097. :  35%|███▌      | 35/100 [00:10<00:16,  4.06it/s]Train Iter: 2736/5000. LR: 0.0281. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9911. T_Loss: 4.8110. Mask: 0.9097. :  36%|███▌      | 36/100 [00:10<00:13,  4.67it/s]Train Iter: 2737/5000. LR: 0.0280. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9876. T_Loss: 4.7885. Mask: 0.9105. :  36%|███▌      | 36/100 [00:10<00:13,  4.67it/s]Train Iter: 2737/5000. LR: 0.0280. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9876. T_Loss: 4.7885. Mask: 0.9105. :  37%|███▋      | 37/100 [00:10<00:11,  5.33it/s]Train Iter: 2738/5000. LR: 0.0280. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9859. T_Loss: 4.7786. Mask: 0.9112. :  37%|███▋      | 37/100 [00:10<00:11,  5.33it/s]Train Iter: 2738/5000. LR: 0.0280. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9859. T_Loss: 4.7786. Mask: 0.9112. :  38%|███▊      | 38/100 [00:10<00:10,  5.88it/s]Train Iter: 2739/5000. LR: 0.0280. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9835. T_Loss: 4.7552. Mask: 0.9111. :  38%|███▊      | 38/100 [00:10<00:10,  5.88it/s]Train Iter: 2739/5000. LR: 0.0280. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9835. T_Loss: 4.7552. Mask: 0.9111. :  39%|███▉      | 39/100 [00:10<00:14,  4.29it/s]Train Iter: 2740/5000. LR: 0.0280. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9831. T_Loss: 4.7506. Mask: 0.9102. :  39%|███▉      | 39/100 [00:10<00:14,  4.29it/s]Train Iter: 2740/5000. LR: 0.0280. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9831. T_Loss: 4.7506. Mask: 0.9102. :  40%|████      | 40/100 [00:10<00:12,  5.00it/s]Train Iter: 2741/5000. LR: 0.0280. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9859. T_Loss: 4.7639. Mask: 0.9108. :  40%|████      | 40/100 [00:11<00:12,  5.00it/s]Train Iter: 2741/5000. LR: 0.0280. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9859. T_Loss: 4.7639. Mask: 0.9108. :  41%|████      | 41/100 [00:11<00:11,  5.24it/s]Train Iter: 2742/5000. LR: 0.0279. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9848. T_Loss: 4.7552. Mask: 0.9107. :  41%|████      | 41/100 [00:11<00:11,  5.24it/s]Train Iter: 2742/5000. LR: 0.0279. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9848. T_Loss: 4.7552. Mask: 0.9107. :  42%|████▏     | 42/100 [00:11<00:10,  5.66it/s]Train Iter: 2743/5000. LR: 0.0279. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9853. T_Loss: 4.7717. Mask: 0.9121. :  42%|████▏     | 42/100 [00:11<00:10,  5.66it/s]Train Iter: 2743/5000. LR: 0.0279. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9853. T_Loss: 4.7717. Mask: 0.9121. :  43%|████▎     | 43/100 [00:11<00:09,  6.09it/s]Train Iter: 2744/5000. LR: 0.0279. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9866. T_Loss: 4.7737. Mask: 0.9112. :  43%|████▎     | 43/100 [00:11<00:09,  6.09it/s]Train Iter: 2744/5000. LR: 0.0279. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9866. T_Loss: 4.7737. Mask: 0.9112. :  44%|████▍     | 44/100 [00:11<00:08,  6.52it/s]Train Iter: 2745/5000. LR: 0.0279. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9862. T_Loss: 4.7616. Mask: 0.9104. :  44%|████▍     | 44/100 [00:11<00:08,  6.52it/s]Train Iter: 2745/5000. LR: 0.0279. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9862. T_Loss: 4.7616. Mask: 0.9104. :  45%|████▌     | 45/100 [00:11<00:11,  4.92it/s]Train Iter: 2746/5000. LR: 0.0279. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9876. T_Loss: 4.7787. Mask: 0.9110. :  45%|████▌     | 45/100 [00:11<00:11,  4.92it/s]Train Iter: 2746/5000. LR: 0.0279. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9876. T_Loss: 4.7787. Mask: 0.9110. :  46%|████▌     | 46/100 [00:11<00:09,  5.53it/s]Train Iter: 2747/5000. LR: 0.0279. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9849. T_Loss: 4.7779. Mask: 0.9116. :  46%|████▌     | 46/100 [00:12<00:09,  5.53it/s]Train Iter: 2747/5000. LR: 0.0279. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9849. T_Loss: 4.7779. Mask: 0.9116. :  47%|████▋     | 47/100 [00:12<00:08,  6.08it/s]Train Iter: 2748/5000. LR: 0.0278. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.7735. Mask: 0.9134. :  47%|████▋     | 47/100 [00:12<00:08,  6.08it/s]Train Iter: 2748/5000. LR: 0.0278. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.7735. Mask: 0.9134. :  48%|████▊     | 48/100 [00:12<00:08,  6.26it/s]Train Iter: 2749/5000. LR: 0.0278. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.7969. Mask: 0.9145. :  48%|████▊     | 48/100 [00:12<00:08,  6.26it/s]Train Iter: 2749/5000. LR: 0.0278. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9820. T_Loss: 4.7969. Mask: 0.9145. :  49%|████▉     | 49/100 [00:12<00:10,  4.97it/s]Train Iter: 2750/5000. LR: 0.0278. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9831. T_Loss: 4.7946. Mask: 0.9131. :  49%|████▉     | 49/100 [00:12<00:10,  4.97it/s]Train Iter: 2750/5000. LR: 0.0278. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9831. T_Loss: 4.7946. Mask: 0.9131. :  50%|█████     | 50/100 [00:12<00:09,  5.55it/s]total : 5000  current step :  2726
total : 5000  current step :  2727
total : 5000  current step :  2728
total : 5000  current step :  2729
total : 5000  current step :  2730
total : 5000  current step :  2731
total : 5000  current step :  2732
total : 5000  current step :  2733
total : 5000  current step :  2734
total : 5000  current step :  2735
total : 5000  current step :  2736
total : 5000  current step :  2737
total : 5000  current step :  2738
total : 5000  current step :  2739
total : 5000  current step :  2740
total : 5000  current step :  2741
total : 5000  current step :  2742
total : 5000  current step :  2743
total : 5000  current step :  2744
total : 5000  current step :  2745
total : 5000  current step :  2746
total : 5000  current step :  2747
total : 5000  current step :  2748
total : 5000  current step :  2749
total : 5000  current step :  2750
Train Iter: 2751/5000. LR: 0.0278. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9829. T_Loss: 4.7991. Mask: 0.9130. :  50%|█████     | 50/100 [00:14<00:09,  5.55it/s]Train Iter: 2751/5000. LR: 0.0278. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9829. T_Loss: 4.7991. Mask: 0.9130. :  51%|█████     | 51/100 [00:14<00:34,  1.41it/s]Train Iter: 2752/5000. LR: 0.0278. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9838. T_Loss: 4.7899. Mask: 0.9123. :  51%|█████     | 51/100 [00:14<00:34,  1.41it/s]Train Iter: 2752/5000. LR: 0.0278. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9838. T_Loss: 4.7899. Mask: 0.9123. :  52%|█████▏    | 52/100 [00:14<00:25,  1.89it/s]Train Iter: 2753/5000. LR: 0.0277. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9822. T_Loss: 4.7902. Mask: 0.9133. :  52%|█████▏    | 52/100 [00:14<00:25,  1.89it/s]Train Iter: 2753/5000. LR: 0.0277. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9822. T_Loss: 4.7902. Mask: 0.9133. :  53%|█████▎    | 53/100 [00:14<00:18,  2.48it/s]Train Iter: 2754/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9813. T_Loss: 4.7937. Mask: 0.9138. :  53%|█████▎    | 53/100 [00:14<00:18,  2.48it/s]Train Iter: 2754/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9813. T_Loss: 4.7937. Mask: 0.9138. :  54%|█████▍    | 54/100 [00:14<00:14,  3.07it/s]Train Iter: 2755/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9800. T_Loss: 4.7893. Mask: 0.9148. :  54%|█████▍    | 54/100 [00:15<00:14,  3.07it/s]Train Iter: 2755/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9800. T_Loss: 4.7893. Mask: 0.9148. :  55%|█████▌    | 55/100 [00:15<00:17,  2.53it/s]Train Iter: 2756/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9793. T_Loss: 4.7970. Mask: 0.9157. :  55%|█████▌    | 55/100 [00:15<00:17,  2.53it/s]Train Iter: 2756/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9793. T_Loss: 4.7970. Mask: 0.9157. :  56%|█████▌    | 56/100 [00:15<00:13,  3.19it/s]Train Iter: 2757/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9788. T_Loss: 4.7880. Mask: 0.9156. :  56%|█████▌    | 56/100 [00:15<00:13,  3.19it/s]Train Iter: 2757/5000. LR: 0.0277. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9788. T_Loss: 4.7880. Mask: 0.9156. :  57%|█████▋    | 57/100 [00:15<00:11,  3.91it/s]Train Iter: 2758/5000. LR: 0.0277. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9783. T_Loss: 4.7712. Mask: 0.9154. :  57%|█████▋    | 57/100 [00:15<00:11,  3.91it/s]Train Iter: 2758/5000. LR: 0.0277. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9783. T_Loss: 4.7712. Mask: 0.9154. :  58%|█████▊    | 58/100 [00:15<00:09,  4.64it/s]Train Iter: 2759/5000. LR: 0.0276. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9773. T_Loss: 4.7726. Mask: 0.9168. :  58%|█████▊    | 58/100 [00:16<00:09,  4.64it/s]Train Iter: 2759/5000. LR: 0.0276. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9773. T_Loss: 4.7726. Mask: 0.9168. :  59%|█████▉    | 59/100 [00:16<00:07,  5.33it/s]Train Iter: 2760/5000. LR: 0.0276. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9792. T_Loss: 4.7793. Mask: 0.9167. :  59%|█████▉    | 59/100 [00:16<00:07,  5.33it/s]Train Iter: 2760/5000. LR: 0.0276. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9792. T_Loss: 4.7793. Mask: 0.9167. :  60%|██████    | 60/100 [00:16<00:06,  5.85it/s]Train Iter: 2761/5000. LR: 0.0276. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9780. T_Loss: 4.7748. Mask: 0.9170. :  60%|██████    | 60/100 [00:16<00:06,  5.85it/s]Train Iter: 2761/5000. LR: 0.0276. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9780. T_Loss: 4.7748. Mask: 0.9170. :  61%|██████    | 61/100 [00:16<00:06,  6.33it/s]Train Iter: 2762/5000. LR: 0.0276. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9781. T_Loss: 4.7719. Mask: 0.9173. :  61%|██████    | 61/100 [00:16<00:06,  6.33it/s]Train Iter: 2762/5000. LR: 0.0276. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9781. T_Loss: 4.7719. Mask: 0.9173. :  62%|██████▏   | 62/100 [00:16<00:05,  6.77it/s]Train Iter: 2763/5000. LR: 0.0276. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9796. T_Loss: 4.7789. Mask: 0.9162. :  62%|██████▏   | 62/100 [00:16<00:05,  6.77it/s]Train Iter: 2763/5000. LR: 0.0276. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9796. T_Loss: 4.7789. Mask: 0.9162. :  63%|██████▎   | 63/100 [00:16<00:05,  7.13it/s]Train Iter: 2764/5000. LR: 0.0275. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9807. T_Loss: 4.7733. Mask: 0.9155. :  63%|██████▎   | 63/100 [00:16<00:05,  7.13it/s]Train Iter: 2764/5000. LR: 0.0275. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9807. T_Loss: 4.7733. Mask: 0.9155. :  64%|██████▍   | 64/100 [00:16<00:04,  7.41it/s]Train Iter: 2765/5000. LR: 0.0275. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9811. T_Loss: 4.7701. Mask: 0.9144. :  64%|██████▍   | 64/100 [00:16<00:04,  7.41it/s]Train Iter: 2765/5000. LR: 0.0275. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9811. T_Loss: 4.7701. Mask: 0.9144. :  65%|██████▌   | 65/100 [00:16<00:05,  5.87it/s]Train Iter: 2766/5000. LR: 0.0275. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9790. T_Loss: 4.7561. Mask: 0.9148. :  65%|██████▌   | 65/100 [00:17<00:05,  5.87it/s]Train Iter: 2766/5000. LR: 0.0275. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9790. T_Loss: 4.7561. Mask: 0.9148. :  66%|██████▌   | 66/100 [00:17<00:05,  6.31it/s]Train Iter: 2767/5000. LR: 0.0275. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9791. T_Loss: 4.7518. Mask: 0.9146. :  66%|██████▌   | 66/100 [00:17<00:05,  6.31it/s]Train Iter: 2767/5000. LR: 0.0275. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9791. T_Loss: 4.7518. Mask: 0.9146. :  67%|██████▋   | 67/100 [00:17<00:04,  6.75it/s]Train Iter: 2768/5000. LR: 0.0275. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9806. T_Loss: 4.7613. Mask: 0.9150. :  67%|██████▋   | 67/100 [00:17<00:04,  6.75it/s]Train Iter: 2768/5000. LR: 0.0275. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9806. T_Loss: 4.7613. Mask: 0.9150. :  68%|██████▊   | 68/100 [00:17<00:04,  7.12it/s]Train Iter: 2769/5000. LR: 0.0274. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9803. T_Loss: 4.7594. Mask: 0.9149. :  68%|██████▊   | 68/100 [00:17<00:04,  7.12it/s]Train Iter: 2769/5000. LR: 0.0274. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9803. T_Loss: 4.7594. Mask: 0.9149. :  69%|██████▉   | 69/100 [00:17<00:06,  4.60it/s]Train Iter: 2770/5000. LR: 0.0274. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9799. T_Loss: 4.7526. Mask: 0.9147. :  69%|██████▉   | 69/100 [00:17<00:06,  4.60it/s]Train Iter: 2770/5000. LR: 0.0274. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9799. T_Loss: 4.7526. Mask: 0.9147. :  70%|███████   | 70/100 [00:17<00:05,  5.24it/s]Train Iter: 2771/5000. LR: 0.0274. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9806. T_Loss: 4.7603. Mask: 0.9151. :  70%|███████   | 70/100 [00:17<00:05,  5.24it/s]Train Iter: 2771/5000. LR: 0.0274. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9806. T_Loss: 4.7603. Mask: 0.9151. :  71%|███████   | 71/100 [00:17<00:05,  5.74it/s]Train Iter: 2772/5000. LR: 0.0274. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9806. T_Loss: 4.7510. Mask: 0.9149. :  71%|███████   | 71/100 [00:18<00:05,  5.74it/s]Train Iter: 2772/5000. LR: 0.0274. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9806. T_Loss: 4.7510. Mask: 0.9149. :  72%|███████▏  | 72/100 [00:18<00:04,  6.18it/s]Train Iter: 2773/5000. LR: 0.0274. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9791. T_Loss: 4.7424. Mask: 0.9157. :  72%|███████▏  | 72/100 [00:18<00:04,  6.18it/s]Train Iter: 2773/5000. LR: 0.0274. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9791. T_Loss: 4.7424. Mask: 0.9157. :  73%|███████▎  | 73/100 [00:18<00:04,  6.58it/s]Train Iter: 2774/5000. LR: 0.0274. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9795. T_Loss: 4.7412. Mask: 0.9151. :  73%|███████▎  | 73/100 [00:18<00:04,  6.58it/s]Train Iter: 2774/5000. LR: 0.0274. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9795. T_Loss: 4.7412. Mask: 0.9151. :  74%|███████▍  | 74/100 [00:18<00:03,  6.79it/s]Train Iter: 2775/5000. LR: 0.0273. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.7304. Mask: 0.9146. :  74%|███████▍  | 74/100 [00:18<00:03,  6.79it/s]Train Iter: 2775/5000. LR: 0.0273. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.7304. Mask: 0.9146. :  75%|███████▌  | 75/100 [00:18<00:05,  4.84it/s]total : 5000  current step :  2751
total : 5000  current step :  2752
total : 5000  current step :  2753
total : 5000  current step :  2754
total : 5000  current step :  2755
total : 5000  current step :  2756
total : 5000  current step :  2757
total : 5000  current step :  2758
total : 5000  current step :  2759
total : 5000  current step :  2760
total : 5000  current step :  2761
total : 5000  current step :  2762
total : 5000  current step :  2763
total : 5000  current step :  2764
total : 5000  current step :  2765
total : 5000  current step :  2766
total : 5000  current step :  2767
total : 5000  current step :  2768
total : 5000  current step :  2769
total : 5000  current step :  2770
total : 5000  current step :  2771
total : 5000  current step :  2772
total : 5000  current step :  2773
total : 5000  current step :  2774
total : 5000  current step :  2775
Train Iter: 2776/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9775. T_Loss: 4.7275. Mask: 0.9153. :  75%|███████▌  | 75/100 [00:20<00:05,  4.84it/s]Train Iter: 2776/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9775. T_Loss: 4.7275. Mask: 0.9153. :  76%|███████▌  | 76/100 [00:20<00:19,  1.21it/s]Train Iter: 2777/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9763. T_Loss: 4.7186. Mask: 0.9152. :  76%|███████▌  | 76/100 [00:21<00:19,  1.21it/s]Train Iter: 2777/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9763. T_Loss: 4.7186. Mask: 0.9152. :  77%|███████▋  | 77/100 [00:21<00:14,  1.62it/s]Train Iter: 2778/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9766. T_Loss: 4.7076. Mask: 0.9151. :  77%|███████▋  | 77/100 [00:21<00:14,  1.62it/s]Train Iter: 2778/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9766. T_Loss: 4.7076. Mask: 0.9151. :  78%|███████▊  | 78/100 [00:21<00:10,  2.10it/s]Train Iter: 2779/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9762. T_Loss: 4.7104. Mask: 0.9142. :  78%|███████▊  | 78/100 [00:21<00:10,  2.10it/s]Train Iter: 2779/5000. LR: 0.0273. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9762. T_Loss: 4.7104. Mask: 0.9142. :  79%|███████▉  | 79/100 [00:21<00:08,  2.40it/s]Train Iter: 2780/5000. LR: 0.0272. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9765. T_Loss: 4.7083. Mask: 0.9129. :  79%|███████▉  | 79/100 [00:21<00:08,  2.40it/s]Train Iter: 2781/5000. LR: 0.0272. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9766. T_Loss: 4.7107. Mask: 0.9136. :  80%|████████  | 80/100 [00:21<00:08,  2.40it/s]Train Iter: 2781/5000. LR: 0.0272. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9766. T_Loss: 4.7107. Mask: 0.9136. :  81%|████████  | 81/100 [00:21<00:05,  3.73it/s]Train Iter: 2782/5000. LR: 0.0272. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9765. T_Loss: 4.7065. Mask: 0.9139. :  81%|████████  | 81/100 [00:21<00:05,  3.73it/s]Train Iter: 2782/5000. LR: 0.0272. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9765. T_Loss: 4.7065. Mask: 0.9139. :  82%|████████▏ | 82/100 [00:21<00:04,  4.30it/s]Train Iter: 2783/5000. LR: 0.0272. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9762. T_Loss: 4.7056. Mask: 0.9142. :  82%|████████▏ | 82/100 [00:21<00:04,  4.30it/s]Train Iter: 2783/5000. LR: 0.0272. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9762. T_Loss: 4.7056. Mask: 0.9142. :  83%|████████▎ | 83/100 [00:21<00:03,  4.78it/s]Train Iter: 2784/5000. LR: 0.0272. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9757. T_Loss: 4.7021. Mask: 0.9152. :  83%|████████▎ | 83/100 [00:22<00:03,  4.78it/s]Train Iter: 2784/5000. LR: 0.0272. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9757. T_Loss: 4.7021. Mask: 0.9152. :  84%|████████▍ | 84/100 [00:22<00:02,  5.35it/s]Train Iter: 2785/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9747. T_Loss: 4.6929. Mask: 0.9158. :  84%|████████▍ | 84/100 [00:22<00:02,  5.35it/s]Train Iter: 2785/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9747. T_Loss: 4.6929. Mask: 0.9158. :  85%|████████▌ | 85/100 [00:22<00:03,  4.78it/s]Train Iter: 2786/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9750. T_Loss: 4.6924. Mask: 0.9164. :  85%|████████▌ | 85/100 [00:22<00:03,  4.78it/s]Train Iter: 2786/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9750. T_Loss: 4.6924. Mask: 0.9164. :  86%|████████▌ | 86/100 [00:22<00:02,  5.42it/s]Train Iter: 2787/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9743. T_Loss: 4.6953. Mask: 0.9174. :  86%|████████▌ | 86/100 [00:22<00:02,  5.42it/s]Train Iter: 2787/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9743. T_Loss: 4.6953. Mask: 0.9174. :  87%|████████▋ | 87/100 [00:22<00:02,  6.01it/s]Train Iter: 2788/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9729. T_Loss: 4.6864. Mask: 0.9180. :  87%|████████▋ | 87/100 [00:22<00:02,  6.01it/s]Train Iter: 2788/5000. LR: 0.0271. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9729. T_Loss: 4.6864. Mask: 0.9180. :  88%|████████▊ | 88/100 [00:22<00:01,  6.50it/s]Train Iter: 2789/5000. LR: 0.0271. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9722. T_Loss: 4.6678. Mask: 0.9171. :  88%|████████▊ | 88/100 [00:22<00:01,  6.50it/s]Train Iter: 2789/5000. LR: 0.0271. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9722. T_Loss: 4.6678. Mask: 0.9171. :  89%|████████▉ | 89/100 [00:22<00:01,  5.99it/s]Train Iter: 2790/5000. LR: 0.0271. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9716. T_Loss: 4.6666. Mask: 0.9170. :  89%|████████▉ | 89/100 [00:23<00:01,  5.99it/s]Train Iter: 2790/5000. LR: 0.0271. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9716. T_Loss: 4.6666. Mask: 0.9170. :  90%|█████████ | 90/100 [00:23<00:01,  6.47it/s]Train Iter: 2791/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9713. T_Loss: 4.6650. Mask: 0.9166. :  90%|█████████ | 90/100 [00:23<00:01,  6.47it/s]Train Iter: 2791/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9713. T_Loss: 4.6650. Mask: 0.9166. :  91%|█████████ | 91/100 [00:23<00:01,  6.94it/s]Train Iter: 2792/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9709. T_Loss: 4.6591. Mask: 0.9168. :  91%|█████████ | 91/100 [00:23<00:01,  6.94it/s]Train Iter: 2793/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9703. T_Loss: 4.6602. Mask: 0.9167. :  92%|█████████▏| 92/100 [00:23<00:01,  6.94it/s]Train Iter: 2793/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9703. T_Loss: 4.6602. Mask: 0.9167. :  93%|█████████▎| 93/100 [00:23<00:00,  7.83it/s]Train Iter: 2794/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9687. T_Loss: 4.6538. Mask: 0.9169. :  93%|█████████▎| 93/100 [00:23<00:00,  7.83it/s]Train Iter: 2794/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9687. T_Loss: 4.6538. Mask: 0.9169. :  94%|█████████▍| 94/100 [00:23<00:00,  8.20it/s]Train Iter: 2795/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9697. T_Loss: 4.6522. Mask: 0.9168. :  94%|█████████▍| 94/100 [00:23<00:00,  8.20it/s]Train Iter: 2795/5000. LR: 0.0270. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9697. T_Loss: 4.6522. Mask: 0.9168. :  95%|█████████▌| 95/100 [00:23<00:00,  6.05it/s]Train Iter: 2796/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9702. T_Loss: 4.6581. Mask: 0.9170. :  95%|█████████▌| 95/100 [00:23<00:00,  6.05it/s]Train Iter: 2796/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9702. T_Loss: 4.6581. Mask: 0.9170. :  96%|█████████▌| 96/100 [00:23<00:00,  6.62it/s]Train Iter: 2797/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9700. T_Loss: 4.6465. Mask: 0.9172. :  96%|█████████▌| 96/100 [00:24<00:00,  6.62it/s]Train Iter: 2797/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9700. T_Loss: 4.6465. Mask: 0.9172. :  97%|█████████▋| 97/100 [00:24<00:00,  6.91it/s]Train Iter: 2798/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9701. T_Loss: 4.6385. Mask: 0.9171. :  97%|█████████▋| 97/100 [00:24<00:00,  6.91it/s]Train Iter: 2798/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9701. T_Loss: 4.6385. Mask: 0.9171. :  98%|█████████▊| 98/100 [00:24<00:00,  7.20it/s]Train Iter: 2799/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9702. T_Loss: 4.6363. Mask: 0.9164. :  98%|█████████▊| 98/100 [00:24<00:00,  7.20it/s]Train Iter: 2799/5000. LR: 0.0269. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9702. T_Loss: 4.6363. Mask: 0.9164. :  99%|█████████▉| 99/100 [00:24<00:00,  4.80it/s]Train Iter: 2800/5000. LR: 0.0269. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9696. T_Loss: 4.6288. Mask: 0.9163. :  99%|█████████▉| 99/100 [00:24<00:00,  4.80it/s]Train Iter: 2800/5000. LR: 0.0269. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9696. T_Loss: 4.6288. Mask: 0.9163. : 100%|██████████| 100/100 [00:24<00:00,  5.40it/s]Train Iter: 2800/5000. LR: 0.0269. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9696. T_Loss: 4.6288. Mask: 0.9163. : 100%|██████████| 100/100 [00:24<00:00,  4.05it/s]
total : 5000  current step :  2776
total : 5000  current step :  2777
total : 5000  current step :  2778
total : 5000  current step :  2779
total : 5000  current step :  2780
total : 5000  current step :  2781
total : 5000  current step :  2782
total : 5000  current step :  2783
total : 5000  current step :  2784
total : 5000  current step :  2785
total : 5000  current step :  2786
total : 5000  current step :  2787
total : 5000  current step :  2788
total : 5000  current step :  2789
total : 5000  current step :  2790
total : 5000  current step :  2791
total : 5000  current step :  2792
total : 5000  current step :  2793
total : 5000  current step :  2794
total : 5000  current step :  2795
total : 5000  current step :  2796
total : 5000  current step :  2797
total : 5000  current step :  2798
total : 5000  current step :  2799
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 0.9230. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 0.9230. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 0.9115. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.8856. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.8942. top1: 88.28. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8791. top1: 90.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8774. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8910. top1: 88.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8926. top1: 88.28. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8860. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.67s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8860. top1: 88.54. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8926. top1: 88.12. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8817. top1: 88.92. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8811. top1: 89.06. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8755. top1: 89.18. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8723. top1: 89.29. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8695. top1: 89.38. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8709. top1: 89.26. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8679. top1: 89.15. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.83it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8679. top1: 89.15. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8671. top1: 89.24. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8671. top1: 89.31. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8671. top1: 89.38. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8715. top1: 89.43. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8690. top1: 89.63. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8652. top1: 89.95. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8626. top1: 90.10. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8601. top1: 90.25. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8642. top1: 89.78. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.17it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8642. top1: 89.78. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 23.48it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8641. top1: 89.70. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 23.48it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8664. top1: 89.73. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8644. top1: 89.87. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8645. top1: 89.79. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8646. top1: 89.72. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8815. top1: 88.96. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8911. top1: 88.45. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9028. top1: 87.68. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9153. top1: 86.88. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9402. top1: 85.59. top5: 99.74. :  41%|████▏     | 26/63 [00:02<00:01, 23.48it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9402. top1: 85.59. top5: 99.74. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9467. top1: 85.22. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9556. top1: 84.70. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9702. top1: 84.05. top5: 99.68. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9804. top1: 83.52. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9873. top1: 83.23. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0030. top1: 82.44. top5: 99.48. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0112. top1: 82.05. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0151. top1: 81.96. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 34.65it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0151. top1: 81.96. top5: 99.50. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0182. top1: 81.67. top5: 99.51. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0262. top1: 81.11. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0330. top1: 80.78. top5: 99.53. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0377. top1: 80.47. top5: 99.54. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0446. top1: 80.23. top5: 99.55. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0488. top1: 79.94. top5: 99.50. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0625. top1: 79.11. top5: 99.51. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0667. top1: 78.97. top5: 99.46. :  70%|██████▉   | 44/63 [00:02<00:00, 42.23it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0667. top1: 78.97. top5: 99.46. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0759. top1: 78.54. top5: 99.47. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0847. top1: 78.18. top5: 99.42. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0884. top1: 78.01. top5: 99.43. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0913. top1: 77.85. top5: 99.44. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1002. top1: 77.25. top5: 99.45. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1074. top1: 76.67. top5: 99.46. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1130. top1: 76.32. top5: 99.47. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1125. top1: 76.35. top5: 99.48. :  83%|████████▎ | 52/63 [00:02<00:00, 46.58it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1125. top1: 76.35. top5: 99.48. :  95%|█████████▌| 60/63 [00:02<00:00, 53.38it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1193. top1: 75.87. top5: 99.49. :  95%|█████████▌| 60/63 [00:02<00:00, 53.38it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1288. top1: 75.30. top5: 99.50. :  95%|█████████▌| 60/63 [00:02<00:00, 53.38it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1295. top1: 75.30. top5: 99.50. :  95%|█████████▌| 60/63 [00:02<00:00, 53.38it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1295. top1: 75.30. top5: 99.50. : 100%|██████████| 63/63 [00:02<00:00, 23.61it/s]
total : 5000  current step :  2800
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2801/5000. LR: 0.0268. Data: 2.11s. Batch: 2.23s. S_Loss: 1.0993. T_Loss: 4.6666. Mask: 0.9062. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2801/5000. LR: 0.0268. Data: 2.11s. Batch: 2.23s. S_Loss: 1.0993. T_Loss: 4.6666. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:41,  2.23s/it]Train Iter: 2802/5000. LR: 0.0268. Data: 1.06s. Batch: 1.17s. S_Loss: 1.0233. T_Loss: 4.3249. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:41,  2.23s/it]Train Iter: 2802/5000. LR: 0.0268. Data: 1.06s. Batch: 1.17s. S_Loss: 1.0233. T_Loss: 4.3249. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 2803/5000. LR: 0.0268. Data: 0.71s. Batch: 0.83s. S_Loss: 1.0209. T_Loss: 4.3429. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:36,  1.01it/s]Train Iter: 2803/5000. LR: 0.0268. Data: 0.71s. Batch: 0.83s. S_Loss: 1.0209. T_Loss: 4.3429. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<00:58,  1.67it/s]Train Iter: 2804/5000. LR: 0.0268. Data: 0.53s. Batch: 0.65s. S_Loss: 1.0292. T_Loss: 4.3317. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:58,  1.67it/s]Train Iter: 2804/5000. LR: 0.0268. Data: 0.53s. Batch: 0.65s. S_Loss: 1.0292. T_Loss: 4.3317. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:39,  2.43it/s]Train Iter: 2805/5000. LR: 0.0268. Data: 0.43s. Batch: 0.58s. S_Loss: 1.0009. T_Loss: 4.3127. Mask: 0.9313. :   4%|▍         | 4/100 [00:02<00:39,  2.43it/s]Train Iter: 2805/5000. LR: 0.0268. Data: 0.43s. Batch: 0.58s. S_Loss: 1.0009. T_Loss: 4.3127. Mask: 0.9313. :   5%|▌         | 5/100 [00:02<00:34,  2.72it/s]Train Iter: 2806/5000. LR: 0.0268. Data: 0.35s. Batch: 0.50s. S_Loss: 1.0189. T_Loss: 4.4498. Mask: 0.9271. :   5%|▌         | 5/100 [00:03<00:34,  2.72it/s]Train Iter: 2806/5000. LR: 0.0268. Data: 0.35s. Batch: 0.50s. S_Loss: 1.0189. T_Loss: 4.4498. Mask: 0.9271. :   6%|▌         | 6/100 [00:03<00:26,  3.54it/s]Train Iter: 2807/5000. LR: 0.0267. Data: 0.30s. Batch: 0.45s. S_Loss: 1.0195. T_Loss: 4.5937. Mask: 0.9286. :   6%|▌         | 6/100 [00:03<00:26,  3.54it/s]Train Iter: 2807/5000. LR: 0.0267. Data: 0.30s. Batch: 0.45s. S_Loss: 1.0195. T_Loss: 4.5937. Mask: 0.9286. :   7%|▋         | 7/100 [00:03<00:21,  4.29it/s]Train Iter: 2808/5000. LR: 0.0267. Data: 0.27s. Batch: 0.41s. S_Loss: 1.0139. T_Loss: 4.5553. Mask: 0.9297. :   7%|▋         | 7/100 [00:03<00:21,  4.29it/s]Train Iter: 2808/5000. LR: 0.0267. Data: 0.27s. Batch: 0.41s. S_Loss: 1.0139. T_Loss: 4.5553. Mask: 0.9297. :   8%|▊         | 8/100 [00:03<00:18,  5.02it/s]Train Iter: 2809/5000. LR: 0.0267. Data: 0.24s. Batch: 0.40s. S_Loss: 1.0055. T_Loss: 4.4808. Mask: 0.9306. :   8%|▊         | 8/100 [00:03<00:18,  5.02it/s]Train Iter: 2809/5000. LR: 0.0267. Data: 0.24s. Batch: 0.40s. S_Loss: 1.0055. T_Loss: 4.4808. Mask: 0.9306. :   9%|▉         | 9/100 [00:03<00:21,  4.18it/s]Train Iter: 2810/5000. LR: 0.0267. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9960. T_Loss: 4.4600. Mask: 0.9187. :   9%|▉         | 9/100 [00:03<00:21,  4.18it/s]Train Iter: 2810/5000. LR: 0.0267. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9960. T_Loss: 4.4600. Mask: 0.9187. :  10%|█         | 10/100 [00:03<00:18,  4.90it/s]Train Iter: 2811/5000. LR: 0.0267. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9960. T_Loss: 4.4988. Mask: 0.9233. :  10%|█         | 10/100 [00:03<00:18,  4.90it/s]Train Iter: 2811/5000. LR: 0.0267. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9960. T_Loss: 4.4988. Mask: 0.9233. :  11%|█         | 11/100 [00:03<00:15,  5.58it/s]Train Iter: 2812/5000. LR: 0.0266. Data: 0.18s. Batch: 0.33s. S_Loss: 1.0010. T_Loss: 4.5423. Mask: 0.9219. :  11%|█         | 11/100 [00:03<00:15,  5.58it/s]Train Iter: 2812/5000. LR: 0.0266. Data: 0.18s. Batch: 0.33s. S_Loss: 1.0010. T_Loss: 4.5423. Mask: 0.9219. :  12%|█▏        | 12/100 [00:03<00:14,  6.18it/s]Train Iter: 2813/5000. LR: 0.0266. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0025. T_Loss: 4.5404. Mask: 0.9207. :  12%|█▏        | 12/100 [00:04<00:14,  6.18it/s]Train Iter: 2813/5000. LR: 0.0266. Data: 0.17s. Batch: 0.31s. S_Loss: 1.0025. T_Loss: 4.5404. Mask: 0.9207. :  13%|█▎        | 13/100 [00:04<00:13,  6.63it/s]Train Iter: 2814/5000. LR: 0.0266. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0051. T_Loss: 4.6245. Mask: 0.9241. :  13%|█▎        | 13/100 [00:04<00:13,  6.63it/s]Train Iter: 2814/5000. LR: 0.0266. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0051. T_Loss: 4.6245. Mask: 0.9241. :  14%|█▍        | 14/100 [00:04<00:12,  7.07it/s]Train Iter: 2815/5000. LR: 0.0266. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0061. T_Loss: 4.6755. Mask: 0.9271. :  14%|█▍        | 14/100 [00:04<00:12,  7.07it/s]Train Iter: 2815/5000. LR: 0.0266. Data: 0.14s. Batch: 0.30s. S_Loss: 1.0061. T_Loss: 4.6755. Mask: 0.9271. :  15%|█▌        | 15/100 [00:04<00:16,  5.30it/s]Train Iter: 2816/5000. LR: 0.0266. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0041. T_Loss: 4.6449. Mask: 0.9238. :  15%|█▌        | 15/100 [00:04<00:16,  5.30it/s]Train Iter: 2816/5000. LR: 0.0266. Data: 0.14s. Batch: 0.29s. S_Loss: 1.0041. T_Loss: 4.6449. Mask: 0.9238. :  16%|█▌        | 16/100 [00:04<00:14,  5.61it/s]total : 5000  current step :  2801
total : 5000  current step :  2802
total : 5000  current step :  2803
total : 5000  current step :  2804
total : 5000  current step :  2805
total : 5000  current step :  2806
total : 5000  current step :  2807
total : 5000  current step :  2808
total : 5000  current step :  2809
total : 5000  current step :  2810
total : 5000  current step :  2811
total : 5000  current step :  2812
total : 5000  current step :  2813
total : 5000  current step :  2814
total : 5000  current step :  2815
total : 5000  current step :  2816
Train Iter: 2817/5000. LR: 0.0266. Data: 0.23s. Batch: 0.39s. S_Loss: 1.0000. T_Loss: 4.6181. Mask: 0.9228. :  16%|█▌        | 16/100 [00:06<00:14,  5.61it/s]Train Iter: 2817/5000. LR: 0.0266. Data: 0.23s. Batch: 0.39s. S_Loss: 1.0000. T_Loss: 4.6181. Mask: 0.9228. :  17%|█▋        | 17/100 [00:06<00:58,  1.42it/s]Train Iter: 2818/5000. LR: 0.0265. Data: 0.22s. Batch: 0.37s. S_Loss: 0.9964. T_Loss: 4.6249. Mask: 0.9271. :  17%|█▋        | 17/100 [00:06<00:58,  1.42it/s]Train Iter: 2818/5000. LR: 0.0265. Data: 0.22s. Batch: 0.37s. S_Loss: 0.9964. T_Loss: 4.6249. Mask: 0.9271. :  18%|█▊        | 18/100 [00:06<00:43,  1.87it/s]Train Iter: 2819/5000. LR: 0.0265. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9932. T_Loss: 4.6593. Mask: 0.9293. :  18%|█▊        | 18/100 [00:07<00:43,  1.87it/s]Train Iter: 2819/5000. LR: 0.0265. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9932. T_Loss: 4.6593. Mask: 0.9293. :  19%|█▉        | 19/100 [00:07<00:38,  2.11it/s]Train Iter: 2820/5000. LR: 0.0265. Data: 0.20s. Batch: 0.36s. S_Loss: 0.9951. T_Loss: 4.6359. Mask: 0.9266. :  19%|█▉        | 19/100 [00:07<00:38,  2.11it/s]Train Iter: 2821/5000. LR: 0.0265. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9954. T_Loss: 4.6796. Mask: 0.9271. :  20%|██        | 20/100 [00:07<00:37,  2.11it/s]Train Iter: 2821/5000. LR: 0.0265. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9954. T_Loss: 4.6796. Mask: 0.9271. :  21%|██        | 21/100 [00:07<00:23,  3.30it/s]Train Iter: 2822/5000. LR: 0.0265. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9933. T_Loss: 4.7239. Mask: 0.9304. :  21%|██        | 21/100 [00:07<00:23,  3.30it/s]Train Iter: 2822/5000. LR: 0.0265. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9933. T_Loss: 4.7239. Mask: 0.9304. :  22%|██▏       | 22/100 [00:07<00:20,  3.89it/s]Train Iter: 2823/5000. LR: 0.0264. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9927. T_Loss: 4.7244. Mask: 0.9307. :  22%|██▏       | 22/100 [00:07<00:20,  3.89it/s]Train Iter: 2823/5000. LR: 0.0264. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9927. T_Loss: 4.7244. Mask: 0.9307. :  23%|██▎       | 23/100 [00:07<00:16,  4.55it/s]Train Iter: 2824/5000. LR: 0.0264. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9883. T_Loss: 4.7020. Mask: 0.9323. :  23%|██▎       | 23/100 [00:07<00:16,  4.55it/s]Train Iter: 2824/5000. LR: 0.0264. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9883. T_Loss: 4.7020. Mask: 0.9323. :  24%|██▍       | 24/100 [00:07<00:14,  5.24it/s]Train Iter: 2825/5000. LR: 0.0264. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9838. T_Loss: 4.7052. Mask: 0.9337. :  24%|██▍       | 24/100 [00:07<00:14,  5.24it/s]Train Iter: 2825/5000. LR: 0.0264. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9838. T_Loss: 4.7052. Mask: 0.9337. :  25%|██▌       | 25/100 [00:07<00:16,  4.67it/s]total : 5000  current step :  2817
total : 5000  current step :  2818
total : 5000  current step :  2819
total : 5000  current step :  2820
total : 5000  current step :  2821
total : 5000  current step :  2822
total : 5000  current step :  2823
total : 5000  current step :  2824
total : 5000  current step :  2825
Train Iter: 2826/5000. LR: 0.0264. Data: 0.23s. Batch: 0.38s. S_Loss: 0.9855. T_Loss: 4.7194. Mask: 0.9327. :  25%|██▌       | 25/100 [00:09<00:16,  4.67it/s]Train Iter: 2826/5000. LR: 0.0264. Data: 0.23s. Batch: 0.38s. S_Loss: 0.9855. T_Loss: 4.7194. Mask: 0.9327. :  26%|██▌       | 26/100 [00:09<00:53,  1.38it/s]Train Iter: 2827/5000. LR: 0.0264. Data: 0.22s. Batch: 0.37s. S_Loss: 0.9832. T_Loss: 4.7186. Mask: 0.9306. :  26%|██▌       | 26/100 [00:09<00:53,  1.38it/s]Train Iter: 2827/5000. LR: 0.0264. Data: 0.22s. Batch: 0.37s. S_Loss: 0.9832. T_Loss: 4.7186. Mask: 0.9306. :  27%|██▋       | 27/100 [00:09<00:39,  1.84it/s]Train Iter: 2828/5000. LR: 0.0263. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9864. T_Loss: 4.7488. Mask: 0.9308. :  27%|██▋       | 27/100 [00:10<00:39,  1.84it/s]Train Iter: 2828/5000. LR: 0.0263. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9864. T_Loss: 4.7488. Mask: 0.9308. :  28%|██▊       | 28/100 [00:10<00:29,  2.41it/s]Train Iter: 2829/5000. LR: 0.0263. Data: 0.20s. Batch: 0.36s. S_Loss: 0.9851. T_Loss: 4.7282. Mask: 0.9267. :  28%|██▊       | 28/100 [00:10<00:29,  2.41it/s]Train Iter: 2829/5000. LR: 0.0263. Data: 0.20s. Batch: 0.36s. S_Loss: 0.9851. T_Loss: 4.7282. Mask: 0.9267. :  29%|██▉       | 29/100 [00:10<00:26,  2.65it/s]Train Iter: 2830/5000. LR: 0.0263. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9861. T_Loss: 4.7240. Mask: 0.9250. :  29%|██▉       | 29/100 [00:10<00:26,  2.65it/s]Train Iter: 2830/5000. LR: 0.0263. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9861. T_Loss: 4.7240. Mask: 0.9250. :  30%|███       | 30/100 [00:10<00:21,  3.26it/s]Train Iter: 2831/5000. LR: 0.0263. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9847. T_Loss: 4.7146. Mask: 0.9244. :  30%|███       | 30/100 [00:10<00:21,  3.26it/s]Train Iter: 2831/5000. LR: 0.0263. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9847. T_Loss: 4.7146. Mask: 0.9244. :  31%|███       | 31/100 [00:10<00:17,  3.94it/s]Train Iter: 2832/5000. LR: 0.0263. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9842. T_Loss: 4.6979. Mask: 0.9209. :  31%|███       | 31/100 [00:10<00:17,  3.94it/s]Train Iter: 2832/5000. LR: 0.0263. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9842. T_Loss: 4.6979. Mask: 0.9209. :  32%|███▏      | 32/100 [00:10<00:14,  4.71it/s]Train Iter: 2833/5000. LR: 0.0263. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9860. T_Loss: 4.7358. Mask: 0.9214. :  32%|███▏      | 32/100 [00:10<00:14,  4.71it/s]Train Iter: 2833/5000. LR: 0.0263. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9860. T_Loss: 4.7358. Mask: 0.9214. :  33%|███▎      | 33/100 [00:10<00:12,  5.39it/s]Train Iter: 2834/5000. LR: 0.0262. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9866. T_Loss: 4.7311. Mask: 0.9219. :  33%|███▎      | 33/100 [00:11<00:12,  5.39it/s]Train Iter: 2834/5000. LR: 0.0262. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9866. T_Loss: 4.7311. Mask: 0.9219. :  34%|███▍      | 34/100 [00:11<00:12,  5.47it/s]Train Iter: 2835/5000. LR: 0.0262. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9881. T_Loss: 4.7276. Mask: 0.9187. :  34%|███▍      | 34/100 [00:11<00:12,  5.47it/s]Train Iter: 2835/5000. LR: 0.0262. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9881. T_Loss: 4.7276. Mask: 0.9187. :  35%|███▌      | 35/100 [00:11<00:14,  4.45it/s]Train Iter: 2836/5000. LR: 0.0262. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9877. T_Loss: 4.7100. Mask: 0.9167. :  35%|███▌      | 35/100 [00:11<00:14,  4.45it/s]Train Iter: 2836/5000. LR: 0.0262. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9877. T_Loss: 4.7100. Mask: 0.9167. :  36%|███▌      | 36/100 [00:11<00:12,  5.18it/s]Train Iter: 2837/5000. LR: 0.0262. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9871. T_Loss: 4.7245. Mask: 0.9155. :  36%|███▌      | 36/100 [00:11<00:12,  5.18it/s]Train Iter: 2837/5000. LR: 0.0262. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9871. T_Loss: 4.7245. Mask: 0.9155. :  37%|███▋      | 37/100 [00:11<00:10,  5.86it/s]Train Iter: 2838/5000. LR: 0.0262. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9849. T_Loss: 4.7239. Mask: 0.9161. :  37%|███▋      | 37/100 [00:11<00:10,  5.86it/s]Train Iter: 2838/5000. LR: 0.0262. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9849. T_Loss: 4.7239. Mask: 0.9161. :  38%|███▊      | 38/100 [00:11<00:09,  6.45it/s]Train Iter: 2839/5000. LR: 0.0261. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9838. T_Loss: 4.7209. Mask: 0.9151. :  38%|███▊      | 38/100 [00:12<00:09,  6.45it/s]Train Iter: 2839/5000. LR: 0.0261. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9838. T_Loss: 4.7209. Mask: 0.9151. :  39%|███▉      | 39/100 [00:12<00:11,  5.12it/s]Train Iter: 2840/5000. LR: 0.0261. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9816. T_Loss: 4.6921. Mask: 0.9141. :  39%|███▉      | 39/100 [00:12<00:11,  5.12it/s]Train Iter: 2840/5000. LR: 0.0261. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9816. T_Loss: 4.6921. Mask: 0.9141. :  40%|████      | 40/100 [00:12<00:10,  5.76it/s]Train Iter: 2841/5000. LR: 0.0261. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9800. T_Loss: 4.6846. Mask: 0.9146. :  40%|████      | 40/100 [00:12<00:10,  5.76it/s]Train Iter: 2841/5000. LR: 0.0261. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9800. T_Loss: 4.6846. Mask: 0.9146. :  41%|████      | 41/100 [00:12<00:09,  6.28it/s]Train Iter: 2842/5000. LR: 0.0261. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9817. T_Loss: 4.6844. Mask: 0.9144. :  41%|████      | 41/100 [00:12<00:09,  6.28it/s]Train Iter: 2842/5000. LR: 0.0261. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9817. T_Loss: 4.6844. Mask: 0.9144. :  42%|████▏     | 42/100 [00:12<00:08,  6.91it/s]Train Iter: 2843/5000. LR: 0.0261. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9808. T_Loss: 4.6830. Mask: 0.9150. :  42%|████▏     | 42/100 [00:12<00:08,  6.91it/s]Train Iter: 2843/5000. LR: 0.0261. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9808. T_Loss: 4.6830. Mask: 0.9150. :  43%|████▎     | 43/100 [00:12<00:07,  7.22it/s]Train Iter: 2844/5000. LR: 0.0260. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9791. T_Loss: 4.6805. Mask: 0.9141. :  43%|████▎     | 43/100 [00:12<00:07,  7.22it/s]Train Iter: 2845/5000. LR: 0.0260. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9822. T_Loss: 4.6951. Mask: 0.9132. :  44%|████▍     | 44/100 [00:12<00:07,  7.22it/s]Train Iter: 2845/5000. LR: 0.0260. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9822. T_Loss: 4.6951. Mask: 0.9132. :  45%|████▌     | 45/100 [00:12<00:06,  7.89it/s]Train Iter: 2846/5000. LR: 0.0260. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9851. T_Loss: 4.7081. Mask: 0.9137. :  45%|████▌     | 45/100 [00:12<00:06,  7.89it/s]Train Iter: 2846/5000. LR: 0.0260. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9851. T_Loss: 4.7081. Mask: 0.9137. :  46%|████▌     | 46/100 [00:12<00:06,  8.00it/s]Train Iter: 2847/5000. LR: 0.0260. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9825. T_Loss: 4.6972. Mask: 0.9136. :  46%|████▌     | 46/100 [00:12<00:06,  8.00it/s]Train Iter: 2847/5000. LR: 0.0260. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9825. T_Loss: 4.6972. Mask: 0.9136. :  47%|████▋     | 47/100 [00:12<00:06,  8.07it/s]Train Iter: 2848/5000. LR: 0.0260. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9813. T_Loss: 4.6959. Mask: 0.9154. :  47%|████▋     | 47/100 [00:13<00:06,  8.07it/s]Train Iter: 2848/5000. LR: 0.0260. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9813. T_Loss: 4.6959. Mask: 0.9154. :  48%|████▊     | 48/100 [00:13<00:06,  8.02it/s]Train Iter: 2849/5000. LR: 0.0260. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9820. T_Loss: 4.7070. Mask: 0.9158. :  48%|████▊     | 48/100 [00:13<00:06,  8.02it/s]Train Iter: 2849/5000. LR: 0.0260. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9820. T_Loss: 4.7070. Mask: 0.9158. :  49%|████▉     | 49/100 [00:13<00:09,  5.27it/s]Train Iter: 2850/5000. LR: 0.0259. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9801. T_Loss: 4.6896. Mask: 0.9163. :  49%|████▉     | 49/100 [00:13<00:09,  5.27it/s]Train Iter: 2850/5000. LR: 0.0259. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9801. T_Loss: 4.6896. Mask: 0.9163. :  50%|█████     | 50/100 [00:13<00:08,  6.06it/s]total : 5000  current step :  2826
total : 5000  current step :  2827
total : 5000  current step :  2828
total : 5000  current step :  2829
total : 5000  current step :  2830
total : 5000  current step :  2831
total : 5000  current step :  2832
total : 5000  current step :  2833
total : 5000  current step :  2834
total : 5000  current step :  2835
total : 5000  current step :  2836
total : 5000  current step :  2837
total : 5000  current step :  2838
total : 5000  current step :  2839
total : 5000  current step :  2840
total : 5000  current step :  2841
total : 5000  current step :  2842
total : 5000  current step :  2843
total : 5000  current step :  2844
total : 5000  current step :  2845
total : 5000  current step :  2846
total : 5000  current step :  2847
total : 5000  current step :  2848
total : 5000  current step :  2849
total : 5000  current step :  2850
Train Iter: 2851/5000. LR: 0.0259. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9795. T_Loss: 4.6830. Mask: 0.9167. :  50%|█████     | 50/100 [00:15<00:08,  6.06it/s]Train Iter: 2851/5000. LR: 0.0259. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9795. T_Loss: 4.6830. Mask: 0.9167. :  51%|█████     | 51/100 [00:15<00:34,  1.42it/s]Train Iter: 2852/5000. LR: 0.0259. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9783. T_Loss: 4.6719. Mask: 0.9171. :  51%|█████     | 51/100 [00:15<00:34,  1.42it/s]Train Iter: 2852/5000. LR: 0.0259. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9783. T_Loss: 4.6719. Mask: 0.9171. :  52%|█████▏    | 52/100 [00:15<00:25,  1.88it/s]Train Iter: 2853/5000. LR: 0.0259. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9791. T_Loss: 4.6739. Mask: 0.9169. :  52%|█████▏    | 52/100 [00:15<00:25,  1.88it/s]Train Iter: 2853/5000. LR: 0.0259. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9791. T_Loss: 4.6739. Mask: 0.9169. :  53%|█████▎    | 53/100 [00:15<00:19,  2.41it/s]Train Iter: 2854/5000. LR: 0.0259. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9789. T_Loss: 4.6751. Mask: 0.9172. :  53%|█████▎    | 53/100 [00:15<00:19,  2.41it/s]Train Iter: 2854/5000. LR: 0.0259. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9789. T_Loss: 4.6751. Mask: 0.9172. :  54%|█████▍    | 54/100 [00:15<00:15,  3.04it/s]Train Iter: 2855/5000. LR: 0.0258. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9796. T_Loss: 4.6771. Mask: 0.9170. :  54%|█████▍    | 54/100 [00:16<00:15,  3.04it/s]Train Iter: 2855/5000. LR: 0.0258. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9796. T_Loss: 4.6771. Mask: 0.9170. :  55%|█████▌    | 55/100 [00:16<00:13,  3.32it/s]Train Iter: 2856/5000. LR: 0.0258. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9792. T_Loss: 4.6757. Mask: 0.9169. :  55%|█████▌    | 55/100 [00:16<00:13,  3.32it/s]Train Iter: 2857/5000. LR: 0.0258. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9787. T_Loss: 4.6649. Mask: 0.9172. :  56%|█████▌    | 56/100 [00:16<00:13,  3.32it/s]Train Iter: 2857/5000. LR: 0.0258. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9787. T_Loss: 4.6649. Mask: 0.9172. :  57%|█████▋    | 57/100 [00:16<00:08,  5.02it/s]Train Iter: 2858/5000. LR: 0.0258. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9782. T_Loss: 4.6555. Mask: 0.9165. :  57%|█████▋    | 57/100 [00:16<00:08,  5.02it/s]Train Iter: 2859/5000. LR: 0.0258. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9775. T_Loss: 4.6734. Mask: 0.9179. :  58%|█████▊    | 58/100 [00:16<00:08,  5.02it/s]Train Iter: 2859/5000. LR: 0.0258. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9775. T_Loss: 4.6734. Mask: 0.9179. :  59%|█████▉    | 59/100 [00:16<00:08,  4.93it/s]Train Iter: 2860/5000. LR: 0.0257. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9768. T_Loss: 4.6616. Mask: 0.9161. :  59%|█████▉    | 59/100 [00:16<00:08,  4.93it/s]Train Iter: 2861/5000. LR: 0.0257. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9744. T_Loss: 4.6574. Mask: 0.9170. :  60%|██████    | 60/100 [00:16<00:08,  4.93it/s]Train Iter: 2861/5000. LR: 0.0257. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9744. T_Loss: 4.6574. Mask: 0.9170. :  61%|██████    | 61/100 [00:16<00:06,  6.06it/s]Train Iter: 2862/5000. LR: 0.0257. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9743. T_Loss: 4.6684. Mask: 0.9183. :  61%|██████    | 61/100 [00:17<00:06,  6.06it/s]Train Iter: 2862/5000. LR: 0.0257. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9743. T_Loss: 4.6684. Mask: 0.9183. :  62%|██████▏   | 62/100 [00:17<00:05,  6.52it/s]Train Iter: 2863/5000. LR: 0.0257. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9758. T_Loss: 4.6757. Mask: 0.9187. :  62%|██████▏   | 62/100 [00:17<00:05,  6.52it/s]Train Iter: 2863/5000. LR: 0.0257. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9758. T_Loss: 4.6757. Mask: 0.9187. :  63%|██████▎   | 63/100 [00:17<00:05,  7.00it/s]Train Iter: 2864/5000. LR: 0.0257. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9743. T_Loss: 4.6652. Mask: 0.9189. :  63%|██████▎   | 63/100 [00:17<00:05,  7.00it/s]Train Iter: 2864/5000. LR: 0.0257. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9743. T_Loss: 4.6652. Mask: 0.9189. :  64%|██████▍   | 64/100 [00:17<00:04,  7.56it/s]Train Iter: 2865/5000. LR: 0.0257. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9739. T_Loss: 4.6586. Mask: 0.9192. :  64%|██████▍   | 64/100 [00:17<00:04,  7.56it/s]Train Iter: 2866/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9726. T_Loss: 4.6535. Mask: 0.9200. :  65%|██████▌   | 65/100 [00:17<00:04,  7.56it/s]Train Iter: 2866/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9726. T_Loss: 4.6535. Mask: 0.9200. :  66%|██████▌   | 66/100 [00:17<00:03,  8.87it/s]Train Iter: 2867/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9731. T_Loss: 4.6446. Mask: 0.9193. :  66%|██████▌   | 66/100 [00:17<00:03,  8.87it/s]Train Iter: 2867/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9731. T_Loss: 4.6446. Mask: 0.9193. :  67%|██████▋   | 67/100 [00:17<00:03,  8.81it/s]Train Iter: 2868/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9726. T_Loss: 4.6376. Mask: 0.9191. :  67%|██████▋   | 67/100 [00:17<00:03,  8.81it/s]Train Iter: 2868/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9726. T_Loss: 4.6376. Mask: 0.9191. :  68%|██████▊   | 68/100 [00:17<00:03,  8.77it/s]Train Iter: 2869/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9730. T_Loss: 4.6433. Mask: 0.9198. :  68%|██████▊   | 68/100 [00:17<00:03,  8.77it/s]Train Iter: 2869/5000. LR: 0.0256. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9730. T_Loss: 4.6433. Mask: 0.9198. :  69%|██████▉   | 69/100 [00:17<00:04,  6.36it/s]Train Iter: 2870/5000. LR: 0.0256. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9734. T_Loss: 4.6463. Mask: 0.9205. :  69%|██████▉   | 69/100 [00:18<00:04,  6.36it/s]Train Iter: 2870/5000. LR: 0.0256. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9734. T_Loss: 4.6463. Mask: 0.9205. :  70%|███████   | 70/100 [00:18<00:04,  6.85it/s]Train Iter: 2871/5000. LR: 0.0255. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9734. T_Loss: 4.6404. Mask: 0.9199. :  70%|███████   | 70/100 [00:18<00:04,  6.85it/s]Train Iter: 2871/5000. LR: 0.0255. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9734. T_Loss: 4.6404. Mask: 0.9199. :  71%|███████   | 71/100 [00:18<00:04,  7.00it/s]Train Iter: 2872/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9750. T_Loss: 4.6556. Mask: 0.9193. :  71%|███████   | 71/100 [00:18<00:04,  7.00it/s]Train Iter: 2872/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9750. T_Loss: 4.6556. Mask: 0.9193. :  72%|███████▏  | 72/100 [00:18<00:03,  7.23it/s]Train Iter: 2873/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9731. T_Loss: 4.6532. Mask: 0.9204. :  72%|███████▏  | 72/100 [00:18<00:03,  7.23it/s]Train Iter: 2873/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9731. T_Loss: 4.6532. Mask: 0.9204. :  73%|███████▎  | 73/100 [00:18<00:03,  7.46it/s]Train Iter: 2874/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9731. T_Loss: 4.6591. Mask: 0.9198. :  73%|███████▎  | 73/100 [00:18<00:03,  7.46it/s]Train Iter: 2874/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9731. T_Loss: 4.6591. Mask: 0.9198. :  74%|███████▍  | 74/100 [00:18<00:03,  7.64it/s]Train Iter: 2875/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9741. T_Loss: 4.6544. Mask: 0.9196. :  74%|███████▍  | 74/100 [00:18<00:03,  7.64it/s]Train Iter: 2875/5000. LR: 0.0255. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9741. T_Loss: 4.6544. Mask: 0.9196. :  75%|███████▌  | 75/100 [00:18<00:05,  4.88it/s]total : 5000  current step :  2851
total : 5000  current step :  2852
total : 5000  current step :  2853
total : 5000  current step :  2854
total : 5000  current step :  2855
total : 5000  current step :  2856
total : 5000  current step :  2857
total : 5000  current step :  2858
total : 5000  current step :  2859
total : 5000  current step :  2860
total : 5000  current step :  2861
total : 5000  current step :  2862
total : 5000  current step :  2863
total : 5000  current step :  2864
total : 5000  current step :  2865
total : 5000  current step :  2866
total : 5000  current step :  2867
total : 5000  current step :  2868
total : 5000  current step :  2869
total : 5000  current step :  2870
total : 5000  current step :  2871
total : 5000  current step :  2872
total : 5000  current step :  2873
total : 5000  current step :  2874
total : 5000  current step :  2875
Train Iter: 2876/5000. LR: 0.0254. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9732. T_Loss: 4.6418. Mask: 0.9182. :  75%|███████▌  | 75/100 [00:20<00:05,  4.88it/s]Train Iter: 2876/5000. LR: 0.0254. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9732. T_Loss: 4.6418. Mask: 0.9182. :  76%|███████▌  | 76/100 [00:20<00:17,  1.41it/s]Train Iter: 2877/5000. LR: 0.0254. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9729. T_Loss: 4.6471. Mask: 0.9188. :  76%|███████▌  | 76/100 [00:21<00:17,  1.41it/s]Train Iter: 2877/5000. LR: 0.0254. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9729. T_Loss: 4.6471. Mask: 0.9188. :  77%|███████▋  | 77/100 [00:21<00:12,  1.84it/s]Train Iter: 2878/5000. LR: 0.0254. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9724. T_Loss: 4.6495. Mask: 0.9187. :  77%|███████▋  | 77/100 [00:21<00:12,  1.84it/s]Train Iter: 2878/5000. LR: 0.0254. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9724. T_Loss: 4.6495. Mask: 0.9187. :  78%|███████▊  | 78/100 [00:21<00:09,  2.34it/s]Train Iter: 2879/5000. LR: 0.0254. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9728. T_Loss: 4.6663. Mask: 0.9189. :  78%|███████▊  | 78/100 [00:21<00:09,  2.34it/s]Train Iter: 2879/5000. LR: 0.0254. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9728. T_Loss: 4.6663. Mask: 0.9189. :  79%|███████▉  | 79/100 [00:21<00:08,  2.47it/s]Train Iter: 2880/5000. LR: 0.0254. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9725. T_Loss: 4.6692. Mask: 0.9187. :  79%|███████▉  | 79/100 [00:21<00:08,  2.47it/s]Train Iter: 2880/5000. LR: 0.0254. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9725. T_Loss: 4.6692. Mask: 0.9187. :  80%|████████  | 80/100 [00:21<00:06,  3.12it/s]Train Iter: 2881/5000. LR: 0.0254. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9743. T_Loss: 4.6800. Mask: 0.9182. :  80%|████████  | 80/100 [00:21<00:06,  3.12it/s]Train Iter: 2881/5000. LR: 0.0254. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9743. T_Loss: 4.6800. Mask: 0.9182. :  81%|████████  | 81/100 [00:21<00:04,  3.83it/s]Train Iter: 2882/5000. LR: 0.0253. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9768. T_Loss: 4.6857. Mask: 0.9177. :  81%|████████  | 81/100 [00:21<00:04,  3.83it/s]Train Iter: 2882/5000. LR: 0.0253. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9768. T_Loss: 4.6857. Mask: 0.9177. :  82%|████████▏ | 82/100 [00:21<00:03,  4.54it/s]Train Iter: 2883/5000. LR: 0.0253. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9763. T_Loss: 4.6830. Mask: 0.9160. :  82%|████████▏ | 82/100 [00:22<00:03,  4.54it/s]Train Iter: 2883/5000. LR: 0.0253. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9763. T_Loss: 4.6830. Mask: 0.9160. :  83%|████████▎ | 83/100 [00:22<00:03,  5.25it/s]Train Iter: 2884/5000. LR: 0.0253. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9793. T_Loss: 4.6774. Mask: 0.9144. :  83%|████████▎ | 83/100 [00:22<00:03,  5.25it/s]Train Iter: 2884/5000. LR: 0.0253. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9793. T_Loss: 4.6774. Mask: 0.9144. :  84%|████████▍ | 84/100 [00:22<00:02,  5.80it/s]Train Iter: 2885/5000. LR: 0.0253. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9788. T_Loss: 4.6830. Mask: 0.9140. :  84%|████████▍ | 84/100 [00:22<00:02,  5.80it/s]Train Iter: 2885/5000. LR: 0.0253. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9788. T_Loss: 4.6830. Mask: 0.9140. :  85%|████████▌ | 85/100 [00:22<00:03,  4.79it/s]Train Iter: 2886/5000. LR: 0.0253. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9789. T_Loss: 4.6859. Mask: 0.9139. :  85%|████████▌ | 85/100 [00:22<00:03,  4.79it/s]Train Iter: 2886/5000. LR: 0.0253. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9789. T_Loss: 4.6859. Mask: 0.9139. :  86%|████████▌ | 86/100 [00:22<00:02,  5.43it/s]Train Iter: 2887/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9792. T_Loss: 4.6938. Mask: 0.9138. :  86%|████████▌ | 86/100 [00:22<00:02,  5.43it/s]Train Iter: 2887/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9792. T_Loss: 4.6938. Mask: 0.9138. :  87%|████████▋ | 87/100 [00:22<00:02,  5.97it/s]Train Iter: 2888/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9783. T_Loss: 4.6971. Mask: 0.9144. :  87%|████████▋ | 87/100 [00:22<00:02,  5.97it/s]Train Iter: 2888/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9783. T_Loss: 4.6971. Mask: 0.9144. :  88%|████████▊ | 88/100 [00:22<00:01,  6.58it/s]Train Iter: 2889/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9781. T_Loss: 4.6997. Mask: 0.9140. :  88%|████████▊ | 88/100 [00:22<00:01,  6.58it/s]Train Iter: 2889/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9781. T_Loss: 4.6997. Mask: 0.9140. :  89%|████████▉ | 89/100 [00:22<00:01,  7.08it/s]Train Iter: 2890/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9780. T_Loss: 4.7033. Mask: 0.9142. :  89%|████████▉ | 89/100 [00:23<00:01,  7.08it/s]Train Iter: 2890/5000. LR: 0.0252. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9780. T_Loss: 4.7033. Mask: 0.9142. :  90%|█████████ | 90/100 [00:23<00:01,  7.35it/s]Train Iter: 2891/5000. LR: 0.0252. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9766. T_Loss: 4.6985. Mask: 0.9145. :  90%|█████████ | 90/100 [00:23<00:01,  7.35it/s]Train Iter: 2891/5000. LR: 0.0252. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9766. T_Loss: 4.6985. Mask: 0.9145. :  91%|█████████ | 91/100 [00:23<00:01,  7.33it/s]Train Iter: 2892/5000. LR: 0.0251. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9776. T_Loss: 4.7052. Mask: 0.9147. :  91%|█████████ | 91/100 [00:23<00:01,  7.33it/s]Train Iter: 2892/5000. LR: 0.0251. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9776. T_Loss: 4.7052. Mask: 0.9147. :  92%|█████████▏| 92/100 [00:23<00:01,  7.30it/s]Train Iter: 2893/5000. LR: 0.0251. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9767. T_Loss: 4.7000. Mask: 0.9153. :  92%|█████████▏| 92/100 [00:23<00:01,  7.30it/s]Train Iter: 2893/5000. LR: 0.0251. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9767. T_Loss: 4.7000. Mask: 0.9153. :  93%|█████████▎| 93/100 [00:23<00:00,  7.53it/s]Train Iter: 2894/5000. LR: 0.0251. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9763. T_Loss: 4.6962. Mask: 0.9152. :  93%|█████████▎| 93/100 [00:23<00:00,  7.53it/s]Train Iter: 2894/5000. LR: 0.0251. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9763. T_Loss: 4.6962. Mask: 0.9152. :  94%|█████████▍| 94/100 [00:23<00:00,  7.36it/s]Train Iter: 2895/5000. LR: 0.0251. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9772. T_Loss: 4.6992. Mask: 0.9155. :  94%|█████████▍| 94/100 [00:23<00:00,  7.36it/s]Train Iter: 2895/5000. LR: 0.0251. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9772. T_Loss: 4.6992. Mask: 0.9155. :  95%|█████████▌| 95/100 [00:23<00:00,  5.60it/s]Train Iter: 2896/5000. LR: 0.0251. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9773. T_Loss: 4.6904. Mask: 0.9150. :  95%|█████████▌| 95/100 [00:24<00:00,  5.60it/s]Train Iter: 2896/5000. LR: 0.0251. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9773. T_Loss: 4.6904. Mask: 0.9150. :  96%|█████████▌| 96/100 [00:24<00:00,  6.22it/s]Train Iter: 2897/5000. LR: 0.0251. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9775. T_Loss: 4.6846. Mask: 0.9143. :  96%|█████████▌| 96/100 [00:24<00:00,  6.22it/s]Train Iter: 2897/5000. LR: 0.0251. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9775. T_Loss: 4.6846. Mask: 0.9143. :  97%|█████████▋| 97/100 [00:24<00:00,  6.77it/s]Train Iter: 2898/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9769. T_Loss: 4.6760. Mask: 0.9142. :  97%|█████████▋| 97/100 [00:24<00:00,  6.77it/s]Train Iter: 2898/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9769. T_Loss: 4.6760. Mask: 0.9142. :  98%|█████████▊| 98/100 [00:24<00:00,  7.13it/s]Train Iter: 2899/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.6784. Mask: 0.9138. :  98%|█████████▊| 98/100 [00:24<00:00,  7.13it/s]Train Iter: 2899/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.6784. Mask: 0.9138. :  99%|█████████▉| 99/100 [00:24<00:00,  5.62it/s]Train Iter: 2900/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9783. T_Loss: 4.6623. Mask: 0.9128. :  99%|█████████▉| 99/100 [00:24<00:00,  5.62it/s]Train Iter: 2900/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9783. T_Loss: 4.6623. Mask: 0.9128. : 100%|██████████| 100/100 [00:24<00:00,  6.13it/s]Train Iter: 2900/5000. LR: 0.0250. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9783. T_Loss: 4.6623. Mask: 0.9128. : 100%|██████████| 100/100 [00:24<00:00,  4.06it/s]
total : 5000  current step :  2876
total : 5000  current step :  2877
total : 5000  current step :  2878
total : 5000  current step :  2879
total : 5000  current step :  2880
total : 5000  current step :  2881
total : 5000  current step :  2882
total : 5000  current step :  2883
total : 5000  current step :  2884
total : 5000  current step :  2885
total : 5000  current step :  2886
total : 5000  current step :  2887
total : 5000  current step :  2888
total : 5000  current step :  2889
total : 5000  current step :  2890
total : 5000  current step :  2891
total : 5000  current step :  2892
total : 5000  current step :  2893
total : 5000  current step :  2894
total : 5000  current step :  2895
total : 5000  current step :  2896
total : 5000  current step :  2897
total : 5000  current step :  2898
total : 5000  current step :  2899
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.81s. Loss: 0.9321. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.81s. Loss: 0.9321. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 0.9185. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.8901. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.8994. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.8847. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8835. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8968. top1: 87.95. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8991. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8924. top1: 87.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8924. top1: 87.85. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.36it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8996. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.36it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8891. top1: 88.35. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.36it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8875. top1: 88.54. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.36it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8820. top1: 88.70. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.36it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8786. top1: 88.62. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.36it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8757. top1: 88.75. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.36it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8768. top1: 88.87. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.36it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8768. top1: 88.87. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8737. top1: 88.79. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8731. top1: 88.72. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8734. top1: 88.65. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8731. top1: 88.75. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8775. top1: 88.69. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8748. top1: 88.92. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8711. top1: 89.27. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8684. top1: 89.45. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8658. top1: 89.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.02it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8658. top1: 89.62. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8703. top1: 89.18. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8702. top1: 89.24. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8725. top1: 89.29. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8703. top1: 89.44. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8702. top1: 89.38. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8702. top1: 89.31. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8863. top1: 88.57. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8948. top1: 88.16. top5: 99.91. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9055. top1: 87.41. top5: 99.91. :  40%|███▉      | 25/63 [00:02<00:01, 20.96it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9055. top1: 87.41. top5: 99.91. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9172. top1: 86.61. top5: 99.91. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9409. top1: 85.50. top5: 99.74. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9466. top1: 85.30. top5: 99.75. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9548. top1: 84.87. top5: 99.75. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9688. top1: 84.29. top5: 99.60. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9785. top1: 83.67. top5: 99.61. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9851. top1: 83.38. top5: 99.54. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0002. top1: 82.66. top5: 99.55. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.27. top5: 99.56. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0117. top1: 82.17. top5: 99.57. :  54%|█████▍    | 34/63 [00:02<00:00, 30.31it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0117. top1: 82.17. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0143. top1: 81.88. top5: 99.58. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0219. top1: 81.32. top5: 99.59. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0283. top1: 80.98. top5: 99.60. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0324. top1: 80.66. top5: 99.61. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0389. top1: 80.42. top5: 99.62. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0427. top1: 80.19. top5: 99.56. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0554. top1: 79.41. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0593. top1: 79.33. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 41.26it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0593. top1: 79.33. top5: 99.52. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0681. top1: 78.95. top5: 99.53. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0764. top1: 78.59. top5: 99.48. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0796. top1: 78.47. top5: 99.49. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0823. top1: 78.35. top5: 99.50. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0906. top1: 77.85. top5: 99.51. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0974. top1: 77.32. top5: 99.52. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1027. top1: 77.01. top5: 99.52. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1020. top1: 77.08. top5: 99.53. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1086. top1: 76.59. top5: 99.54. :  83%|████████▎ | 52/63 [00:02<00:00, 48.09it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1086. top1: 76.59. top5: 99.54. :  97%|█████████▋| 61/63 [00:02<00:00, 56.35it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1175. top1: 76.06. top5: 99.55. :  97%|█████████▋| 61/63 [00:02<00:00, 56.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1181. top1: 76.05. top5: 99.55. :  97%|█████████▋| 61/63 [00:02<00:00, 56.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1181. top1: 76.05. top5: 99.55. : 100%|██████████| 63/63 [00:02<00:00, 22.74it/s]
total : 5000  current step :  2900
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 2901/5000. LR: 0.0250. Data: 1.89s. Batch: 2.02s. S_Loss: 0.9328. T_Loss: 4.2102. Mask: 0.9062. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 2901/5000. LR: 0.0250. Data: 1.89s. Batch: 2.02s. S_Loss: 0.9328. T_Loss: 4.2102. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:19,  2.02s/it]Train Iter: 2902/5000. LR: 0.0250. Data: 0.95s. Batch: 1.08s. S_Loss: 1.0342. T_Loss: 4.6226. Mask: 0.8906. :   1%|          | 1/100 [00:02<03:19,  2.02s/it]Train Iter: 2902/5000. LR: 0.0250. Data: 0.95s. Batch: 1.08s. S_Loss: 1.0342. T_Loss: 4.6226. Mask: 0.8906. :   2%|▏         | 2/100 [00:02<01:29,  1.09it/s]Train Iter: 2903/5000. LR: 0.0249. Data: 0.64s. Batch: 0.77s. S_Loss: 1.0602. T_Loss: 4.8728. Mask: 0.8958. :   2%|▏         | 2/100 [00:02<01:29,  1.09it/s]Train Iter: 2903/5000. LR: 0.0249. Data: 0.64s. Batch: 0.77s. S_Loss: 1.0602. T_Loss: 4.8728. Mask: 0.8958. :   3%|▎         | 3/100 [00:02<00:54,  1.77it/s]Train Iter: 2904/5000. LR: 0.0249. Data: 0.48s. Batch: 0.61s. S_Loss: 1.0267. T_Loss: 4.6598. Mask: 0.8984. :   3%|▎         | 3/100 [00:02<00:54,  1.77it/s]Train Iter: 2904/5000. LR: 0.0249. Data: 0.48s. Batch: 0.61s. S_Loss: 1.0267. T_Loss: 4.6598. Mask: 0.8984. :   4%|▍         | 4/100 [00:02<00:37,  2.56it/s]Train Iter: 2905/5000. LR: 0.0249. Data: 0.38s. Batch: 0.56s. S_Loss: 1.0478. T_Loss: 5.1352. Mask: 0.9062. :   4%|▍         | 4/100 [00:02<00:37,  2.56it/s]Train Iter: 2905/5000. LR: 0.0249. Data: 0.38s. Batch: 0.56s. S_Loss: 1.0478. T_Loss: 5.1352. Mask: 0.9062. :   5%|▌         | 5/100 [00:02<00:35,  2.64it/s]Train Iter: 2906/5000. LR: 0.0249. Data: 0.32s. Batch: 0.48s. S_Loss: 1.0421. T_Loss: 4.9460. Mask: 0.9062. :   5%|▌         | 5/100 [00:02<00:35,  2.64it/s]Train Iter: 2906/5000. LR: 0.0249. Data: 0.32s. Batch: 0.48s. S_Loss: 1.0421. T_Loss: 4.9460. Mask: 0.9062. :   6%|▌         | 6/100 [00:02<00:27,  3.42it/s]Train Iter: 2907/5000. LR: 0.0249. Data: 0.28s. Batch: 0.43s. S_Loss: 1.0482. T_Loss: 4.9991. Mask: 0.9152. :   6%|▌         | 6/100 [00:03<00:27,  3.42it/s]Train Iter: 2907/5000. LR: 0.0249. Data: 0.28s. Batch: 0.43s. S_Loss: 1.0482. T_Loss: 4.9991. Mask: 0.9152. :   7%|▋         | 7/100 [00:03<00:21,  4.23it/s]Train Iter: 2908/5000. LR: 0.0249. Data: 0.24s. Batch: 0.39s. S_Loss: 1.0294. T_Loss: 4.8677. Mask: 0.9141. :   7%|▋         | 7/100 [00:03<00:21,  4.23it/s]Train Iter: 2908/5000. LR: 0.0249. Data: 0.24s. Batch: 0.39s. S_Loss: 1.0294. T_Loss: 4.8677. Mask: 0.9141. :   8%|▊         | 8/100 [00:03<00:18,  4.95it/s]Train Iter: 2909/5000. LR: 0.0248. Data: 0.21s. Batch: 0.39s. S_Loss: 1.0253. T_Loss: 4.7354. Mask: 0.9167. :   8%|▊         | 8/100 [00:03<00:18,  4.95it/s]Train Iter: 2909/5000. LR: 0.0248. Data: 0.21s. Batch: 0.39s. S_Loss: 1.0253. T_Loss: 4.7354. Mask: 0.9167. :   9%|▉         | 9/100 [00:03<00:21,  4.17it/s]Train Iter: 2910/5000. LR: 0.0248. Data: 0.19s. Batch: 0.36s. S_Loss: 1.0198. T_Loss: 4.7548. Mask: 0.9250. :   9%|▉         | 9/100 [00:03<00:21,  4.17it/s]Train Iter: 2911/5000. LR: 0.0248. Data: 0.18s. Batch: 0.34s. S_Loss: 1.0192. T_Loss: 4.6795. Mask: 0.9205. :  10%|█         | 10/100 [00:03<00:21,  4.17it/s]Train Iter: 2911/5000. LR: 0.0248. Data: 0.18s. Batch: 0.34s. S_Loss: 1.0192. T_Loss: 4.6795. Mask: 0.9205. :  11%|█         | 11/100 [00:03<00:15,  5.65it/s]Train Iter: 2912/5000. LR: 0.0248. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0182. T_Loss: 4.6832. Mask: 0.9193. :  11%|█         | 11/100 [00:03<00:15,  5.65it/s]Train Iter: 2912/5000. LR: 0.0248. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0182. T_Loss: 4.6832. Mask: 0.9193. :  12%|█▏        | 12/100 [00:03<00:14,  6.25it/s]Train Iter: 2913/5000. LR: 0.0248. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0066. T_Loss: 4.5855. Mask: 0.9207. :  12%|█▏        | 12/100 [00:03<00:14,  6.25it/s]Train Iter: 2913/5000. LR: 0.0248. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0066. T_Loss: 4.5855. Mask: 0.9207. :  13%|█▎        | 13/100 [00:03<00:13,  6.60it/s]Train Iter: 2914/5000. LR: 0.0247. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9995. T_Loss: 4.5694. Mask: 0.9263. :  13%|█▎        | 13/100 [00:04<00:13,  6.60it/s]Train Iter: 2914/5000. LR: 0.0247. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9995. T_Loss: 4.5694. Mask: 0.9263. :  14%|█▍        | 14/100 [00:04<00:12,  6.98it/s]Train Iter: 2915/5000. LR: 0.0247. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9960. T_Loss: 4.5649. Mask: 0.9250. :  14%|█▍        | 14/100 [00:04<00:12,  6.98it/s]Train Iter: 2915/5000. LR: 0.0247. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9960. T_Loss: 4.5649. Mask: 0.9250. :  15%|█▌        | 15/100 [00:04<00:11,  7.32it/s]Train Iter: 2916/5000. LR: 0.0247. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9959. T_Loss: 4.5485. Mask: 0.9238. :  15%|█▌        | 15/100 [00:04<00:11,  7.32it/s]Train Iter: 2916/5000. LR: 0.0247. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9959. T_Loss: 4.5485. Mask: 0.9238. :  16%|█▌        | 16/100 [00:04<00:11,  7.51it/s]Train Iter: 2917/5000. LR: 0.0247. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9874. T_Loss: 4.5154. Mask: 0.9265. :  16%|█▌        | 16/100 [00:04<00:11,  7.51it/s]Train Iter: 2917/5000. LR: 0.0247. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9874. T_Loss: 4.5154. Mask: 0.9265. :  17%|█▋        | 17/100 [00:04<00:10,  7.62it/s]Train Iter: 2918/5000. LR: 0.0247. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9835. T_Loss: 4.5269. Mask: 0.9288. :  17%|█▋        | 17/100 [00:04<00:10,  7.62it/s]Train Iter: 2918/5000. LR: 0.0247. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9835. T_Loss: 4.5269. Mask: 0.9288. :  18%|█▊        | 18/100 [00:04<00:10,  8.06it/s]Train Iter: 2919/5000. LR: 0.0246. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9819. T_Loss: 4.5222. Mask: 0.9276. :  18%|█▊        | 18/100 [00:04<00:10,  8.06it/s]Train Iter: 2919/5000. LR: 0.0246. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9819. T_Loss: 4.5222. Mask: 0.9276. :  19%|█▉        | 19/100 [00:04<00:13,  5.84it/s]Train Iter: 2920/5000. LR: 0.0246. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9826. T_Loss: 4.5742. Mask: 0.9281. :  19%|█▉        | 19/100 [00:04<00:13,  5.84it/s]Train Iter: 2920/5000. LR: 0.0246. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9826. T_Loss: 4.5742. Mask: 0.9281. :  20%|██        | 20/100 [00:04<00:12,  6.39it/s]Train Iter: 2921/5000. LR: 0.0246. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9856. T_Loss: 4.6121. Mask: 0.9286. :  20%|██        | 20/100 [00:05<00:12,  6.39it/s]Train Iter: 2921/5000. LR: 0.0246. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9856. T_Loss: 4.6121. Mask: 0.9286. :  21%|██        | 21/100 [00:05<00:11,  6.75it/s]Train Iter: 2922/5000. LR: 0.0246. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9844. T_Loss: 4.5775. Mask: 0.9276. :  21%|██        | 21/100 [00:05<00:11,  6.75it/s]Train Iter: 2922/5000. LR: 0.0246. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9844. T_Loss: 4.5775. Mask: 0.9276. :  22%|██▏       | 22/100 [00:05<00:10,  7.34it/s]Train Iter: 2923/5000. LR: 0.0246. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9808. T_Loss: 4.5676. Mask: 0.9293. :  22%|██▏       | 22/100 [00:05<00:10,  7.34it/s]Train Iter: 2923/5000. LR: 0.0246. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9808. T_Loss: 4.5676. Mask: 0.9293. :  23%|██▎       | 23/100 [00:05<00:09,  7.97it/s]Train Iter: 2924/5000. LR: 0.0246. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9802. T_Loss: 4.5687. Mask: 0.9284. :  23%|██▎       | 23/100 [00:05<00:09,  7.97it/s]Train Iter: 2924/5000. LR: 0.0246. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9802. T_Loss: 4.5687. Mask: 0.9284. :  24%|██▍       | 24/100 [00:05<00:09,  8.25it/s]Train Iter: 2925/5000. LR: 0.0245. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9774. T_Loss: 4.5701. Mask: 0.9287. :  24%|██▍       | 24/100 [00:05<00:09,  8.25it/s]Train Iter: 2925/5000. LR: 0.0245. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9774. T_Loss: 4.5701. Mask: 0.9287. :  25%|██▌       | 25/100 [00:05<00:15,  4.94it/s]total : 5000  current step :  2901
total : 5000  current step :  2902
total : 5000  current step :  2903
total : 5000  current step :  2904
total : 5000  current step :  2905
total : 5000  current step :  2906
total : 5000  current step :  2907
total : 5000  current step :  2908
total : 5000  current step :  2909
total : 5000  current step :  2910
total : 5000  current step :  2911
total : 5000  current step :  2912
total : 5000  current step :  2913
total : 5000  current step :  2914
total : 5000  current step :  2915
total : 5000  current step :  2916
total : 5000  current step :  2917
total : 5000  current step :  2918
total : 5000  current step :  2919
total : 5000  current step :  2920
total : 5000  current step :  2921
total : 5000  current step :  2922
total : 5000  current step :  2923
total : 5000  current step :  2924
total : 5000  current step :  2925
Train Iter: 2926/5000. LR: 0.0245. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9774. T_Loss: 4.5428. Mask: 0.9279. :  25%|██▌       | 25/100 [00:07<00:15,  4.94it/s]Train Iter: 2926/5000. LR: 0.0245. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9774. T_Loss: 4.5428. Mask: 0.9279. :  26%|██▌       | 26/100 [00:07<00:58,  1.26it/s]Train Iter: 2927/5000. LR: 0.0245. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9779. T_Loss: 4.5606. Mask: 0.9282. :  26%|██▌       | 26/100 [00:08<00:58,  1.26it/s]Train Iter: 2927/5000. LR: 0.0245. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9779. T_Loss: 4.5606. Mask: 0.9282. :  27%|██▋       | 27/100 [00:08<00:43,  1.69it/s]Train Iter: 2928/5000. LR: 0.0245. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9733. T_Loss: 4.5550. Mask: 0.9286. :  27%|██▋       | 27/100 [00:08<00:43,  1.69it/s]Train Iter: 2928/5000. LR: 0.0245. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9733. T_Loss: 4.5550. Mask: 0.9286. :  28%|██▊       | 28/100 [00:08<00:33,  2.17it/s]Train Iter: 2929/5000. LR: 0.0245. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9709. T_Loss: 4.5483. Mask: 0.9289. :  28%|██▊       | 28/100 [00:08<00:33,  2.17it/s]Train Iter: 2929/5000. LR: 0.0245. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9709. T_Loss: 4.5483. Mask: 0.9289. :  29%|██▉       | 29/100 [00:08<00:29,  2.40it/s]Train Iter: 2930/5000. LR: 0.0244. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9700. T_Loss: 4.5387. Mask: 0.9292. :  29%|██▉       | 29/100 [00:08<00:29,  2.40it/s]Train Iter: 2930/5000. LR: 0.0244. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9700. T_Loss: 4.5387. Mask: 0.9292. :  30%|███       | 30/100 [00:08<00:23,  3.00it/s]Train Iter: 2931/5000. LR: 0.0244. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9688. T_Loss: 4.4986. Mask: 0.9274. :  30%|███       | 30/100 [00:08<00:23,  3.00it/s]Train Iter: 2931/5000. LR: 0.0244. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9688. T_Loss: 4.4986. Mask: 0.9274. :  31%|███       | 31/100 [00:08<00:18,  3.74it/s]Train Iter: 2932/5000. LR: 0.0244. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9673. T_Loss: 4.5099. Mask: 0.9287. :  31%|███       | 31/100 [00:08<00:18,  3.74it/s]Train Iter: 2932/5000. LR: 0.0244. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9673. T_Loss: 4.5099. Mask: 0.9287. :  32%|███▏      | 32/100 [00:08<00:15,  4.42it/s]Train Iter: 2933/5000. LR: 0.0244. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9698. T_Loss: 4.5296. Mask: 0.9261. :  32%|███▏      | 32/100 [00:09<00:15,  4.42it/s]Train Iter: 2933/5000. LR: 0.0244. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9698. T_Loss: 4.5296. Mask: 0.9261. :  33%|███▎      | 33/100 [00:09<00:13,  5.12it/s]Train Iter: 2934/5000. LR: 0.0244. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9697. T_Loss: 4.5075. Mask: 0.9265. :  33%|███▎      | 33/100 [00:09<00:13,  5.12it/s]Train Iter: 2934/5000. LR: 0.0244. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9697. T_Loss: 4.5075. Mask: 0.9265. :  34%|███▍      | 34/100 [00:09<00:11,  5.68it/s]Train Iter: 2935/5000. LR: 0.0243. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9697. T_Loss: 4.5461. Mask: 0.9277. :  34%|███▍      | 34/100 [00:09<00:11,  5.68it/s]Train Iter: 2935/5000. LR: 0.0243. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9697. T_Loss: 4.5461. Mask: 0.9277. :  35%|███▌      | 35/100 [00:09<00:14,  4.47it/s]Train Iter: 2936/5000. LR: 0.0243. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9686. T_Loss: 4.5285. Mask: 0.9262. :  35%|███▌      | 35/100 [00:09<00:14,  4.47it/s]Train Iter: 2936/5000. LR: 0.0243. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9686. T_Loss: 4.5285. Mask: 0.9262. :  36%|███▌      | 36/100 [00:09<00:12,  5.18it/s]Train Iter: 2937/5000. LR: 0.0243. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9735. T_Loss: 4.5892. Mask: 0.9274. :  36%|███▌      | 36/100 [00:09<00:12,  5.18it/s]Train Iter: 2937/5000. LR: 0.0243. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9735. T_Loss: 4.5892. Mask: 0.9274. :  37%|███▋      | 37/100 [00:09<00:10,  5.82it/s]Train Iter: 2938/5000. LR: 0.0243. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9696. T_Loss: 4.5719. Mask: 0.9293. :  37%|███▋      | 37/100 [00:09<00:10,  5.82it/s]Train Iter: 2939/5000. LR: 0.0243. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9681. T_Loss: 4.5544. Mask: 0.9279. :  38%|███▊      | 38/100 [00:10<00:10,  5.82it/s]Train Iter: 2939/5000. LR: 0.0243. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9681. T_Loss: 4.5544. Mask: 0.9279. :  39%|███▉      | 39/100 [00:10<00:11,  5.17it/s]Train Iter: 2940/5000. LR: 0.0243. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9665. T_Loss: 4.5456. Mask: 0.9289. :  39%|███▉      | 39/100 [00:10<00:11,  5.17it/s]Train Iter: 2940/5000. LR: 0.0243. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9665. T_Loss: 4.5456. Mask: 0.9289. :  40%|████      | 40/100 [00:10<00:10,  5.72it/s]Train Iter: 2941/5000. LR: 0.0242. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.5325. Mask: 0.9276. :  40%|████      | 40/100 [00:10<00:10,  5.72it/s]Train Iter: 2941/5000. LR: 0.0242. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.5325. Mask: 0.9276. :  41%|████      | 41/100 [00:10<00:09,  5.91it/s]Train Iter: 2942/5000. LR: 0.0242. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9622. T_Loss: 4.5084. Mask: 0.9286. :  41%|████      | 41/100 [00:10<00:09,  5.91it/s]Train Iter: 2942/5000. LR: 0.0242. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9622. T_Loss: 4.5084. Mask: 0.9286. :  42%|████▏     | 42/100 [00:10<00:09,  6.39it/s]Train Iter: 2943/5000. LR: 0.0242. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.5063. Mask: 0.9273. :  42%|████▏     | 42/100 [00:10<00:09,  6.39it/s]Train Iter: 2943/5000. LR: 0.0242. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.5063. Mask: 0.9273. :  43%|████▎     | 43/100 [00:10<00:08,  6.68it/s]Train Iter: 2944/5000. LR: 0.0242. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9606. T_Loss: 4.5103. Mask: 0.9268. :  43%|████▎     | 43/100 [00:10<00:08,  6.68it/s]Train Iter: 2944/5000. LR: 0.0242. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9606. T_Loss: 4.5103. Mask: 0.9268. :  44%|████▍     | 44/100 [00:10<00:07,  7.01it/s]Train Iter: 2945/5000. LR: 0.0242. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9609. T_Loss: 4.5242. Mask: 0.9271. :  44%|████▍     | 44/100 [00:10<00:07,  7.01it/s]Train Iter: 2945/5000. LR: 0.0242. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9609. T_Loss: 4.5242. Mask: 0.9271. :  45%|████▌     | 45/100 [00:10<00:07,  7.11it/s]Train Iter: 2946/5000. LR: 0.0241. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9618. T_Loss: 4.5556. Mask: 0.9287. :  45%|████▌     | 45/100 [00:11<00:07,  7.11it/s]Train Iter: 2946/5000. LR: 0.0241. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9618. T_Loss: 4.5556. Mask: 0.9287. :  46%|████▌     | 46/100 [00:11<00:07,  7.24it/s]Train Iter: 2947/5000. LR: 0.0241. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9630. T_Loss: 4.5702. Mask: 0.9282. :  46%|████▌     | 46/100 [00:11<00:07,  7.24it/s]Train Iter: 2947/5000. LR: 0.0241. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9630. T_Loss: 4.5702. Mask: 0.9282. :  47%|████▋     | 47/100 [00:11<00:07,  7.29it/s]Train Iter: 2948/5000. LR: 0.0241. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9608. T_Loss: 4.5623. Mask: 0.9284. :  47%|████▋     | 47/100 [00:11<00:07,  7.29it/s]Train Iter: 2948/5000. LR: 0.0241. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9608. T_Loss: 4.5623. Mask: 0.9284. :  48%|████▊     | 48/100 [00:11<00:07,  7.34it/s]Train Iter: 2949/5000. LR: 0.0241. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9617. T_Loss: 4.5760. Mask: 0.9273. :  48%|████▊     | 48/100 [00:11<00:07,  7.34it/s]Train Iter: 2949/5000. LR: 0.0241. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9617. T_Loss: 4.5760. Mask: 0.9273. :  49%|████▉     | 49/100 [00:11<00:09,  5.45it/s]Train Iter: 2950/5000. LR: 0.0241. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9607. T_Loss: 4.5925. Mask: 0.9281. :  49%|████▉     | 49/100 [00:11<00:09,  5.45it/s]Train Iter: 2950/5000. LR: 0.0241. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9607. T_Loss: 4.5925. Mask: 0.9281. :  50%|█████     | 50/100 [00:11<00:08,  5.79it/s]total : 5000  current step :  2926
total : 5000  current step :  2927
total : 5000  current step :  2928
total : 5000  current step :  2929
total : 5000  current step :  2930
total : 5000  current step :  2931
total : 5000  current step :  2932
total : 5000  current step :  2933
total : 5000  current step :  2934
total : 5000  current step :  2935
total : 5000  current step :  2936
total : 5000  current step :  2937
total : 5000  current step :  2938
total : 5000  current step :  2939
total : 5000  current step :  2940
total : 5000  current step :  2941
total : 5000  current step :  2942
total : 5000  current step :  2943
total : 5000  current step :  2944
total : 5000  current step :  2945
total : 5000  current step :  2946
total : 5000  current step :  2947
total : 5000  current step :  2948
total : 5000  current step :  2949
total : 5000  current step :  2950
Train Iter: 2951/5000. LR: 0.0240. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9594. T_Loss: 4.5764. Mask: 0.9277. :  50%|█████     | 50/100 [00:13<00:08,  5.79it/s]Train Iter: 2951/5000. LR: 0.0240. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9594. T_Loss: 4.5764. Mask: 0.9277. :  51%|█████     | 51/100 [00:13<00:35,  1.40it/s]Train Iter: 2952/5000. LR: 0.0240. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9617. T_Loss: 4.5849. Mask: 0.9261. :  51%|█████     | 51/100 [00:13<00:35,  1.40it/s]Train Iter: 2952/5000. LR: 0.0240. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9617. T_Loss: 4.5849. Mask: 0.9261. :  52%|█████▏    | 52/100 [00:13<00:25,  1.85it/s]Train Iter: 2953/5000. LR: 0.0240. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9596. T_Loss: 4.5847. Mask: 0.9269. :  52%|█████▏    | 52/100 [00:14<00:25,  1.85it/s]Train Iter: 2953/5000. LR: 0.0240. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9596. T_Loss: 4.5847. Mask: 0.9269. :  53%|█████▎    | 53/100 [00:14<00:19,  2.43it/s]Train Iter: 2954/5000. LR: 0.0240. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9578. T_Loss: 4.5938. Mask: 0.9271. :  53%|█████▎    | 53/100 [00:14<00:19,  2.43it/s]Train Iter: 2955/5000. LR: 0.0240. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9584. T_Loss: 4.5845. Mask: 0.9261. :  54%|█████▍    | 54/100 [00:14<00:18,  2.43it/s]Train Iter: 2955/5000. LR: 0.0240. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9584. T_Loss: 4.5845. Mask: 0.9261. :  55%|█████▌    | 55/100 [00:14<00:13,  3.43it/s]Train Iter: 2956/5000. LR: 0.0240. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9582. T_Loss: 4.5840. Mask: 0.9258. :  55%|█████▌    | 55/100 [00:14<00:13,  3.43it/s]Train Iter: 2957/5000. LR: 0.0239. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9569. T_Loss: 4.5800. Mask: 0.9260. :  56%|█████▌    | 56/100 [00:14<00:12,  3.43it/s]Train Iter: 2957/5000. LR: 0.0239. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9569. T_Loss: 4.5800. Mask: 0.9260. :  57%|█████▋    | 57/100 [00:14<00:09,  4.70it/s]Train Iter: 2958/5000. LR: 0.0239. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9585. T_Loss: 4.5809. Mask: 0.9256. :  57%|█████▋    | 57/100 [00:14<00:09,  4.70it/s]Train Iter: 2958/5000. LR: 0.0239. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9585. T_Loss: 4.5809. Mask: 0.9256. :  58%|█████▊    | 58/100 [00:14<00:08,  5.21it/s]Train Iter: 2959/5000. LR: 0.0239. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9590. T_Loss: 4.5981. Mask: 0.9264. :  58%|█████▊    | 58/100 [00:15<00:08,  5.21it/s]Train Iter: 2959/5000. LR: 0.0239. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9590. T_Loss: 4.5981. Mask: 0.9264. :  59%|█████▉    | 59/100 [00:15<00:09,  4.36it/s]Train Iter: 2960/5000. LR: 0.0239. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9581. T_Loss: 4.5973. Mask: 0.9271. :  59%|█████▉    | 59/100 [00:15<00:09,  4.36it/s]Train Iter: 2961/5000. LR: 0.0239. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9570. T_Loss: 4.5919. Mask: 0.9278. :  60%|██████    | 60/100 [00:15<00:09,  4.36it/s]Train Iter: 2961/5000. LR: 0.0239. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9570. T_Loss: 4.5919. Mask: 0.9278. :  61%|██████    | 61/100 [00:15<00:07,  5.51it/s]Train Iter: 2962/5000. LR: 0.0238. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9556. T_Loss: 4.5812. Mask: 0.9274. :  61%|██████    | 61/100 [00:15<00:07,  5.51it/s]Train Iter: 2962/5000. LR: 0.0238. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9556. T_Loss: 4.5812. Mask: 0.9274. :  62%|██████▏   | 62/100 [00:15<00:06,  5.94it/s]Train Iter: 2963/5000. LR: 0.0238. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9565. T_Loss: 4.5731. Mask: 0.9246. :  62%|██████▏   | 62/100 [00:15<00:06,  5.94it/s]Train Iter: 2963/5000. LR: 0.0238. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9565. T_Loss: 4.5731. Mask: 0.9246. :  63%|██████▎   | 63/100 [00:15<00:05,  6.20it/s]Train Iter: 2964/5000. LR: 0.0238. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9547. T_Loss: 4.5729. Mask: 0.9258. :  63%|██████▎   | 63/100 [00:15<00:05,  6.20it/s]Train Iter: 2964/5000. LR: 0.0238. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9547. T_Loss: 4.5729. Mask: 0.9258. :  64%|██████▍   | 64/100 [00:15<00:05,  6.59it/s]Train Iter: 2965/5000. LR: 0.0238. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9540. T_Loss: 4.5624. Mask: 0.9245. :  64%|██████▍   | 64/100 [00:15<00:05,  6.59it/s]Train Iter: 2965/5000. LR: 0.0238. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9540. T_Loss: 4.5624. Mask: 0.9245. :  65%|██████▌   | 65/100 [00:15<00:06,  5.04it/s]Train Iter: 2966/5000. LR: 0.0238. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9542. T_Loss: 4.5547. Mask: 0.9238. :  65%|██████▌   | 65/100 [00:16<00:06,  5.04it/s]Train Iter: 2966/5000. LR: 0.0238. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9542. T_Loss: 4.5547. Mask: 0.9238. :  66%|██████▌   | 66/100 [00:16<00:06,  5.56it/s]Train Iter: 2967/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9558. T_Loss: 4.5620. Mask: 0.9235. :  66%|██████▌   | 66/100 [00:16<00:06,  5.56it/s]Train Iter: 2967/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9558. T_Loss: 4.5620. Mask: 0.9235. :  67%|██████▋   | 67/100 [00:16<00:05,  6.12it/s]Train Iter: 2968/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9563. T_Loss: 4.5615. Mask: 0.9223. :  67%|██████▋   | 67/100 [00:16<00:05,  6.12it/s]Train Iter: 2968/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9563. T_Loss: 4.5615. Mask: 0.9223. :  68%|██████▊   | 68/100 [00:16<00:04,  6.49it/s]Train Iter: 2969/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9580. T_Loss: 4.5721. Mask: 0.9226. :  68%|██████▊   | 68/100 [00:16<00:04,  6.49it/s]Train Iter: 2969/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9580. T_Loss: 4.5721. Mask: 0.9226. :  69%|██████▉   | 69/100 [00:16<00:04,  6.20it/s]Train Iter: 2970/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9581. T_Loss: 4.5792. Mask: 0.9228. :  69%|██████▉   | 69/100 [00:16<00:04,  6.20it/s]Train Iter: 2970/5000. LR: 0.0237. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9581. T_Loss: 4.5792. Mask: 0.9228. :  70%|███████   | 70/100 [00:16<00:04,  6.59it/s]Train Iter: 2971/5000. LR: 0.0237. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9579. T_Loss: 4.5880. Mask: 0.9234. :  70%|███████   | 70/100 [00:16<00:04,  6.59it/s]Train Iter: 2971/5000. LR: 0.0237. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9579. T_Loss: 4.5880. Mask: 0.9234. :  71%|███████   | 71/100 [00:16<00:04,  7.20it/s]Train Iter: 2972/5000. LR: 0.0237. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9567. T_Loss: 4.5825. Mask: 0.9240. :  71%|███████   | 71/100 [00:16<00:04,  7.20it/s]Train Iter: 2972/5000. LR: 0.0237. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9567. T_Loss: 4.5825. Mask: 0.9240. :  72%|███████▏  | 72/100 [00:16<00:03,  7.52it/s]Train Iter: 2973/5000. LR: 0.0236. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9580. T_Loss: 4.6048. Mask: 0.9247. :  72%|███████▏  | 72/100 [00:16<00:03,  7.52it/s]Train Iter: 2973/5000. LR: 0.0236. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9580. T_Loss: 4.6048. Mask: 0.9247. :  73%|███████▎  | 73/100 [00:16<00:03,  7.67it/s]Train Iter: 2974/5000. LR: 0.0236. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9588. T_Loss: 4.6054. Mask: 0.9240. :  73%|███████▎  | 73/100 [00:17<00:03,  7.67it/s]Train Iter: 2974/5000. LR: 0.0236. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9588. T_Loss: 4.6054. Mask: 0.9240. :  74%|███████▍  | 74/100 [00:17<00:03,  7.80it/s]Train Iter: 2975/5000. LR: 0.0236. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9593. T_Loss: 4.5991. Mask: 0.9233. :  74%|███████▍  | 74/100 [00:17<00:03,  7.80it/s]Train Iter: 2975/5000. LR: 0.0236. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9593. T_Loss: 4.5991. Mask: 0.9233. :  75%|███████▌  | 75/100 [00:17<00:04,  5.17it/s]total : 5000  current step :  2951
total : 5000  current step :  2952
total : 5000  current step :  2953
total : 5000  current step :  2954
total : 5000  current step :  2955
total : 5000  current step :  2956
total : 5000  current step :  2957
total : 5000  current step :  2958
total : 5000  current step :  2959
total : 5000  current step :  2960
total : 5000  current step :  2961
total : 5000  current step :  2962
total : 5000  current step :  2963
total : 5000  current step :  2964
total : 5000  current step :  2965
total : 5000  current step :  2966
total : 5000  current step :  2967
total : 5000  current step :  2968
total : 5000  current step :  2969
total : 5000  current step :  2970
total : 5000  current step :  2971
total : 5000  current step :  2972
total : 5000  current step :  2973
total : 5000  current step :  2974
total : 5000  current step :  2975
Train Iter: 2976/5000. LR: 0.0236. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9583. T_Loss: 4.5922. Mask: 0.9235. :  75%|███████▌  | 75/100 [00:19<00:04,  5.17it/s]Train Iter: 2976/5000. LR: 0.0236. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9583. T_Loss: 4.5922. Mask: 0.9235. :  76%|███████▌  | 76/100 [00:19<00:18,  1.33it/s]Train Iter: 2977/5000. LR: 0.0236. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9573. T_Loss: 4.5899. Mask: 0.9237. :  76%|███████▌  | 76/100 [00:19<00:18,  1.33it/s]Train Iter: 2977/5000. LR: 0.0236. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9573. T_Loss: 4.5899. Mask: 0.9237. :  77%|███████▋  | 77/100 [00:19<00:13,  1.73it/s]Train Iter: 2978/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9576. T_Loss: 4.5935. Mask: 0.9239. :  77%|███████▋  | 77/100 [00:19<00:13,  1.73it/s]Train Iter: 2978/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9576. T_Loss: 4.5935. Mask: 0.9239. :  78%|███████▊  | 78/100 [00:19<00:09,  2.28it/s]Train Iter: 2979/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9584. T_Loss: 4.5828. Mask: 0.9229. :  78%|███████▊  | 78/100 [00:20<00:09,  2.28it/s]Train Iter: 2979/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9584. T_Loss: 4.5828. Mask: 0.9229. :  79%|███████▉  | 79/100 [00:20<00:07,  2.65it/s]Train Iter: 2980/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9582. T_Loss: 4.5799. Mask: 0.9219. :  79%|███████▉  | 79/100 [00:20<00:07,  2.65it/s]Train Iter: 2980/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9582. T_Loss: 4.5799. Mask: 0.9219. :  80%|████████  | 80/100 [00:20<00:06,  3.31it/s]Train Iter: 2981/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9588. T_Loss: 4.5789. Mask: 0.9209. :  80%|████████  | 80/100 [00:20<00:06,  3.31it/s]Train Iter: 2981/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9588. T_Loss: 4.5789. Mask: 0.9209. :  81%|████████  | 81/100 [00:20<00:04,  4.01it/s]Train Iter: 2982/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9589. T_Loss: 4.5840. Mask: 0.9211. :  81%|████████  | 81/100 [00:20<00:04,  4.01it/s]Train Iter: 2982/5000. LR: 0.0235. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9589. T_Loss: 4.5840. Mask: 0.9211. :  82%|████████▏ | 82/100 [00:20<00:03,  4.73it/s]Train Iter: 2983/5000. LR: 0.0234. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9596. T_Loss: 4.5894. Mask: 0.9213. :  82%|████████▏ | 82/100 [00:20<00:03,  4.73it/s]Train Iter: 2983/5000. LR: 0.0234. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9596. T_Loss: 4.5894. Mask: 0.9213. :  83%|████████▎ | 83/100 [00:20<00:03,  5.33it/s]Train Iter: 2984/5000. LR: 0.0234. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9598. T_Loss: 4.5794. Mask: 0.9215. :  83%|████████▎ | 83/100 [00:20<00:03,  5.33it/s]Train Iter: 2984/5000. LR: 0.0234. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9598. T_Loss: 4.5794. Mask: 0.9215. :  84%|████████▍ | 84/100 [00:20<00:02,  6.12it/s]Train Iter: 2985/5000. LR: 0.0234. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9590. T_Loss: 4.5659. Mask: 0.9221. :  84%|████████▍ | 84/100 [00:20<00:02,  6.12it/s]Train Iter: 2985/5000. LR: 0.0234. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9590. T_Loss: 4.5659. Mask: 0.9221. :  85%|████████▌ | 85/100 [00:20<00:02,  5.16it/s]Train Iter: 2986/5000. LR: 0.0234. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9586. T_Loss: 4.5556. Mask: 0.9208. :  85%|████████▌ | 85/100 [00:21<00:02,  5.16it/s]Train Iter: 2986/5000. LR: 0.0234. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9586. T_Loss: 4.5556. Mask: 0.9208. :  86%|████████▌ | 86/100 [00:21<00:02,  5.85it/s]Train Iter: 2987/5000. LR: 0.0234. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9587. T_Loss: 4.5551. Mask: 0.9206. :  86%|████████▌ | 86/100 [00:21<00:02,  5.85it/s]Train Iter: 2987/5000. LR: 0.0234. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9587. T_Loss: 4.5551. Mask: 0.9206. :  87%|████████▋ | 87/100 [00:21<00:02,  6.30it/s]Train Iter: 2988/5000. LR: 0.0234. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.5641. Mask: 0.9212. :  87%|████████▋ | 87/100 [00:21<00:02,  6.30it/s]Train Iter: 2988/5000. LR: 0.0234. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.5641. Mask: 0.9212. :  88%|████████▊ | 88/100 [00:21<00:01,  6.84it/s]Train Iter: 2989/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.5605. Mask: 0.9213. :  88%|████████▊ | 88/100 [00:21<00:01,  6.84it/s]Train Iter: 2989/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.5605. Mask: 0.9213. :  89%|████████▉ | 89/100 [00:21<00:01,  7.18it/s]Train Iter: 2990/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9597. T_Loss: 4.5591. Mask: 0.9219. :  89%|████████▉ | 89/100 [00:21<00:01,  7.18it/s]Train Iter: 2990/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9597. T_Loss: 4.5591. Mask: 0.9219. :  90%|█████████ | 90/100 [00:21<00:01,  7.32it/s]Train Iter: 2991/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.5652. Mask: 0.9217. :  90%|█████████ | 90/100 [00:21<00:01,  7.32it/s]Train Iter: 2991/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.5652. Mask: 0.9217. :  91%|█████████ | 91/100 [00:21<00:01,  7.45it/s]Train Iter: 2992/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9593. T_Loss: 4.5466. Mask: 0.9205. :  91%|█████████ | 91/100 [00:21<00:01,  7.45it/s]Train Iter: 2992/5000. LR: 0.0233. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9593. T_Loss: 4.5466. Mask: 0.9205. :  92%|█████████▏| 92/100 [00:21<00:01,  7.88it/s]Train Iter: 2993/5000. LR: 0.0233. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9602. T_Loss: 4.5448. Mask: 0.9204. :  92%|█████████▏| 92/100 [00:21<00:01,  7.88it/s]Train Iter: 2993/5000. LR: 0.0233. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9602. T_Loss: 4.5448. Mask: 0.9204. :  93%|█████████▎| 93/100 [00:21<00:00,  8.39it/s]Train Iter: 2994/5000. LR: 0.0232. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9596. T_Loss: 4.5441. Mask: 0.9209. :  93%|█████████▎| 93/100 [00:21<00:00,  8.39it/s]Train Iter: 2994/5000. LR: 0.0232. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9596. T_Loss: 4.5441. Mask: 0.9209. :  94%|█████████▍| 94/100 [00:21<00:00,  8.67it/s]Train Iter: 2995/5000. LR: 0.0232. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9596. T_Loss: 4.5466. Mask: 0.9211. :  94%|█████████▍| 94/100 [00:22<00:00,  8.67it/s]Train Iter: 2995/5000. LR: 0.0232. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9596. T_Loss: 4.5466. Mask: 0.9211. :  95%|█████████▌| 95/100 [00:22<00:00,  5.92it/s]Train Iter: 2996/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9595. T_Loss: 4.5526. Mask: 0.9219. :  95%|█████████▌| 95/100 [00:22<00:00,  5.92it/s]Train Iter: 2996/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9595. T_Loss: 4.5526. Mask: 0.9219. :  96%|█████████▌| 96/100 [00:22<00:00,  6.42it/s]Train Iter: 2997/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9592. T_Loss: 4.5537. Mask: 0.9220. :  96%|█████████▌| 96/100 [00:22<00:00,  6.42it/s]Train Iter: 2997/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9592. T_Loss: 4.5537. Mask: 0.9220. :  97%|█████████▋| 97/100 [00:22<00:00,  7.00it/s]Train Iter: 2998/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9603. T_Loss: 4.5634. Mask: 0.9222. :  97%|█████████▋| 97/100 [00:22<00:00,  7.00it/s]Train Iter: 2998/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9603. T_Loss: 4.5634. Mask: 0.9222. :  98%|█████████▊| 98/100 [00:22<00:00,  7.00it/s]Train Iter: 2999/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9615. T_Loss: 4.5622. Mask: 0.9217. :  98%|█████████▊| 98/100 [00:22<00:00,  7.00it/s]Train Iter: 2999/5000. LR: 0.0232. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9615. T_Loss: 4.5622. Mask: 0.9217. :  99%|█████████▉| 99/100 [00:23<00:00,  4.92it/s]Train Iter: 3000/5000. LR: 0.0231. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9614. T_Loss: 4.5680. Mask: 0.9216. :  99%|█████████▉| 99/100 [00:23<00:00,  4.92it/s]Train Iter: 3000/5000. LR: 0.0231. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9614. T_Loss: 4.5680. Mask: 0.9216. : 100%|██████████| 100/100 [00:23<00:00,  5.78it/s]Train Iter: 3000/5000. LR: 0.0231. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9614. T_Loss: 4.5680. Mask: 0.9216. : 100%|██████████| 100/100 [00:23<00:00,  4.33it/s]
total : 5000  current step :  2976
total : 5000  current step :  2977
total : 5000  current step :  2978
total : 5000  current step :  2979
total : 5000  current step :  2980
total : 5000  current step :  2981
total : 5000  current step :  2982
total : 5000  current step :  2983
total : 5000  current step :  2984
total : 5000  current step :  2985
total : 5000  current step :  2986
total : 5000  current step :  2987
total : 5000  current step :  2988
total : 5000  current step :  2989
total : 5000  current step :  2990
total : 5000  current step :  2991
total : 5000  current step :  2992
total : 5000  current step :  2993
total : 5000  current step :  2994
total : 5000  current step :  2995
total : 5000  current step :  2996
total : 5000  current step :  2997
total : 5000  current step :  2998
total : 5000  current step :  2999
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 0.9249. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 0.9249. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 0.9156. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 0.8829. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.8917. top1: 86.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8765. top1: 88.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8765. top1: 88.75. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8751. top1: 88.54. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8867. top1: 87.95. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8886. top1: 87.50. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8826. top1: 87.85. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8888. top1: 87.50. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8778. top1: 88.64. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8754. top1: 88.80. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8703. top1: 88.94. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8677. top1: 89.06. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8649. top1: 89.17. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.47it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8654. top1: 89.26. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:16,  3.47it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8654. top1: 89.26. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8624. top1: 89.15. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8614. top1: 89.06. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8621. top1: 88.98. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8616. top1: 89.06. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8653. top1: 89.14. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8626. top1: 89.49. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8589. top1: 89.81. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8565. top1: 89.97. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8539. top1: 90.12. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8582. top1: 89.66. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8580. top1: 89.81. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.28it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8580. top1: 89.81. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8605. top1: 89.84. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8580. top1: 90.09. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8579. top1: 90.00. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8580. top1: 89.92. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8753. top1: 89.16. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8844. top1: 88.83. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8960. top1: 87.96. top5: 99.82. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9091. top1: 87.05. top5: 99.82. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9345. top1: 85.85. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9408. top1: 85.47. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 24.42it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9408. top1: 85.47. top5: 99.66. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9499. top1: 84.95. top5: 99.67. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9654. top1: 84.29. top5: 99.52. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9761. top1: 83.52. top5: 99.45. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9832. top1: 83.23. top5: 99.39. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9988. top1: 82.51. top5: 99.40. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0070. top1: 82.12. top5: 99.42. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0110. top1: 82.03. top5: 99.43. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0141. top1: 81.67. top5: 99.44. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0226. top1: 80.98. top5: 99.46. :  59%|█████▊    | 37/63 [00:02<00:00, 35.12it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0226. top1: 80.98. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0297. top1: 80.59. top5: 99.40. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0343. top1: 80.34. top5: 99.41. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0415. top1: 80.10. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0455. top1: 79.88. top5: 99.38. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0590. top1: 79.11. top5: 99.39. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0634. top1: 79.03. top5: 99.34. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0725. top1: 78.60. top5: 99.29. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0812. top1: 78.24. top5: 99.25. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0844. top1: 78.07. top5: 99.26. :  73%|███████▎  | 46/63 [00:02<00:00, 42.90it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0844. top1: 78.07. top5: 99.26. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0876. top1: 77.96. top5: 99.27. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0967. top1: 77.47. top5: 99.29. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1038. top1: 76.94. top5: 99.30. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1096. top1: 76.59. top5: 99.26. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1089. top1: 76.67. top5: 99.27. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1160. top1: 76.18. top5: 99.23. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1255. top1: 75.66. top5: 99.24. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1265. top1: 75.60. top5: 99.25. :  87%|████████▋ | 55/63 [00:02<00:00, 51.68it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1265. top1: 75.60. top5: 99.25. : 100%|██████████| 63/63 [00:02<00:00, 23.17it/s]
total : 5000  current step :  3000
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3001/5000. LR: 0.0231. Data: 1.85s. Batch: 1.97s. S_Loss: 0.9889. T_Loss: 4.9897. Mask: 0.8750. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 3001/5000. LR: 0.0231. Data: 1.85s. Batch: 1.97s. S_Loss: 0.9889. T_Loss: 4.9897. Mask: 0.8750. :   1%|          | 1/100 [00:01<03:15,  1.97s/it]Train Iter: 3002/5000. LR: 0.0231. Data: 0.93s. Batch: 1.05s. S_Loss: 0.9644. T_Loss: 4.9737. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:15,  1.97s/it]Train Iter: 3002/5000. LR: 0.0231. Data: 0.93s. Batch: 1.05s. S_Loss: 0.9644. T_Loss: 4.9737. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 3003/5000. LR: 0.0231. Data: 0.62s. Batch: 0.75s. S_Loss: 0.9580. T_Loss: 4.7535. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 3003/5000. LR: 0.0231. Data: 0.62s. Batch: 0.75s. S_Loss: 0.9580. T_Loss: 4.7535. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:53,  1.82it/s]Train Iter: 3004/5000. LR: 0.0231. Data: 0.47s. Batch: 0.59s. S_Loss: 0.9279. T_Loss: 4.6104. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:53,  1.82it/s]Train Iter: 3004/5000. LR: 0.0231. Data: 0.47s. Batch: 0.59s. S_Loss: 0.9279. T_Loss: 4.6104. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:36,  2.63it/s]Train Iter: 3005/5000. LR: 0.0230. Data: 0.37s. Batch: 0.55s. S_Loss: 0.9540. T_Loss: 4.6475. Mask: 0.9250. :   4%|▍         | 4/100 [00:02<00:36,  2.63it/s]Train Iter: 3005/5000. LR: 0.0230. Data: 0.37s. Batch: 0.55s. S_Loss: 0.9540. T_Loss: 4.6475. Mask: 0.9250. :   5%|▌         | 5/100 [00:02<00:35,  2.65it/s]Train Iter: 3006/5000. LR: 0.0230. Data: 0.31s. Batch: 0.48s. S_Loss: 0.9684. T_Loss: 4.6069. Mask: 0.9219. :   5%|▌         | 5/100 [00:02<00:35,  2.65it/s]Train Iter: 3006/5000. LR: 0.0230. Data: 0.31s. Batch: 0.48s. S_Loss: 0.9684. T_Loss: 4.6069. Mask: 0.9219. :   6%|▌         | 6/100 [00:02<00:28,  3.32it/s]Train Iter: 3007/5000. LR: 0.0230. Data: 0.27s. Batch: 0.43s. S_Loss: 1.0021. T_Loss: 4.6453. Mask: 0.9107. :   6%|▌         | 6/100 [00:03<00:28,  3.32it/s]Train Iter: 3007/5000. LR: 0.0230. Data: 0.27s. Batch: 0.43s. S_Loss: 1.0021. T_Loss: 4.6453. Mask: 0.9107. :   7%|▋         | 7/100 [00:03<00:22,  4.12it/s]Train Iter: 3008/5000. LR: 0.0230. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9869. T_Loss: 4.6139. Mask: 0.9180. :   7%|▋         | 7/100 [00:03<00:22,  4.12it/s]Train Iter: 3008/5000. LR: 0.0230. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9869. T_Loss: 4.6139. Mask: 0.9180. :   8%|▊         | 8/100 [00:03<00:19,  4.79it/s]Train Iter: 3009/5000. LR: 0.0230. Data: 0.21s. Batch: 0.39s. S_Loss: 0.9830. T_Loss: 4.5833. Mask: 0.9201. :   8%|▊         | 8/100 [00:03<00:19,  4.79it/s]Train Iter: 3009/5000. LR: 0.0230. Data: 0.21s. Batch: 0.39s. S_Loss: 0.9830. T_Loss: 4.5833. Mask: 0.9201. :   9%|▉         | 9/100 [00:03<00:22,  3.97it/s]Train Iter: 3010/5000. LR: 0.0229. Data: 0.19s. Batch: 0.36s. S_Loss: 0.9884. T_Loss: 4.5616. Mask: 0.9125. :   9%|▉         | 9/100 [00:03<00:22,  3.97it/s]Train Iter: 3010/5000. LR: 0.0229. Data: 0.19s. Batch: 0.36s. S_Loss: 0.9884. T_Loss: 4.5616. Mask: 0.9125. :  10%|█         | 10/100 [00:03<00:19,  4.74it/s]Train Iter: 3011/5000. LR: 0.0229. Data: 0.17s. Batch: 0.34s. S_Loss: 0.9941. T_Loss: 4.4827. Mask: 0.9062. :  10%|█         | 10/100 [00:03<00:19,  4.74it/s]Train Iter: 3011/5000. LR: 0.0229. Data: 0.17s. Batch: 0.34s. S_Loss: 0.9941. T_Loss: 4.4827. Mask: 0.9062. :  11%|█         | 11/100 [00:03<00:16,  5.50it/s]Train Iter: 3012/5000. LR: 0.0229. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0013. T_Loss: 4.5352. Mask: 0.9036. :  11%|█         | 11/100 [00:03<00:16,  5.50it/s]Train Iter: 3012/5000. LR: 0.0229. Data: 0.16s. Batch: 0.32s. S_Loss: 1.0013. T_Loss: 4.5352. Mask: 0.9036. :  12%|█▏        | 12/100 [00:03<00:14,  6.06it/s]Train Iter: 3013/5000. LR: 0.0229. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9932. T_Loss: 4.5446. Mask: 0.9062. :  12%|█▏        | 12/100 [00:03<00:14,  6.06it/s]Train Iter: 3013/5000. LR: 0.0229. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9932. T_Loss: 4.5446. Mask: 0.9062. :  13%|█▎        | 13/100 [00:03<00:13,  6.52it/s]Train Iter: 3014/5000. LR: 0.0229. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9940. T_Loss: 4.5948. Mask: 0.9107. :  13%|█▎        | 13/100 [00:04<00:13,  6.52it/s]Train Iter: 3014/5000. LR: 0.0229. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9940. T_Loss: 4.5948. Mask: 0.9107. :  14%|█▍        | 14/100 [00:04<00:12,  7.11it/s]Train Iter: 3015/5000. LR: 0.0229. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9999. T_Loss: 4.5938. Mask: 0.9062. :  14%|█▍        | 14/100 [00:04<00:12,  7.11it/s]Train Iter: 3015/5000. LR: 0.0229. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9999. T_Loss: 4.5938. Mask: 0.9062. :  15%|█▌        | 15/100 [00:04<00:16,  5.26it/s]Train Iter: 3016/5000. LR: 0.0228. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9988. T_Loss: 4.6324. Mask: 0.9102. :  15%|█▌        | 15/100 [00:04<00:16,  5.26it/s]Train Iter: 3016/5000. LR: 0.0228. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9988. T_Loss: 4.6324. Mask: 0.9102. :  16%|█▌        | 16/100 [00:04<00:14,  5.85it/s]Train Iter: 3017/5000. LR: 0.0228. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9958. T_Loss: 4.6158. Mask: 0.9099. :  16%|█▌        | 16/100 [00:04<00:14,  5.85it/s]Train Iter: 3017/5000. LR: 0.0228. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9958. T_Loss: 4.6158. Mask: 0.9099. :  17%|█▋        | 17/100 [00:04<00:13,  6.35it/s]Train Iter: 3018/5000. LR: 0.0228. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9893. T_Loss: 4.6036. Mask: 0.9080. :  17%|█▋        | 17/100 [00:04<00:13,  6.35it/s]Train Iter: 3018/5000. LR: 0.0228. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9893. T_Loss: 4.6036. Mask: 0.9080. :  18%|█▊        | 18/100 [00:04<00:11,  6.95it/s]Train Iter: 3019/5000. LR: 0.0228. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9894. T_Loss: 4.6051. Mask: 0.9112. :  18%|█▊        | 18/100 [00:05<00:11,  6.95it/s]Train Iter: 3019/5000. LR: 0.0228. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9894. T_Loss: 4.6051. Mask: 0.9112. :  19%|█▉        | 19/100 [00:05<00:15,  5.36it/s]Train Iter: 3020/5000. LR: 0.0228. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9806. T_Loss: 4.5595. Mask: 0.9141. :  19%|█▉        | 19/100 [00:05<00:15,  5.36it/s]Train Iter: 3020/5000. LR: 0.0228. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9806. T_Loss: 4.5595. Mask: 0.9141. :  20%|██        | 20/100 [00:05<00:13,  5.88it/s]Train Iter: 3021/5000. LR: 0.0227. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9818. T_Loss: 4.6086. Mask: 0.9182. :  20%|██        | 20/100 [00:05<00:13,  5.88it/s]Train Iter: 3021/5000. LR: 0.0227. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9818. T_Loss: 4.6086. Mask: 0.9182. :  21%|██        | 21/100 [00:05<00:12,  6.42it/s]Train Iter: 3022/5000. LR: 0.0227. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9778. T_Loss: 4.5867. Mask: 0.9176. :  21%|██        | 21/100 [00:05<00:12,  6.42it/s]Train Iter: 3022/5000. LR: 0.0227. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9778. T_Loss: 4.5867. Mask: 0.9176. :  22%|██▏       | 22/100 [00:05<00:11,  6.96it/s]Train Iter: 3023/5000. LR: 0.0227. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9795. T_Loss: 4.6476. Mask: 0.9212. :  22%|██▏       | 22/100 [00:05<00:11,  6.96it/s]Train Iter: 3023/5000. LR: 0.0227. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9795. T_Loss: 4.6476. Mask: 0.9212. :  23%|██▎       | 23/100 [00:05<00:10,  7.39it/s]Train Iter: 3024/5000. LR: 0.0227. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9788. T_Loss: 4.6701. Mask: 0.9232. :  23%|██▎       | 23/100 [00:05<00:10,  7.39it/s]Train Iter: 3024/5000. LR: 0.0227. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9788. T_Loss: 4.6701. Mask: 0.9232. :  24%|██▍       | 24/100 [00:05<00:10,  7.50it/s]Train Iter: 3025/5000. LR: 0.0227. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9756. T_Loss: 4.6584. Mask: 0.9213. :  24%|██▍       | 24/100 [00:05<00:10,  7.50it/s]Train Iter: 3025/5000. LR: 0.0227. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9756. T_Loss: 4.6584. Mask: 0.9213. :  25%|██▌       | 25/100 [00:05<00:09,  7.77it/s]total : 5000  current step :  3001
total : 5000  current step :  3002
total : 5000  current step :  3003
total : 5000  current step :  3004
total : 5000  current step :  3005
total : 5000  current step :  3006
total : 5000  current step :  3007
total : 5000  current step :  3008
total : 5000  current step :  3009
total : 5000  current step :  3010
total : 5000  current step :  3011
total : 5000  current step :  3012
total : 5000  current step :  3013
total : 5000  current step :  3014
total : 5000  current step :  3015
total : 5000  current step :  3016
total : 5000  current step :  3017
total : 5000  current step :  3018
total : 5000  current step :  3019
total : 5000  current step :  3020
total : 5000  current step :  3021
total : 5000  current step :  3022
total : 5000  current step :  3023
total : 5000  current step :  3024
total : 5000  current step :  3025
Train Iter: 3026/5000. LR: 0.0226. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9757. T_Loss: 4.6637. Mask: 0.9231. :  25%|██▌       | 25/100 [00:07<00:09,  7.77it/s]Train Iter: 3026/5000. LR: 0.0226. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9757. T_Loss: 4.6637. Mask: 0.9231. :  26%|██▌       | 26/100 [00:07<00:50,  1.47it/s]Train Iter: 3027/5000. LR: 0.0226. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9827. T_Loss: 4.7271. Mask: 0.9236. :  26%|██▌       | 26/100 [00:07<00:50,  1.47it/s]Train Iter: 3027/5000. LR: 0.0226. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9827. T_Loss: 4.7271. Mask: 0.9236. :  27%|██▋       | 27/100 [00:07<00:37,  1.95it/s]Train Iter: 3028/5000. LR: 0.0226. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9862. T_Loss: 4.7266. Mask: 0.9219. :  27%|██▋       | 27/100 [00:08<00:37,  1.95it/s]Train Iter: 3028/5000. LR: 0.0226. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9862. T_Loss: 4.7266. Mask: 0.9219. :  28%|██▊       | 28/100 [00:08<00:28,  2.53it/s]Train Iter: 3029/5000. LR: 0.0226. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9874. T_Loss: 4.7185. Mask: 0.9213. :  28%|██▊       | 28/100 [00:08<00:28,  2.53it/s]Train Iter: 3029/5000. LR: 0.0226. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9874. T_Loss: 4.7185. Mask: 0.9213. :  29%|██▉       | 29/100 [00:08<00:21,  3.24it/s]Train Iter: 3030/5000. LR: 0.0226. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9850. T_Loss: 4.7255. Mask: 0.9229. :  29%|██▉       | 29/100 [00:08<00:21,  3.24it/s]Train Iter: 3030/5000. LR: 0.0226. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9850. T_Loss: 4.7255. Mask: 0.9229. :  30%|███       | 30/100 [00:08<00:17,  3.97it/s]Train Iter: 3031/5000. LR: 0.0226. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9830. T_Loss: 4.7270. Mask: 0.9234. :  30%|███       | 30/100 [00:08<00:17,  3.97it/s]Train Iter: 3031/5000. LR: 0.0226. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9830. T_Loss: 4.7270. Mask: 0.9234. :  31%|███       | 31/100 [00:08<00:14,  4.68it/s]Train Iter: 3032/5000. LR: 0.0225. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9851. T_Loss: 4.7170. Mask: 0.9238. :  31%|███       | 31/100 [00:08<00:14,  4.68it/s]Train Iter: 3032/5000. LR: 0.0225. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9851. T_Loss: 4.7170. Mask: 0.9238. :  32%|███▏      | 32/100 [00:08<00:12,  5.41it/s]Train Iter: 3033/5000. LR: 0.0225. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9893. T_Loss: 4.7149. Mask: 0.9233. :  32%|███▏      | 32/100 [00:08<00:12,  5.41it/s]Train Iter: 3033/5000. LR: 0.0225. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9893. T_Loss: 4.7149. Mask: 0.9233. :  33%|███▎      | 33/100 [00:08<00:11,  5.99it/s]Train Iter: 3034/5000. LR: 0.0225. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9920. T_Loss: 4.7114. Mask: 0.9237. :  33%|███▎      | 33/100 [00:08<00:11,  5.99it/s]Train Iter: 3034/5000. LR: 0.0225. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9920. T_Loss: 4.7114. Mask: 0.9237. :  34%|███▍      | 34/100 [00:08<00:10,  6.57it/s]Train Iter: 3035/5000. LR: 0.0225. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9908. T_Loss: 4.7054. Mask: 0.9241. :  34%|███▍      | 34/100 [00:09<00:10,  6.57it/s]Train Iter: 3035/5000. LR: 0.0225. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9908. T_Loss: 4.7054. Mask: 0.9241. :  35%|███▌      | 35/100 [00:09<00:12,  5.02it/s]Train Iter: 3036/5000. LR: 0.0225. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9930. T_Loss: 4.7188. Mask: 0.9236. :  35%|███▌      | 35/100 [00:09<00:12,  5.02it/s]Train Iter: 3036/5000. LR: 0.0225. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9930. T_Loss: 4.7188. Mask: 0.9236. :  36%|███▌      | 36/100 [00:09<00:11,  5.60it/s]Train Iter: 3037/5000. LR: 0.0224. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9927. T_Loss: 4.7017. Mask: 0.9240. :  36%|███▌      | 36/100 [00:09<00:11,  5.60it/s]Train Iter: 3037/5000. LR: 0.0224. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9927. T_Loss: 4.7017. Mask: 0.9240. :  37%|███▋      | 37/100 [00:09<00:10,  6.19it/s]Train Iter: 3038/5000. LR: 0.0224. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9921. T_Loss: 4.6827. Mask: 0.9227. :  37%|███▋      | 37/100 [00:09<00:10,  6.19it/s]Train Iter: 3038/5000. LR: 0.0224. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9921. T_Loss: 4.6827. Mask: 0.9227. :  38%|███▊      | 38/100 [00:09<00:09,  6.50it/s]Train Iter: 3039/5000. LR: 0.0224. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9905. T_Loss: 4.6661. Mask: 0.9215. :  38%|███▊      | 38/100 [00:09<00:09,  6.50it/s]Train Iter: 3039/5000. LR: 0.0224. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9905. T_Loss: 4.6661. Mask: 0.9215. :  39%|███▉      | 39/100 [00:09<00:11,  5.39it/s]Train Iter: 3040/5000. LR: 0.0224. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9891. T_Loss: 4.6831. Mask: 0.9219. :  39%|███▉      | 39/100 [00:09<00:11,  5.39it/s]Train Iter: 3040/5000. LR: 0.0224. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9891. T_Loss: 4.6831. Mask: 0.9219. :  40%|████      | 40/100 [00:09<00:10,  5.89it/s]Train Iter: 3041/5000. LR: 0.0224. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9860. T_Loss: 4.6772. Mask: 0.9223. :  40%|████      | 40/100 [00:09<00:10,  5.89it/s]Train Iter: 3041/5000. LR: 0.0224. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9860. T_Loss: 4.6772. Mask: 0.9223. :  41%|████      | 41/100 [00:09<00:09,  6.09it/s]Train Iter: 3042/5000. LR: 0.0223. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9869. T_Loss: 4.6652. Mask: 0.9211. :  41%|████      | 41/100 [00:10<00:09,  6.09it/s]Train Iter: 3042/5000. LR: 0.0223. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9869. T_Loss: 4.6652. Mask: 0.9211. :  42%|████▏     | 42/100 [00:10<00:08,  6.59it/s]Train Iter: 3043/5000. LR: 0.0223. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9849. T_Loss: 4.6628. Mask: 0.9222. :  42%|████▏     | 42/100 [00:10<00:08,  6.59it/s]Train Iter: 3043/5000. LR: 0.0223. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9849. T_Loss: 4.6628. Mask: 0.9222. :  43%|████▎     | 43/100 [00:10<00:08,  6.97it/s]Train Iter: 3044/5000. LR: 0.0223. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9852. T_Loss: 4.6531. Mask: 0.9219. :  43%|████▎     | 43/100 [00:10<00:08,  6.97it/s]Train Iter: 3044/5000. LR: 0.0223. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9852. T_Loss: 4.6531. Mask: 0.9219. :  44%|████▍     | 44/100 [00:10<00:07,  7.57it/s]Train Iter: 3045/5000. LR: 0.0223. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9823. T_Loss: 4.6365. Mask: 0.9215. :  44%|████▍     | 44/100 [00:10<00:07,  7.57it/s]Train Iter: 3045/5000. LR: 0.0223. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9823. T_Loss: 4.6365. Mask: 0.9215. :  45%|████▌     | 45/100 [00:10<00:06,  8.13it/s]Train Iter: 3046/5000. LR: 0.0223. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9812. T_Loss: 4.6512. Mask: 0.9232. :  45%|████▌     | 45/100 [00:10<00:06,  8.13it/s]Train Iter: 3046/5000. LR: 0.0223. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9812. T_Loss: 4.6512. Mask: 0.9232. :  46%|████▌     | 46/100 [00:10<00:06,  7.94it/s]Train Iter: 3047/5000. LR: 0.0223. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9793. T_Loss: 4.6445. Mask: 0.9235. :  46%|████▌     | 46/100 [00:10<00:06,  7.94it/s]Train Iter: 3047/5000. LR: 0.0223. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9793. T_Loss: 4.6445. Mask: 0.9235. :  47%|████▋     | 47/100 [00:10<00:06,  7.87it/s]Train Iter: 3048/5000. LR: 0.0222. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9777. T_Loss: 4.6382. Mask: 0.9251. :  47%|████▋     | 47/100 [00:10<00:06,  7.87it/s]Train Iter: 3048/5000. LR: 0.0222. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9777. T_Loss: 4.6382. Mask: 0.9251. :  48%|████▊     | 48/100 [00:10<00:06,  8.34it/s]Train Iter: 3049/5000. LR: 0.0222. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9775. T_Loss: 4.6317. Mask: 0.9260. :  48%|████▊     | 48/100 [00:11<00:06,  8.34it/s]Train Iter: 3049/5000. LR: 0.0222. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9775. T_Loss: 4.6317. Mask: 0.9260. :  49%|████▉     | 49/100 [00:11<00:09,  5.67it/s]Train Iter: 3050/5000. LR: 0.0222. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9795. T_Loss: 4.6343. Mask: 0.9244. :  49%|████▉     | 49/100 [00:11<00:09,  5.67it/s]Train Iter: 3050/5000. LR: 0.0222. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9795. T_Loss: 4.6343. Mask: 0.9244. :  50%|█████     | 50/100 [00:11<00:07,  6.25it/s]total : 5000  current step :  3026
total : 5000  current step :  3027
total : 5000  current step :  3028
total : 5000  current step :  3029
total : 5000  current step :  3030
total : 5000  current step :  3031
total : 5000  current step :  3032
total : 5000  current step :  3033
total : 5000  current step :  3034
total : 5000  current step :  3035
total : 5000  current step :  3036
total : 5000  current step :  3037
total : 5000  current step :  3038
total : 5000  current step :  3039
total : 5000  current step :  3040
total : 5000  current step :  3041
total : 5000  current step :  3042
total : 5000  current step :  3043
total : 5000  current step :  3044
total : 5000  current step :  3045
total : 5000  current step :  3046
total : 5000  current step :  3047
total : 5000  current step :  3048
total : 5000  current step :  3049
total : 5000  current step :  3050
Train Iter: 3051/5000. LR: 0.0222. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9795. T_Loss: 4.6358. Mask: 0.9246. :  50%|█████     | 50/100 [00:13<00:07,  6.25it/s]Train Iter: 3051/5000. LR: 0.0222. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9795. T_Loss: 4.6358. Mask: 0.9246. :  51%|█████     | 51/100 [00:13<00:34,  1.42it/s]Train Iter: 3052/5000. LR: 0.0222. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9813. T_Loss: 4.6531. Mask: 0.9261. :  51%|█████     | 51/100 [00:13<00:34,  1.42it/s]Train Iter: 3052/5000. LR: 0.0222. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9813. T_Loss: 4.6531. Mask: 0.9261. :  52%|█████▏    | 52/100 [00:13<00:25,  1.86it/s]Train Iter: 3053/5000. LR: 0.0221. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.6515. Mask: 0.9263. :  52%|█████▏    | 52/100 [00:13<00:25,  1.86it/s]Train Iter: 3053/5000. LR: 0.0221. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.6515. Mask: 0.9263. :  53%|█████▎    | 53/100 [00:13<00:19,  2.40it/s]Train Iter: 3054/5000. LR: 0.0221. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9823. T_Loss: 4.6581. Mask: 0.9265. :  53%|█████▎    | 53/100 [00:13<00:19,  2.40it/s]Train Iter: 3054/5000. LR: 0.0221. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9823. T_Loss: 4.6581. Mask: 0.9265. :  54%|█████▍    | 54/100 [00:13<00:15,  3.04it/s]Train Iter: 3055/5000. LR: 0.0221. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9830. T_Loss: 4.6692. Mask: 0.9267. :  54%|█████▍    | 54/100 [00:13<00:15,  3.04it/s]Train Iter: 3055/5000. LR: 0.0221. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9830. T_Loss: 4.6692. Mask: 0.9267. :  55%|█████▌    | 55/100 [00:13<00:14,  3.13it/s]Train Iter: 3056/5000. LR: 0.0221. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9833. T_Loss: 4.6724. Mask: 0.9269. :  55%|█████▌    | 55/100 [00:13<00:14,  3.13it/s]Train Iter: 3057/5000. LR: 0.0221. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9812. T_Loss: 4.6627. Mask: 0.9265. :  56%|█████▌    | 56/100 [00:14<00:14,  3.13it/s]Train Iter: 3057/5000. LR: 0.0221. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9812. T_Loss: 4.6627. Mask: 0.9265. :  57%|█████▋    | 57/100 [00:14<00:09,  4.52it/s]Train Iter: 3058/5000. LR: 0.0221. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9800. T_Loss: 4.6592. Mask: 0.9267. :  57%|█████▋    | 57/100 [00:14<00:09,  4.52it/s]Train Iter: 3059/5000. LR: 0.0220. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9801. T_Loss: 4.6595. Mask: 0.9269. :  58%|█████▊    | 58/100 [00:14<00:09,  4.52it/s]Train Iter: 3059/5000. LR: 0.0220. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9801. T_Loss: 4.6595. Mask: 0.9269. :  59%|█████▉    | 59/100 [00:14<00:08,  4.89it/s]Train Iter: 3060/5000. LR: 0.0220. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9803. T_Loss: 4.6715. Mask: 0.9281. :  59%|█████▉    | 59/100 [00:14<00:08,  4.89it/s]Train Iter: 3061/5000. LR: 0.0220. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9802. T_Loss: 4.6744. Mask: 0.9283. :  60%|██████    | 60/100 [00:14<00:08,  4.89it/s]Train Iter: 3061/5000. LR: 0.0220. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9802. T_Loss: 4.6744. Mask: 0.9283. :  61%|██████    | 61/100 [00:14<00:06,  6.31it/s]Train Iter: 3062/5000. LR: 0.0220. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9801. T_Loss: 4.6807. Mask: 0.9279. :  61%|██████    | 61/100 [00:14<00:06,  6.31it/s]Train Iter: 3063/5000. LR: 0.0220. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9784. T_Loss: 4.6850. Mask: 0.9276. :  62%|██████▏   | 62/100 [00:14<00:06,  6.31it/s]Train Iter: 3063/5000. LR: 0.0220. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9784. T_Loss: 4.6850. Mask: 0.9276. :  63%|██████▎   | 63/100 [00:14<00:05,  7.29it/s]Train Iter: 3064/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9772. T_Loss: 4.6819. Mask: 0.9268. :  63%|██████▎   | 63/100 [00:14<00:05,  7.29it/s]Train Iter: 3064/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9772. T_Loss: 4.6819. Mask: 0.9268. :  64%|██████▍   | 64/100 [00:14<00:04,  7.61it/s]Train Iter: 3065/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9781. T_Loss: 4.6749. Mask: 0.9264. :  64%|██████▍   | 64/100 [00:15<00:04,  7.61it/s]Train Iter: 3065/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9781. T_Loss: 4.6749. Mask: 0.9264. :  65%|██████▌   | 65/100 [00:15<00:04,  7.58it/s]Train Iter: 3066/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9757. T_Loss: 4.6638. Mask: 0.9266. :  65%|██████▌   | 65/100 [00:15<00:04,  7.58it/s]Train Iter: 3066/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9757. T_Loss: 4.6638. Mask: 0.9266. :  66%|██████▌   | 66/100 [00:15<00:04,  7.73it/s]Train Iter: 3067/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9769. T_Loss: 4.6741. Mask: 0.9272. :  66%|██████▌   | 66/100 [00:15<00:04,  7.73it/s]Train Iter: 3067/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9769. T_Loss: 4.6741. Mask: 0.9272. :  67%|██████▋   | 67/100 [00:15<00:04,  7.81it/s]Train Iter: 3068/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9767. T_Loss: 4.6798. Mask: 0.9265. :  67%|██████▋   | 67/100 [00:15<00:04,  7.81it/s]Train Iter: 3068/5000. LR: 0.0219. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9767. T_Loss: 4.6798. Mask: 0.9265. :  68%|██████▊   | 68/100 [00:15<00:03,  8.04it/s]Train Iter: 3069/5000. LR: 0.0218. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9759. T_Loss: 4.6809. Mask: 0.9266. :  68%|██████▊   | 68/100 [00:15<00:03,  8.04it/s]Train Iter: 3069/5000. LR: 0.0218. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9759. T_Loss: 4.6809. Mask: 0.9266. :  69%|██████▉   | 69/100 [00:15<00:05,  5.23it/s]Train Iter: 3070/5000. LR: 0.0218. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9758. T_Loss: 4.6865. Mask: 0.9272. :  69%|██████▉   | 69/100 [00:15<00:05,  5.23it/s]Train Iter: 3070/5000. LR: 0.0218. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9758. T_Loss: 4.6865. Mask: 0.9272. :  70%|███████   | 70/100 [00:15<00:05,  5.98it/s]Train Iter: 3071/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9766. T_Loss: 4.6860. Mask: 0.9265. :  70%|███████   | 70/100 [00:15<00:05,  5.98it/s]Train Iter: 3071/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9766. T_Loss: 4.6860. Mask: 0.9265. :  71%|███████   | 71/100 [00:15<00:04,  6.74it/s]Train Iter: 3072/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9772. T_Loss: 4.6740. Mask: 0.9266. :  71%|███████   | 71/100 [00:16<00:04,  6.74it/s]Train Iter: 3072/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9772. T_Loss: 4.6740. Mask: 0.9266. :  72%|███████▏  | 72/100 [00:16<00:03,  7.36it/s]Train Iter: 3073/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9765. T_Loss: 4.6758. Mask: 0.9272. :  72%|███████▏  | 72/100 [00:16<00:03,  7.36it/s]Train Iter: 3073/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9765. T_Loss: 4.6758. Mask: 0.9272. :  73%|███████▎  | 73/100 [00:16<00:03,  7.46it/s]Train Iter: 3074/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9763. T_Loss: 4.6714. Mask: 0.9274. :  73%|███████▎  | 73/100 [00:16<00:03,  7.46it/s]Train Iter: 3074/5000. LR: 0.0218. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9763. T_Loss: 4.6714. Mask: 0.9274. :  74%|███████▍  | 74/100 [00:16<00:03,  7.75it/s]Train Iter: 3075/5000. LR: 0.0217. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9767. T_Loss: 4.6851. Mask: 0.9279. :  74%|███████▍  | 74/100 [00:16<00:03,  7.75it/s]Train Iter: 3075/5000. LR: 0.0217. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9767. T_Loss: 4.6851. Mask: 0.9279. :  75%|███████▌  | 75/100 [00:16<00:04,  5.54it/s]total : 5000  current step :  3051
total : 5000  current step :  3052
total : 5000  current step :  3053
total : 5000  current step :  3054
total : 5000  current step :  3055
total : 5000  current step :  3056
total : 5000  current step :  3057
total : 5000  current step :  3058
total : 5000  current step :  3059
total : 5000  current step :  3060
total : 5000  current step :  3061
total : 5000  current step :  3062
total : 5000  current step :  3063
total : 5000  current step :  3064
total : 5000  current step :  3065
total : 5000  current step :  3066
total : 5000  current step :  3067
total : 5000  current step :  3068
total : 5000  current step :  3069
total : 5000  current step :  3070
total : 5000  current step :  3071
total : 5000  current step :  3072
total : 5000  current step :  3073
total : 5000  current step :  3074
total : 5000  current step :  3075
Train Iter: 3076/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9780. T_Loss: 4.6768. Mask: 0.9276. :  75%|███████▌  | 75/100 [00:18<00:04,  5.54it/s]Train Iter: 3076/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9780. T_Loss: 4.6768. Mask: 0.9276. :  76%|███████▌  | 76/100 [00:18<00:17,  1.36it/s]Train Iter: 3077/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9780. T_Loss: 4.6792. Mask: 0.9278. :  76%|███████▌  | 76/100 [00:18<00:17,  1.36it/s]Train Iter: 3077/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9780. T_Loss: 4.6792. Mask: 0.9278. :  77%|███████▋  | 77/100 [00:18<00:12,  1.79it/s]Train Iter: 3078/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9778. T_Loss: 4.6691. Mask: 0.9267. :  77%|███████▋  | 77/100 [00:18<00:12,  1.79it/s]Train Iter: 3078/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9778. T_Loss: 4.6691. Mask: 0.9267. :  78%|███████▊  | 78/100 [00:18<00:09,  2.32it/s]Train Iter: 3079/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9773. T_Loss: 4.6676. Mask: 0.9268. :  78%|███████▊  | 78/100 [00:19<00:09,  2.32it/s]Train Iter: 3079/5000. LR: 0.0217. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9773. T_Loss: 4.6676. Mask: 0.9268. :  79%|███████▉  | 79/100 [00:19<00:08,  2.58it/s]Train Iter: 3080/5000. LR: 0.0216. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9789. T_Loss: 4.6869. Mask: 0.9273. :  79%|███████▉  | 79/100 [00:19<00:08,  2.58it/s]Train Iter: 3080/5000. LR: 0.0216. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9789. T_Loss: 4.6869. Mask: 0.9273. :  80%|████████  | 80/100 [00:19<00:06,  3.24it/s]Train Iter: 3081/5000. LR: 0.0216. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9795. T_Loss: 4.6864. Mask: 0.9267. :  80%|████████  | 80/100 [00:19<00:06,  3.24it/s]Train Iter: 3081/5000. LR: 0.0216. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9795. T_Loss: 4.6864. Mask: 0.9267. :  81%|████████  | 81/100 [00:19<00:04,  4.03it/s]Train Iter: 3082/5000. LR: 0.0216. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9788. T_Loss: 4.6853. Mask: 0.9268. :  81%|████████  | 81/100 [00:19<00:04,  4.03it/s]Train Iter: 3082/5000. LR: 0.0216. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9788. T_Loss: 4.6853. Mask: 0.9268. :  82%|████████▏ | 82/100 [00:19<00:03,  4.70it/s]Train Iter: 3083/5000. LR: 0.0216. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9794. T_Loss: 4.6944. Mask: 0.9270. :  82%|████████▏ | 82/100 [00:19<00:03,  4.70it/s]Train Iter: 3083/5000. LR: 0.0216. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9794. T_Loss: 4.6944. Mask: 0.9270. :  83%|████████▎ | 83/100 [00:19<00:03,  5.38it/s]Train Iter: 3084/5000. LR: 0.0216. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9803. T_Loss: 4.6848. Mask: 0.9249. :  83%|████████▎ | 83/100 [00:19<00:03,  5.38it/s]Train Iter: 3084/5000. LR: 0.0216. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9803. T_Loss: 4.6848. Mask: 0.9249. :  84%|████████▍ | 84/100 [00:19<00:02,  5.92it/s]Train Iter: 3085/5000. LR: 0.0216. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9815. T_Loss: 4.6838. Mask: 0.9235. :  84%|████████▍ | 84/100 [00:20<00:02,  5.92it/s]Train Iter: 3085/5000. LR: 0.0216. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9815. T_Loss: 4.6838. Mask: 0.9235. :  85%|████████▌ | 85/100 [00:20<00:03,  4.53it/s]Train Iter: 3086/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9813. T_Loss: 4.6886. Mask: 0.9233. :  85%|████████▌ | 85/100 [00:20<00:03,  4.53it/s]Train Iter: 3086/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9813. T_Loss: 4.6886. Mask: 0.9233. :  86%|████████▌ | 86/100 [00:20<00:02,  5.31it/s]Train Iter: 3087/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9799. T_Loss: 4.6901. Mask: 0.9242. :  86%|████████▌ | 86/100 [00:20<00:02,  5.31it/s]Train Iter: 3088/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9798. T_Loss: 4.6923. Mask: 0.9244. :  87%|████████▋ | 87/100 [00:20<00:02,  5.31it/s]Train Iter: 3088/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9798. T_Loss: 4.6923. Mask: 0.9244. :  88%|████████▊ | 88/100 [00:20<00:01,  6.79it/s]Train Iter: 3089/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9795. T_Loss: 4.6972. Mask: 0.9252. :  88%|████████▊ | 88/100 [00:20<00:01,  6.79it/s]Train Iter: 3089/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9795. T_Loss: 4.6972. Mask: 0.9252. :  89%|████████▉ | 89/100 [00:20<00:02,  5.39it/s]Train Iter: 3090/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9784. T_Loss: 4.6887. Mask: 0.9260. :  89%|████████▉ | 89/100 [00:20<00:02,  5.39it/s]Train Iter: 3090/5000. LR: 0.0215. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9784. T_Loss: 4.6887. Mask: 0.9260. :  90%|█████████ | 90/100 [00:20<00:01,  6.00it/s]Train Iter: 3091/5000. LR: 0.0214. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9792. T_Loss: 4.6924. Mask: 0.9258. :  90%|█████████ | 90/100 [00:21<00:01,  6.00it/s]Train Iter: 3091/5000. LR: 0.0214. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9792. T_Loss: 4.6924. Mask: 0.9258. :  91%|█████████ | 91/100 [00:21<00:01,  6.42it/s]Train Iter: 3092/5000. LR: 0.0214. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9783. T_Loss: 4.6898. Mask: 0.9249. :  91%|█████████ | 91/100 [00:21<00:01,  6.42it/s]Train Iter: 3092/5000. LR: 0.0214. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9783. T_Loss: 4.6898. Mask: 0.9249. :  92%|█████████▏| 92/100 [00:21<00:01,  7.03it/s]Train Iter: 3093/5000. LR: 0.0214. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9786. T_Loss: 4.6911. Mask: 0.9247. :  92%|█████████▏| 92/100 [00:21<00:01,  7.03it/s]Train Iter: 3093/5000. LR: 0.0214. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9786. T_Loss: 4.6911. Mask: 0.9247. :  93%|█████████▎| 93/100 [00:21<00:00,  7.58it/s]Train Iter: 3094/5000. LR: 0.0214. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9798. T_Loss: 4.6954. Mask: 0.9242. :  93%|█████████▎| 93/100 [00:21<00:00,  7.58it/s]Train Iter: 3094/5000. LR: 0.0214. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9798. T_Loss: 4.6954. Mask: 0.9242. :  94%|█████████▍| 94/100 [00:21<00:00,  7.86it/s]Train Iter: 3095/5000. LR: 0.0214. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9798. T_Loss: 4.6976. Mask: 0.9230. :  94%|█████████▍| 94/100 [00:21<00:00,  7.86it/s]Train Iter: 3095/5000. LR: 0.0214. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9798. T_Loss: 4.6976. Mask: 0.9230. :  95%|█████████▌| 95/100 [00:21<00:00,  5.01it/s]Train Iter: 3096/5000. LR: 0.0213. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9797. T_Loss: 4.6974. Mask: 0.9225. :  95%|█████████▌| 95/100 [00:21<00:00,  5.01it/s]Train Iter: 3096/5000. LR: 0.0213. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9797. T_Loss: 4.6974. Mask: 0.9225. :  96%|█████████▌| 96/100 [00:21<00:00,  5.66it/s]Train Iter: 3097/5000. LR: 0.0213. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9805. T_Loss: 4.7032. Mask: 0.9227. :  96%|█████████▌| 96/100 [00:21<00:00,  5.66it/s]Train Iter: 3097/5000. LR: 0.0213. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9805. T_Loss: 4.7032. Mask: 0.9227. :  97%|█████████▋| 97/100 [00:21<00:00,  6.21it/s]Train Iter: 3098/5000. LR: 0.0213. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9798. T_Loss: 4.7044. Mask: 0.9225. :  97%|█████████▋| 97/100 [00:22<00:00,  6.21it/s]Train Iter: 3098/5000. LR: 0.0213. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9798. T_Loss: 4.7044. Mask: 0.9225. :  98%|█████████▊| 98/100 [00:22<00:00,  6.62it/s]Train Iter: 3099/5000. LR: 0.0213. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9807. T_Loss: 4.7145. Mask: 0.9214. :  98%|█████████▊| 98/100 [00:22<00:00,  6.62it/s]Train Iter: 3099/5000. LR: 0.0213. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9807. T_Loss: 4.7145. Mask: 0.9214. :  99%|█████████▉| 99/100 [00:22<00:00,  4.70it/s]Train Iter: 3100/5000. LR: 0.0213. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9810. T_Loss: 4.7116. Mask: 0.9209. :  99%|█████████▉| 99/100 [00:22<00:00,  4.70it/s]Train Iter: 3100/5000. LR: 0.0213. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9810. T_Loss: 4.7116. Mask: 0.9209. : 100%|██████████| 100/100 [00:22<00:00,  5.38it/s]Train Iter: 3100/5000. LR: 0.0213. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9810. T_Loss: 4.7116. Mask: 0.9209. : 100%|██████████| 100/100 [00:22<00:00,  4.43it/s]
total : 5000  current step :  3076
total : 5000  current step :  3077
total : 5000  current step :  3078
total : 5000  current step :  3079
total : 5000  current step :  3080
total : 5000  current step :  3081
total : 5000  current step :  3082
total : 5000  current step :  3083
total : 5000  current step :  3084
total : 5000  current step :  3085
total : 5000  current step :  3086
total : 5000  current step :  3087
total : 5000  current step :  3088
total : 5000  current step :  3089
total : 5000  current step :  3090
total : 5000  current step :  3091
total : 5000  current step :  3092
total : 5000  current step :  3093
total : 5000  current step :  3094
total : 5000  current step :  3095
total : 5000  current step :  3096
total : 5000  current step :  3097
total : 5000  current step :  3098
total : 5000  current step :  3099
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.91s. Loss: 0.9134. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.91s. Loss: 0.9134. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.97s. Loss: 0.9038. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.65s. Loss: 0.8712. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.49s. Loss: 0.8777. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 0.8621. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.8614. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8712. top1: 88.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8734. top1: 88.28. top5: 100.00. :   2%|▏         | 1/63 [00:02<01:58,  1.91s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8685. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:02<01:58,  1.91s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8685. top1: 88.54. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8732. top1: 88.44. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8625. top1: 89.49. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8605. top1: 89.84. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8554. top1: 89.90. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8537. top1: 89.96. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8508. top1: 90.00. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8512. top1: 90.04. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.03it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8512. top1: 90.04. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8490. top1: 89.89. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8482. top1: 89.76. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8492. top1: 89.97. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8484. top1: 90.16. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8511. top1: 90.18. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8487. top1: 90.48. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8451. top1: 90.76. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8430. top1: 91.02. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8405. top1: 91.25. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8447. top1: 90.87. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.69it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8447. top1: 90.87. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8443. top1: 90.97. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8465. top1: 90.96. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8442. top1: 91.16. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8441. top1: 91.15. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8444. top1: 91.03. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8626. top1: 90.14. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8720. top1: 89.68. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8848. top1: 88.79. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8993. top1: 87.86. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9253. top1: 86.55. top5: 99.74. :  41%|████▏     | 26/63 [00:02<00:01, 21.68it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9253. top1: 86.55. top5: 99.74. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9328. top1: 86.06. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9423. top1: 85.36. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9584. top1: 84.70. top5: 99.52. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9694. top1: 83.91. top5: 99.53. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9761. top1: 83.54. top5: 99.47. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9913. top1: 82.74. top5: 99.48. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9994. top1: 82.19. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0042. top1: 82.03. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0077. top1: 81.67. top5: 99.51. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0161. top1: 81.05. top5: 99.52. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0239. top1: 80.65. top5: 99.53. :  57%|█████▋    | 36/63 [00:02<00:00, 32.47it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0239. top1: 80.65. top5: 99.53. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0291. top1: 80.40. top5: 99.54. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0361. top1: 80.23. top5: 99.55. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0407. top1: 80.00. top5: 99.56. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0546. top1: 79.17. top5: 99.57. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0592. top1: 79.03. top5: 99.52. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0678. top1: 78.60. top5: 99.47. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0764. top1: 78.24. top5: 99.42. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0795. top1: 78.07. top5: 99.43. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0834. top1: 77.96. top5: 99.44. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0928. top1: 77.41. top5: 99.40. :  75%|███████▍  | 47/63 [00:02<00:00, 43.69it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0928. top1: 77.41. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 53.46it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0997. top1: 76.89. top5: 99.41. :  90%|█████████ | 57/63 [00:02<00:00, 53.46it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1056. top1: 76.59. top5: 99.36. :  90%|█████████ | 57/63 [00:02<00:00, 53.46it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1052. top1: 76.67. top5: 99.38. :  90%|█████████ | 57/63 [00:02<00:00, 53.46it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1126. top1: 76.18. top5: 99.39. :  90%|█████████ | 57/63 [00:02<00:00, 53.46it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1232. top1: 75.50. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 53.46it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1245. top1: 75.40. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 53.46it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1245. top1: 75.40. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 22.53it/s]
total : 5000  current step :  3100
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3101/5000. LR: 0.0213. Data: 1.72s. Batch: 1.85s. S_Loss: 1.0113. T_Loss: 5.4772. Mask: 0.9062. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 3101/5000. LR: 0.0213. Data: 1.72s. Batch: 1.85s. S_Loss: 1.0113. T_Loss: 5.4772. Mask: 0.9062. :   1%|          | 1/100 [00:01<03:03,  1.85s/it]Train Iter: 3102/5000. LR: 0.0212. Data: 0.86s. Batch: 0.99s. S_Loss: 0.9832. T_Loss: 5.3469. Mask: 0.9375. :   1%|          | 1/100 [00:01<03:03,  1.85s/it]Train Iter: 3102/5000. LR: 0.0212. Data: 0.86s. Batch: 0.99s. S_Loss: 0.9832. T_Loss: 5.3469. Mask: 0.9375. :   2%|▏         | 2/100 [00:01<01:21,  1.20it/s]Train Iter: 3103/5000. LR: 0.0212. Data: 0.58s. Batch: 0.71s. S_Loss: 0.9757. T_Loss: 5.2037. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:21,  1.20it/s]Train Iter: 3103/5000. LR: 0.0212. Data: 0.58s. Batch: 0.71s. S_Loss: 0.9757. T_Loss: 5.2037. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:50,  1.92it/s]Train Iter: 3104/5000. LR: 0.0212. Data: 0.44s. Batch: 0.56s. S_Loss: 0.9672. T_Loss: 5.0384. Mask: 0.8828. :   3%|▎         | 3/100 [00:02<00:50,  1.92it/s]Train Iter: 3104/5000. LR: 0.0212. Data: 0.44s. Batch: 0.56s. S_Loss: 0.9672. T_Loss: 5.0384. Mask: 0.8828. :   4%|▍         | 4/100 [00:02<00:35,  2.73it/s]Train Iter: 3105/5000. LR: 0.0212. Data: 0.35s. Batch: 0.47s. S_Loss: 0.9688. T_Loss: 5.0173. Mask: 0.9000. :   4%|▍         | 4/100 [00:02<00:35,  2.73it/s]Train Iter: 3105/5000. LR: 0.0212. Data: 0.35s. Batch: 0.47s. S_Loss: 0.9688. T_Loss: 5.0173. Mask: 0.9000. :   5%|▌         | 5/100 [00:02<00:26,  3.59it/s]Train Iter: 3106/5000. LR: 0.0212. Data: 0.29s. Batch: 0.41s. S_Loss: 0.9738. T_Loss: 4.9410. Mask: 0.8958. :   5%|▌         | 5/100 [00:02<00:26,  3.59it/s]Train Iter: 3106/5000. LR: 0.0212. Data: 0.29s. Batch: 0.41s. S_Loss: 0.9738. T_Loss: 4.9410. Mask: 0.8958. :   6%|▌         | 6/100 [00:02<00:21,  4.46it/s]Train Iter: 3107/5000. LR: 0.0211. Data: 0.25s. Batch: 0.37s. S_Loss: 0.9592. T_Loss: 4.8881. Mask: 0.9018. :   6%|▌         | 6/100 [00:02<00:21,  4.46it/s]Train Iter: 3107/5000. LR: 0.0211. Data: 0.25s. Batch: 0.37s. S_Loss: 0.9592. T_Loss: 4.8881. Mask: 0.9018. :   7%|▋         | 7/100 [00:02<00:17,  5.24it/s]Train Iter: 3108/5000. LR: 0.0211. Data: 0.22s. Batch: 0.34s. S_Loss: 0.9520. T_Loss: 4.9131. Mask: 0.9062. :   7%|▋         | 7/100 [00:02<00:17,  5.24it/s]Train Iter: 3108/5000. LR: 0.0211. Data: 0.22s. Batch: 0.34s. S_Loss: 0.9520. T_Loss: 4.9131. Mask: 0.9062. :   8%|▊         | 8/100 [00:02<00:15,  6.00it/s]Train Iter: 3109/5000. LR: 0.0211. Data: 0.20s. Batch: 0.33s. S_Loss: 0.9484. T_Loss: 4.9100. Mask: 0.9062. :   8%|▊         | 8/100 [00:03<00:15,  6.00it/s]Train Iter: 3109/5000. LR: 0.0211. Data: 0.20s. Batch: 0.33s. S_Loss: 0.9484. T_Loss: 4.9100. Mask: 0.9062. :   9%|▉         | 9/100 [00:03<00:18,  4.85it/s]Train Iter: 3110/5000. LR: 0.0211. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9578. T_Loss: 4.9570. Mask: 0.9062. :   9%|▉         | 9/100 [00:03<00:18,  4.85it/s]Train Iter: 3110/5000. LR: 0.0211. Data: 0.18s. Batch: 0.31s. S_Loss: 0.9578. T_Loss: 4.9570. Mask: 0.9062. :  10%|█         | 10/100 [00:03<00:16,  5.61it/s]Train Iter: 3111/5000. LR: 0.0211. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9575. T_Loss: 4.8775. Mask: 0.9062. :  10%|█         | 10/100 [00:03<00:16,  5.61it/s]Train Iter: 3111/5000. LR: 0.0211. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9575. T_Loss: 4.8775. Mask: 0.9062. :  11%|█         | 11/100 [00:03<00:13,  6.39it/s]Train Iter: 3112/5000. LR: 0.0211. Data: 0.15s. Batch: 0.28s. S_Loss: 0.9587. T_Loss: 4.8622. Mask: 0.9089. :  11%|█         | 11/100 [00:03<00:13,  6.39it/s]Train Iter: 3112/5000. LR: 0.0211. Data: 0.15s. Batch: 0.28s. S_Loss: 0.9587. T_Loss: 4.8622. Mask: 0.9089. :  12%|█▏        | 12/100 [00:03<00:12,  6.88it/s]Train Iter: 3113/5000. LR: 0.0210. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9631. T_Loss: 4.8177. Mask: 0.9111. :  12%|█▏        | 12/100 [00:03<00:12,  6.88it/s]Train Iter: 3113/5000. LR: 0.0210. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9631. T_Loss: 4.8177. Mask: 0.9111. :  13%|█▎        | 13/100 [00:03<00:12,  7.02it/s]Train Iter: 3114/5000. LR: 0.0210. Data: 0.13s. Batch: 0.26s. S_Loss: 0.9698. T_Loss: 4.8484. Mask: 0.9129. :  13%|█▎        | 13/100 [00:03<00:12,  7.02it/s]Train Iter: 3114/5000. LR: 0.0210. Data: 0.13s. Batch: 0.26s. S_Loss: 0.9698. T_Loss: 4.8484. Mask: 0.9129. :  14%|█▍        | 14/100 [00:03<00:11,  7.51it/s]Train Iter: 3115/5000. LR: 0.0210. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9738. T_Loss: 4.9051. Mask: 0.9125. :  14%|█▍        | 14/100 [00:03<00:11,  7.51it/s]Train Iter: 3115/5000. LR: 0.0210. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9738. T_Loss: 4.9051. Mask: 0.9125. :  15%|█▌        | 15/100 [00:03<00:15,  5.58it/s]Train Iter: 3116/5000. LR: 0.0210. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9667. T_Loss: 4.8298. Mask: 0.9160. :  15%|█▌        | 15/100 [00:04<00:15,  5.58it/s]Train Iter: 3116/5000. LR: 0.0210. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9667. T_Loss: 4.8298. Mask: 0.9160. :  16%|█▌        | 16/100 [00:04<00:13,  6.18it/s]Train Iter: 3117/5000. LR: 0.0210. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9650. T_Loss: 4.8420. Mask: 0.9173. :  16%|█▌        | 16/100 [00:04<00:13,  6.18it/s]Train Iter: 3117/5000. LR: 0.0210. Data: 0.11s. Batch: 0.24s. S_Loss: 0.9650. T_Loss: 4.8420. Mask: 0.9173. :  17%|█▋        | 17/100 [00:04<00:12,  6.70it/s]Train Iter: 3118/5000. LR: 0.0209. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9617. T_Loss: 4.7690. Mask: 0.9132. :  17%|█▋        | 17/100 [00:04<00:12,  6.70it/s]Train Iter: 3118/5000. LR: 0.0209. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9617. T_Loss: 4.7690. Mask: 0.9132. :  18%|█▊        | 18/100 [00:04<00:11,  7.21it/s]Train Iter: 3119/5000. LR: 0.0209. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9597. T_Loss: 4.7548. Mask: 0.9161. :  18%|█▊        | 18/100 [00:04<00:11,  7.21it/s]Train Iter: 3119/5000. LR: 0.0209. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9597. T_Loss: 4.7548. Mask: 0.9161. :  19%|█▉        | 19/100 [00:04<00:14,  5.61it/s]Train Iter: 3120/5000. LR: 0.0209. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9583. T_Loss: 4.7314. Mask: 0.9109. :  19%|█▉        | 19/100 [00:04<00:14,  5.61it/s]Train Iter: 3121/5000. LR: 0.0209. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9564. T_Loss: 4.7368. Mask: 0.9137. :  20%|██        | 20/100 [00:04<00:14,  5.61it/s]Train Iter: 3121/5000. LR: 0.0209. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9564. T_Loss: 4.7368. Mask: 0.9137. :  21%|██        | 21/100 [00:04<00:11,  6.94it/s]Train Iter: 3122/5000. LR: 0.0209. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9587. T_Loss: 4.7493. Mask: 0.9119. :  21%|██        | 21/100 [00:04<00:11,  6.94it/s]Train Iter: 3122/5000. LR: 0.0209. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9587. T_Loss: 4.7493. Mask: 0.9119. :  22%|██▏       | 22/100 [00:04<00:10,  7.22it/s]Train Iter: 3123/5000. LR: 0.0208. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9582. T_Loss: 4.7359. Mask: 0.9130. :  22%|██▏       | 22/100 [00:04<00:10,  7.22it/s]Train Iter: 3123/5000. LR: 0.0208. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9582. T_Loss: 4.7359. Mask: 0.9130. :  23%|██▎       | 23/100 [00:04<00:10,  7.47it/s]Train Iter: 3124/5000. LR: 0.0208. Data: 0.08s. Batch: 0.21s. S_Loss: 0.9605. T_Loss: 4.7740. Mask: 0.9141. :  23%|██▎       | 23/100 [00:05<00:10,  7.47it/s]Train Iter: 3124/5000. LR: 0.0208. Data: 0.08s. Batch: 0.21s. S_Loss: 0.9605. T_Loss: 4.7740. Mask: 0.9141. :  24%|██▍       | 24/100 [00:05<00:09,  7.67it/s]Train Iter: 3125/5000. LR: 0.0208. Data: 0.07s. Batch: 0.22s. S_Loss: 0.9558. T_Loss: 4.7596. Mask: 0.9175. :  24%|██▍       | 24/100 [00:05<00:09,  7.67it/s]Train Iter: 3125/5000. LR: 0.0208. Data: 0.07s. Batch: 0.22s. S_Loss: 0.9558. T_Loss: 4.7596. Mask: 0.9175. :  25%|██▌       | 25/100 [00:05<00:14,  5.18it/s]total : 5000  current step :  3101
total : 5000  current step :  3102
total : 5000  current step :  3103
total : 5000  current step :  3104
total : 5000  current step :  3105
total : 5000  current step :  3106
total : 5000  current step :  3107
total : 5000  current step :  3108
total : 5000  current step :  3109
total : 5000  current step :  3110
total : 5000  current step :  3111
total : 5000  current step :  3112
total : 5000  current step :  3113
total : 5000  current step :  3114
total : 5000  current step :  3115
total : 5000  current step :  3116
total : 5000  current step :  3117
total : 5000  current step :  3118
total : 5000  current step :  3119
total : 5000  current step :  3120
total : 5000  current step :  3121
total : 5000  current step :  3122
total : 5000  current step :  3123
total : 5000  current step :  3124
total : 5000  current step :  3125
Train Iter: 3126/5000. LR: 0.0208. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9568. T_Loss: 4.7431. Mask: 0.9147. :  25%|██▌       | 25/100 [00:07<00:14,  5.18it/s]Train Iter: 3126/5000. LR: 0.0208. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9568. T_Loss: 4.7431. Mask: 0.9147. :  26%|██▌       | 26/100 [00:07<00:54,  1.35it/s]Train Iter: 3127/5000. LR: 0.0208. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9547. T_Loss: 4.7279. Mask: 0.9167. :  26%|██▌       | 26/100 [00:07<00:54,  1.35it/s]Train Iter: 3127/5000. LR: 0.0208. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9547. T_Loss: 4.7279. Mask: 0.9167. :  27%|██▋       | 27/100 [00:07<00:41,  1.76it/s]Train Iter: 3128/5000. LR: 0.0208. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9544. T_Loss: 4.7474. Mask: 0.9196. :  27%|██▋       | 27/100 [00:07<00:41,  1.76it/s]Train Iter: 3128/5000. LR: 0.0208. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9544. T_Loss: 4.7474. Mask: 0.9196. :  28%|██▊       | 28/100 [00:07<00:31,  2.25it/s]Train Iter: 3129/5000. LR: 0.0207. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9576. T_Loss: 4.7589. Mask: 0.9181. :  28%|██▊       | 28/100 [00:08<00:31,  2.25it/s]Train Iter: 3129/5000. LR: 0.0207. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9576. T_Loss: 4.7589. Mask: 0.9181. :  29%|██▉       | 29/100 [00:08<00:29,  2.44it/s]total : 5000  current step :  3126
total : 5000  current step :  3127
total : 5000  current step :  3128
total : 5000  current step :  3129
Train Iter: 3130/5000. LR: 0.0207. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9603. T_Loss: 4.7746. Mask: 0.9177. :  29%|██▉       | 29/100 [00:10<00:29,  2.44it/s]Train Iter: 3130/5000. LR: 0.0207. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9603. T_Loss: 4.7746. Mask: 0.9177. :  30%|███       | 30/100 [00:10<00:59,  1.18it/s]Train Iter: 3131/5000. LR: 0.0207. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9569. T_Loss: 4.7646. Mask: 0.9204. :  30%|███       | 30/100 [00:10<00:59,  1.18it/s]Train Iter: 3131/5000. LR: 0.0207. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9569. T_Loss: 4.7646. Mask: 0.9204. :  31%|███       | 31/100 [00:10<00:43,  1.57it/s]Train Iter: 3132/5000. LR: 0.0207. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9569. T_Loss: 4.7701. Mask: 0.9199. :  31%|███       | 31/100 [00:10<00:43,  1.57it/s]Train Iter: 3132/5000. LR: 0.0207. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9569. T_Loss: 4.7701. Mask: 0.9199. :  32%|███▏      | 32/100 [00:10<00:32,  2.09it/s]Train Iter: 3133/5000. LR: 0.0207. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9546. T_Loss: 4.7497. Mask: 0.9205. :  32%|███▏      | 32/100 [00:10<00:32,  2.09it/s]Train Iter: 3133/5000. LR: 0.0207. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9546. T_Loss: 4.7497. Mask: 0.9205. :  33%|███▎      | 33/100 [00:10<00:24,  2.70it/s]Train Iter: 3134/5000. LR: 0.0206. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9593. T_Loss: 4.7483. Mask: 0.9182. :  33%|███▎      | 33/100 [00:10<00:24,  2.70it/s]Train Iter: 3134/5000. LR: 0.0206. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9593. T_Loss: 4.7483. Mask: 0.9182. :  34%|███▍      | 34/100 [00:10<00:19,  3.31it/s]Train Iter: 3135/5000. LR: 0.0206. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9588. T_Loss: 4.7326. Mask: 0.9170. :  34%|███▍      | 34/100 [00:10<00:19,  3.31it/s]Train Iter: 3135/5000. LR: 0.0206. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9588. T_Loss: 4.7326. Mask: 0.9170. :  35%|███▌      | 35/100 [00:10<00:20,  3.11it/s]Train Iter: 3136/5000. LR: 0.0206. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9652. T_Loss: 4.7387. Mask: 0.9149. :  35%|███▌      | 35/100 [00:11<00:20,  3.11it/s]Train Iter: 3136/5000. LR: 0.0206. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9652. T_Loss: 4.7387. Mask: 0.9149. :  36%|███▌      | 36/100 [00:11<00:16,  3.76it/s]Train Iter: 3137/5000. LR: 0.0206. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9621. T_Loss: 4.7235. Mask: 0.9164. :  36%|███▌      | 36/100 [00:11<00:16,  3.76it/s]Train Iter: 3137/5000. LR: 0.0206. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9621. T_Loss: 4.7235. Mask: 0.9164. :  37%|███▋      | 37/100 [00:11<00:13,  4.51it/s]Train Iter: 3138/5000. LR: 0.0206. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9617. T_Loss: 4.7493. Mask: 0.9178. :  37%|███▋      | 37/100 [00:11<00:13,  4.51it/s]Train Iter: 3138/5000. LR: 0.0206. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9617. T_Loss: 4.7493. Mask: 0.9178. :  38%|███▊      | 38/100 [00:11<00:11,  5.29it/s]Train Iter: 3139/5000. LR: 0.0206. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9613. T_Loss: 4.7577. Mask: 0.9191. :  38%|███▊      | 38/100 [00:11<00:11,  5.29it/s]Train Iter: 3139/5000. LR: 0.0206. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9613. T_Loss: 4.7577. Mask: 0.9191. :  39%|███▉      | 39/100 [00:11<00:12,  4.75it/s]Train Iter: 3140/5000. LR: 0.0205. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9626. T_Loss: 4.7394. Mask: 0.9172. :  39%|███▉      | 39/100 [00:11<00:12,  4.75it/s]Train Iter: 3140/5000. LR: 0.0205. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9626. T_Loss: 4.7394. Mask: 0.9172. :  40%|████      | 40/100 [00:11<00:10,  5.51it/s]Train Iter: 3141/5000. LR: 0.0205. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9628. T_Loss: 4.7261. Mask: 0.9146. :  40%|████      | 40/100 [00:11<00:10,  5.51it/s]Train Iter: 3141/5000. LR: 0.0205. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9628. T_Loss: 4.7261. Mask: 0.9146. :  41%|████      | 41/100 [00:11<00:09,  6.11it/s]Train Iter: 3142/5000. LR: 0.0205. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9613. T_Loss: 4.7129. Mask: 0.9144. :  41%|████      | 41/100 [00:11<00:09,  6.11it/s]Train Iter: 3142/5000. LR: 0.0205. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9613. T_Loss: 4.7129. Mask: 0.9144. :  42%|████▏     | 42/100 [00:11<00:08,  6.51it/s]Train Iter: 3143/5000. LR: 0.0205. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9632. T_Loss: 4.7193. Mask: 0.9142. :  42%|████▏     | 42/100 [00:12<00:08,  6.51it/s]Train Iter: 3143/5000. LR: 0.0205. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9632. T_Loss: 4.7193. Mask: 0.9142. :  43%|████▎     | 43/100 [00:12<00:08,  7.06it/s]Train Iter: 3144/5000. LR: 0.0205. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9617. T_Loss: 4.7293. Mask: 0.9148. :  43%|████▎     | 43/100 [00:12<00:08,  7.06it/s]Train Iter: 3144/5000. LR: 0.0205. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9617. T_Loss: 4.7293. Mask: 0.9148. :  44%|████▍     | 44/100 [00:12<00:07,  7.36it/s]Train Iter: 3145/5000. LR: 0.0204. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9618. T_Loss: 4.7266. Mask: 0.9125. :  44%|████▍     | 44/100 [00:12<00:07,  7.36it/s]Train Iter: 3145/5000. LR: 0.0204. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9618. T_Loss: 4.7266. Mask: 0.9125. :  45%|████▌     | 45/100 [00:12<00:10,  5.18it/s]Train Iter: 3146/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9633. T_Loss: 4.7352. Mask: 0.9137. :  45%|████▌     | 45/100 [00:12<00:10,  5.18it/s]Train Iter: 3146/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9633. T_Loss: 4.7352. Mask: 0.9137. :  46%|████▌     | 46/100 [00:12<00:10,  5.26it/s]Train Iter: 3147/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9637. T_Loss: 4.7344. Mask: 0.9136. :  46%|████▌     | 46/100 [00:12<00:10,  5.26it/s]Train Iter: 3147/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9637. T_Loss: 4.7344. Mask: 0.9136. :  47%|████▋     | 47/100 [00:12<00:08,  5.89it/s]Train Iter: 3148/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9643. T_Loss: 4.7474. Mask: 0.9141. :  47%|████▋     | 47/100 [00:12<00:08,  5.89it/s]Train Iter: 3148/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9643. T_Loss: 4.7474. Mask: 0.9141. :  48%|████▊     | 48/100 [00:12<00:08,  6.41it/s]Train Iter: 3149/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9650. T_Loss: 4.7609. Mask: 0.9145. :  48%|████▊     | 48/100 [00:13<00:08,  6.41it/s]Train Iter: 3149/5000. LR: 0.0204. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9650. T_Loss: 4.7609. Mask: 0.9145. :  49%|████▉     | 49/100 [00:13<00:09,  5.23it/s]Train Iter: 3150/5000. LR: 0.0204. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9664. T_Loss: 4.7676. Mask: 0.9131. :  49%|████▉     | 49/100 [00:13<00:09,  5.23it/s]Train Iter: 3150/5000. LR: 0.0204. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9664. T_Loss: 4.7676. Mask: 0.9131. :  50%|█████     | 50/100 [00:13<00:08,  5.90it/s]total : 5000  current step :  3130
total : 5000  current step :  3131
total : 5000  current step :  3132
total : 5000  current step :  3133
total : 5000  current step :  3134
total : 5000  current step :  3135
total : 5000  current step :  3136
total : 5000  current step :  3137
total : 5000  current step :  3138
total : 5000  current step :  3139
total : 5000  current step :  3140
total : 5000  current step :  3141
total : 5000  current step :  3142
total : 5000  current step :  3143
total : 5000  current step :  3144
total : 5000  current step :  3145
total : 5000  current step :  3146
total : 5000  current step :  3147
total : 5000  current step :  3148
total : 5000  current step :  3149
total : 5000  current step :  3150
Train Iter: 3151/5000. LR: 0.0203. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9672. T_Loss: 4.7551. Mask: 0.9105. :  50%|█████     | 50/100 [00:15<00:08,  5.90it/s]Train Iter: 3151/5000. LR: 0.0203. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9672. T_Loss: 4.7551. Mask: 0.9105. :  51%|█████     | 51/100 [00:15<00:35,  1.40it/s]Train Iter: 3152/5000. LR: 0.0203. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9693. T_Loss: 4.7592. Mask: 0.9099. :  51%|█████     | 51/100 [00:15<00:35,  1.40it/s]Train Iter: 3152/5000. LR: 0.0203. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9693. T_Loss: 4.7592. Mask: 0.9099. :  52%|█████▏    | 52/100 [00:15<00:25,  1.85it/s]Train Iter: 3153/5000. LR: 0.0203. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9675. T_Loss: 4.7721. Mask: 0.9092. :  52%|█████▏    | 52/100 [00:15<00:25,  1.85it/s]Train Iter: 3153/5000. LR: 0.0203. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9675. T_Loss: 4.7721. Mask: 0.9092. :  53%|█████▎    | 53/100 [00:15<00:20,  2.35it/s]Train Iter: 3154/5000. LR: 0.0203. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9689. T_Loss: 4.7641. Mask: 0.9086. :  53%|█████▎    | 53/100 [00:15<00:20,  2.35it/s]Train Iter: 3154/5000. LR: 0.0203. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9689. T_Loss: 4.7641. Mask: 0.9086. :  54%|█████▍    | 54/100 [00:15<00:15,  2.99it/s]Train Iter: 3155/5000. LR: 0.0203. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9677. T_Loss: 4.7606. Mask: 0.9080. :  54%|█████▍    | 54/100 [00:15<00:15,  2.99it/s]Train Iter: 3155/5000. LR: 0.0203. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9677. T_Loss: 4.7606. Mask: 0.9080. :  55%|█████▌    | 55/100 [00:15<00:14,  3.16it/s]Train Iter: 3156/5000. LR: 0.0202. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9688. T_Loss: 4.7544. Mask: 0.9079. :  55%|█████▌    | 55/100 [00:16<00:14,  3.16it/s]Train Iter: 3156/5000. LR: 0.0202. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9688. T_Loss: 4.7544. Mask: 0.9079. :  56%|█████▌    | 56/100 [00:16<00:11,  3.87it/s]Train Iter: 3157/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9708. T_Loss: 4.7531. Mask: 0.9052. :  56%|█████▌    | 56/100 [00:16<00:11,  3.87it/s]Train Iter: 3157/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9708. T_Loss: 4.7531. Mask: 0.9052. :  57%|█████▋    | 57/100 [00:16<00:09,  4.61it/s]Train Iter: 3158/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9717. T_Loss: 4.7656. Mask: 0.9052. :  57%|█████▋    | 57/100 [00:16<00:09,  4.61it/s]Train Iter: 3158/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9717. T_Loss: 4.7656. Mask: 0.9052. :  58%|█████▊    | 58/100 [00:16<00:07,  5.37it/s]Train Iter: 3159/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9701. T_Loss: 4.7553. Mask: 0.9047. :  58%|█████▊    | 58/100 [00:16<00:07,  5.37it/s]Train Iter: 3159/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9701. T_Loss: 4.7553. Mask: 0.9047. :  59%|█████▉    | 59/100 [00:16<00:09,  4.18it/s]Train Iter: 3160/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9698. T_Loss: 4.7569. Mask: 0.9052. :  59%|█████▉    | 59/100 [00:16<00:09,  4.18it/s]Train Iter: 3160/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9698. T_Loss: 4.7569. Mask: 0.9052. :  60%|██████    | 60/100 [00:16<00:08,  4.89it/s]Train Iter: 3161/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9719. T_Loss: 4.7543. Mask: 0.9047. :  60%|██████    | 60/100 [00:16<00:08,  4.89it/s]Train Iter: 3161/5000. LR: 0.0202. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9719. T_Loss: 4.7543. Mask: 0.9047. :  61%|██████    | 61/100 [00:16<00:06,  5.60it/s]Train Iter: 3162/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9710. T_Loss: 4.7588. Mask: 0.9042. :  61%|██████    | 61/100 [00:17<00:06,  5.60it/s]Train Iter: 3162/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9710. T_Loss: 4.7588. Mask: 0.9042. :  62%|██████▏   | 62/100 [00:17<00:06,  6.31it/s]Train Iter: 3163/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9704. T_Loss: 4.7718. Mask: 0.9043. :  62%|██████▏   | 62/100 [00:17<00:06,  6.31it/s]Train Iter: 3163/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9704. T_Loss: 4.7718. Mask: 0.9043. :  63%|██████▎   | 63/100 [00:17<00:05,  6.76it/s]Train Iter: 3164/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9687. T_Loss: 4.7673. Mask: 0.9053. :  63%|██████▎   | 63/100 [00:17<00:05,  6.76it/s]Train Iter: 3164/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9687. T_Loss: 4.7673. Mask: 0.9053. :  64%|██████▍   | 64/100 [00:17<00:05,  7.02it/s]Train Iter: 3165/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9677. T_Loss: 4.7609. Mask: 0.9062. :  64%|██████▍   | 64/100 [00:17<00:05,  7.02it/s]Train Iter: 3165/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9677. T_Loss: 4.7609. Mask: 0.9062. :  65%|██████▌   | 65/100 [00:17<00:04,  7.15it/s]Train Iter: 3166/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9684. T_Loss: 4.7653. Mask: 0.9058. :  65%|██████▌   | 65/100 [00:17<00:04,  7.15it/s]Train Iter: 3166/5000. LR: 0.0201. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9684. T_Loss: 4.7653. Mask: 0.9058. :  66%|██████▌   | 66/100 [00:17<00:04,  7.09it/s]Train Iter: 3167/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9672. T_Loss: 4.7627. Mask: 0.9072. :  66%|██████▌   | 66/100 [00:17<00:04,  7.09it/s]Train Iter: 3167/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9672. T_Loss: 4.7627. Mask: 0.9072. :  67%|██████▋   | 67/100 [00:17<00:04,  7.37it/s]Train Iter: 3168/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9666. T_Loss: 4.7548. Mask: 0.9081. :  67%|██████▋   | 67/100 [00:17<00:04,  7.37it/s]Train Iter: 3168/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9666. T_Loss: 4.7548. Mask: 0.9081. :  68%|██████▊   | 68/100 [00:17<00:04,  7.52it/s]Train Iter: 3169/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9656. T_Loss: 4.7448. Mask: 0.9081. :  68%|██████▊   | 68/100 [00:18<00:04,  7.52it/s]Train Iter: 3169/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9656. T_Loss: 4.7448. Mask: 0.9081. :  69%|██████▉   | 69/100 [00:18<00:06,  5.06it/s]Train Iter: 3170/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9660. T_Loss: 4.7505. Mask: 0.9089. :  69%|██████▉   | 69/100 [00:18<00:06,  5.06it/s]Train Iter: 3170/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9660. T_Loss: 4.7505. Mask: 0.9089. :  70%|███████   | 70/100 [00:18<00:05,  5.65it/s]Train Iter: 3171/5000. LR: 0.0200. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9653. T_Loss: 4.7478. Mask: 0.9098. :  70%|███████   | 70/100 [00:18<00:05,  5.65it/s]Train Iter: 3172/5000. LR: 0.0199. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9653. T_Loss: 4.7448. Mask: 0.9110. :  71%|███████   | 71/100 [00:18<00:05,  5.65it/s]Train Iter: 3172/5000. LR: 0.0199. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9653. T_Loss: 4.7448. Mask: 0.9110. :  72%|███████▏  | 72/100 [00:18<00:04,  6.80it/s]Train Iter: 3173/5000. LR: 0.0199. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9665. T_Loss: 4.7396. Mask: 0.9105. :  72%|███████▏  | 72/100 [00:18<00:04,  6.80it/s]Train Iter: 3173/5000. LR: 0.0199. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9665. T_Loss: 4.7396. Mask: 0.9105. :  73%|███████▎  | 73/100 [00:18<00:03,  7.17it/s]Train Iter: 3174/5000. LR: 0.0199. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9671. T_Loss: 4.7434. Mask: 0.9105. :  73%|███████▎  | 73/100 [00:18<00:03,  7.17it/s]Train Iter: 3174/5000. LR: 0.0199. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9671. T_Loss: 4.7434. Mask: 0.9105. :  74%|███████▍  | 74/100 [00:18<00:03,  7.32it/s]Train Iter: 3175/5000. LR: 0.0199. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9673. T_Loss: 4.7357. Mask: 0.9108. :  74%|███████▍  | 74/100 [00:19<00:03,  7.32it/s]Train Iter: 3175/5000. LR: 0.0199. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9673. T_Loss: 4.7357. Mask: 0.9108. :  75%|███████▌  | 75/100 [00:19<00:05,  4.74it/s]total : 5000  current step :  3151
total : 5000  current step :  3152
total : 5000  current step :  3153
total : 5000  current step :  3154
total : 5000  current step :  3155
total : 5000  current step :  3156
total : 5000  current step :  3157
total : 5000  current step :  3158
total : 5000  current step :  3159
total : 5000  current step :  3160
total : 5000  current step :  3161
total : 5000  current step :  3162
total : 5000  current step :  3163
total : 5000  current step :  3164
total : 5000  current step :  3165
total : 5000  current step :  3166
total : 5000  current step :  3167
total : 5000  current step :  3168
total : 5000  current step :  3169
total : 5000  current step :  3170
total : 5000  current step :  3171
total : 5000  current step :  3172
total : 5000  current step :  3173
total : 5000  current step :  3174
total : 5000  current step :  3175
Train Iter: 3176/5000. LR: 0.0199. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9675. T_Loss: 4.7295. Mask: 0.9108. :  75%|███████▌  | 75/100 [00:21<00:05,  4.74it/s]Train Iter: 3176/5000. LR: 0.0199. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9675. T_Loss: 4.7295. Mask: 0.9108. :  76%|███████▌  | 76/100 [00:21<00:18,  1.28it/s]Train Iter: 3177/5000. LR: 0.0199. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9680. T_Loss: 4.7288. Mask: 0.9103. :  76%|███████▌  | 76/100 [00:21<00:18,  1.28it/s]Train Iter: 3177/5000. LR: 0.0199. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9680. T_Loss: 4.7288. Mask: 0.9103. :  77%|███████▋  | 77/100 [00:21<00:13,  1.68it/s]Train Iter: 3178/5000. LR: 0.0198. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9684. T_Loss: 4.7273. Mask: 0.9099. :  77%|███████▋  | 77/100 [00:21<00:13,  1.68it/s]Train Iter: 3178/5000. LR: 0.0198. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9684. T_Loss: 4.7273. Mask: 0.9099. :  78%|███████▊  | 78/100 [00:21<00:10,  2.13it/s]Train Iter: 3179/5000. LR: 0.0198. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9687. T_Loss: 4.7221. Mask: 0.9098. :  78%|███████▊  | 78/100 [00:21<00:10,  2.13it/s]Train Iter: 3179/5000. LR: 0.0198. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9687. T_Loss: 4.7221. Mask: 0.9098. :  79%|███████▉  | 79/100 [00:21<00:07,  2.66it/s]Train Iter: 3180/5000. LR: 0.0198. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9670. T_Loss: 4.7188. Mask: 0.9109. :  79%|███████▉  | 79/100 [00:22<00:07,  2.66it/s]Train Iter: 3180/5000. LR: 0.0198. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9670. T_Loss: 4.7188. Mask: 0.9109. :  80%|████████  | 80/100 [00:22<00:06,  3.26it/s]Train Iter: 3181/5000. LR: 0.0198. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9670. T_Loss: 4.7129. Mask: 0.9105. :  80%|████████  | 80/100 [00:22<00:06,  3.26it/s]Train Iter: 3181/5000. LR: 0.0198. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9670. T_Loss: 4.7129. Mask: 0.9105. :  81%|████████  | 81/100 [00:22<00:04,  3.93it/s]Train Iter: 3182/5000. LR: 0.0198. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9656. T_Loss: 4.7114. Mask: 0.9101. :  81%|████████  | 81/100 [00:22<00:04,  3.93it/s]Train Iter: 3182/5000. LR: 0.0198. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9656. T_Loss: 4.7114. Mask: 0.9101. :  82%|████████▏ | 82/100 [00:22<00:03,  4.59it/s]Train Iter: 3183/5000. LR: 0.0197. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9654. T_Loss: 4.7058. Mask: 0.9096. :  82%|████████▏ | 82/100 [00:22<00:03,  4.59it/s]Train Iter: 3183/5000. LR: 0.0197. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9654. T_Loss: 4.7058. Mask: 0.9096. :  83%|████████▎ | 83/100 [00:22<00:03,  5.11it/s]Train Iter: 3184/5000. LR: 0.0197. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9667. T_Loss: 4.7198. Mask: 0.9089. :  83%|████████▎ | 83/100 [00:22<00:03,  5.11it/s]Train Iter: 3184/5000. LR: 0.0197. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9667. T_Loss: 4.7198. Mask: 0.9089. :  84%|████████▍ | 84/100 [00:22<00:02,  5.75it/s]Train Iter: 3185/5000. LR: 0.0197. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9670. T_Loss: 4.7180. Mask: 0.9092. :  84%|████████▍ | 84/100 [00:22<00:02,  5.75it/s]Train Iter: 3185/5000. LR: 0.0197. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9670. T_Loss: 4.7180. Mask: 0.9092. :  85%|████████▌ | 85/100 [00:22<00:03,  5.00it/s]Train Iter: 3186/5000. LR: 0.0197. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9672. T_Loss: 4.7229. Mask: 0.9099. :  85%|████████▌ | 85/100 [00:22<00:03,  5.00it/s]Train Iter: 3186/5000. LR: 0.0197. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9672. T_Loss: 4.7229. Mask: 0.9099. :  86%|████████▌ | 86/100 [00:22<00:02,  5.63it/s]Train Iter: 3187/5000. LR: 0.0197. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9664. T_Loss: 4.7210. Mask: 0.9102. :  86%|████████▌ | 86/100 [00:23<00:02,  5.63it/s]Train Iter: 3187/5000. LR: 0.0197. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9664. T_Loss: 4.7210. Mask: 0.9102. :  87%|████████▋ | 87/100 [00:23<00:02,  6.05it/s]Train Iter: 3188/5000. LR: 0.0197. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9670. T_Loss: 4.7217. Mask: 0.9102. :  87%|████████▋ | 87/100 [00:23<00:02,  6.05it/s]Train Iter: 3188/5000. LR: 0.0197. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9670. T_Loss: 4.7217. Mask: 0.9102. :  88%|████████▊ | 88/100 [00:23<00:01,  6.64it/s]Train Iter: 3189/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9657. T_Loss: 4.7173. Mask: 0.9105. :  88%|████████▊ | 88/100 [00:23<00:01,  6.64it/s]Train Iter: 3189/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9657. T_Loss: 4.7173. Mask: 0.9105. :  89%|████████▉ | 89/100 [00:23<00:02,  4.56it/s]Train Iter: 3190/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9653. T_Loss: 4.7152. Mask: 0.9101. :  89%|████████▉ | 89/100 [00:23<00:02,  4.56it/s]Train Iter: 3190/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9653. T_Loss: 4.7152. Mask: 0.9101. :  90%|█████████ | 90/100 [00:23<00:01,  5.36it/s]Train Iter: 3191/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9658. T_Loss: 4.7166. Mask: 0.9100. :  90%|█████████ | 90/100 [00:23<00:01,  5.36it/s]Train Iter: 3191/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9658. T_Loss: 4.7166. Mask: 0.9100. :  91%|█████████ | 91/100 [00:23<00:01,  5.90it/s]Train Iter: 3192/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9662. T_Loss: 4.7163. Mask: 0.9093. :  91%|█████████ | 91/100 [00:23<00:01,  5.90it/s]Train Iter: 3192/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9662. T_Loss: 4.7163. Mask: 0.9093. :  92%|█████████▏| 92/100 [00:23<00:01,  6.37it/s]Train Iter: 3193/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9656. T_Loss: 4.7184. Mask: 0.9096. :  92%|█████████▏| 92/100 [00:24<00:01,  6.37it/s]Train Iter: 3193/5000. LR: 0.0196. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9656. T_Loss: 4.7184. Mask: 0.9096. :  93%|█████████▎| 93/100 [00:24<00:00,  7.03it/s]Train Iter: 3194/5000. LR: 0.0195. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9655. T_Loss: 4.7197. Mask: 0.9096. :  93%|█████████▎| 93/100 [00:24<00:00,  7.03it/s]Train Iter: 3194/5000. LR: 0.0195. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9655. T_Loss: 4.7197. Mask: 0.9096. :  94%|█████████▍| 94/100 [00:24<00:00,  7.57it/s]Train Iter: 3195/5000. LR: 0.0195. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9646. T_Loss: 4.7096. Mask: 0.9095. :  94%|█████████▍| 94/100 [00:24<00:00,  7.57it/s]Train Iter: 3195/5000. LR: 0.0195. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9646. T_Loss: 4.7096. Mask: 0.9095. :  95%|█████████▌| 95/100 [00:24<00:00,  5.46it/s]Train Iter: 3196/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9635. T_Loss: 4.7005. Mask: 0.9082. :  95%|█████████▌| 95/100 [00:24<00:00,  5.46it/s]Train Iter: 3196/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9635. T_Loss: 4.7005. Mask: 0.9082. :  96%|█████████▌| 96/100 [00:24<00:00,  5.93it/s]Train Iter: 3197/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9632. T_Loss: 4.6990. Mask: 0.9082. :  96%|█████████▌| 96/100 [00:24<00:00,  5.93it/s]Train Iter: 3197/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9632. T_Loss: 4.6990. Mask: 0.9082. :  97%|█████████▋| 97/100 [00:24<00:00,  6.39it/s]Train Iter: 3198/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9631. T_Loss: 4.6964. Mask: 0.9082. :  97%|█████████▋| 97/100 [00:24<00:00,  6.39it/s]Train Iter: 3198/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9631. T_Loss: 4.6964. Mask: 0.9082. :  98%|█████████▊| 98/100 [00:24<00:00,  6.84it/s]Train Iter: 3199/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9627. T_Loss: 4.6984. Mask: 0.9091. :  98%|█████████▊| 98/100 [00:25<00:00,  6.84it/s]Train Iter: 3199/5000. LR: 0.0195. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9627. T_Loss: 4.6984. Mask: 0.9091. :  99%|█████████▉| 99/100 [00:25<00:00,  5.33it/s]Train Iter: 3200/5000. LR: 0.0194. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9636. T_Loss: 4.7003. Mask: 0.9091. :  99%|█████████▉| 99/100 [00:25<00:00,  5.33it/s]Train Iter: 3200/5000. LR: 0.0194. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9636. T_Loss: 4.7003. Mask: 0.9091. : 100%|██████████| 100/100 [00:25<00:00,  5.88it/s]Train Iter: 3200/5000. LR: 0.0194. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9636. T_Loss: 4.7003. Mask: 0.9091. : 100%|██████████| 100/100 [00:25<00:00,  3.96it/s]
total : 5000  current step :  3176
total : 5000  current step :  3177
total : 5000  current step :  3178
total : 5000  current step :  3179
total : 5000  current step :  3180
total : 5000  current step :  3181
total : 5000  current step :  3182
total : 5000  current step :  3183
total : 5000  current step :  3184
total : 5000  current step :  3185
total : 5000  current step :  3186
total : 5000  current step :  3187
total : 5000  current step :  3188
total : 5000  current step :  3189
total : 5000  current step :  3190
total : 5000  current step :  3191
total : 5000  current step :  3192
total : 5000  current step :  3193
total : 5000  current step :  3194
total : 5000  current step :  3195
total : 5000  current step :  3196
total : 5000  current step :  3197
total : 5000  current step :  3198
total : 5000  current step :  3199
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 0.9161. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 0.9161. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 0.9053. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.8718. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.8799. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.8650. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8661. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8768. top1: 88.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8796. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8796. top1: 87.50. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8746. top1: 87.85. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8799. top1: 88.12. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8697. top1: 89.20. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8681. top1: 89.32. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8628. top1: 89.42. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8602. top1: 89.51. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8573. top1: 89.58. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8574. top1: 89.45. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8557. top1: 89.34. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8554. top1: 89.41. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.70it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8554. top1: 89.41. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.66it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8561. top1: 89.31. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.66it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8551. top1: 89.53. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8582. top1: 89.58. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8555. top1: 89.91. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8522. top1: 90.22. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8502. top1: 90.36. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8478. top1: 90.62. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8523. top1: 90.14. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8524. top1: 90.28. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8546. top1: 90.29. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8521. top1: 90.52. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.66it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8521. top1: 90.52. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8518. top1: 90.42. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8520. top1: 90.32. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8701. top1: 89.45. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8788. top1: 89.20. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8911. top1: 88.33. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9044. top1: 87.32. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9292. top1: 86.20. top5: 99.74. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9359. top1: 85.73. top5: 99.75. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9450. top1: 85.03. top5: 99.75. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9600. top1: 84.38. top5: 99.60. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9703. top1: 83.67. top5: 99.61. :  46%|████▌     | 29/63 [00:02<00:01, 25.97it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9703. top1: 83.67. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9768. top1: 83.31. top5: 99.54. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9907. top1: 82.51. top5: 99.55. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9985. top1: 82.12. top5: 99.56. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0030. top1: 82.03. top5: 99.57. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0065. top1: 81.67. top5: 99.58. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0140. top1: 81.11. top5: 99.59. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0212. top1: 80.72. top5: 99.60. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0256. top1: 80.47. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0325. top1: 80.23. top5: 99.62. :  63%|██████▎   | 40/63 [00:02<00:00, 37.67it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0325. top1: 80.23. top5: 99.62. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0366. top1: 80.00. top5: 99.62. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0497. top1: 79.17. top5: 99.63. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0539. top1: 79.09. top5: 99.58. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0626. top1: 78.71. top5: 99.53. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0705. top1: 78.36. top5: 99.48. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0733. top1: 78.18. top5: 99.49. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0765. top1: 78.07. top5: 99.50. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0851. top1: 77.63. top5: 99.45. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0915. top1: 77.16. top5: 99.46. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0970. top1: 76.85. top5: 99.42. :  78%|███████▊  | 49/63 [00:02<00:00, 45.54it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0970. top1: 76.85. top5: 99.42. :  94%|█████████▎| 59/63 [00:02<00:00, 55.05it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0965. top1: 76.93. top5: 99.43. :  94%|█████████▎| 59/63 [00:02<00:00, 55.05it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1037. top1: 76.43. top5: 99.44. :  94%|█████████▎| 59/63 [00:02<00:00, 55.05it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1134. top1: 75.91. top5: 99.45. :  94%|█████████▎| 59/63 [00:02<00:00, 55.05it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1144. top1: 75.90. top5: 99.45. :  94%|█████████▎| 59/63 [00:02<00:00, 55.05it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1144. top1: 75.90. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.72it/s]
total : 5000  current step :  3200
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3201/5000. LR: 0.0194. Data: 1.89s. Batch: 1.99s. S_Loss: 1.0791. T_Loss: 4.7195. Mask: 0.8750. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 3201/5000. LR: 0.0194. Data: 1.89s. Batch: 1.99s. S_Loss: 1.0791. T_Loss: 4.7195. Mask: 0.8750. :   1%|          | 1/100 [00:01<03:17,  1.99s/it]Train Iter: 3202/5000. LR: 0.0194. Data: 0.95s. Batch: 1.06s. S_Loss: 1.0166. T_Loss: 4.7412. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:17,  1.99s/it]Train Iter: 3202/5000. LR: 0.0194. Data: 0.95s. Batch: 1.06s. S_Loss: 1.0166. T_Loss: 4.7412. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 3203/5000. LR: 0.0194. Data: 0.63s. Batch: 0.74s. S_Loss: 0.9773. T_Loss: 4.7733. Mask: 0.8958. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 3203/5000. LR: 0.0194. Data: 0.63s. Batch: 0.74s. S_Loss: 0.9773. T_Loss: 4.7733. Mask: 0.8958. :   3%|▎         | 3/100 [00:02<00:52,  1.86it/s]Train Iter: 3204/5000. LR: 0.0194. Data: 0.47s. Batch: 0.59s. S_Loss: 0.9713. T_Loss: 4.8028. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:52,  1.86it/s]Train Iter: 3204/5000. LR: 0.0194. Data: 0.47s. Batch: 0.59s. S_Loss: 0.9713. T_Loss: 4.8028. Mask: 0.9062. :   4%|▍         | 4/100 [00:02<00:35,  2.69it/s]Train Iter: 3205/5000. LR: 0.0193. Data: 0.38s. Batch: 0.53s. S_Loss: 0.9633. T_Loss: 4.8091. Mask: 0.9125. :   4%|▍         | 4/100 [00:02<00:35,  2.69it/s]Train Iter: 3205/5000. LR: 0.0193. Data: 0.38s. Batch: 0.53s. S_Loss: 0.9633. T_Loss: 4.8091. Mask: 0.9125. :   5%|▌         | 5/100 [00:02<00:33,  2.81it/s]Train Iter: 3206/5000. LR: 0.0193. Data: 0.32s. Batch: 0.47s. S_Loss: 0.9587. T_Loss: 4.7449. Mask: 0.9167. :   5%|▌         | 5/100 [00:02<00:33,  2.81it/s]Train Iter: 3206/5000. LR: 0.0193. Data: 0.32s. Batch: 0.47s. S_Loss: 0.9587. T_Loss: 4.7449. Mask: 0.9167. :   6%|▌         | 6/100 [00:02<00:26,  3.61it/s]Train Iter: 3207/5000. LR: 0.0193. Data: 0.27s. Batch: 0.42s. S_Loss: 0.9451. T_Loss: 4.6100. Mask: 0.9196. :   6%|▌         | 6/100 [00:02<00:26,  3.61it/s]Train Iter: 3207/5000. LR: 0.0193. Data: 0.27s. Batch: 0.42s. S_Loss: 0.9451. T_Loss: 4.6100. Mask: 0.9196. :   7%|▋         | 7/100 [00:02<00:20,  4.43it/s]Train Iter: 3208/5000. LR: 0.0193. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9535. T_Loss: 4.6897. Mask: 0.9297. :   7%|▋         | 7/100 [00:03<00:20,  4.43it/s]Train Iter: 3208/5000. LR: 0.0193. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9535. T_Loss: 4.6897. Mask: 0.9297. :   8%|▊         | 8/100 [00:03<00:17,  5.19it/s]Train Iter: 3209/5000. LR: 0.0193. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9439. T_Loss: 4.6749. Mask: 0.9375. :   8%|▊         | 8/100 [00:03<00:17,  5.19it/s]Train Iter: 3209/5000. LR: 0.0193. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9439. T_Loss: 4.6749. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:21,  4.33it/s]Train Iter: 3210/5000. LR: 0.0193. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9356. T_Loss: 4.5851. Mask: 0.9375. :   9%|▉         | 9/100 [00:03<00:21,  4.33it/s]Train Iter: 3210/5000. LR: 0.0193. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9356. T_Loss: 4.5851. Mask: 0.9375. :  10%|█         | 10/100 [00:03<00:17,  5.01it/s]Train Iter: 3211/5000. LR: 0.0192. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9283. T_Loss: 4.5518. Mask: 0.9403. :  10%|█         | 10/100 [00:03<00:17,  5.01it/s]Train Iter: 3211/5000. LR: 0.0192. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9283. T_Loss: 4.5518. Mask: 0.9403. :  11%|█         | 11/100 [00:03<00:15,  5.66it/s]Train Iter: 3212/5000. LR: 0.0192. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9233. T_Loss: 4.5144. Mask: 0.9375. :  11%|█         | 11/100 [00:03<00:15,  5.66it/s]Train Iter: 3212/5000. LR: 0.0192. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9233. T_Loss: 4.5144. Mask: 0.9375. :  12%|█▏        | 12/100 [00:03<00:13,  6.45it/s]Train Iter: 3213/5000. LR: 0.0192. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9266. T_Loss: 4.5018. Mask: 0.9351. :  12%|█▏        | 12/100 [00:03<00:13,  6.45it/s]Train Iter: 3213/5000. LR: 0.0192. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9266. T_Loss: 4.5018. Mask: 0.9351. :  13%|█▎        | 13/100 [00:03<00:12,  7.00it/s]Train Iter: 3214/5000. LR: 0.0192. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9299. T_Loss: 4.5802. Mask: 0.9397. :  13%|█▎        | 13/100 [00:03<00:12,  7.00it/s]Train Iter: 3214/5000. LR: 0.0192. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9299. T_Loss: 4.5802. Mask: 0.9397. :  14%|█▍        | 14/100 [00:03<00:11,  7.34it/s]Train Iter: 3215/5000. LR: 0.0192. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9362. T_Loss: 4.6118. Mask: 0.9417. :  14%|█▍        | 14/100 [00:04<00:11,  7.34it/s]Train Iter: 3215/5000. LR: 0.0192. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9362. T_Loss: 4.6118. Mask: 0.9417. :  15%|█▌        | 15/100 [00:04<00:15,  5.34it/s]Train Iter: 3216/5000. LR: 0.0191. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9381. T_Loss: 4.6458. Mask: 0.9414. :  15%|█▌        | 15/100 [00:04<00:15,  5.34it/s]Train Iter: 3216/5000. LR: 0.0191. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9381. T_Loss: 4.6458. Mask: 0.9414. :  16%|█▌        | 16/100 [00:04<00:14,  5.94it/s]Train Iter: 3217/5000. LR: 0.0191. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9344. T_Loss: 4.6343. Mask: 0.9412. :  16%|█▌        | 16/100 [00:04<00:14,  5.94it/s]Train Iter: 3217/5000. LR: 0.0191. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9344. T_Loss: 4.6343. Mask: 0.9412. :  17%|█▋        | 17/100 [00:04<00:12,  6.49it/s]Train Iter: 3218/5000. LR: 0.0191. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9372. T_Loss: 4.6126. Mask: 0.9375. :  17%|█▋        | 17/100 [00:04<00:12,  6.49it/s]Train Iter: 3218/5000. LR: 0.0191. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9372. T_Loss: 4.6126. Mask: 0.9375. :  18%|█▊        | 18/100 [00:04<00:11,  6.92it/s]Train Iter: 3219/5000. LR: 0.0191. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9316. T_Loss: 4.5950. Mask: 0.9375. :  18%|█▊        | 18/100 [00:04<00:11,  6.92it/s]Train Iter: 3219/5000. LR: 0.0191. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9316. T_Loss: 4.5950. Mask: 0.9375. :  19%|█▉        | 19/100 [00:04<00:14,  5.55it/s]Train Iter: 3220/5000. LR: 0.0191. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.5394. Mask: 0.9359. :  19%|█▉        | 19/100 [00:05<00:14,  5.55it/s]Train Iter: 3220/5000. LR: 0.0191. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.5394. Mask: 0.9359. :  20%|██        | 20/100 [00:05<00:13,  6.13it/s]Train Iter: 3221/5000. LR: 0.0191. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9277. T_Loss: 4.5613. Mask: 0.9375. :  20%|██        | 20/100 [00:05<00:13,  6.13it/s]Train Iter: 3222/5000. LR: 0.0190. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9294. T_Loss: 4.5798. Mask: 0.9389. :  21%|██        | 21/100 [00:05<00:12,  6.13it/s]Train Iter: 3222/5000. LR: 0.0190. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9294. T_Loss: 4.5798. Mask: 0.9389. :  22%|██▏       | 22/100 [00:05<00:10,  7.37it/s]Train Iter: 3223/5000. LR: 0.0190. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9276. T_Loss: 4.5571. Mask: 0.9402. :  22%|██▏       | 22/100 [00:05<00:10,  7.37it/s]Train Iter: 3223/5000. LR: 0.0190. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9276. T_Loss: 4.5571. Mask: 0.9402. :  23%|██▎       | 23/100 [00:05<00:10,  7.69it/s]Train Iter: 3224/5000. LR: 0.0190. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9294. T_Loss: 4.5527. Mask: 0.9401. :  23%|██▎       | 23/100 [00:05<00:10,  7.69it/s]Train Iter: 3224/5000. LR: 0.0190. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9294. T_Loss: 4.5527. Mask: 0.9401. :  24%|██▍       | 24/100 [00:05<00:09,  7.81it/s]Train Iter: 3225/5000. LR: 0.0190. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9315. T_Loss: 4.5537. Mask: 0.9400. :  24%|██▍       | 24/100 [00:05<00:09,  7.81it/s]Train Iter: 3225/5000. LR: 0.0190. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9315. T_Loss: 4.5537. Mask: 0.9400. :  25%|██▌       | 25/100 [00:05<00:15,  4.85it/s]total : 5000  current step :  3201
total : 5000  current step :  3202
total : 5000  current step :  3203
total : 5000  current step :  3204
total : 5000  current step :  3205
total : 5000  current step :  3206
total : 5000  current step :  3207
total : 5000  current step :  3208
total : 5000  current step :  3209
total : 5000  current step :  3210
total : 5000  current step :  3211
total : 5000  current step :  3212
total : 5000  current step :  3213
total : 5000  current step :  3214
total : 5000  current step :  3215
total : 5000  current step :  3216
total : 5000  current step :  3217
total : 5000  current step :  3218
total : 5000  current step :  3219
total : 5000  current step :  3220
total : 5000  current step :  3221
total : 5000  current step :  3222
total : 5000  current step :  3223
total : 5000  current step :  3224
total : 5000  current step :  3225
Train Iter: 3226/5000. LR: 0.0190. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9338. T_Loss: 4.5509. Mask: 0.9387. :  25%|██▌       | 25/100 [00:07<00:15,  4.85it/s]Train Iter: 3226/5000. LR: 0.0190. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9338. T_Loss: 4.5509. Mask: 0.9387. :  26%|██▌       | 26/100 [00:07<00:48,  1.52it/s]Train Iter: 3227/5000. LR: 0.0189. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9374. T_Loss: 4.5806. Mask: 0.9387. :  26%|██▌       | 26/100 [00:07<00:48,  1.52it/s]Train Iter: 3227/5000. LR: 0.0189. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9374. T_Loss: 4.5806. Mask: 0.9387. :  27%|██▋       | 27/100 [00:07<00:37,  1.97it/s]Train Iter: 3228/5000. LR: 0.0189. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9369. T_Loss: 4.5728. Mask: 0.9386. :  27%|██▋       | 27/100 [00:07<00:37,  1.97it/s]Train Iter: 3228/5000. LR: 0.0189. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9369. T_Loss: 4.5728. Mask: 0.9386. :  28%|██▊       | 28/100 [00:07<00:29,  2.47it/s]Train Iter: 3229/5000. LR: 0.0189. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9391. T_Loss: 4.5653. Mask: 0.9343. :  28%|██▊       | 28/100 [00:08<00:29,  2.47it/s]Train Iter: 3229/5000. LR: 0.0189. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9391. T_Loss: 4.5653. Mask: 0.9343. :  29%|██▉       | 29/100 [00:08<00:28,  2.51it/s]Train Iter: 3230/5000. LR: 0.0189. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9358. T_Loss: 4.5380. Mask: 0.9354. :  29%|██▉       | 29/100 [00:08<00:28,  2.51it/s]Train Iter: 3230/5000. LR: 0.0189. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9358. T_Loss: 4.5380. Mask: 0.9354. :  30%|███       | 30/100 [00:08<00:22,  3.15it/s]Train Iter: 3231/5000. LR: 0.0189. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9378. T_Loss: 4.5386. Mask: 0.9355. :  30%|███       | 30/100 [00:08<00:22,  3.15it/s]Train Iter: 3231/5000. LR: 0.0189. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9378. T_Loss: 4.5386. Mask: 0.9355. :  31%|███       | 31/100 [00:08<00:17,  3.86it/s]Train Iter: 3232/5000. LR: 0.0189. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9379. T_Loss: 4.5364. Mask: 0.9346. :  31%|███       | 31/100 [00:08<00:17,  3.86it/s]Train Iter: 3232/5000. LR: 0.0189. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9379. T_Loss: 4.5364. Mask: 0.9346. :  32%|███▏      | 32/100 [00:08<00:14,  4.55it/s]Train Iter: 3233/5000. LR: 0.0188. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9383. T_Loss: 4.5576. Mask: 0.9347. :  32%|███▏      | 32/100 [00:08<00:14,  4.55it/s]Train Iter: 3233/5000. LR: 0.0188. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9383. T_Loss: 4.5576. Mask: 0.9347. :  33%|███▎      | 33/100 [00:08<00:12,  5.29it/s]Train Iter: 3234/5000. LR: 0.0188. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9398. T_Loss: 4.5709. Mask: 0.9338. :  33%|███▎      | 33/100 [00:08<00:12,  5.29it/s]Train Iter: 3234/5000. LR: 0.0188. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9398. T_Loss: 4.5709. Mask: 0.9338. :  34%|███▍      | 34/100 [00:08<00:11,  5.92it/s]Train Iter: 3235/5000. LR: 0.0188. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9438. T_Loss: 4.5856. Mask: 0.9339. :  34%|███▍      | 34/100 [00:09<00:11,  5.92it/s]Train Iter: 3235/5000. LR: 0.0188. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9438. T_Loss: 4.5856. Mask: 0.9339. :  35%|███▌      | 35/100 [00:09<00:13,  4.71it/s]Train Iter: 3236/5000. LR: 0.0188. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9428. T_Loss: 4.6015. Mask: 0.9349. :  35%|███▌      | 35/100 [00:09<00:13,  4.71it/s]Train Iter: 3236/5000. LR: 0.0188. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9428. T_Loss: 4.6015. Mask: 0.9349. :  36%|███▌      | 36/100 [00:09<00:12,  5.30it/s]Train Iter: 3237/5000. LR: 0.0188. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9420. T_Loss: 4.5911. Mask: 0.9341. :  36%|███▌      | 36/100 [00:09<00:12,  5.30it/s]Train Iter: 3237/5000. LR: 0.0188. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9420. T_Loss: 4.5911. Mask: 0.9341. :  37%|███▋      | 37/100 [00:09<00:10,  5.94it/s]Train Iter: 3238/5000. LR: 0.0187. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9430. T_Loss: 4.5736. Mask: 0.9309. :  37%|███▋      | 37/100 [00:09<00:10,  5.94it/s]Train Iter: 3238/5000. LR: 0.0187. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9430. T_Loss: 4.5736. Mask: 0.9309. :  38%|███▊      | 38/100 [00:09<00:09,  6.44it/s]Train Iter: 3239/5000. LR: 0.0187. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9424. T_Loss: 4.5564. Mask: 0.9287. :  38%|███▊      | 38/100 [00:09<00:09,  6.44it/s]Train Iter: 3239/5000. LR: 0.0187. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9424. T_Loss: 4.5564. Mask: 0.9287. :  39%|███▉      | 39/100 [00:09<00:08,  6.85it/s]Train Iter: 3240/5000. LR: 0.0187. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9433. T_Loss: 4.5397. Mask: 0.9266. :  39%|███▉      | 39/100 [00:09<00:08,  6.85it/s]Train Iter: 3240/5000. LR: 0.0187. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9433. T_Loss: 4.5397. Mask: 0.9266. :  40%|████      | 40/100 [00:09<00:08,  7.15it/s]Train Iter: 3241/5000. LR: 0.0187. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9430. T_Loss: 4.5483. Mask: 0.9276. :  40%|████      | 40/100 [00:10<00:08,  7.15it/s]Train Iter: 3241/5000. LR: 0.0187. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9430. T_Loss: 4.5483. Mask: 0.9276. :  41%|████      | 41/100 [00:10<00:08,  7.31it/s]Train Iter: 3242/5000. LR: 0.0187. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9467. T_Loss: 4.5615. Mask: 0.9271. :  41%|████      | 41/100 [00:10<00:08,  7.31it/s]Train Iter: 3242/5000. LR: 0.0187. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9467. T_Loss: 4.5615. Mask: 0.9271. :  42%|████▏     | 42/100 [00:10<00:07,  7.73it/s]Train Iter: 3243/5000. LR: 0.0187. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9455. T_Loss: 4.5684. Mask: 0.9281. :  42%|████▏     | 42/100 [00:10<00:07,  7.73it/s]Train Iter: 3243/5000. LR: 0.0187. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9455. T_Loss: 4.5684. Mask: 0.9281. :  43%|████▎     | 43/100 [00:10<00:07,  7.72it/s]Train Iter: 3244/5000. LR: 0.0186. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9472. T_Loss: 4.5769. Mask: 0.9290. :  43%|████▎     | 43/100 [00:10<00:07,  7.72it/s]Train Iter: 3244/5000. LR: 0.0186. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9472. T_Loss: 4.5769. Mask: 0.9290. :  44%|████▍     | 44/100 [00:10<00:07,  7.85it/s]Train Iter: 3245/5000. LR: 0.0186. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9471. T_Loss: 4.5932. Mask: 0.9292. :  44%|████▍     | 44/100 [00:10<00:07,  7.85it/s]Train Iter: 3245/5000. LR: 0.0186. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9471. T_Loss: 4.5932. Mask: 0.9292. :  45%|████▌     | 45/100 [00:10<00:10,  5.32it/s]Train Iter: 3246/5000. LR: 0.0186. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9478. T_Loss: 4.5890. Mask: 0.9273. :  45%|████▌     | 45/100 [00:10<00:10,  5.32it/s]Train Iter: 3246/5000. LR: 0.0186. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9478. T_Loss: 4.5890. Mask: 0.9273. :  46%|████▌     | 46/100 [00:10<00:08,  6.10it/s]Train Iter: 3247/5000. LR: 0.0186. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9459. T_Loss: 4.5919. Mask: 0.9289. :  46%|████▌     | 46/100 [00:10<00:08,  6.10it/s]Train Iter: 3248/5000. LR: 0.0186. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9440. T_Loss: 4.5813. Mask: 0.9297. :  47%|████▋     | 47/100 [00:11<00:08,  6.10it/s]Train Iter: 3248/5000. LR: 0.0186. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9440. T_Loss: 4.5813. Mask: 0.9297. :  48%|████▊     | 48/100 [00:11<00:07,  7.36it/s]Train Iter: 3249/5000. LR: 0.0185. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9431. T_Loss: 4.5626. Mask: 0.9286. :  48%|████▊     | 48/100 [00:11<00:07,  7.36it/s]Train Iter: 3249/5000. LR: 0.0185. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9431. T_Loss: 4.5626. Mask: 0.9286. :  49%|████▉     | 49/100 [00:11<00:08,  5.77it/s]Train Iter: 3250/5000. LR: 0.0185. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9424. T_Loss: 4.5690. Mask: 0.9294. :  49%|████▉     | 49/100 [00:11<00:08,  5.77it/s]Train Iter: 3250/5000. LR: 0.0185. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9424. T_Loss: 4.5690. Mask: 0.9294. :  50%|█████     | 50/100 [00:11<00:07,  6.31it/s]total : 5000  current step :  3226
total : 5000  current step :  3227
total : 5000  current step :  3228
total : 5000  current step :  3229
total : 5000  current step :  3230
total : 5000  current step :  3231
total : 5000  current step :  3232
total : 5000  current step :  3233
total : 5000  current step :  3234
total : 5000  current step :  3235
total : 5000  current step :  3236
total : 5000  current step :  3237
total : 5000  current step :  3238
total : 5000  current step :  3239
total : 5000  current step :  3240
total : 5000  current step :  3241
total : 5000  current step :  3242
total : 5000  current step :  3243
total : 5000  current step :  3244
total : 5000  current step :  3245
total : 5000  current step :  3246
total : 5000  current step :  3247
total : 5000  current step :  3248
total : 5000  current step :  3249
total : 5000  current step :  3250
Train Iter: 3251/5000. LR: 0.0185. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9396. T_Loss: 4.5537. Mask: 0.9301. :  50%|█████     | 50/100 [00:13<00:07,  6.31it/s]Train Iter: 3251/5000. LR: 0.0185. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9396. T_Loss: 4.5537. Mask: 0.9301. :  51%|█████     | 51/100 [00:13<00:31,  1.55it/s]Train Iter: 3252/5000. LR: 0.0185. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9406. T_Loss: 4.5422. Mask: 0.9285. :  51%|█████     | 51/100 [00:13<00:31,  1.55it/s]Train Iter: 3253/5000. LR: 0.0185. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9434. T_Loss: 4.5500. Mask: 0.9281. :  52%|█████▏    | 52/100 [00:13<00:30,  1.55it/s]Train Iter: 3253/5000. LR: 0.0185. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9434. T_Loss: 4.5500. Mask: 0.9281. :  53%|█████▎    | 53/100 [00:13<00:19,  2.45it/s]Train Iter: 3254/5000. LR: 0.0185. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9451. T_Loss: 4.5593. Mask: 0.9282. :  53%|█████▎    | 53/100 [00:13<00:19,  2.45it/s]Train Iter: 3254/5000. LR: 0.0185. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9451. T_Loss: 4.5593. Mask: 0.9282. :  54%|█████▍    | 54/100 [00:13<00:15,  2.95it/s]Train Iter: 3255/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9457. T_Loss: 4.5513. Mask: 0.9278. :  54%|█████▍    | 54/100 [00:14<00:15,  2.95it/s]Train Iter: 3255/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9457. T_Loss: 4.5513. Mask: 0.9278. :  55%|█████▌    | 55/100 [00:14<00:15,  2.98it/s]Train Iter: 3256/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9458. T_Loss: 4.5450. Mask: 0.9275. :  55%|█████▌    | 55/100 [00:14<00:15,  2.98it/s]Train Iter: 3256/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9458. T_Loss: 4.5450. Mask: 0.9275. :  56%|█████▌    | 56/100 [00:14<00:12,  3.59it/s]Train Iter: 3257/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9464. T_Loss: 4.5562. Mask: 0.9276. :  56%|█████▌    | 56/100 [00:14<00:12,  3.59it/s]Train Iter: 3258/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9485. T_Loss: 4.5525. Mask: 0.9262. :  57%|█████▋    | 57/100 [00:14<00:11,  3.59it/s]Train Iter: 3258/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9485. T_Loss: 4.5525. Mask: 0.9262. :  58%|█████▊    | 58/100 [00:14<00:08,  4.90it/s]Train Iter: 3259/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9473. T_Loss: 4.5436. Mask: 0.9264. :  58%|█████▊    | 58/100 [00:14<00:08,  4.90it/s]Train Iter: 3259/5000. LR: 0.0184. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9473. T_Loss: 4.5436. Mask: 0.9264. :  59%|█████▉    | 59/100 [00:14<00:09,  4.43it/s]Train Iter: 3260/5000. LR: 0.0183. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9468. T_Loss: 4.5475. Mask: 0.9260. :  59%|█████▉    | 59/100 [00:14<00:09,  4.43it/s]Train Iter: 3260/5000. LR: 0.0183. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9468. T_Loss: 4.5475. Mask: 0.9260. :  60%|██████    | 60/100 [00:14<00:07,  5.07it/s]Train Iter: 3261/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9460. T_Loss: 4.5519. Mask: 0.9257. :  60%|██████    | 60/100 [00:14<00:07,  5.07it/s]Train Iter: 3261/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9460. T_Loss: 4.5519. Mask: 0.9257. :  61%|██████    | 61/100 [00:14<00:06,  5.57it/s]Train Iter: 3262/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.5398. Mask: 0.9259. :  61%|██████    | 61/100 [00:15<00:06,  5.57it/s]Train Iter: 3262/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.5398. Mask: 0.9259. :  62%|██████▏   | 62/100 [00:15<00:06,  6.11it/s]Train Iter: 3263/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9458. T_Loss: 4.5401. Mask: 0.9256. :  62%|██████▏   | 62/100 [00:15<00:06,  6.11it/s]Train Iter: 3263/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9458. T_Loss: 4.5401. Mask: 0.9256. :  63%|██████▎   | 63/100 [00:15<00:05,  6.58it/s]Train Iter: 3264/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5417. Mask: 0.9253. :  63%|██████▎   | 63/100 [00:15<00:05,  6.58it/s]Train Iter: 3264/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5417. Mask: 0.9253. :  64%|██████▍   | 64/100 [00:15<00:05,  6.98it/s]Train Iter: 3265/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5293. Mask: 0.9245. :  64%|██████▍   | 64/100 [00:15<00:05,  6.98it/s]Train Iter: 3265/5000. LR: 0.0183. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5293. Mask: 0.9245. :  65%|██████▌   | 65/100 [00:15<00:04,  7.17it/s]Train Iter: 3266/5000. LR: 0.0182. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9442. T_Loss: 4.5162. Mask: 0.9252. :  65%|██████▌   | 65/100 [00:15<00:04,  7.17it/s]Train Iter: 3266/5000. LR: 0.0182. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9442. T_Loss: 4.5162. Mask: 0.9252. :  66%|██████▌   | 66/100 [00:15<00:04,  7.20it/s]Train Iter: 3267/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9438. T_Loss: 4.5139. Mask: 0.9258. :  66%|██████▌   | 66/100 [00:15<00:04,  7.20it/s]Train Iter: 3267/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9438. T_Loss: 4.5139. Mask: 0.9258. :  67%|██████▋   | 67/100 [00:15<00:04,  7.61it/s]Train Iter: 3268/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9436. T_Loss: 4.5008. Mask: 0.9251. :  67%|██████▋   | 67/100 [00:15<00:04,  7.61it/s]Train Iter: 3268/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9436. T_Loss: 4.5008. Mask: 0.9251. :  68%|██████▊   | 68/100 [00:15<00:04,  7.85it/s]Train Iter: 3269/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9464. T_Loss: 4.5139. Mask: 0.9248. :  68%|██████▊   | 68/100 [00:16<00:04,  7.85it/s]Train Iter: 3269/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9464. T_Loss: 4.5139. Mask: 0.9248. :  69%|██████▉   | 69/100 [00:16<00:06,  5.05it/s]Train Iter: 3270/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9468. T_Loss: 4.5207. Mask: 0.9254. :  69%|██████▉   | 69/100 [00:16<00:06,  5.05it/s]Train Iter: 3270/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9468. T_Loss: 4.5207. Mask: 0.9254. :  70%|███████   | 70/100 [00:16<00:05,  5.71it/s]Train Iter: 3271/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9473. T_Loss: 4.5260. Mask: 0.9252. :  70%|███████   | 70/100 [00:16<00:05,  5.71it/s]Train Iter: 3271/5000. LR: 0.0182. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9473. T_Loss: 4.5260. Mask: 0.9252. :  71%|███████   | 71/100 [00:16<00:04,  6.28it/s]Train Iter: 3272/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9461. T_Loss: 4.5284. Mask: 0.9258. :  71%|███████   | 71/100 [00:16<00:04,  6.28it/s]Train Iter: 3272/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9461. T_Loss: 4.5284. Mask: 0.9258. :  72%|███████▏  | 72/100 [00:16<00:04,  6.72it/s]Train Iter: 3273/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9452. T_Loss: 4.5234. Mask: 0.9259. :  72%|███████▏  | 72/100 [00:16<00:04,  6.72it/s]Train Iter: 3273/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9452. T_Loss: 4.5234. Mask: 0.9259. :  73%|███████▎  | 73/100 [00:16<00:03,  7.07it/s]Train Iter: 3274/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9476. T_Loss: 4.5119. Mask: 0.9257. :  73%|███████▎  | 73/100 [00:16<00:03,  7.07it/s]Train Iter: 3274/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9476. T_Loss: 4.5119. Mask: 0.9257. :  74%|███████▍  | 74/100 [00:16<00:03,  7.31it/s]Train Iter: 3275/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9475. T_Loss: 4.5104. Mask: 0.9258. :  74%|███████▍  | 74/100 [00:17<00:03,  7.31it/s]Train Iter: 3275/5000. LR: 0.0181. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9475. T_Loss: 4.5104. Mask: 0.9258. :  75%|███████▌  | 75/100 [00:17<00:04,  5.24it/s]total : 5000  current step :  3251
total : 5000  current step :  3252
total : 5000  current step :  3253
total : 5000  current step :  3254
total : 5000  current step :  3255
total : 5000  current step :  3256
total : 5000  current step :  3257
total : 5000  current step :  3258
total : 5000  current step :  3259
total : 5000  current step :  3260
total : 5000  current step :  3261
total : 5000  current step :  3262
total : 5000  current step :  3263
total : 5000  current step :  3264
total : 5000  current step :  3265
total : 5000  current step :  3266
total : 5000  current step :  3267
total : 5000  current step :  3268
total : 5000  current step :  3269
total : 5000  current step :  3270
total : 5000  current step :  3271
total : 5000  current step :  3272
total : 5000  current step :  3273
total : 5000  current step :  3274
total : 5000  current step :  3275
Train Iter: 3276/5000. LR: 0.0181. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9473. T_Loss: 4.5188. Mask: 0.9264. :  75%|███████▌  | 75/100 [00:18<00:04,  5.24it/s]Train Iter: 3276/5000. LR: 0.0181. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9473. T_Loss: 4.5188. Mask: 0.9264. :  76%|███████▌  | 76/100 [00:18<00:16,  1.42it/s]Train Iter: 3277/5000. LR: 0.0180. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5227. Mask: 0.9269. :  76%|███████▌  | 76/100 [00:19<00:16,  1.42it/s]Train Iter: 3277/5000. LR: 0.0180. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5227. Mask: 0.9269. :  77%|███████▋  | 77/100 [00:19<00:12,  1.85it/s]Train Iter: 3278/5000. LR: 0.0180. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9466. T_Loss: 4.5197. Mask: 0.9267. :  77%|███████▋  | 77/100 [00:19<00:12,  1.85it/s]Train Iter: 3278/5000. LR: 0.0180. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9466. T_Loss: 4.5197. Mask: 0.9267. :  78%|███████▊  | 78/100 [00:19<00:09,  2.41it/s]Train Iter: 3279/5000. LR: 0.0180. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.5237. Mask: 0.9264. :  78%|███████▊  | 78/100 [00:19<00:09,  2.41it/s]Train Iter: 3279/5000. LR: 0.0180. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.5237. Mask: 0.9264. :  79%|███████▉  | 79/100 [00:19<00:07,  2.65it/s]Train Iter: 3280/5000. LR: 0.0180. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9491. T_Loss: 4.5325. Mask: 0.9266. :  79%|███████▉  | 79/100 [00:19<00:07,  2.65it/s]Train Iter: 3280/5000. LR: 0.0180. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9491. T_Loss: 4.5325. Mask: 0.9266. :  80%|████████  | 80/100 [00:19<00:05,  3.36it/s]Train Iter: 3281/5000. LR: 0.0180. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9504. T_Loss: 4.5388. Mask: 0.9259. :  80%|████████  | 80/100 [00:19<00:05,  3.36it/s]Train Iter: 3281/5000. LR: 0.0180. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9504. T_Loss: 4.5388. Mask: 0.9259. :  81%|████████  | 81/100 [00:19<00:04,  4.12it/s]Train Iter: 3282/5000. LR: 0.0180. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.5435. Mask: 0.9257. :  81%|████████  | 81/100 [00:19<00:04,  4.12it/s]Train Iter: 3282/5000. LR: 0.0180. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.5435. Mask: 0.9257. :  82%|████████▏ | 82/100 [00:19<00:03,  4.84it/s]Train Iter: 3283/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9512. T_Loss: 4.5507. Mask: 0.9255. :  82%|████████▏ | 82/100 [00:20<00:03,  4.84it/s]Train Iter: 3283/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9512. T_Loss: 4.5507. Mask: 0.9255. :  83%|████████▎ | 83/100 [00:20<00:03,  5.51it/s]Train Iter: 3284/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9510. T_Loss: 4.5540. Mask: 0.9256. :  83%|████████▎ | 83/100 [00:20<00:03,  5.51it/s]Train Iter: 3284/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9510. T_Loss: 4.5540. Mask: 0.9256. :  84%|████████▍ | 84/100 [00:20<00:02,  6.16it/s]Train Iter: 3285/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.5558. Mask: 0.9261. :  84%|████████▍ | 84/100 [00:20<00:02,  6.16it/s]Train Iter: 3285/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.5558. Mask: 0.9261. :  85%|████████▌ | 85/100 [00:20<00:03,  4.88it/s]Train Iter: 3286/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.5505. Mask: 0.9259. :  85%|████████▌ | 85/100 [00:20<00:03,  4.88it/s]Train Iter: 3286/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.5505. Mask: 0.9259. :  86%|████████▌ | 86/100 [00:20<00:02,  5.57it/s]Train Iter: 3287/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9518. T_Loss: 4.5638. Mask: 0.9264. :  86%|████████▌ | 86/100 [00:20<00:02,  5.57it/s]Train Iter: 3287/5000. LR: 0.0179. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9518. T_Loss: 4.5638. Mask: 0.9264. :  87%|████████▋ | 87/100 [00:20<00:02,  6.14it/s]Train Iter: 3288/5000. LR: 0.0178. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9516. T_Loss: 4.5596. Mask: 0.9265. :  87%|████████▋ | 87/100 [00:20<00:02,  6.14it/s]Train Iter: 3288/5000. LR: 0.0178. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9516. T_Loss: 4.5596. Mask: 0.9265. :  88%|████████▊ | 88/100 [00:20<00:01,  6.56it/s]Train Iter: 3289/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9514. T_Loss: 4.5529. Mask: 0.9256. :  88%|████████▊ | 88/100 [00:22<00:01,  6.56it/s]Train Iter: 3289/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9514. T_Loss: 4.5529. Mask: 0.9256. :  89%|████████▉ | 89/100 [00:22<00:06,  1.61it/s]Train Iter: 3290/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9519. T_Loss: 4.5456. Mask: 0.9247. :  89%|████████▉ | 89/100 [00:22<00:06,  1.61it/s]Train Iter: 3290/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9519. T_Loss: 4.5456. Mask: 0.9247. :  90%|█████████ | 90/100 [00:22<00:04,  2.12it/s]Train Iter: 3291/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.5449. Mask: 0.9245. :  90%|█████████ | 90/100 [00:22<00:04,  2.12it/s]Train Iter: 3291/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.5449. Mask: 0.9245. :  91%|█████████ | 91/100 [00:22<00:03,  2.73it/s]Train Iter: 3292/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.5365. Mask: 0.9229. :  91%|█████████ | 91/100 [00:22<00:03,  2.73it/s]Train Iter: 3292/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.5365. Mask: 0.9229. :  92%|█████████▏| 92/100 [00:22<00:02,  3.43it/s]Train Iter: 3293/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9507. T_Loss: 4.5297. Mask: 0.9227. :  92%|█████████▏| 92/100 [00:23<00:02,  3.43it/s]Train Iter: 3293/5000. LR: 0.0178. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9507. T_Loss: 4.5297. Mask: 0.9227. :  93%|█████████▎| 93/100 [00:23<00:01,  4.08it/s]Train Iter: 3294/5000. LR: 0.0177. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9513. T_Loss: 4.5321. Mask: 0.9225. :  93%|█████████▎| 93/100 [00:23<00:01,  4.08it/s]Train Iter: 3294/5000. LR: 0.0177. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9513. T_Loss: 4.5321. Mask: 0.9225. :  94%|█████████▍| 94/100 [00:23<00:01,  4.91it/s]Train Iter: 3295/5000. LR: 0.0177. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9514. T_Loss: 4.5214. Mask: 0.9217. :  94%|█████████▍| 94/100 [00:23<00:01,  4.91it/s]Train Iter: 3295/5000. LR: 0.0177. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9514. T_Loss: 4.5214. Mask: 0.9217. :  95%|█████████▌| 95/100 [00:23<00:01,  4.34it/s]Train Iter: 3296/5000. LR: 0.0177. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9517. T_Loss: 4.5175. Mask: 0.9215. :  95%|█████████▌| 95/100 [00:23<00:01,  4.34it/s]Train Iter: 3296/5000. LR: 0.0177. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9517. T_Loss: 4.5175. Mask: 0.9215. :  96%|█████████▌| 96/100 [00:23<00:00,  5.05it/s]Train Iter: 3297/5000. LR: 0.0177. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9517. T_Loss: 4.5141. Mask: 0.9217. :  96%|█████████▌| 96/100 [00:23<00:00,  5.05it/s]Train Iter: 3298/5000. LR: 0.0177. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9533. T_Loss: 4.5328. Mask: 0.9222. :  97%|█████████▋| 97/100 [00:23<00:00,  5.05it/s]Train Iter: 3298/5000. LR: 0.0177. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9533. T_Loss: 4.5328. Mask: 0.9222. :  98%|█████████▊| 98/100 [00:23<00:00,  6.31it/s]Train Iter: 3299/5000. LR: 0.0176. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9534. T_Loss: 4.5410. Mask: 0.9223. :  98%|█████████▊| 98/100 [00:23<00:00,  6.31it/s]Train Iter: 3299/5000. LR: 0.0176. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9534. T_Loss: 4.5410. Mask: 0.9223. :  99%|█████████▉| 99/100 [00:23<00:00,  6.91it/s]Train Iter: 3300/5000. LR: 0.0176. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9538. T_Loss: 4.5372. Mask: 0.9216. :  99%|█████████▉| 99/100 [00:24<00:00,  6.91it/s]Train Iter: 3300/5000. LR: 0.0176. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9538. T_Loss: 4.5372. Mask: 0.9216. : 100%|██████████| 100/100 [00:24<00:00,  7.12it/s]Train Iter: 3300/5000. LR: 0.0176. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9538. T_Loss: 4.5372. Mask: 0.9216. : 100%|██████████| 100/100 [00:24<00:00,  4.16it/s]
total : 5000  current step :  3276
total : 5000  current step :  3277
total : 5000  current step :  3278
total : 5000  current step :  3279
total : 5000  current step :  3280
total : 5000  current step :  3281
total : 5000  current step :  3282
total : 5000  current step :  3283
total : 5000  current step :  3284
total : 5000  current step :  3285
total : 5000  current step :  3286
total : 5000  current step :  3287
total : 5000  current step :  3288
total : 5000  current step :  3289
total : 5000  current step :  3290
total : 5000  current step :  3291
total : 5000  current step :  3292
total : 5000  current step :  3293
total : 5000  current step :  3294
total : 5000  current step :  3295
total : 5000  current step :  3296
total : 5000  current step :  3297
total : 5000  current step :  3298
total : 5000  current step :  3299
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 0.9230. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 0.9230. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 0.9127. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.8762. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.8827. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8686. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8694. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8816. top1: 88.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8847. top1: 87.89. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8794. top1: 88.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8854. top1: 88.44. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8854. top1: 88.44. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.90it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8751. top1: 89.49. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.90it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8736. top1: 89.58. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.90it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8677. top1: 89.66. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.90it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8646. top1: 89.73. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.90it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8621. top1: 89.79. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.90it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8623. top1: 89.84. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.90it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8623. top1: 89.84. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8605. top1: 89.71. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8604. top1: 89.76. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8611. top1: 89.80. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8599. top1: 90.00. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8634. top1: 90.03. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8605. top1: 90.34. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8570. top1: 90.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8549. top1: 90.76. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8523. top1: 90.88. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8568. top1: 90.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8569. top1: 90.51. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.74it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8569. top1: 90.51. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8597. top1: 90.51. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8572. top1: 90.73. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8569. top1: 90.62. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8571. top1: 90.52. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8752. top1: 89.75. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8837. top1: 89.39. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8947. top1: 88.60. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9073. top1: 87.68. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9313. top1: 86.63. top5: 99.74. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9375. top1: 86.23. top5: 99.75. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9466. top1: 85.69. top5: 99.75. :  43%|████▎     | 27/63 [00:02<00:01, 23.03it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9466. top1: 85.69. top5: 99.75. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9607. top1: 85.26. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9703. top1: 84.61. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9765. top1: 84.22. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9902. top1: 83.41. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9982. top1: 82.99. top5: 99.56. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0025. top1: 82.88. top5: 99.57. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0056. top1: 82.50. top5: 99.58. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0127. top1: 82.00. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0193. top1: 81.58. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0238. top1: 81.25. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 34.98it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0238. top1: 81.25. top5: 99.61. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0305. top1: 80.99. top5: 99.62. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0344. top1: 80.75. top5: 99.62. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0467. top1: 80.02. top5: 99.63. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0506. top1: 79.93. top5: 99.58. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0591. top1: 79.54. top5: 99.53. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0666. top1: 79.17. top5: 99.54. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0693. top1: 78.98. top5: 99.55. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0722. top1: 78.85. top5: 99.55. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0805. top1: 78.40. top5: 99.56. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0871. top1: 77.86. top5: 99.57. :  76%|███████▌  | 48/63 [00:02<00:00, 45.49it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0871. top1: 77.86. top5: 99.57. :  92%|█████████▏| 58/63 [00:02<00:00, 55.14it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0924. top1: 77.54. top5: 99.52. :  92%|█████████▏| 58/63 [00:02<00:00, 55.14it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0919. top1: 77.71. top5: 99.53. :  92%|█████████▏| 58/63 [00:02<00:00, 55.14it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0990. top1: 77.25. top5: 99.54. :  92%|█████████▏| 58/63 [00:02<00:00, 55.14it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1079. top1: 76.71. top5: 99.55. :  92%|█████████▏| 58/63 [00:02<00:00, 55.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1089. top1: 76.65. top5: 99.55. :  92%|█████████▏| 58/63 [00:02<00:00, 55.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1089. top1: 76.65. top5: 99.55. : 100%|██████████| 63/63 [00:02<00:00, 23.11it/s]
total : 5000  current step :  3300
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3301/5000. LR: 0.0176. Data: 1.78s. Batch: 1.92s. S_Loss: 0.9449. T_Loss: 4.8102. Mask: 0.9688. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 3301/5000. LR: 0.0176. Data: 1.78s. Batch: 1.92s. S_Loss: 0.9449. T_Loss: 4.8102. Mask: 0.9688. :   1%|          | 1/100 [00:01<03:10,  1.92s/it]Train Iter: 3302/5000. LR: 0.0176. Data: 0.89s. Batch: 1.02s. S_Loss: 0.9121. T_Loss: 4.2270. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:10,  1.92s/it]Train Iter: 3302/5000. LR: 0.0176. Data: 0.89s. Batch: 1.02s. S_Loss: 0.9121. T_Loss: 4.2270. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:23,  1.17it/s]Train Iter: 3303/5000. LR: 0.0176. Data: 0.59s. Batch: 0.72s. S_Loss: 0.9762. T_Loss: 4.6023. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:23,  1.17it/s]Train Iter: 3303/5000. LR: 0.0176. Data: 0.59s. Batch: 0.72s. S_Loss: 0.9762. T_Loss: 4.6023. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<00:50,  1.90it/s]Train Iter: 3304/5000. LR: 0.0176. Data: 0.45s. Batch: 0.57s. S_Loss: 1.0157. T_Loss: 4.9008. Mask: 0.9375. :   3%|▎         | 3/100 [00:02<00:50,  1.90it/s]Train Iter: 3304/5000. LR: 0.0176. Data: 0.45s. Batch: 0.57s. S_Loss: 1.0157. T_Loss: 4.9008. Mask: 0.9375. :   4%|▍         | 4/100 [00:02<00:35,  2.70it/s]Train Iter: 3305/5000. LR: 0.0175. Data: 0.36s. Batch: 0.51s. S_Loss: 0.9918. T_Loss: 4.7241. Mask: 0.9500. :   4%|▍         | 4/100 [00:02<00:35,  2.70it/s]Train Iter: 3305/5000. LR: 0.0175. Data: 0.36s. Batch: 0.51s. S_Loss: 0.9918. T_Loss: 4.7241. Mask: 0.9500. :   5%|▌         | 5/100 [00:02<00:32,  2.95it/s]Train Iter: 3306/5000. LR: 0.0175. Data: 0.30s. Batch: 0.45s. S_Loss: 0.9962. T_Loss: 4.6973. Mask: 0.9427. :   5%|▌         | 5/100 [00:02<00:32,  2.95it/s]Train Iter: 3306/5000. LR: 0.0175. Data: 0.30s. Batch: 0.45s. S_Loss: 0.9962. T_Loss: 4.6973. Mask: 0.9427. :   6%|▌         | 6/100 [00:02<00:24,  3.80it/s]Train Iter: 3307/5000. LR: 0.0175. Data: 0.26s. Batch: 0.40s. S_Loss: 1.0034. T_Loss: 4.6920. Mask: 0.9330. :   6%|▌         | 6/100 [00:02<00:24,  3.80it/s]Train Iter: 3307/5000. LR: 0.0175. Data: 0.26s. Batch: 0.40s. S_Loss: 1.0034. T_Loss: 4.6920. Mask: 0.9330. :   7%|▋         | 7/100 [00:02<00:20,  4.54it/s]Train Iter: 3308/5000. LR: 0.0175. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9888. T_Loss: 4.6361. Mask: 0.9375. :   7%|▋         | 7/100 [00:02<00:20,  4.54it/s]Train Iter: 3308/5000. LR: 0.0175. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9888. T_Loss: 4.6361. Mask: 0.9375. :   8%|▊         | 8/100 [00:02<00:17,  5.32it/s]Train Iter: 3309/5000. LR: 0.0175. Data: 0.20s. Batch: 0.36s. S_Loss: 0.9864. T_Loss: 4.5648. Mask: 0.9340. :   8%|▊         | 8/100 [00:03<00:17,  5.32it/s]Train Iter: 3309/5000. LR: 0.0175. Data: 0.20s. Batch: 0.36s. S_Loss: 0.9864. T_Loss: 4.5648. Mask: 0.9340. :   9%|▉         | 9/100 [00:03<00:20,  4.46it/s]Train Iter: 3310/5000. LR: 0.0175. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9985. T_Loss: 4.6424. Mask: 0.9313. :   9%|▉         | 9/100 [00:03<00:20,  4.46it/s]Train Iter: 3310/5000. LR: 0.0175. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9985. T_Loss: 4.6424. Mask: 0.9313. :  10%|█         | 10/100 [00:03<00:17,  5.22it/s]Train Iter: 3311/5000. LR: 0.0174. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0009. T_Loss: 4.6903. Mask: 0.9261. :  10%|█         | 10/100 [00:03<00:17,  5.22it/s]Train Iter: 3311/5000. LR: 0.0174. Data: 0.17s. Batch: 0.32s. S_Loss: 1.0009. T_Loss: 4.6903. Mask: 0.9261. :  11%|█         | 11/100 [00:03<00:14,  5.96it/s]Train Iter: 3312/5000. LR: 0.0174. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0024. T_Loss: 4.5836. Mask: 0.9141. :  11%|█         | 11/100 [00:03<00:14,  5.96it/s]Train Iter: 3312/5000. LR: 0.0174. Data: 0.15s. Batch: 0.30s. S_Loss: 1.0024. T_Loss: 4.5836. Mask: 0.9141. :  12%|█▏        | 12/100 [00:03<00:13,  6.54it/s]Train Iter: 3313/5000. LR: 0.0174. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9992. T_Loss: 4.5230. Mask: 0.9062. :  12%|█▏        | 12/100 [00:03<00:13,  6.54it/s]Train Iter: 3313/5000. LR: 0.0174. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9992. T_Loss: 4.5230. Mask: 0.9062. :  13%|█▎        | 13/100 [00:03<00:12,  7.04it/s]Train Iter: 3314/5000. LR: 0.0174. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9946. T_Loss: 4.4819. Mask: 0.9107. :  13%|█▎        | 13/100 [00:03<00:12,  7.04it/s]Train Iter: 3314/5000. LR: 0.0174. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9946. T_Loss: 4.4819. Mask: 0.9107. :  14%|█▍        | 14/100 [00:03<00:11,  7.35it/s]Train Iter: 3315/5000. LR: 0.0174. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9897. T_Loss: 4.4241. Mask: 0.9083. :  14%|█▍        | 14/100 [00:04<00:11,  7.35it/s]Train Iter: 3315/5000. LR: 0.0174. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9897. T_Loss: 4.4241. Mask: 0.9083. :  15%|█▌        | 15/100 [00:04<00:17,  4.75it/s]Train Iter: 3316/5000. LR: 0.0173. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9840. T_Loss: 4.3947. Mask: 0.9062. :  15%|█▌        | 15/100 [00:04<00:17,  4.75it/s]Train Iter: 3316/5000. LR: 0.0173. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9840. T_Loss: 4.3947. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:15,  5.44it/s]Train Iter: 3317/5000. LR: 0.0173. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9843. T_Loss: 4.3656. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:15,  5.44it/s]Train Iter: 3317/5000. LR: 0.0173. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9843. T_Loss: 4.3656. Mask: 0.9062. :  17%|█▋        | 17/100 [00:04<00:14,  5.87it/s]Train Iter: 3318/5000. LR: 0.0173. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9877. T_Loss: 4.3554. Mask: 0.9062. :  17%|█▋        | 17/100 [00:04<00:14,  5.87it/s]Train Iter: 3319/5000. LR: 0.0173. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9836. T_Loss: 4.3495. Mask: 0.9095. :  18%|█▊        | 18/100 [00:04<00:13,  5.87it/s]Train Iter: 3319/5000. LR: 0.0173. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9836. T_Loss: 4.3495. Mask: 0.9095. :  19%|█▉        | 19/100 [00:04<00:13,  6.13it/s]Train Iter: 3320/5000. LR: 0.0173. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9865. T_Loss: 4.3780. Mask: 0.9062. :  19%|█▉        | 19/100 [00:04<00:13,  6.13it/s]Train Iter: 3320/5000. LR: 0.0173. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9865. T_Loss: 4.3780. Mask: 0.9062. :  20%|██        | 20/100 [00:04<00:12,  6.56it/s]Train Iter: 3321/5000. LR: 0.0173. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9830. T_Loss: 4.3577. Mask: 0.9048. :  20%|██        | 20/100 [00:05<00:12,  6.56it/s]Train Iter: 3321/5000. LR: 0.0173. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9830. T_Loss: 4.3577. Mask: 0.9048. :  21%|██        | 21/100 [00:05<00:11,  6.92it/s]Train Iter: 3322/5000. LR: 0.0172. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9807. T_Loss: 4.3573. Mask: 0.9062. :  21%|██        | 21/100 [00:05<00:11,  6.92it/s]Train Iter: 3322/5000. LR: 0.0172. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9807. T_Loss: 4.3573. Mask: 0.9062. :  22%|██▏       | 22/100 [00:05<00:10,  7.22it/s]Train Iter: 3323/5000. LR: 0.0172. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9777. T_Loss: 4.3284. Mask: 0.9062. :  22%|██▏       | 22/100 [00:05<00:10,  7.22it/s]Train Iter: 3323/5000. LR: 0.0172. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9777. T_Loss: 4.3284. Mask: 0.9062. :  23%|██▎       | 23/100 [00:05<00:10,  7.47it/s]Train Iter: 3324/5000. LR: 0.0172. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9769. T_Loss: 4.3478. Mask: 0.9062. :  23%|██▎       | 23/100 [00:05<00:10,  7.47it/s]Train Iter: 3324/5000. LR: 0.0172. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9769. T_Loss: 4.3478. Mask: 0.9062. :  24%|██▍       | 24/100 [00:05<00:09,  7.78it/s]Train Iter: 3325/5000. LR: 0.0172. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9742. T_Loss: 4.3136. Mask: 0.9038. :  24%|██▍       | 24/100 [00:05<00:09,  7.78it/s]Train Iter: 3325/5000. LR: 0.0172. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9742. T_Loss: 4.3136. Mask: 0.9038. :  25%|██▌       | 25/100 [00:05<00:13,  5.37it/s]total : 5000  current step :  3301
total : 5000  current step :  3302
total : 5000  current step :  3303
total : 5000  current step :  3304
total : 5000  current step :  3305
total : 5000  current step :  3306
total : 5000  current step :  3307
total : 5000  current step :  3308
total : 5000  current step :  3309
total : 5000  current step :  3310
total : 5000  current step :  3311
total : 5000  current step :  3312
total : 5000  current step :  3313
total : 5000  current step :  3314
total : 5000  current step :  3315
total : 5000  current step :  3316
total : 5000  current step :  3317
total : 5000  current step :  3318
total : 5000  current step :  3319
total : 5000  current step :  3320
total : 5000  current step :  3321
total : 5000  current step :  3322
total : 5000  current step :  3323
total : 5000  current step :  3324
total : 5000  current step :  3325
Train Iter: 3326/5000. LR: 0.0172. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9736. T_Loss: 4.3160. Mask: 0.9038. :  25%|██▌       | 25/100 [00:07<00:13,  5.37it/s]Train Iter: 3326/5000. LR: 0.0172. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9736. T_Loss: 4.3160. Mask: 0.9038. :  26%|██▌       | 26/100 [00:07<00:55,  1.34it/s]Train Iter: 3327/5000. LR: 0.0172. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9723. T_Loss: 4.3240. Mask: 0.9028. :  26%|██▌       | 26/100 [00:07<00:55,  1.34it/s]Train Iter: 3327/5000. LR: 0.0172. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9723. T_Loss: 4.3240. Mask: 0.9028. :  27%|██▋       | 27/100 [00:07<00:41,  1.77it/s]Train Iter: 3328/5000. LR: 0.0171. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9713. T_Loss: 4.3166. Mask: 0.9040. :  27%|██▋       | 27/100 [00:08<00:41,  1.77it/s]Train Iter: 3328/5000. LR: 0.0171. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9713. T_Loss: 4.3166. Mask: 0.9040. :  28%|██▊       | 28/100 [00:08<00:31,  2.31it/s]Train Iter: 3329/5000. LR: 0.0171. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9672. T_Loss: 4.3040. Mask: 0.9052. :  28%|██▊       | 28/100 [00:08<00:31,  2.31it/s]Train Iter: 3329/5000. LR: 0.0171. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9672. T_Loss: 4.3040. Mask: 0.9052. :  29%|██▉       | 29/100 [00:08<00:24,  2.93it/s]Train Iter: 3330/5000. LR: 0.0171. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9670. T_Loss: 4.2875. Mask: 0.9031. :  29%|██▉       | 29/100 [00:08<00:24,  2.93it/s]Train Iter: 3330/5000. LR: 0.0171. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9670. T_Loss: 4.2875. Mask: 0.9031. :  30%|███       | 30/100 [00:08<00:19,  3.64it/s]Train Iter: 3331/5000. LR: 0.0171. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9672. T_Loss: 4.3219. Mask: 0.9042. :  30%|███       | 30/100 [00:08<00:19,  3.64it/s]Train Iter: 3331/5000. LR: 0.0171. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9672. T_Loss: 4.3219. Mask: 0.9042. :  31%|███       | 31/100 [00:08<00:15,  4.41it/s]Train Iter: 3332/5000. LR: 0.0171. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9684. T_Loss: 4.3471. Mask: 0.9053. :  31%|███       | 31/100 [00:08<00:15,  4.41it/s]Train Iter: 3333/5000. LR: 0.0170. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9735. T_Loss: 4.3613. Mask: 0.9053. :  32%|███▏      | 32/100 [00:08<00:15,  4.41it/s]Train Iter: 3333/5000. LR: 0.0170. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9735. T_Loss: 4.3613. Mask: 0.9053. :  33%|███▎      | 33/100 [00:08<00:11,  5.91it/s]Train Iter: 3334/5000. LR: 0.0170. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9747. T_Loss: 4.3814. Mask: 0.9081. :  33%|███▎      | 33/100 [00:08<00:11,  5.91it/s]Train Iter: 3334/5000. LR: 0.0170. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9747. T_Loss: 4.3814. Mask: 0.9081. :  34%|███▍      | 34/100 [00:08<00:10,  6.46it/s]Train Iter: 3335/5000. LR: 0.0170. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9743. T_Loss: 4.3775. Mask: 0.9071. :  34%|███▍      | 34/100 [00:09<00:10,  6.46it/s]Train Iter: 3335/5000. LR: 0.0170. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9743. T_Loss: 4.3775. Mask: 0.9071. :  35%|███▌      | 35/100 [00:09<00:12,  5.16it/s]Train Iter: 3336/5000. LR: 0.0170. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9726. T_Loss: 4.3916. Mask: 0.9080. :  35%|███▌      | 35/100 [00:09<00:12,  5.16it/s]Train Iter: 3336/5000. LR: 0.0170. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9726. T_Loss: 4.3916. Mask: 0.9080. :  36%|███▌      | 36/100 [00:09<00:11,  5.75it/s]Train Iter: 3337/5000. LR: 0.0170. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9730. T_Loss: 4.3911. Mask: 0.9079. :  36%|███▌      | 36/100 [00:09<00:11,  5.75it/s]Train Iter: 3337/5000. LR: 0.0170. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9730. T_Loss: 4.3911. Mask: 0.9079. :  37%|███▋      | 37/100 [00:09<00:09,  6.51it/s]Train Iter: 3338/5000. LR: 0.0170. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9720. T_Loss: 4.3981. Mask: 0.9104. :  37%|███▋      | 37/100 [00:09<00:09,  6.51it/s]Train Iter: 3338/5000. LR: 0.0170. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9720. T_Loss: 4.3981. Mask: 0.9104. :  38%|███▊      | 38/100 [00:09<00:08,  7.08it/s]Train Iter: 3339/5000. LR: 0.0169. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9707. T_Loss: 4.3869. Mask: 0.9103. :  38%|███▊      | 38/100 [00:09<00:08,  7.08it/s]Train Iter: 3339/5000. LR: 0.0169. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9707. T_Loss: 4.3869. Mask: 0.9103. :  39%|███▉      | 39/100 [00:09<00:12,  4.84it/s]Train Iter: 3340/5000. LR: 0.0169. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9686. T_Loss: 4.3703. Mask: 0.9102. :  39%|███▉      | 39/100 [00:09<00:12,  4.84it/s]Train Iter: 3340/5000. LR: 0.0169. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9686. T_Loss: 4.3703. Mask: 0.9102. :  40%|████      | 40/100 [00:09<00:10,  5.50it/s]Train Iter: 3341/5000. LR: 0.0169. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9665. T_Loss: 4.3875. Mask: 0.9116. :  40%|████      | 40/100 [00:10<00:10,  5.50it/s]Train Iter: 3341/5000. LR: 0.0169. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9665. T_Loss: 4.3875. Mask: 0.9116. :  41%|████      | 41/100 [00:10<00:09,  5.93it/s]Train Iter: 3342/5000. LR: 0.0169. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9650. T_Loss: 4.3965. Mask: 0.9129. :  41%|████      | 41/100 [00:10<00:09,  5.93it/s]Train Iter: 3342/5000. LR: 0.0169. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9650. T_Loss: 4.3965. Mask: 0.9129. :  42%|████▏     | 42/100 [00:10<00:08,  6.52it/s]Train Iter: 3343/5000. LR: 0.0169. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9638. T_Loss: 4.3794. Mask: 0.9128. :  42%|████▏     | 42/100 [00:10<00:08,  6.52it/s]Train Iter: 3344/5000. LR: 0.0168. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9636. T_Loss: 4.3860. Mask: 0.9119. :  43%|████▎     | 43/100 [00:10<00:08,  6.52it/s]Train Iter: 3344/5000. LR: 0.0168. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9636. T_Loss: 4.3860. Mask: 0.9119. :  44%|████▍     | 44/100 [00:10<00:07,  7.57it/s]Train Iter: 3345/5000. LR: 0.0168. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9630. T_Loss: 4.4025. Mask: 0.9139. :  44%|████▍     | 44/100 [00:10<00:07,  7.57it/s]Train Iter: 3345/5000. LR: 0.0168. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9630. T_Loss: 4.4025. Mask: 0.9139. :  45%|████▌     | 45/100 [00:10<00:10,  5.21it/s]Train Iter: 3346/5000. LR: 0.0168. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9635. T_Loss: 4.4230. Mask: 0.9144. :  45%|████▌     | 45/100 [00:10<00:10,  5.21it/s]Train Iter: 3346/5000. LR: 0.0168. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9635. T_Loss: 4.4230. Mask: 0.9144. :  46%|████▌     | 46/100 [00:10<00:09,  5.73it/s]Train Iter: 3347/5000. LR: 0.0168. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9624. T_Loss: 4.4115. Mask: 0.9149. :  46%|████▌     | 46/100 [00:10<00:09,  5.73it/s]Train Iter: 3347/5000. LR: 0.0168. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9624. T_Loss: 4.4115. Mask: 0.9149. :  47%|████▋     | 47/100 [00:10<00:08,  6.04it/s]Train Iter: 3348/5000. LR: 0.0168. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9629. T_Loss: 4.4077. Mask: 0.9147. :  47%|████▋     | 47/100 [00:11<00:08,  6.04it/s]Train Iter: 3348/5000. LR: 0.0168. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9629. T_Loss: 4.4077. Mask: 0.9147. :  48%|████▊     | 48/100 [00:11<00:08,  6.47it/s]Train Iter: 3349/5000. LR: 0.0168. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9628. T_Loss: 4.4155. Mask: 0.9145. :  48%|████▊     | 48/100 [00:11<00:08,  6.47it/s]Train Iter: 3349/5000. LR: 0.0168. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9628. T_Loss: 4.4155. Mask: 0.9145. :  49%|████▉     | 49/100 [00:11<00:10,  4.97it/s]Train Iter: 3350/5000. LR: 0.0167. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9644. T_Loss: 4.4280. Mask: 0.9137. :  49%|████▉     | 49/100 [00:11<00:10,  4.97it/s]Train Iter: 3350/5000. LR: 0.0167. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9644. T_Loss: 4.4280. Mask: 0.9137. :  50%|█████     | 50/100 [00:11<00:09,  5.52it/s]total : 5000  current step :  3326
total : 5000  current step :  3327
total : 5000  current step :  3328
total : 5000  current step :  3329
total : 5000  current step :  3330
total : 5000  current step :  3331
total : 5000  current step :  3332
total : 5000  current step :  3333
total : 5000  current step :  3334
total : 5000  current step :  3335
total : 5000  current step :  3336
total : 5000  current step :  3337
total : 5000  current step :  3338
total : 5000  current step :  3339
total : 5000  current step :  3340
total : 5000  current step :  3341
total : 5000  current step :  3342
total : 5000  current step :  3343
total : 5000  current step :  3344
total : 5000  current step :  3345
total : 5000  current step :  3346
total : 5000  current step :  3347
total : 5000  current step :  3348
total : 5000  current step :  3349
total : 5000  current step :  3350
Train Iter: 3351/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9627. T_Loss: 4.4213. Mask: 0.9142. :  50%|█████     | 50/100 [00:13<00:09,  5.52it/s]Train Iter: 3351/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9627. T_Loss: 4.4213. Mask: 0.9142. :  51%|█████     | 51/100 [00:13<00:34,  1.41it/s]Train Iter: 3352/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9614. T_Loss: 4.4260. Mask: 0.9153. :  51%|█████     | 51/100 [00:13<00:34,  1.41it/s]Train Iter: 3352/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9614. T_Loss: 4.4260. Mask: 0.9153. :  52%|█████▏    | 52/100 [00:13<00:25,  1.85it/s]Train Iter: 3353/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9620. T_Loss: 4.4343. Mask: 0.9151. :  52%|█████▏    | 52/100 [00:13<00:25,  1.85it/s]Train Iter: 3353/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9620. T_Loss: 4.4343. Mask: 0.9151. :  53%|█████▎    | 53/100 [00:13<00:20,  2.33it/s]Train Iter: 3354/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9616. T_Loss: 4.4398. Mask: 0.9167. :  53%|█████▎    | 53/100 [00:13<00:20,  2.33it/s]Train Iter: 3354/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9616. T_Loss: 4.4398. Mask: 0.9167. :  54%|█████▍    | 54/100 [00:13<00:15,  2.95it/s]Train Iter: 3355/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9609. T_Loss: 4.4511. Mask: 0.9170. :  54%|█████▍    | 54/100 [00:14<00:15,  2.95it/s]Train Iter: 3355/5000. LR: 0.0167. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9609. T_Loss: 4.4511. Mask: 0.9170. :  55%|█████▌    | 55/100 [00:14<00:14,  3.07it/s]Train Iter: 3356/5000. LR: 0.0166. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9601. T_Loss: 4.4476. Mask: 0.9174. :  55%|█████▌    | 55/100 [00:14<00:14,  3.07it/s]Train Iter: 3356/5000. LR: 0.0166. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9601. T_Loss: 4.4476. Mask: 0.9174. :  56%|█████▌    | 56/100 [00:14<00:11,  3.80it/s]Train Iter: 3357/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9629. T_Loss: 4.4666. Mask: 0.9167. :  56%|█████▌    | 56/100 [00:14<00:11,  3.80it/s]Train Iter: 3357/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9629. T_Loss: 4.4666. Mask: 0.9167. :  57%|█████▋    | 57/100 [00:14<00:09,  4.52it/s]Train Iter: 3358/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.4814. Mask: 0.9176. :  57%|█████▋    | 57/100 [00:14<00:09,  4.52it/s]Train Iter: 3358/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.4814. Mask: 0.9176. :  58%|█████▊    | 58/100 [00:14<00:08,  5.16it/s]Train Iter: 3359/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9608. T_Loss: 4.4794. Mask: 0.9163. :  58%|█████▊    | 58/100 [00:14<00:08,  5.16it/s]Train Iter: 3359/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9608. T_Loss: 4.4794. Mask: 0.9163. :  59%|█████▉    | 59/100 [00:14<00:07,  5.81it/s]Train Iter: 3360/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9595. T_Loss: 4.4859. Mask: 0.9172. :  59%|█████▉    | 59/100 [00:14<00:07,  5.81it/s]Train Iter: 3360/5000. LR: 0.0166. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9595. T_Loss: 4.4859. Mask: 0.9172. :  60%|██████    | 60/100 [00:14<00:06,  6.48it/s]Train Iter: 3361/5000. LR: 0.0165. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9589. T_Loss: 4.4986. Mask: 0.9180. :  60%|██████    | 60/100 [00:15<00:06,  6.48it/s]Train Iter: 3361/5000. LR: 0.0165. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9589. T_Loss: 4.4986. Mask: 0.9180. :  61%|██████    | 61/100 [00:15<00:05,  6.74it/s]Train Iter: 3362/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9587. T_Loss: 4.4908. Mask: 0.9183. :  61%|██████    | 61/100 [00:15<00:05,  6.74it/s]Train Iter: 3362/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9587. T_Loss: 4.4908. Mask: 0.9183. :  62%|██████▏   | 62/100 [00:15<00:05,  7.11it/s]Train Iter: 3363/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9589. T_Loss: 4.4918. Mask: 0.9187. :  62%|██████▏   | 62/100 [00:15<00:05,  7.11it/s]Train Iter: 3363/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9589. T_Loss: 4.4918. Mask: 0.9187. :  63%|██████▎   | 63/100 [00:15<00:04,  7.42it/s]Train Iter: 3364/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9591. T_Loss: 4.4933. Mask: 0.9194. :  63%|██████▎   | 63/100 [00:15<00:04,  7.42it/s]Train Iter: 3364/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9591. T_Loss: 4.4933. Mask: 0.9194. :  64%|██████▍   | 64/100 [00:15<00:04,  7.62it/s]Train Iter: 3365/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9577. T_Loss: 4.4935. Mask: 0.9197. :  64%|██████▍   | 64/100 [00:15<00:04,  7.62it/s]Train Iter: 3365/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9577. T_Loss: 4.4935. Mask: 0.9197. :  65%|██████▌   | 65/100 [00:15<00:05,  6.21it/s]Train Iter: 3366/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9573. T_Loss: 4.5065. Mask: 0.9205. :  65%|██████▌   | 65/100 [00:15<00:05,  6.21it/s]Train Iter: 3366/5000. LR: 0.0165. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9573. T_Loss: 4.5065. Mask: 0.9205. :  66%|██████▌   | 66/100 [00:15<00:05,  6.68it/s]Train Iter: 3367/5000. LR: 0.0164. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9575. T_Loss: 4.5118. Mask: 0.9207. :  66%|██████▌   | 66/100 [00:15<00:05,  6.68it/s]Train Iter: 3367/5000. LR: 0.0164. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9575. T_Loss: 4.5118. Mask: 0.9207. :  67%|██████▋   | 67/100 [00:15<00:04,  7.08it/s]Train Iter: 3368/5000. LR: 0.0164. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9574. T_Loss: 4.5120. Mask: 0.9205. :  67%|██████▋   | 67/100 [00:15<00:04,  7.08it/s]Train Iter: 3368/5000. LR: 0.0164. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9574. T_Loss: 4.5120. Mask: 0.9205. :  68%|██████▊   | 68/100 [00:15<00:04,  7.39it/s]Train Iter: 3369/5000. LR: 0.0164. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9589. T_Loss: 4.5293. Mask: 0.9198. :  68%|██████▊   | 68/100 [00:16<00:04,  7.39it/s]Train Iter: 3369/5000. LR: 0.0164. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9589. T_Loss: 4.5293. Mask: 0.9198. :  69%|██████▉   | 69/100 [00:16<00:05,  6.12it/s]Train Iter: 3370/5000. LR: 0.0164. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9602. T_Loss: 4.5384. Mask: 0.9201. :  69%|██████▉   | 69/100 [00:16<00:05,  6.12it/s]Train Iter: 3370/5000. LR: 0.0164. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9602. T_Loss: 4.5384. Mask: 0.9201. :  70%|███████   | 70/100 [00:16<00:04,  6.87it/s]Train Iter: 3371/5000. LR: 0.0164. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9596. T_Loss: 4.5320. Mask: 0.9195. :  70%|███████   | 70/100 [00:16<00:04,  6.87it/s]Train Iter: 3371/5000. LR: 0.0164. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9596. T_Loss: 4.5320. Mask: 0.9195. :  71%|███████   | 71/100 [00:16<00:03,  7.56it/s]Train Iter: 3372/5000. LR: 0.0164. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9609. T_Loss: 4.5453. Mask: 0.9193. :  71%|███████   | 71/100 [00:16<00:03,  7.56it/s]Train Iter: 3372/5000. LR: 0.0164. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9609. T_Loss: 4.5453. Mask: 0.9193. :  72%|███████▏  | 72/100 [00:16<00:03,  7.91it/s]Train Iter: 3373/5000. LR: 0.0163. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9623. T_Loss: 4.5519. Mask: 0.9199. :  72%|███████▏  | 72/100 [00:16<00:03,  7.91it/s]Train Iter: 3374/5000. LR: 0.0163. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9616. T_Loss: 4.5542. Mask: 0.9210. :  73%|███████▎  | 73/100 [00:16<00:03,  7.91it/s]Train Iter: 3374/5000. LR: 0.0163. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9616. T_Loss: 4.5542. Mask: 0.9210. :  74%|███████▍  | 74/100 [00:16<00:03,  8.64it/s]Train Iter: 3375/5000. LR: 0.0163. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9625. T_Loss: 4.5602. Mask: 0.9217. :  74%|███████▍  | 74/100 [00:16<00:03,  8.64it/s]Train Iter: 3375/5000. LR: 0.0163. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9625. T_Loss: 4.5602. Mask: 0.9217. :  75%|███████▌  | 75/100 [00:16<00:03,  7.17it/s]total : 5000  current step :  3351
total : 5000  current step :  3352
total : 5000  current step :  3353
total : 5000  current step :  3354
total : 5000  current step :  3355
total : 5000  current step :  3356
total : 5000  current step :  3357
total : 5000  current step :  3358
total : 5000  current step :  3359
total : 5000  current step :  3360
total : 5000  current step :  3361
total : 5000  current step :  3362
total : 5000  current step :  3363
total : 5000  current step :  3364
total : 5000  current step :  3365
total : 5000  current step :  3366
total : 5000  current step :  3367
total : 5000  current step :  3368
total : 5000  current step :  3369
total : 5000  current step :  3370
total : 5000  current step :  3371
total : 5000  current step :  3372
total : 5000  current step :  3373
total : 5000  current step :  3374
total : 5000  current step :  3375
Train Iter: 3376/5000. LR: 0.0163. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.5507. Mask: 0.9223. :  75%|███████▌  | 75/100 [00:18<00:03,  7.17it/s]Train Iter: 3376/5000. LR: 0.0163. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.5507. Mask: 0.9223. :  76%|███████▌  | 76/100 [00:18<00:14,  1.64it/s]Train Iter: 3377/5000. LR: 0.0163. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9628. T_Loss: 4.5519. Mask: 0.9221. :  76%|███████▌  | 76/100 [00:18<00:14,  1.64it/s]Train Iter: 3377/5000. LR: 0.0163. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9628. T_Loss: 4.5519. Mask: 0.9221. :  77%|███████▋  | 77/100 [00:18<00:10,  2.10it/s]Train Iter: 3378/5000. LR: 0.0163. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.5540. Mask: 0.9223. :  77%|███████▋  | 77/100 [00:19<00:10,  2.10it/s]Train Iter: 3378/5000. LR: 0.0163. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.5540. Mask: 0.9223. :  78%|███████▊  | 78/100 [00:19<00:08,  2.66it/s]Train Iter: 3379/5000. LR: 0.0162. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9616. T_Loss: 4.5592. Mask: 0.9229. :  78%|███████▊  | 78/100 [00:19<00:08,  2.66it/s]Train Iter: 3379/5000. LR: 0.0162. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9616. T_Loss: 4.5592. Mask: 0.9229. :  79%|███████▉  | 79/100 [00:19<00:06,  3.34it/s]Train Iter: 3380/5000. LR: 0.0162. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9621. T_Loss: 4.5605. Mask: 0.9223. :  79%|███████▉  | 79/100 [00:19<00:06,  3.34it/s]Train Iter: 3380/5000. LR: 0.0162. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9621. T_Loss: 4.5605. Mask: 0.9223. :  80%|████████  | 80/100 [00:19<00:04,  4.03it/s]Train Iter: 3381/5000. LR: 0.0162. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9634. T_Loss: 4.5568. Mask: 0.9221. :  80%|████████  | 80/100 [00:19<00:04,  4.03it/s]Train Iter: 3381/5000. LR: 0.0162. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9634. T_Loss: 4.5568. Mask: 0.9221. :  81%|████████  | 81/100 [00:19<00:04,  4.71it/s]Train Iter: 3382/5000. LR: 0.0162. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9630. T_Loss: 4.5462. Mask: 0.9215. :  81%|████████  | 81/100 [00:19<00:04,  4.71it/s]Train Iter: 3382/5000. LR: 0.0162. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9630. T_Loss: 4.5462. Mask: 0.9215. :  82%|████████▏ | 82/100 [00:19<00:03,  5.44it/s]Train Iter: 3383/5000. LR: 0.0162. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9629. T_Loss: 4.5446. Mask: 0.9217. :  82%|████████▏ | 82/100 [00:19<00:03,  5.44it/s]Train Iter: 3383/5000. LR: 0.0162. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9629. T_Loss: 4.5446. Mask: 0.9217. :  83%|████████▎ | 83/100 [00:19<00:02,  6.17it/s]Train Iter: 3384/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9625. T_Loss: 4.5456. Mask: 0.9222. :  83%|████████▎ | 83/100 [00:19<00:02,  6.17it/s]Train Iter: 3385/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9619. T_Loss: 4.5508. Mask: 0.9228. :  84%|████████▍ | 84/100 [00:20<00:02,  6.17it/s]Train Iter: 3385/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9619. T_Loss: 4.5508. Mask: 0.9228. :  85%|████████▌ | 85/100 [00:20<00:02,  6.09it/s]Train Iter: 3386/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9636. T_Loss: 4.5579. Mask: 0.9215. :  85%|████████▌ | 85/100 [00:20<00:02,  6.09it/s]Train Iter: 3386/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9636. T_Loss: 4.5579. Mask: 0.9215. :  86%|████████▌ | 86/100 [00:20<00:02,  6.48it/s]Train Iter: 3387/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9634. T_Loss: 4.5568. Mask: 0.9221. :  86%|████████▌ | 86/100 [00:20<00:02,  6.48it/s]Train Iter: 3387/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9634. T_Loss: 4.5568. Mask: 0.9221. :  87%|████████▋ | 87/100 [00:20<00:01,  6.72it/s]Train Iter: 3388/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9629. T_Loss: 4.5547. Mask: 0.9226. :  87%|████████▋ | 87/100 [00:20<00:01,  6.72it/s]Train Iter: 3388/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9629. T_Loss: 4.5547. Mask: 0.9226. :  88%|████████▊ | 88/100 [00:20<00:01,  7.32it/s]Train Iter: 3389/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9620. T_Loss: 4.5475. Mask: 0.9231. :  88%|████████▊ | 88/100 [00:20<00:01,  7.32it/s]Train Iter: 3389/5000. LR: 0.0161. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9620. T_Loss: 4.5475. Mask: 0.9231. :  89%|████████▉ | 89/100 [00:20<00:02,  5.39it/s]Train Iter: 3390/5000. LR: 0.0160. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9606. T_Loss: 4.5439. Mask: 0.9236. :  89%|████████▉ | 89/100 [00:20<00:02,  5.39it/s]Train Iter: 3390/5000. LR: 0.0160. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9606. T_Loss: 4.5439. Mask: 0.9236. :  90%|█████████ | 90/100 [00:20<00:01,  5.95it/s]Train Iter: 3391/5000. LR: 0.0160. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9612. T_Loss: 4.5474. Mask: 0.9238. :  90%|█████████ | 90/100 [00:20<00:01,  5.95it/s]Train Iter: 3391/5000. LR: 0.0160. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9612. T_Loss: 4.5474. Mask: 0.9238. :  91%|█████████ | 91/100 [00:20<00:01,  6.25it/s]Train Iter: 3392/5000. LR: 0.0160. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9615. T_Loss: 4.5449. Mask: 0.9236. :  91%|█████████ | 91/100 [00:21<00:01,  6.25it/s]Train Iter: 3392/5000. LR: 0.0160. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9615. T_Loss: 4.5449. Mask: 0.9236. :  92%|█████████▏| 92/100 [00:21<00:01,  6.73it/s]Train Iter: 3393/5000. LR: 0.0160. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9615. T_Loss: 4.5451. Mask: 0.9234. :  92%|█████████▏| 92/100 [00:21<00:01,  6.73it/s]Train Iter: 3393/5000. LR: 0.0160. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9615. T_Loss: 4.5451. Mask: 0.9234. :  93%|█████████▎| 93/100 [00:21<00:00,  7.24it/s]Train Iter: 3394/5000. LR: 0.0160. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9611. T_Loss: 4.5507. Mask: 0.9239. :  93%|█████████▎| 93/100 [00:21<00:00,  7.24it/s]Train Iter: 3394/5000. LR: 0.0160. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9611. T_Loss: 4.5507. Mask: 0.9239. :  94%|█████████▍| 94/100 [00:21<00:00,  7.74it/s]Train Iter: 3395/5000. LR: 0.0160. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9615. T_Loss: 4.5541. Mask: 0.9240. :  94%|█████████▍| 94/100 [00:21<00:00,  7.74it/s]Train Iter: 3395/5000. LR: 0.0160. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9615. T_Loss: 4.5541. Mask: 0.9240. :  95%|█████████▌| 95/100 [00:21<00:00,  7.80it/s]Train Iter: 3396/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9606. T_Loss: 4.5487. Mask: 0.9242. :  95%|█████████▌| 95/100 [00:21<00:00,  7.80it/s]Train Iter: 3396/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9606. T_Loss: 4.5487. Mask: 0.9242. :  96%|█████████▌| 96/100 [00:21<00:00,  7.93it/s]Train Iter: 3397/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9599. T_Loss: 4.5488. Mask: 0.9243. :  96%|█████████▌| 96/100 [00:21<00:00,  7.93it/s]Train Iter: 3397/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9599. T_Loss: 4.5488. Mask: 0.9243. :  97%|█████████▋| 97/100 [00:21<00:00,  8.25it/s]Train Iter: 3398/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9611. T_Loss: 4.5541. Mask: 0.9241. :  97%|█████████▋| 97/100 [00:21<00:00,  8.25it/s]Train Iter: 3398/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9611. T_Loss: 4.5541. Mask: 0.9241. :  98%|█████████▊| 98/100 [00:21<00:00,  8.38it/s]Train Iter: 3399/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9612. T_Loss: 4.5565. Mask: 0.9236. :  98%|█████████▊| 98/100 [00:22<00:00,  8.38it/s]Train Iter: 3399/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9612. T_Loss: 4.5565. Mask: 0.9236. :  99%|█████████▉| 99/100 [00:22<00:00,  5.93it/s]Train Iter: 3400/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9599. T_Loss: 4.5501. Mask: 0.9241. :  99%|█████████▉| 99/100 [00:22<00:00,  5.93it/s]Train Iter: 3400/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9599. T_Loss: 4.5501. Mask: 0.9241. : 100%|██████████| 100/100 [00:22<00:00,  6.47it/s]Train Iter: 3400/5000. LR: 0.0159. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9599. T_Loss: 4.5501. Mask: 0.9241. : 100%|██████████| 100/100 [00:22<00:00,  4.51it/s]
total : 5000  current step :  3376
total : 5000  current step :  3377
total : 5000  current step :  3378
total : 5000  current step :  3379
total : 5000  current step :  3380
total : 5000  current step :  3381
total : 5000  current step :  3382
total : 5000  current step :  3383
total : 5000  current step :  3384
total : 5000  current step :  3385
total : 5000  current step :  3386
total : 5000  current step :  3387
total : 5000  current step :  3388
total : 5000  current step :  3389
total : 5000  current step :  3390
total : 5000  current step :  3391
total : 5000  current step :  3392
total : 5000  current step :  3393
total : 5000  current step :  3394
total : 5000  current step :  3395
total : 5000  current step :  3396
total : 5000  current step :  3397
total : 5000  current step :  3398
total : 5000  current step :  3399
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.71s. Loss: 0.8940. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.71s. Loss: 0.8940. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.71s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.89s. Loss: 0.8852. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.71s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 0.8544. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.71s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.8600. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.71s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.8600. top1: 89.06. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.8482. top1: 90.62. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8495. top1: 90.62. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8622. top1: 89.73. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8641. top1: 89.45. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8590. top1: 89.58. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8643. top1: 89.69. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8552. top1: 90.62. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8548. top1: 90.62. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8498. top1: 90.62. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8464. top1: 90.85. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.82it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8464. top1: 90.85. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:04, 12.24it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8444. top1: 91.04. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:04, 12.24it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8446. top1: 91.21. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:04, 12.24it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8429. top1: 90.99. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:04, 12.24it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8429. top1: 91.15. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 12.24it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8431. top1: 91.12. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 12.24it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8424. top1: 91.25. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 12.24it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8458. top1: 91.22. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 12.24it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8458. top1: 91.22. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8432. top1: 91.48. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8402. top1: 91.85. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8382. top1: 91.93. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8359. top1: 92.00. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8399. top1: 91.59. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8404. top1: 91.67. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8429. top1: 91.63. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8406. top1: 91.81. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8401. top1: 91.77. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8401. top1: 91.73. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 19.11it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8401. top1: 91.73. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8599. top1: 90.82. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8704. top1: 90.34. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8834. top1: 89.43. top5: 99.91. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8976. top1: 88.39. top5: 99.91. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9230. top1: 87.24. top5: 99.74. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9306. top1: 86.57. top5: 99.75. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9414. top1: 85.94. top5: 99.75. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9564. top1: 85.42. top5: 99.60. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9673. top1: 84.69. top5: 99.61. :  49%|████▉     | 31/63 [00:02<00:01, 30.76it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9673. top1: 84.69. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9746. top1: 84.30. top5: 99.54. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9895. top1: 83.48. top5: 99.55. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9990. top1: 83.07. top5: 99.56. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0042. top1: 82.74. top5: 99.57. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0086. top1: 82.36. top5: 99.58. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0167. top1: 81.86. top5: 99.59. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0240. top1: 81.45. top5: 99.60. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0294. top1: 81.12. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0371. top1: 80.87. top5: 99.62. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0416. top1: 80.62. top5: 99.62. :  63%|██████▎   | 40/63 [00:02<00:00, 40.49it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0416. top1: 80.62. top5: 99.62. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0551. top1: 79.84. top5: 99.63. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0597. top1: 79.75. top5: 99.58. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0690. top1: 79.25. top5: 99.53. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0774. top1: 78.88. top5: 99.48. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0807. top1: 78.58. top5: 99.49. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0842. top1: 78.46. top5: 99.50. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0930. top1: 77.91. top5: 99.45. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1008. top1: 77.37. top5: 99.46. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1066. top1: 77.07. top5: 99.42. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1065. top1: 77.14. top5: 99.43. :  79%|███████▉  | 50/63 [00:02<00:00, 50.29it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1065. top1: 77.14. top5: 99.43. :  95%|█████████▌| 60/63 [00:02<00:00, 59.77it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1141. top1: 76.64. top5: 99.44. :  95%|█████████▌| 60/63 [00:02<00:00, 59.77it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1235. top1: 76.11. top5: 99.45. :  95%|█████████▌| 60/63 [00:02<00:00, 59.77it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1247. top1: 76.00. top5: 99.45. :  95%|█████████▌| 60/63 [00:02<00:00, 59.77it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1247. top1: 76.00. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.56it/s]
total : 5000  current step :  3400
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3401/5000. LR: 0.0158. Data: 1.81s. Batch: 1.92s. S_Loss: 0.9730. T_Loss: 4.5551. Mask: 0.9375. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 3401/5000. LR: 0.0158. Data: 1.81s. Batch: 1.92s. S_Loss: 0.9730. T_Loss: 4.5551. Mask: 0.9375. :   1%|          | 1/100 [00:01<03:10,  1.92s/it]Train Iter: 3402/5000. LR: 0.0158. Data: 0.91s. Batch: 1.02s. S_Loss: 0.9626. T_Loss: 4.6786. Mask: 0.9531. :   1%|          | 1/100 [00:02<03:10,  1.92s/it]Train Iter: 3402/5000. LR: 0.0158. Data: 0.91s. Batch: 1.02s. S_Loss: 0.9626. T_Loss: 4.6786. Mask: 0.9531. :   2%|▏         | 2/100 [00:02<01:24,  1.15it/s]Train Iter: 3403/5000. LR: 0.0158. Data: 0.61s. Batch: 0.73s. S_Loss: 0.9472. T_Loss: 4.5154. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:24,  1.15it/s]Train Iter: 3403/5000. LR: 0.0158. Data: 0.61s. Batch: 0.73s. S_Loss: 0.9472. T_Loss: 4.5154. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:51,  1.88it/s]Train Iter: 3404/5000. LR: 0.0158. Data: 0.45s. Batch: 0.57s. S_Loss: 0.9701. T_Loss: 4.7352. Mask: 0.9141. :   3%|▎         | 3/100 [00:02<00:51,  1.88it/s]Train Iter: 3404/5000. LR: 0.0158. Data: 0.45s. Batch: 0.57s. S_Loss: 0.9701. T_Loss: 4.7352. Mask: 0.9141. :   4%|▍         | 4/100 [00:02<00:35,  2.71it/s]Train Iter: 3405/5000. LR: 0.0158. Data: 0.36s. Batch: 0.52s. S_Loss: 1.0144. T_Loss: 4.8977. Mask: 0.8875. :   4%|▍         | 4/100 [00:02<00:35,  2.71it/s]Train Iter: 3405/5000. LR: 0.0158. Data: 0.36s. Batch: 0.52s. S_Loss: 1.0144. T_Loss: 4.8977. Mask: 0.8875. :   5%|▌         | 5/100 [00:02<00:33,  2.84it/s]Train Iter: 3406/5000. LR: 0.0158. Data: 0.30s. Batch: 0.46s. S_Loss: 0.9935. T_Loss: 4.8138. Mask: 0.8958. :   5%|▌         | 5/100 [00:02<00:33,  2.84it/s]Train Iter: 3406/5000. LR: 0.0158. Data: 0.30s. Batch: 0.46s. S_Loss: 0.9935. T_Loss: 4.8138. Mask: 0.8958. :   6%|▌         | 6/100 [00:02<00:25,  3.62it/s]Train Iter: 3407/5000. LR: 0.0157. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9697. T_Loss: 4.6712. Mask: 0.8929. :   6%|▌         | 6/100 [00:02<00:25,  3.62it/s]Train Iter: 3407/5000. LR: 0.0157. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9697. T_Loss: 4.6712. Mask: 0.8929. :   7%|▋         | 7/100 [00:02<00:21,  4.41it/s]Train Iter: 3408/5000. LR: 0.0157. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9546. T_Loss: 4.5635. Mask: 0.8984. :   7%|▋         | 7/100 [00:03<00:21,  4.41it/s]Train Iter: 3408/5000. LR: 0.0157. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9546. T_Loss: 4.5635. Mask: 0.8984. :   8%|▊         | 8/100 [00:03<00:17,  5.16it/s]Train Iter: 3409/5000. LR: 0.0157. Data: 0.20s. Batch: 0.37s. S_Loss: 0.9660. T_Loss: 4.6851. Mask: 0.9028. :   8%|▊         | 8/100 [00:03<00:17,  5.16it/s]Train Iter: 3409/5000. LR: 0.0157. Data: 0.20s. Batch: 0.37s. S_Loss: 0.9660. T_Loss: 4.6851. Mask: 0.9028. :   9%|▉         | 9/100 [00:03<00:21,  4.32it/s]Train Iter: 3410/5000. LR: 0.0157. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9708. T_Loss: 4.7489. Mask: 0.9094. :   9%|▉         | 9/100 [00:03<00:21,  4.32it/s]Train Iter: 3410/5000. LR: 0.0157. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9708. T_Loss: 4.7489. Mask: 0.9094. :  10%|█         | 10/100 [00:03<00:17,  5.17it/s]Train Iter: 3411/5000. LR: 0.0157. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9656. T_Loss: 4.8074. Mask: 0.9119. :  10%|█         | 10/100 [00:03<00:17,  5.17it/s]Train Iter: 3411/5000. LR: 0.0157. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9656. T_Loss: 4.8074. Mask: 0.9119. :  11%|█         | 11/100 [00:03<00:14,  5.97it/s]Train Iter: 3412/5000. LR: 0.0157. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9612. T_Loss: 4.7263. Mask: 0.9115. :  11%|█         | 11/100 [00:03<00:14,  5.97it/s]Train Iter: 3412/5000. LR: 0.0157. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9612. T_Loss: 4.7263. Mask: 0.9115. :  12%|█▏        | 12/100 [00:03<00:13,  6.55it/s]Train Iter: 3413/5000. LR: 0.0156. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9601. T_Loss: 4.7335. Mask: 0.9159. :  12%|█▏        | 12/100 [00:03<00:13,  6.55it/s]Train Iter: 3413/5000. LR: 0.0156. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9601. T_Loss: 4.7335. Mask: 0.9159. :  13%|█▎        | 13/100 [00:03<00:12,  6.98it/s]Train Iter: 3414/5000. LR: 0.0156. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9657. T_Loss: 4.7739. Mask: 0.9129. :  13%|█▎        | 13/100 [00:03<00:12,  6.98it/s]Train Iter: 3414/5000. LR: 0.0156. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9657. T_Loss: 4.7739. Mask: 0.9129. :  14%|█▍        | 14/100 [00:03<00:11,  7.47it/s]Train Iter: 3415/5000. LR: 0.0156. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9625. T_Loss: 4.7457. Mask: 0.9125. :  14%|█▍        | 14/100 [00:04<00:11,  7.47it/s]Train Iter: 3415/5000. LR: 0.0156. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9625. T_Loss: 4.7457. Mask: 0.9125. :  15%|█▌        | 15/100 [00:04<00:15,  5.58it/s]Train Iter: 3416/5000. LR: 0.0156. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9700. T_Loss: 4.7430. Mask: 0.9082. :  15%|█▌        | 15/100 [00:04<00:15,  5.58it/s]Train Iter: 3416/5000. LR: 0.0156. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9700. T_Loss: 4.7430. Mask: 0.9082. :  16%|█▌        | 16/100 [00:04<00:14,  5.96it/s]Train Iter: 3417/5000. LR: 0.0156. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9662. T_Loss: 4.7226. Mask: 0.9081. :  16%|█▌        | 16/100 [00:04<00:14,  5.96it/s]Train Iter: 3417/5000. LR: 0.0156. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9662. T_Loss: 4.7226. Mask: 0.9081. :  17%|█▋        | 17/100 [00:04<00:13,  6.37it/s]Train Iter: 3418/5000. LR: 0.0156. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9636. T_Loss: 4.7036. Mask: 0.9062. :  17%|█▋        | 17/100 [00:04<00:13,  6.37it/s]Train Iter: 3418/5000. LR: 0.0156. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9636. T_Loss: 4.7036. Mask: 0.9062. :  18%|█▊        | 18/100 [00:04<00:12,  6.77it/s]Train Iter: 3419/5000. LR: 0.0155. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.7168. Mask: 0.9062. :  18%|█▊        | 18/100 [00:04<00:12,  6.77it/s]Train Iter: 3419/5000. LR: 0.0155. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.7168. Mask: 0.9062. :  19%|█▉        | 19/100 [00:04<00:13,  6.08it/s]Train Iter: 3420/5000. LR: 0.0155. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9602. T_Loss: 4.7220. Mask: 0.9094. :  19%|█▉        | 19/100 [00:04<00:13,  6.08it/s]Train Iter: 3420/5000. LR: 0.0155. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9602. T_Loss: 4.7220. Mask: 0.9094. :  20%|██        | 20/100 [00:04<00:12,  6.61it/s]Train Iter: 3421/5000. LR: 0.0155. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9622. T_Loss: 4.6878. Mask: 0.9062. :  20%|██        | 20/100 [00:05<00:12,  6.61it/s]Train Iter: 3421/5000. LR: 0.0155. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9622. T_Loss: 4.6878. Mask: 0.9062. :  21%|██        | 21/100 [00:05<00:11,  6.94it/s]Train Iter: 3422/5000. LR: 0.0155. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9613. T_Loss: 4.6657. Mask: 0.9048. :  21%|██        | 21/100 [00:05<00:11,  6.94it/s]Train Iter: 3422/5000. LR: 0.0155. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9613. T_Loss: 4.6657. Mask: 0.9048. :  22%|██▏       | 22/100 [00:05<00:10,  7.26it/s]Train Iter: 3423/5000. LR: 0.0155. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9592. T_Loss: 4.6791. Mask: 0.9090. :  22%|██▏       | 22/100 [00:05<00:10,  7.26it/s]Train Iter: 3423/5000. LR: 0.0155. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9592. T_Loss: 4.6791. Mask: 0.9090. :  23%|██▎       | 23/100 [00:05<00:10,  7.47it/s]Train Iter: 3424/5000. LR: 0.0155. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9603. T_Loss: 4.7153. Mask: 0.9102. :  23%|██▎       | 23/100 [00:05<00:10,  7.47it/s]Train Iter: 3424/5000. LR: 0.0155. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9603. T_Loss: 4.7153. Mask: 0.9102. :  24%|██▍       | 24/100 [00:05<00:10,  7.55it/s]Train Iter: 3425/5000. LR: 0.0154. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9601. T_Loss: 4.7163. Mask: 0.9062. :  24%|██▍       | 24/100 [00:05<00:10,  7.55it/s]Train Iter: 3425/5000. LR: 0.0154. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9601. T_Loss: 4.7163. Mask: 0.9062. :  25%|██▌       | 25/100 [00:05<00:12,  5.90it/s]total : 5000  current step :  3401
total : 5000  current step :  3402
total : 5000  current step :  3403
total : 5000  current step :  3404
total : 5000  current step :  3405
total : 5000  current step :  3406
total : 5000  current step :  3407
total : 5000  current step :  3408
total : 5000  current step :  3409
total : 5000  current step :  3410
total : 5000  current step :  3411
total : 5000  current step :  3412
total : 5000  current step :  3413
total : 5000  current step :  3414
total : 5000  current step :  3415
total : 5000  current step :  3416
total : 5000  current step :  3417
total : 5000  current step :  3418
total : 5000  current step :  3419
total : 5000  current step :  3420
total : 5000  current step :  3421
total : 5000  current step :  3422
total : 5000  current step :  3423
total : 5000  current step :  3424
total : 5000  current step :  3425
Train Iter: 3426/5000. LR: 0.0154. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9637. T_Loss: 4.7318. Mask: 0.9075. :  25%|██▌       | 25/100 [00:07<00:12,  5.90it/s]Train Iter: 3426/5000. LR: 0.0154. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9637. T_Loss: 4.7318. Mask: 0.9075. :  26%|██▌       | 26/100 [00:07<01:00,  1.23it/s]Train Iter: 3427/5000. LR: 0.0154. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9622. T_Loss: 4.7415. Mask: 0.9097. :  26%|██▌       | 26/100 [00:08<01:00,  1.23it/s]Train Iter: 3427/5000. LR: 0.0154. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9622. T_Loss: 4.7415. Mask: 0.9097. :  27%|██▋       | 27/100 [00:08<00:43,  1.66it/s]Train Iter: 3428/5000. LR: 0.0154. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9654. T_Loss: 4.7141. Mask: 0.9062. :  27%|██▋       | 27/100 [00:08<00:43,  1.66it/s]Train Iter: 3428/5000. LR: 0.0154. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9654. T_Loss: 4.7141. Mask: 0.9062. :  28%|██▊       | 28/100 [00:08<00:33,  2.16it/s]Train Iter: 3429/5000. LR: 0.0154. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9645. T_Loss: 4.7285. Mask: 0.9095. :  28%|██▊       | 28/100 [00:08<00:33,  2.16it/s]Train Iter: 3429/5000. LR: 0.0154. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9645. T_Loss: 4.7285. Mask: 0.9095. :  29%|██▉       | 29/100 [00:08<00:29,  2.38it/s]Train Iter: 3430/5000. LR: 0.0153. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9620. T_Loss: 4.7235. Mask: 0.9104. :  29%|██▉       | 29/100 [00:08<00:29,  2.38it/s]Train Iter: 3430/5000. LR: 0.0153. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9620. T_Loss: 4.7235. Mask: 0.9104. :  30%|███       | 30/100 [00:08<00:22,  3.07it/s]Train Iter: 3431/5000. LR: 0.0153. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9631. T_Loss: 4.7230. Mask: 0.9093. :  30%|███       | 30/100 [00:08<00:22,  3.07it/s]Train Iter: 3431/5000. LR: 0.0153. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9631. T_Loss: 4.7230. Mask: 0.9093. :  31%|███       | 31/100 [00:08<00:17,  3.86it/s]Train Iter: 3432/5000. LR: 0.0153. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9639. T_Loss: 4.7198. Mask: 0.9082. :  31%|███       | 31/100 [00:08<00:17,  3.86it/s]Train Iter: 3432/5000. LR: 0.0153. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9639. T_Loss: 4.7198. Mask: 0.9082. :  32%|███▏      | 32/100 [00:08<00:15,  4.52it/s]Train Iter: 3433/5000. LR: 0.0153. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9615. T_Loss: 4.7092. Mask: 0.9081. :  32%|███▏      | 32/100 [00:08<00:15,  4.52it/s]Train Iter: 3433/5000. LR: 0.0153. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9615. T_Loss: 4.7092. Mask: 0.9081. :  33%|███▎      | 33/100 [00:08<00:12,  5.20it/s]Train Iter: 3434/5000. LR: 0.0153. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9630. T_Loss: 4.7168. Mask: 0.9090. :  33%|███▎      | 33/100 [00:09<00:12,  5.20it/s]Train Iter: 3434/5000. LR: 0.0153. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9630. T_Loss: 4.7168. Mask: 0.9090. :  34%|███▍      | 34/100 [00:09<00:11,  5.78it/s]Train Iter: 3435/5000. LR: 0.0153. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9628. T_Loss: 4.7165. Mask: 0.9098. :  34%|███▍      | 34/100 [00:09<00:11,  5.78it/s]Train Iter: 3435/5000. LR: 0.0153. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9628. T_Loss: 4.7165. Mask: 0.9098. :  35%|███▌      | 35/100 [00:09<00:10,  6.18it/s]Train Iter: 3436/5000. LR: 0.0152. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9597. T_Loss: 4.6946. Mask: 0.9097. :  35%|███▌      | 35/100 [00:09<00:10,  6.18it/s]Train Iter: 3436/5000. LR: 0.0152. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9597. T_Loss: 4.6946. Mask: 0.9097. :  36%|███▌      | 36/100 [00:09<00:09,  6.60it/s]Train Iter: 3437/5000. LR: 0.0152. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9609. T_Loss: 4.6849. Mask: 0.9071. :  36%|███▌      | 36/100 [00:09<00:09,  6.60it/s]Train Iter: 3437/5000. LR: 0.0152. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9609. T_Loss: 4.6849. Mask: 0.9071. :  37%|███▋      | 37/100 [00:09<00:08,  7.08it/s]Train Iter: 3438/5000. LR: 0.0152. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9596. T_Loss: 4.6821. Mask: 0.9071. :  37%|███▋      | 37/100 [00:09<00:08,  7.08it/s]Train Iter: 3438/5000. LR: 0.0152. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9596. T_Loss: 4.6821. Mask: 0.9071. :  38%|███▊      | 38/100 [00:09<00:08,  7.23it/s]Train Iter: 3439/5000. LR: 0.0152. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9589. T_Loss: 4.6629. Mask: 0.9071. :  38%|███▊      | 38/100 [00:09<00:08,  7.23it/s]Train Iter: 3439/5000. LR: 0.0152. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9589. T_Loss: 4.6629. Mask: 0.9071. :  39%|███▉      | 39/100 [00:09<00:11,  5.51it/s]Train Iter: 3440/5000. LR: 0.0152. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9592. T_Loss: 4.6587. Mask: 0.9062. :  39%|███▉      | 39/100 [00:10<00:11,  5.51it/s]Train Iter: 3440/5000. LR: 0.0152. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9592. T_Loss: 4.6587. Mask: 0.9062. :  40%|████      | 40/100 [00:10<00:10,  5.91it/s]Train Iter: 3441/5000. LR: 0.0152. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9596. T_Loss: 4.6648. Mask: 0.9055. :  40%|████      | 40/100 [00:10<00:10,  5.91it/s]Train Iter: 3441/5000. LR: 0.0152. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9596. T_Loss: 4.6648. Mask: 0.9055. :  41%|████      | 41/100 [00:10<00:09,  6.32it/s]Train Iter: 3442/5000. LR: 0.0151. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9618. T_Loss: 4.6793. Mask: 0.9048. :  41%|████      | 41/100 [00:10<00:09,  6.32it/s]Train Iter: 3442/5000. LR: 0.0151. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9618. T_Loss: 4.6793. Mask: 0.9048. :  42%|████▏     | 42/100 [00:10<00:08,  7.05it/s]total : 5000  current step :  3426
total : 5000  current step :  3427
total : 5000  current step :  3428
total : 5000  current step :  3429
total : 5000  current step :  3430
total : 5000  current step :  3431
total : 5000  current step :  3432
total : 5000  current step :  3433
total : 5000  current step :  3434
total : 5000  current step :  3435
total : 5000  current step :  3436
total : 5000  current step :  3437
total : 5000  current step :  3438
total : 5000  current step :  3439
total : 5000  current step :  3440
total : 5000  current step :  3441
total : 5000  current step :  3442
Train Iter: 3443/5000. LR: 0.0151. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9646. T_Loss: 4.6974. Mask: 0.9041. :  42%|████▏     | 42/100 [00:12<00:08,  7.05it/s]Train Iter: 3443/5000. LR: 0.0151. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9646. T_Loss: 4.6974. Mask: 0.9041. :  43%|████▎     | 43/100 [00:12<00:41,  1.38it/s]Train Iter: 3444/5000. LR: 0.0151. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9627. T_Loss: 4.7012. Mask: 0.9055. :  43%|████▎     | 43/100 [00:12<00:41,  1.38it/s]Train Iter: 3444/5000. LR: 0.0151. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9627. T_Loss: 4.7012. Mask: 0.9055. :  44%|████▍     | 44/100 [00:12<00:30,  1.86it/s]Train Iter: 3445/5000. LR: 0.0151. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9651. T_Loss: 4.7305. Mask: 0.9076. :  44%|████▍     | 44/100 [00:12<00:30,  1.86it/s]Train Iter: 3445/5000. LR: 0.0151. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9651. T_Loss: 4.7305. Mask: 0.9076. :  45%|████▌     | 45/100 [00:12<00:27,  2.04it/s]Train Iter: 3446/5000. LR: 0.0151. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9648. T_Loss: 4.7262. Mask: 0.9069. :  45%|████▌     | 45/100 [00:12<00:27,  2.04it/s]Train Iter: 3446/5000. LR: 0.0151. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9648. T_Loss: 4.7262. Mask: 0.9069. :  46%|████▌     | 46/100 [00:12<00:20,  2.61it/s]Train Iter: 3447/5000. LR: 0.0151. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9642. T_Loss: 4.7206. Mask: 0.9076. :  46%|████▌     | 46/100 [00:13<00:20,  2.61it/s]Train Iter: 3447/5000. LR: 0.0151. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9642. T_Loss: 4.7206. Mask: 0.9076. :  47%|████▋     | 47/100 [00:13<00:16,  3.20it/s]Train Iter: 3448/5000. LR: 0.0150. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9638. T_Loss: 4.7389. Mask: 0.9082. :  47%|████▋     | 47/100 [00:13<00:16,  3.20it/s]Train Iter: 3449/5000. LR: 0.0150. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9636. T_Loss: 4.7224. Mask: 0.9075. :  48%|████▊     | 48/100 [00:13<00:16,  3.20it/s]Train Iter: 3449/5000. LR: 0.0150. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9636. T_Loss: 4.7224. Mask: 0.9075. :  49%|████▉     | 49/100 [00:13<00:11,  4.32it/s]Train Iter: 3450/5000. LR: 0.0150. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9655. T_Loss: 4.7290. Mask: 0.9069. :  49%|████▉     | 49/100 [00:13<00:11,  4.32it/s]Train Iter: 3450/5000. LR: 0.0150. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9655. T_Loss: 4.7290. Mask: 0.9069. :  50%|█████     | 50/100 [00:13<00:10,  4.74it/s]total : 5000  current step :  3443
total : 5000  current step :  3444
total : 5000  current step :  3445
total : 5000  current step :  3446
total : 5000  current step :  3447
total : 5000  current step :  3448
total : 5000  current step :  3449
total : 5000  current step :  3450
Train Iter: 3451/5000. LR: 0.0150. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9642. T_Loss: 4.7216. Mask: 0.9081. :  50%|█████     | 50/100 [00:15<00:10,  4.74it/s]Train Iter: 3451/5000. LR: 0.0150. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9642. T_Loss: 4.7216. Mask: 0.9081. :  51%|█████     | 51/100 [00:15<00:35,  1.40it/s]Train Iter: 3452/5000. LR: 0.0150. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9632. T_Loss: 4.7202. Mask: 0.9099. :  51%|█████     | 51/100 [00:15<00:35,  1.40it/s]Train Iter: 3452/5000. LR: 0.0150. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9632. T_Loss: 4.7202. Mask: 0.9099. :  52%|█████▏    | 52/100 [00:15<00:26,  1.82it/s]Train Iter: 3453/5000. LR: 0.0150. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9633. T_Loss: 4.7196. Mask: 0.9086. :  52%|█████▏    | 52/100 [00:15<00:26,  1.82it/s]Train Iter: 3453/5000. LR: 0.0150. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9633. T_Loss: 4.7196. Mask: 0.9086. :  53%|█████▎    | 53/100 [00:15<00:20,  2.32it/s]Train Iter: 3454/5000. LR: 0.0149. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9651. T_Loss: 4.7120. Mask: 0.9091. :  53%|█████▎    | 53/100 [00:16<00:20,  2.32it/s]Train Iter: 3454/5000. LR: 0.0149. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9651. T_Loss: 4.7120. Mask: 0.9091. :  54%|█████▍    | 54/100 [00:16<00:15,  2.89it/s]Train Iter: 3455/5000. LR: 0.0149. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9647. T_Loss: 4.7189. Mask: 0.9102. :  54%|█████▍    | 54/100 [00:16<00:15,  2.89it/s]Train Iter: 3455/5000. LR: 0.0149. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9647. T_Loss: 4.7189. Mask: 0.9102. :  55%|█████▌    | 55/100 [00:16<00:15,  2.94it/s]Train Iter: 3456/5000. LR: 0.0149. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9632. T_Loss: 4.7106. Mask: 0.9102. :  55%|█████▌    | 55/100 [00:16<00:15,  2.94it/s]Train Iter: 3457/5000. LR: 0.0149. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9646. T_Loss: 4.7222. Mask: 0.9106. :  56%|█████▌    | 56/100 [00:16<00:14,  2.94it/s]Train Iter: 3457/5000. LR: 0.0149. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9646. T_Loss: 4.7222. Mask: 0.9106. :  57%|█████▋    | 57/100 [00:16<00:09,  4.32it/s]Train Iter: 3458/5000. LR: 0.0149. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9630. T_Loss: 4.7211. Mask: 0.9122. :  57%|█████▋    | 57/100 [00:16<00:09,  4.32it/s]Train Iter: 3458/5000. LR: 0.0149. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9630. T_Loss: 4.7211. Mask: 0.9122. :  58%|█████▊    | 58/100 [00:16<00:08,  4.83it/s]Train Iter: 3459/5000. LR: 0.0148. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9616. T_Loss: 4.7127. Mask: 0.9115. :  58%|█████▊    | 58/100 [00:16<00:08,  4.83it/s]Train Iter: 3459/5000. LR: 0.0148. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9616. T_Loss: 4.7127. Mask: 0.9115. :  59%|█████▉    | 59/100 [00:16<00:07,  5.16it/s]Train Iter: 3460/5000. LR: 0.0148. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9621. T_Loss: 4.7265. Mask: 0.9125. :  59%|█████▉    | 59/100 [00:17<00:07,  5.16it/s]Train Iter: 3460/5000. LR: 0.0148. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9621. T_Loss: 4.7265. Mask: 0.9125. :  60%|██████    | 60/100 [00:17<00:06,  5.75it/s]Train Iter: 3461/5000. LR: 0.0148. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9622. T_Loss: 4.7242. Mask: 0.9129. :  60%|██████    | 60/100 [00:17<00:06,  5.75it/s]Train Iter: 3461/5000. LR: 0.0148. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9622. T_Loss: 4.7242. Mask: 0.9129. :  61%|██████    | 61/100 [00:17<00:06,  6.25it/s]Train Iter: 3462/5000. LR: 0.0148. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9626. T_Loss: 4.7248. Mask: 0.9133. :  61%|██████    | 61/100 [00:17<00:06,  6.25it/s]Train Iter: 3462/5000. LR: 0.0148. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9626. T_Loss: 4.7248. Mask: 0.9133. :  62%|██████▏   | 62/100 [00:17<00:05,  6.90it/s]Train Iter: 3463/5000. LR: 0.0148. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9626. T_Loss: 4.7266. Mask: 0.9142. :  62%|██████▏   | 62/100 [00:17<00:05,  6.90it/s]Train Iter: 3463/5000. LR: 0.0148. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9626. T_Loss: 4.7266. Mask: 0.9142. :  63%|██████▎   | 63/100 [00:17<00:05,  7.38it/s]Train Iter: 3464/5000. LR: 0.0148. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9621. T_Loss: 4.7283. Mask: 0.9155. :  63%|██████▎   | 63/100 [00:17<00:05,  7.38it/s]Train Iter: 3465/5000. LR: 0.0147. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9608. T_Loss: 4.7247. Mask: 0.9159. :  64%|██████▍   | 64/100 [00:17<00:04,  7.38it/s]Train Iter: 3465/5000. LR: 0.0147. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9608. T_Loss: 4.7247. Mask: 0.9159. :  65%|██████▌   | 65/100 [00:17<00:05,  6.21it/s]Train Iter: 3466/5000. LR: 0.0147. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9615. T_Loss: 4.7228. Mask: 0.9157. :  65%|██████▌   | 65/100 [00:17<00:05,  6.21it/s]Train Iter: 3466/5000. LR: 0.0147. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9615. T_Loss: 4.7228. Mask: 0.9157. :  66%|██████▌   | 66/100 [00:17<00:05,  6.75it/s]Train Iter: 3467/5000. LR: 0.0147. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9628. T_Loss: 4.7173. Mask: 0.9151. :  66%|██████▌   | 66/100 [00:17<00:05,  6.75it/s]Train Iter: 3467/5000. LR: 0.0147. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9628. T_Loss: 4.7173. Mask: 0.9151. :  67%|██████▋   | 67/100 [00:17<00:04,  7.08it/s]Train Iter: 3468/5000. LR: 0.0147. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9635. T_Loss: 4.7266. Mask: 0.9150. :  67%|██████▋   | 67/100 [00:18<00:04,  7.08it/s]Train Iter: 3468/5000. LR: 0.0147. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9635. T_Loss: 4.7266. Mask: 0.9150. :  68%|██████▊   | 68/100 [00:18<00:04,  7.38it/s]Train Iter: 3469/5000. LR: 0.0147. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9624. T_Loss: 4.7228. Mask: 0.9158. :  68%|██████▊   | 68/100 [00:18<00:04,  7.38it/s]Train Iter: 3469/5000. LR: 0.0147. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9624. T_Loss: 4.7228. Mask: 0.9158. :  69%|██████▉   | 69/100 [00:18<00:04,  7.59it/s]Train Iter: 3470/5000. LR: 0.0147. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9630. T_Loss: 4.7277. Mask: 0.9156. :  69%|██████▉   | 69/100 [00:18<00:04,  7.59it/s]Train Iter: 3470/5000. LR: 0.0147. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9630. T_Loss: 4.7277. Mask: 0.9156. :  70%|███████   | 70/100 [00:18<00:03,  7.84it/s]Train Iter: 3471/5000. LR: 0.0146. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9638. T_Loss: 4.7364. Mask: 0.9155. :  70%|███████   | 70/100 [00:18<00:03,  7.84it/s]Train Iter: 3471/5000. LR: 0.0146. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9638. T_Loss: 4.7364. Mask: 0.9155. :  71%|███████   | 71/100 [00:18<00:03,  7.93it/s]Train Iter: 3472/5000. LR: 0.0146. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9621. T_Loss: 4.7347. Mask: 0.9162. :  71%|███████   | 71/100 [00:18<00:03,  7.93it/s]Train Iter: 3472/5000. LR: 0.0146. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9621. T_Loss: 4.7347. Mask: 0.9162. :  72%|███████▏  | 72/100 [00:18<00:03,  7.92it/s]Train Iter: 3473/5000. LR: 0.0146. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9621. T_Loss: 4.7454. Mask: 0.9165. :  72%|███████▏  | 72/100 [00:18<00:03,  7.92it/s]Train Iter: 3473/5000. LR: 0.0146. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9621. T_Loss: 4.7454. Mask: 0.9165. :  73%|███████▎  | 73/100 [00:18<00:03,  8.20it/s]Train Iter: 3474/5000. LR: 0.0146. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.7370. Mask: 0.9164. :  73%|███████▎  | 73/100 [00:18<00:03,  8.20it/s]Train Iter: 3474/5000. LR: 0.0146. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.7370. Mask: 0.9164. :  74%|███████▍  | 74/100 [00:18<00:03,  8.20it/s]Train Iter: 3475/5000. LR: 0.0146. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9628. T_Loss: 4.7385. Mask: 0.9171. :  74%|███████▍  | 74/100 [00:19<00:03,  8.20it/s]Train Iter: 3475/5000. LR: 0.0146. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9628. T_Loss: 4.7385. Mask: 0.9171. :  75%|███████▌  | 75/100 [00:19<00:04,  5.22it/s]total : 5000  current step :  3451
total : 5000  current step :  3452
total : 5000  current step :  3453
total : 5000  current step :  3454
total : 5000  current step :  3455
total : 5000  current step :  3456
total : 5000  current step :  3457
total : 5000  current step :  3458
total : 5000  current step :  3459
total : 5000  current step :  3460
total : 5000  current step :  3461
total : 5000  current step :  3462
total : 5000  current step :  3463
total : 5000  current step :  3464
total : 5000  current step :  3465
total : 5000  current step :  3466
total : 5000  current step :  3467
total : 5000  current step :  3468
total : 5000  current step :  3469
total : 5000  current step :  3470
total : 5000  current step :  3471
total : 5000  current step :  3472
total : 5000  current step :  3473
total : 5000  current step :  3474
total : 5000  current step :  3475
Train Iter: 3476/5000. LR: 0.0146. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9630. T_Loss: 4.7495. Mask: 0.9178. :  75%|███████▌  | 75/100 [00:21<00:04,  5.22it/s]Train Iter: 3476/5000. LR: 0.0146. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9630. T_Loss: 4.7495. Mask: 0.9178. :  76%|███████▌  | 76/100 [00:21<00:18,  1.28it/s]Train Iter: 3477/5000. LR: 0.0145. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9661. T_Loss: 4.7573. Mask: 0.9168. :  76%|███████▌  | 76/100 [00:21<00:18,  1.28it/s]Train Iter: 3477/5000. LR: 0.0145. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9661. T_Loss: 4.7573. Mask: 0.9168. :  77%|███████▋  | 77/100 [00:21<00:13,  1.71it/s]Train Iter: 3478/5000. LR: 0.0145. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9682. T_Loss: 4.7606. Mask: 0.9155. :  77%|███████▋  | 77/100 [00:21<00:13,  1.71it/s]Train Iter: 3478/5000. LR: 0.0145. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9682. T_Loss: 4.7606. Mask: 0.9155. :  78%|███████▊  | 78/100 [00:21<00:09,  2.26it/s]Train Iter: 3479/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9667. T_Loss: 4.7536. Mask: 0.9153. :  78%|███████▊  | 78/100 [00:21<00:09,  2.26it/s]Train Iter: 3479/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9667. T_Loss: 4.7536. Mask: 0.9153. :  79%|███████▉  | 79/100 [00:21<00:07,  2.87it/s]Train Iter: 3480/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9661. T_Loss: 4.7493. Mask: 0.9160. :  79%|███████▉  | 79/100 [00:21<00:07,  2.87it/s]Train Iter: 3480/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9661. T_Loss: 4.7493. Mask: 0.9160. :  80%|████████  | 80/100 [00:21<00:05,  3.57it/s]Train Iter: 3481/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9656. T_Loss: 4.7462. Mask: 0.9159. :  80%|████████  | 80/100 [00:21<00:05,  3.57it/s]Train Iter: 3481/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9656. T_Loss: 4.7462. Mask: 0.9159. :  81%|████████  | 81/100 [00:21<00:04,  4.30it/s]Train Iter: 3482/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9648. T_Loss: 4.7377. Mask: 0.9158. :  81%|████████  | 81/100 [00:22<00:04,  4.30it/s]Train Iter: 3482/5000. LR: 0.0145. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9648. T_Loss: 4.7377. Mask: 0.9158. :  82%|████████▏ | 82/100 [00:22<00:03,  5.03it/s]Train Iter: 3483/5000. LR: 0.0144. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9641. T_Loss: 4.7382. Mask: 0.9157. :  82%|████████▏ | 82/100 [00:22<00:03,  5.03it/s]Train Iter: 3483/5000. LR: 0.0144. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9641. T_Loss: 4.7382. Mask: 0.9157. :  83%|████████▎ | 83/100 [00:22<00:02,  5.71it/s]Train Iter: 3484/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9648. T_Loss: 4.7512. Mask: 0.9156. :  83%|████████▎ | 83/100 [00:22<00:02,  5.71it/s]Train Iter: 3484/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9648. T_Loss: 4.7512. Mask: 0.9156. :  84%|████████▍ | 84/100 [00:22<00:02,  6.20it/s]Train Iter: 3485/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9652. T_Loss: 4.7596. Mask: 0.9154. :  84%|████████▍ | 84/100 [00:22<00:02,  6.20it/s]Train Iter: 3485/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9652. T_Loss: 4.7596. Mask: 0.9154. :  85%|████████▌ | 85/100 [00:22<00:02,  5.60it/s]Train Iter: 3486/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9670. T_Loss: 4.7618. Mask: 0.9146. :  85%|████████▌ | 85/100 [00:22<00:02,  5.60it/s]Train Iter: 3486/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9670. T_Loss: 4.7618. Mask: 0.9146. :  86%|████████▌ | 86/100 [00:22<00:02,  6.19it/s]Train Iter: 3487/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9669. T_Loss: 4.7536. Mask: 0.9138. :  86%|████████▌ | 86/100 [00:22<00:02,  6.19it/s]Train Iter: 3487/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9669. T_Loss: 4.7536. Mask: 0.9138. :  87%|████████▋ | 87/100 [00:22<00:01,  6.58it/s]Train Iter: 3488/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9675. T_Loss: 4.7493. Mask: 0.9130. :  87%|████████▋ | 87/100 [00:22<00:01,  6.58it/s]Train Iter: 3488/5000. LR: 0.0144. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9675. T_Loss: 4.7493. Mask: 0.9130. :  88%|████████▊ | 88/100 [00:22<00:01,  6.70it/s]Train Iter: 3489/5000. LR: 0.0143. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9693. T_Loss: 4.7533. Mask: 0.9126. :  88%|████████▊ | 88/100 [00:23<00:01,  6.70it/s]Train Iter: 3489/5000. LR: 0.0143. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9693. T_Loss: 4.7533. Mask: 0.9126. :  89%|████████▉ | 89/100 [00:23<00:02,  4.45it/s]Train Iter: 3490/5000. LR: 0.0143. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9689. T_Loss: 4.7521. Mask: 0.9128. :  89%|████████▉ | 89/100 [00:23<00:02,  4.45it/s]Train Iter: 3490/5000. LR: 0.0143. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9689. T_Loss: 4.7521. Mask: 0.9128. :  90%|█████████ | 90/100 [00:23<00:01,  5.11it/s]Train Iter: 3491/5000. LR: 0.0143. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9691. T_Loss: 4.7492. Mask: 0.9135. :  90%|█████████ | 90/100 [00:23<00:01,  5.11it/s]Train Iter: 3491/5000. LR: 0.0143. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9691. T_Loss: 4.7492. Mask: 0.9135. :  91%|█████████ | 91/100 [00:23<00:01,  5.43it/s]Train Iter: 3492/5000. LR: 0.0143. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9684. T_Loss: 4.7477. Mask: 0.9137. :  91%|█████████ | 91/100 [00:23<00:01,  5.43it/s]Train Iter: 3492/5000. LR: 0.0143. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9684. T_Loss: 4.7477. Mask: 0.9137. :  92%|█████████▏| 92/100 [00:23<00:01,  6.07it/s]Train Iter: 3493/5000. LR: 0.0143. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9672. T_Loss: 4.7416. Mask: 0.9136. :  92%|█████████▏| 92/100 [00:23<00:01,  6.07it/s]Train Iter: 3493/5000. LR: 0.0143. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9672. T_Loss: 4.7416. Mask: 0.9136. :  93%|█████████▎| 93/100 [00:23<00:01,  6.66it/s]Train Iter: 3494/5000. LR: 0.0143. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9673. T_Loss: 4.7445. Mask: 0.9136. :  93%|█████████▎| 93/100 [00:23<00:01,  6.66it/s]Train Iter: 3494/5000. LR: 0.0143. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9673. T_Loss: 4.7445. Mask: 0.9136. :  94%|█████████▍| 94/100 [00:23<00:00,  7.26it/s]Train Iter: 3495/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9663. T_Loss: 4.7416. Mask: 0.9138. :  94%|█████████▍| 94/100 [00:24<00:00,  7.26it/s]Train Iter: 3495/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9663. T_Loss: 4.7416. Mask: 0.9138. :  95%|█████████▌| 95/100 [00:24<00:00,  5.02it/s]Train Iter: 3496/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9667. T_Loss: 4.7517. Mask: 0.9131. :  95%|█████████▌| 95/100 [00:24<00:00,  5.02it/s]Train Iter: 3496/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9667. T_Loss: 4.7517. Mask: 0.9131. :  96%|█████████▌| 96/100 [00:24<00:00,  5.54it/s]Train Iter: 3497/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9659. T_Loss: 4.7517. Mask: 0.9137. :  96%|█████████▌| 96/100 [00:24<00:00,  5.54it/s]Train Iter: 3497/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9659. T_Loss: 4.7517. Mask: 0.9137. :  97%|█████████▋| 97/100 [00:24<00:00,  6.01it/s]Train Iter: 3498/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9672. T_Loss: 4.7465. Mask: 0.9133. :  97%|█████████▋| 97/100 [00:24<00:00,  6.01it/s]Train Iter: 3498/5000. LR: 0.0142. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9672. T_Loss: 4.7465. Mask: 0.9133. :  98%|█████████▊| 98/100 [00:24<00:00,  6.45it/s]Train Iter: 3499/5000. LR: 0.0142. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9669. T_Loss: 4.7455. Mask: 0.9138. :  98%|█████████▊| 98/100 [00:25<00:00,  6.45it/s]Train Iter: 3499/5000. LR: 0.0142. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9669. T_Loss: 4.7455. Mask: 0.9138. :  99%|█████████▉| 99/100 [00:25<00:00,  4.89it/s]Train Iter: 3500/5000. LR: 0.0142. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9662. T_Loss: 4.7433. Mask: 0.9137. :  99%|█████████▉| 99/100 [00:25<00:00,  4.89it/s]Train Iter: 3500/5000. LR: 0.0142. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9662. T_Loss: 4.7433. Mask: 0.9137. : 100%|██████████| 100/100 [00:25<00:00,  5.77it/s]Train Iter: 3500/5000. LR: 0.0142. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9662. T_Loss: 4.7433. Mask: 0.9137. : 100%|██████████| 100/100 [00:25<00:00,  3.98it/s]
total : 5000  current step :  3476
total : 5000  current step :  3477
total : 5000  current step :  3478
total : 5000  current step :  3479
total : 5000  current step :  3480
total : 5000  current step :  3481
total : 5000  current step :  3482
total : 5000  current step :  3483
total : 5000  current step :  3484
total : 5000  current step :  3485
total : 5000  current step :  3486
total : 5000  current step :  3487
total : 5000  current step :  3488
total : 5000  current step :  3489
total : 5000  current step :  3490
total : 5000  current step :  3491
total : 5000  current step :  3492
total : 5000  current step :  3493
total : 5000  current step :  3494
total : 5000  current step :  3495
total : 5000  current step :  3496
total : 5000  current step :  3497
total : 5000  current step :  3498
total : 5000  current step :  3499
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.8775. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.8775. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 0.8710. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.8410. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.8455. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8353. top1: 91.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8358. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8358. top1: 91.67. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.8483. top1: 90.62. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8480. top1: 90.23. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8443. top1: 90.28. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8491. top1: 90.31. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8402. top1: 91.19. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8404. top1: 91.15. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8357. top1: 91.35. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8321. top1: 91.74. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8307. top1: 91.88. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8312. top1: 91.99. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8312. top1: 91.99. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8297. top1: 91.73. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8296. top1: 91.84. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8291. top1: 91.78. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8286. top1: 91.88. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8317. top1: 91.96. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8293. top1: 92.19. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8265. top1: 92.53. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8246. top1: 92.71. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8222. top1: 92.75. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.83it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8259. top1: 92.67. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.83it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8259. top1: 92.67. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8265. top1: 92.71. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8293. top1: 92.63. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8270. top1: 92.78. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8267. top1: 92.71. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8266. top1: 92.74. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8475. top1: 91.60. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8597. top1: 91.00. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8738. top1: 90.07. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s] Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8894. top1: 89.02. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9158. top1: 87.76. top5: 99.74. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9242. top1: 87.16. top5: 99.75. :  41%|████▏     | 26/63 [00:02<00:01, 24.47it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9242. top1: 87.16. top5: 99.75. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9366. top1: 86.27. top5: 99.75. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9521. top1: 85.66. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9645. top1: 84.92. top5: 99.61. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9725. top1: 84.53. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9887. top1: 83.71. top5: 99.55. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9990. top1: 83.28. top5: 99.56. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0052. top1: 82.95. top5: 99.57. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0098. top1: 82.57. top5: 99.58. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0183. top1: 81.86. top5: 99.59. :  59%|█████▊    | 37/63 [00:02<00:00, 36.74it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0183. top1: 81.86. top5: 99.59. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0262. top1: 81.45. top5: 99.60. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0324. top1: 80.99. top5: 99.61. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0406. top1: 80.74. top5: 99.55. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0459. top1: 80.44. top5: 99.56. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0604. top1: 79.60. top5: 99.57. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0651. top1: 79.33. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0750. top1: 78.89. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0845. top1: 78.47. top5: 99.48. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0885. top1: 77.95. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0928. top1: 77.79. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 46.01it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0928. top1: 77.79. top5: 99.50. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1028. top1: 77.25. top5: 99.45. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1112. top1: 76.62. top5: 99.46. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1176. top1: 76.22. top5: 99.42. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1180. top1: 76.30. top5: 99.43. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1260. top1: 75.87. top5: 99.44. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1360. top1: 75.25. top5: 99.45. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1373. top1: 75.20. top5: 99.45. :  89%|████████▉ | 56/63 [00:02<00:00, 55.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1373. top1: 75.20. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 24.44it/s]
total : 5000  current step :  3500
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3501/5000. LR: 0.0141. Data: 2.03s. Batch: 2.18s. S_Loss: 0.9462. T_Loss: 4.8107. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 3501/5000. LR: 0.0141. Data: 2.03s. Batch: 2.18s. S_Loss: 0.9462. T_Loss: 4.8107. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:35,  2.18s/it]Train Iter: 3502/5000. LR: 0.0141. Data: 1.02s. Batch: 1.15s. S_Loss: 0.9512. T_Loss: 4.8008. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:35,  2.18s/it]Train Iter: 3502/5000. LR: 0.0141. Data: 1.02s. Batch: 1.15s. S_Loss: 0.9512. T_Loss: 4.8008. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:34,  1.03it/s]Train Iter: 3503/5000. LR: 0.0141. Data: 0.68s. Batch: 0.80s. S_Loss: 0.9574. T_Loss: 4.5001. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:34,  1.03it/s]Train Iter: 3503/5000. LR: 0.0141. Data: 0.68s. Batch: 0.80s. S_Loss: 0.9574. T_Loss: 4.5001. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<00:56,  1.72it/s]Train Iter: 3504/5000. LR: 0.0141. Data: 0.51s. Batch: 0.63s. S_Loss: 0.9975. T_Loss: 4.5780. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:56,  1.72it/s]Train Iter: 3504/5000. LR: 0.0141. Data: 0.51s. Batch: 0.63s. S_Loss: 0.9975. T_Loss: 4.5780. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:38,  2.51it/s]Train Iter: 3505/5000. LR: 0.0141. Data: 0.41s. Batch: 0.55s. S_Loss: 0.9983. T_Loss: 4.5647. Mask: 0.9250. :   4%|▍         | 4/100 [00:02<00:38,  2.51it/s]Train Iter: 3505/5000. LR: 0.0141. Data: 0.41s. Batch: 0.55s. S_Loss: 0.9983. T_Loss: 4.5647. Mask: 0.9250. :   5%|▌         | 5/100 [00:02<00:31,  2.97it/s]Train Iter: 3506/5000. LR: 0.0141. Data: 0.34s. Batch: 0.48s. S_Loss: 0.9816. T_Loss: 4.5144. Mask: 0.9323. :   5%|▌         | 5/100 [00:02<00:31,  2.97it/s]Train Iter: 3506/5000. LR: 0.0141. Data: 0.34s. Batch: 0.48s. S_Loss: 0.9816. T_Loss: 4.5144. Mask: 0.9323. :   6%|▌         | 6/100 [00:02<00:24,  3.78it/s]Train Iter: 3507/5000. LR: 0.0140. Data: 0.29s. Batch: 0.43s. S_Loss: 1.0089. T_Loss: 4.8755. Mask: 0.9330. :   6%|▌         | 6/100 [00:02<00:24,  3.78it/s]Train Iter: 3507/5000. LR: 0.0140. Data: 0.29s. Batch: 0.43s. S_Loss: 1.0089. T_Loss: 4.8755. Mask: 0.9330. :   7%|▋         | 7/100 [00:02<00:19,  4.68it/s]Train Iter: 3508/5000. LR: 0.0140. Data: 0.26s. Batch: 0.39s. S_Loss: 0.9817. T_Loss: 4.7484. Mask: 0.9375. :   7%|▋         | 7/100 [00:03<00:19,  4.68it/s]Train Iter: 3508/5000. LR: 0.0140. Data: 0.26s. Batch: 0.39s. S_Loss: 0.9817. T_Loss: 4.7484. Mask: 0.9375. :   8%|▊         | 8/100 [00:03<00:17,  5.40it/s]Train Iter: 3509/5000. LR: 0.0140. Data: 0.23s. Batch: 0.39s. S_Loss: 0.9672. T_Loss: 4.7321. Mask: 0.9410. :   8%|▊         | 8/100 [00:03<00:17,  5.40it/s]Train Iter: 3509/5000. LR: 0.0140. Data: 0.23s. Batch: 0.39s. S_Loss: 0.9672. T_Loss: 4.7321. Mask: 0.9410. :   9%|▉         | 9/100 [00:03<00:22,  4.10it/s]Train Iter: 3510/5000. LR: 0.0140. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9642. T_Loss: 4.7930. Mask: 0.9437. :   9%|▉         | 9/100 [00:03<00:22,  4.10it/s]Train Iter: 3510/5000. LR: 0.0140. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9642. T_Loss: 4.7930. Mask: 0.9437. :  10%|█         | 10/100 [00:03<00:18,  4.96it/s]Train Iter: 3511/5000. LR: 0.0140. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9721. T_Loss: 4.8836. Mask: 0.9432. :  10%|█         | 10/100 [00:03<00:18,  4.96it/s]Train Iter: 3511/5000. LR: 0.0140. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9721. T_Loss: 4.8836. Mask: 0.9432. :  11%|█         | 11/100 [00:03<00:15,  5.70it/s]Train Iter: 3512/5000. LR: 0.0140. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9665. T_Loss: 4.8522. Mask: 0.9427. :  11%|█         | 11/100 [00:03<00:15,  5.70it/s]Train Iter: 3512/5000. LR: 0.0140. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9665. T_Loss: 4.8522. Mask: 0.9427. :  12%|█▏        | 12/100 [00:03<00:14,  6.28it/s]Train Iter: 3513/5000. LR: 0.0139. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9576. T_Loss: 4.7504. Mask: 0.9423. :  12%|█▏        | 12/100 [00:03<00:14,  6.28it/s]Train Iter: 3513/5000. LR: 0.0139. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9576. T_Loss: 4.7504. Mask: 0.9423. :  13%|█▎        | 13/100 [00:03<00:12,  6.76it/s]Train Iter: 3514/5000. LR: 0.0139. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9636. T_Loss: 4.8057. Mask: 0.9397. :  13%|█▎        | 13/100 [00:04<00:12,  6.76it/s]Train Iter: 3514/5000. LR: 0.0139. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9636. T_Loss: 4.8057. Mask: 0.9397. :  14%|█▍        | 14/100 [00:04<00:12,  7.08it/s]Train Iter: 3515/5000. LR: 0.0139. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9592. T_Loss: 4.7792. Mask: 0.9396. :  14%|█▍        | 14/100 [00:04<00:12,  7.08it/s]Train Iter: 3515/5000. LR: 0.0139. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9592. T_Loss: 4.7792. Mask: 0.9396. :  15%|█▌        | 15/100 [00:04<00:11,  7.45it/s]Train Iter: 3516/5000. LR: 0.0139. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9560. T_Loss: 4.7785. Mask: 0.9375. :  15%|█▌        | 15/100 [00:04<00:11,  7.45it/s]Train Iter: 3516/5000. LR: 0.0139. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9560. T_Loss: 4.7785. Mask: 0.9375. :  16%|█▌        | 16/100 [00:04<00:10,  7.68it/s]Train Iter: 3517/5000. LR: 0.0139. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9502. T_Loss: 4.7469. Mask: 0.9393. :  16%|█▌        | 16/100 [00:04<00:10,  7.68it/s]Train Iter: 3517/5000. LR: 0.0139. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9502. T_Loss: 4.7469. Mask: 0.9393. :  17%|█▋        | 17/100 [00:04<00:10,  7.83it/s]Train Iter: 3518/5000. LR: 0.0139. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.7165. Mask: 0.9358. :  17%|█▋        | 17/100 [00:04<00:10,  7.83it/s]Train Iter: 3518/5000. LR: 0.0139. Data: 0.12s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.7165. Mask: 0.9358. :  18%|█▊        | 18/100 [00:04<00:10,  7.76it/s]Train Iter: 3519/5000. LR: 0.0138. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9433. T_Loss: 4.6785. Mask: 0.9375. :  18%|█▊        | 18/100 [00:04<00:10,  7.76it/s]Train Iter: 3519/5000. LR: 0.0138. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9433. T_Loss: 4.6785. Mask: 0.9375. :  19%|█▉        | 19/100 [00:04<00:15,  5.09it/s]Train Iter: 3520/5000. LR: 0.0138. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9422. T_Loss: 4.6782. Mask: 0.9344. :  19%|█▉        | 19/100 [00:05<00:15,  5.09it/s]Train Iter: 3520/5000. LR: 0.0138. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9422. T_Loss: 4.6782. Mask: 0.9344. :  20%|██        | 20/100 [00:05<00:13,  5.73it/s]Train Iter: 3521/5000. LR: 0.0138. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9450. T_Loss: 4.6573. Mask: 0.9330. :  20%|██        | 20/100 [00:05<00:13,  5.73it/s]Train Iter: 3521/5000. LR: 0.0138. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9450. T_Loss: 4.6573. Mask: 0.9330. :  21%|██        | 21/100 [00:05<00:12,  6.30it/s]Train Iter: 3522/5000. LR: 0.0138. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.6875. Mask: 0.9347. :  21%|██        | 21/100 [00:05<00:12,  6.30it/s]Train Iter: 3522/5000. LR: 0.0138. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.6875. Mask: 0.9347. :  22%|██▏       | 22/100 [00:05<00:11,  6.75it/s]Train Iter: 3523/5000. LR: 0.0138. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9501. T_Loss: 4.7065. Mask: 0.9361. :  22%|██▏       | 22/100 [00:05<00:11,  6.75it/s]Train Iter: 3523/5000. LR: 0.0138. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9501. T_Loss: 4.7065. Mask: 0.9361. :  23%|██▎       | 23/100 [00:05<00:10,  7.18it/s]Train Iter: 3524/5000. LR: 0.0138. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9471. T_Loss: 4.6763. Mask: 0.9349. :  23%|██▎       | 23/100 [00:05<00:10,  7.18it/s]Train Iter: 3524/5000. LR: 0.0138. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9471. T_Loss: 4.6763. Mask: 0.9349. :  24%|██▍       | 24/100 [00:05<00:10,  7.45it/s]Train Iter: 3525/5000. LR: 0.0137. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9508. T_Loss: 4.7064. Mask: 0.9363. :  24%|██▍       | 24/100 [00:05<00:10,  7.45it/s]Train Iter: 3525/5000. LR: 0.0137. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9508. T_Loss: 4.7064. Mask: 0.9363. :  25%|██▌       | 25/100 [00:05<00:15,  4.95it/s]total : 5000  current step :  3501
total : 5000  current step :  3502
total : 5000  current step :  3503
total : 5000  current step :  3504
total : 5000  current step :  3505
total : 5000  current step :  3506
total : 5000  current step :  3507
total : 5000  current step :  3508
total : 5000  current step :  3509
total : 5000  current step :  3510
total : 5000  current step :  3511
total : 5000  current step :  3512
total : 5000  current step :  3513
total : 5000  current step :  3514
total : 5000  current step :  3515
total : 5000  current step :  3516
total : 5000  current step :  3517
total : 5000  current step :  3518
total : 5000  current step :  3519
total : 5000  current step :  3520
total : 5000  current step :  3521
total : 5000  current step :  3522
total : 5000  current step :  3523
total : 5000  current step :  3524
total : 5000  current step :  3525
Train Iter: 3526/5000. LR: 0.0137. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9526. T_Loss: 4.7254. Mask: 0.9375. :  25%|██▌       | 25/100 [00:07<00:15,  4.95it/s]Train Iter: 3526/5000. LR: 0.0137. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9526. T_Loss: 4.7254. Mask: 0.9375. :  26%|██▌       | 26/100 [00:07<00:56,  1.32it/s]Train Iter: 3527/5000. LR: 0.0137. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9538. T_Loss: 4.7362. Mask: 0.9375. :  26%|██▌       | 26/100 [00:08<00:56,  1.32it/s]Train Iter: 3527/5000. LR: 0.0137. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9538. T_Loss: 4.7362. Mask: 0.9375. :  27%|██▋       | 27/100 [00:08<00:41,  1.76it/s]Train Iter: 3528/5000. LR: 0.0137. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9512. T_Loss: 4.7051. Mask: 0.9386. :  27%|██▋       | 27/100 [00:08<00:41,  1.76it/s]Train Iter: 3528/5000. LR: 0.0137. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9512. T_Loss: 4.7051. Mask: 0.9386. :  28%|██▊       | 28/100 [00:08<00:31,  2.29it/s]Train Iter: 3529/5000. LR: 0.0137. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9498. T_Loss: 4.6806. Mask: 0.9397. :  28%|██▊       | 28/100 [00:08<00:31,  2.29it/s]Train Iter: 3529/5000. LR: 0.0137. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9498. T_Loss: 4.6806. Mask: 0.9397. :  29%|██▉       | 29/100 [00:08<00:28,  2.46it/s]Train Iter: 3530/5000. LR: 0.0137. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9472. T_Loss: 4.6519. Mask: 0.9385. :  29%|██▉       | 29/100 [00:08<00:28,  2.46it/s]Train Iter: 3530/5000. LR: 0.0137. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9472. T_Loss: 4.6519. Mask: 0.9385. :  30%|███       | 30/100 [00:08<00:22,  3.08it/s]Train Iter: 3531/5000. LR: 0.0136. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9468. T_Loss: 4.6630. Mask: 0.9385. :  30%|███       | 30/100 [00:08<00:22,  3.08it/s]Train Iter: 3531/5000. LR: 0.0136. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9468. T_Loss: 4.6630. Mask: 0.9385. :  31%|███       | 31/100 [00:08<00:18,  3.75it/s]Train Iter: 3532/5000. LR: 0.0136. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9459. T_Loss: 4.6332. Mask: 0.9365. :  31%|███       | 31/100 [00:08<00:18,  3.75it/s]Train Iter: 3532/5000. LR: 0.0136. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9459. T_Loss: 4.6332. Mask: 0.9365. :  32%|███▏      | 32/100 [00:08<00:15,  4.47it/s]Train Iter: 3533/5000. LR: 0.0136. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9481. T_Loss: 4.6308. Mask: 0.9366. :  32%|███▏      | 32/100 [00:09<00:15,  4.47it/s]Train Iter: 3533/5000. LR: 0.0136. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9481. T_Loss: 4.6308. Mask: 0.9366. :  33%|███▎      | 33/100 [00:09<00:13,  5.05it/s]Train Iter: 3534/5000. LR: 0.0136. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9494. T_Loss: 4.6384. Mask: 0.9366. :  33%|███▎      | 33/100 [00:09<00:13,  5.05it/s]Train Iter: 3534/5000. LR: 0.0136. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9494. T_Loss: 4.6384. Mask: 0.9366. :  34%|███▍      | 34/100 [00:09<00:11,  5.65it/s]Train Iter: 3535/5000. LR: 0.0136. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9506. T_Loss: 4.6397. Mask: 0.9375. :  34%|███▍      | 34/100 [00:09<00:11,  5.65it/s]Train Iter: 3535/5000. LR: 0.0136. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9506. T_Loss: 4.6397. Mask: 0.9375. :  35%|███▌      | 35/100 [00:09<00:16,  4.02it/s]Train Iter: 3536/5000. LR: 0.0136. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9476. T_Loss: 4.6296. Mask: 0.9384. :  35%|███▌      | 35/100 [00:09<00:16,  4.02it/s]Train Iter: 3536/5000. LR: 0.0136. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9476. T_Loss: 4.6296. Mask: 0.9384. :  36%|███▌      | 36/100 [00:09<00:13,  4.75it/s]Train Iter: 3537/5000. LR: 0.0135. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9475. T_Loss: 4.6366. Mask: 0.9392. :  36%|███▌      | 36/100 [00:09<00:13,  4.75it/s]Train Iter: 3537/5000. LR: 0.0135. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9475. T_Loss: 4.6366. Mask: 0.9392. :  37%|███▋      | 37/100 [00:09<00:12,  5.16it/s]Train Iter: 3538/5000. LR: 0.0135. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9491. T_Loss: 4.6127. Mask: 0.9367. :  37%|███▋      | 37/100 [00:10<00:12,  5.16it/s]Train Iter: 3538/5000. LR: 0.0135. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9491. T_Loss: 4.6127. Mask: 0.9367. :  38%|███▊      | 38/100 [00:10<00:10,  5.83it/s]Train Iter: 3539/5000. LR: 0.0135. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9482. T_Loss: 4.6153. Mask: 0.9359. :  38%|███▊      | 38/100 [00:10<00:10,  5.83it/s]Train Iter: 3540/5000. LR: 0.0135. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9514. T_Loss: 4.6080. Mask: 0.9359. :  39%|███▉      | 39/100 [00:10<00:10,  5.83it/s]Train Iter: 3540/5000. LR: 0.0135. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9514. T_Loss: 4.6080. Mask: 0.9359. :  40%|████      | 40/100 [00:10<00:07,  7.71it/s]Train Iter: 3541/5000. LR: 0.0135. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9509. T_Loss: 4.6144. Mask: 0.9360. :  40%|████      | 40/100 [00:10<00:07,  7.71it/s]Train Iter: 3541/5000. LR: 0.0135. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9509. T_Loss: 4.6144. Mask: 0.9360. :  41%|████      | 41/100 [00:10<00:07,  7.54it/s]Train Iter: 3542/5000. LR: 0.0135. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9530. T_Loss: 4.6103. Mask: 0.9353. :  41%|████      | 41/100 [00:10<00:07,  7.54it/s]Train Iter: 3542/5000. LR: 0.0135. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9530. T_Loss: 4.6103. Mask: 0.9353. :  42%|████▏     | 42/100 [00:10<00:07,  7.70it/s]Train Iter: 3543/5000. LR: 0.0134. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9523. T_Loss: 4.6233. Mask: 0.9368. :  42%|████▏     | 42/100 [00:10<00:07,  7.70it/s]Train Iter: 3543/5000. LR: 0.0134. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9523. T_Loss: 4.6233. Mask: 0.9368. :  43%|████▎     | 43/100 [00:10<00:07,  7.87it/s]Train Iter: 3544/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9531. T_Loss: 4.6172. Mask: 0.9368. :  43%|████▎     | 43/100 [00:10<00:07,  7.87it/s]Train Iter: 3544/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9531. T_Loss: 4.6172. Mask: 0.9368. :  44%|████▍     | 44/100 [00:10<00:06,  8.04it/s]Train Iter: 3545/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9540. T_Loss: 4.6147. Mask: 0.9347. :  44%|████▍     | 44/100 [00:10<00:06,  8.04it/s]Train Iter: 3545/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9540. T_Loss: 4.6147. Mask: 0.9347. :  45%|████▌     | 45/100 [00:10<00:08,  6.38it/s]Train Iter: 3546/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9551. T_Loss: 4.6206. Mask: 0.9341. :  45%|████▌     | 45/100 [00:11<00:08,  6.38it/s]Train Iter: 3546/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9551. T_Loss: 4.6206. Mask: 0.9341. :  46%|████▌     | 46/100 [00:11<00:07,  6.82it/s]Train Iter: 3547/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9546. T_Loss: 4.5932. Mask: 0.9322. :  46%|████▌     | 46/100 [00:11<00:07,  6.82it/s]Train Iter: 3547/5000. LR: 0.0134. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9546. T_Loss: 4.5932. Mask: 0.9322. :  47%|████▋     | 47/100 [00:11<00:07,  6.96it/s]Train Iter: 3548/5000. LR: 0.0134. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9543. T_Loss: 4.6007. Mask: 0.9329. :  47%|████▋     | 47/100 [00:11<00:07,  6.96it/s]Train Iter: 3548/5000. LR: 0.0134. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9543. T_Loss: 4.6007. Mask: 0.9329. :  48%|████▊     | 48/100 [00:11<00:07,  7.36it/s]Train Iter: 3549/5000. LR: 0.0133. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9560. T_Loss: 4.6105. Mask: 0.9330. :  48%|████▊     | 48/100 [00:11<00:07,  7.36it/s]Train Iter: 3549/5000. LR: 0.0133. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9560. T_Loss: 4.6105. Mask: 0.9330. :  49%|████▉     | 49/100 [00:11<00:11,  4.63it/s]Train Iter: 3550/5000. LR: 0.0133. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9562. T_Loss: 4.6254. Mask: 0.9344. :  49%|████▉     | 49/100 [00:11<00:11,  4.63it/s]Train Iter: 3550/5000. LR: 0.0133. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9562. T_Loss: 4.6254. Mask: 0.9344. :  50%|█████     | 50/100 [00:11<00:09,  5.36it/s]total : 5000  current step :  3526
total : 5000  current step :  3527
total : 5000  current step :  3528
total : 5000  current step :  3529
total : 5000  current step :  3530
total : 5000  current step :  3531
total : 5000  current step :  3532
total : 5000  current step :  3533
total : 5000  current step :  3534
total : 5000  current step :  3535
total : 5000  current step :  3536
total : 5000  current step :  3537
total : 5000  current step :  3538
total : 5000  current step :  3539
total : 5000  current step :  3540
total : 5000  current step :  3541
total : 5000  current step :  3542
total : 5000  current step :  3543
total : 5000  current step :  3544
total : 5000  current step :  3545
total : 5000  current step :  3546
total : 5000  current step :  3547
total : 5000  current step :  3548
total : 5000  current step :  3549
total : 5000  current step :  3550
Train Iter: 3551/5000. LR: 0.0133. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9588. T_Loss: 4.6226. Mask: 0.9320. :  50%|█████     | 50/100 [00:14<00:09,  5.36it/s]Train Iter: 3551/5000. LR: 0.0133. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9588. T_Loss: 4.6226. Mask: 0.9320. :  51%|█████     | 51/100 [00:14<00:39,  1.23it/s]Train Iter: 3552/5000. LR: 0.0133. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9609. T_Loss: 4.6484. Mask: 0.9315. :  51%|█████     | 51/100 [00:14<00:39,  1.23it/s]Train Iter: 3552/5000. LR: 0.0133. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9609. T_Loss: 4.6484. Mask: 0.9315. :  52%|█████▏    | 52/100 [00:14<00:29,  1.64it/s]Train Iter: 3553/5000. LR: 0.0133. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9591. T_Loss: 4.6451. Mask: 0.9310. :  52%|█████▏    | 52/100 [00:14<00:29,  1.64it/s]Train Iter: 3553/5000. LR: 0.0133. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9591. T_Loss: 4.6451. Mask: 0.9310. :  53%|█████▎    | 53/100 [00:14<00:21,  2.15it/s]Train Iter: 3554/5000. LR: 0.0133. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9586. T_Loss: 4.6449. Mask: 0.9311. :  53%|█████▎    | 53/100 [00:14<00:21,  2.15it/s]Train Iter: 3554/5000. LR: 0.0133. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9586. T_Loss: 4.6449. Mask: 0.9311. :  54%|█████▍    | 54/100 [00:14<00:16,  2.76it/s]Train Iter: 3555/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9604. T_Loss: 4.6409. Mask: 0.9307. :  54%|█████▍    | 54/100 [00:14<00:16,  2.76it/s]Train Iter: 3555/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9604. T_Loss: 4.6409. Mask: 0.9307. :  55%|█████▌    | 55/100 [00:14<00:13,  3.41it/s]Train Iter: 3556/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9587. T_Loss: 4.6474. Mask: 0.9308. :  55%|█████▌    | 55/100 [00:14<00:13,  3.41it/s]Train Iter: 3556/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9587. T_Loss: 4.6474. Mask: 0.9308. :  56%|█████▌    | 56/100 [00:14<00:10,  4.13it/s]Train Iter: 3557/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9573. T_Loss: 4.6385. Mask: 0.9304. :  56%|█████▌    | 56/100 [00:14<00:10,  4.13it/s]Train Iter: 3557/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9573. T_Loss: 4.6385. Mask: 0.9304. :  57%|█████▋    | 57/100 [00:14<00:08,  4.92it/s]Train Iter: 3558/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9555. T_Loss: 4.6285. Mask: 0.9305. :  57%|█████▋    | 57/100 [00:14<00:08,  4.92it/s]Train Iter: 3558/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9555. T_Loss: 4.6285. Mask: 0.9305. :  58%|█████▊    | 58/100 [00:14<00:07,  5.59it/s]Train Iter: 3559/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9547. T_Loss: 4.6224. Mask: 0.9296. :  58%|█████▊    | 58/100 [00:15<00:07,  5.59it/s]Train Iter: 3559/5000. LR: 0.0132. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9547. T_Loss: 4.6224. Mask: 0.9296. :  59%|█████▉    | 59/100 [00:15<00:08,  4.93it/s]Train Iter: 3560/5000. LR: 0.0132. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9567. T_Loss: 4.6384. Mask: 0.9297. :  59%|█████▉    | 59/100 [00:15<00:08,  4.93it/s]Train Iter: 3560/5000. LR: 0.0132. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9567. T_Loss: 4.6384. Mask: 0.9297. :  60%|██████    | 60/100 [00:15<00:07,  5.54it/s]Train Iter: 3561/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9554. T_Loss: 4.6288. Mask: 0.9288. :  60%|██████    | 60/100 [00:15<00:07,  5.54it/s]Train Iter: 3561/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9554. T_Loss: 4.6288. Mask: 0.9288. :  61%|██████    | 61/100 [00:15<00:06,  5.94it/s]Train Iter: 3562/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9566. T_Loss: 4.6244. Mask: 0.9274. :  61%|██████    | 61/100 [00:15<00:06,  5.94it/s]Train Iter: 3562/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9566. T_Loss: 4.6244. Mask: 0.9274. :  62%|██████▏   | 62/100 [00:15<00:05,  6.49it/s]Train Iter: 3563/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9566. T_Loss: 4.6170. Mask: 0.9271. :  62%|██████▏   | 62/100 [00:15<00:05,  6.49it/s]Train Iter: 3563/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9566. T_Loss: 4.6170. Mask: 0.9271. :  63%|██████▎   | 63/100 [00:15<00:05,  6.92it/s]Train Iter: 3564/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9567. T_Loss: 4.6200. Mask: 0.9277. :  63%|██████▎   | 63/100 [00:15<00:05,  6.92it/s]Train Iter: 3564/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9567. T_Loss: 4.6200. Mask: 0.9277. :  64%|██████▍   | 64/100 [00:15<00:05,  7.16it/s]Train Iter: 3565/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9560. T_Loss: 4.6073. Mask: 0.9274. :  64%|██████▍   | 64/100 [00:16<00:05,  7.16it/s]Train Iter: 3565/5000. LR: 0.0131. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9560. T_Loss: 4.6073. Mask: 0.9274. :  65%|██████▌   | 65/100 [00:16<00:06,  5.82it/s]Train Iter: 3566/5000. LR: 0.0131. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9559. T_Loss: 4.6093. Mask: 0.9280. :  65%|██████▌   | 65/100 [00:16<00:06,  5.82it/s]Train Iter: 3566/5000. LR: 0.0131. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9559. T_Loss: 4.6093. Mask: 0.9280. :  66%|██████▌   | 66/100 [00:16<00:05,  6.25it/s]Train Iter: 3567/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9545. T_Loss: 4.5997. Mask: 0.9277. :  66%|██████▌   | 66/100 [00:16<00:05,  6.25it/s]Train Iter: 3567/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9545. T_Loss: 4.5997. Mask: 0.9277. :  67%|██████▋   | 67/100 [00:16<00:04,  6.87it/s]Train Iter: 3568/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9528. T_Loss: 4.5988. Mask: 0.9283. :  67%|██████▋   | 67/100 [00:16<00:04,  6.87it/s]Train Iter: 3568/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9528. T_Loss: 4.5988. Mask: 0.9283. :  68%|██████▊   | 68/100 [00:16<00:04,  7.07it/s]Train Iter: 3569/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9556. T_Loss: 4.5949. Mask: 0.9266. :  68%|██████▊   | 68/100 [00:16<00:04,  7.07it/s]Train Iter: 3569/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9556. T_Loss: 4.5949. Mask: 0.9266. :  69%|██████▉   | 69/100 [00:16<00:04,  6.48it/s]Train Iter: 3570/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9546. T_Loss: 4.5922. Mask: 0.9263. :  69%|██████▉   | 69/100 [00:16<00:04,  6.48it/s]Train Iter: 3570/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9546. T_Loss: 4.5922. Mask: 0.9263. :  70%|███████   | 70/100 [00:16<00:04,  6.94it/s]Train Iter: 3571/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9557. T_Loss: 4.6098. Mask: 0.9265. :  70%|███████   | 70/100 [00:16<00:04,  6.94it/s]Train Iter: 3571/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9557. T_Loss: 4.6098. Mask: 0.9265. :  71%|███████   | 71/100 [00:16<00:04,  6.98it/s]Train Iter: 3572/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9557. T_Loss: 4.6126. Mask: 0.9271. :  71%|███████   | 71/100 [00:17<00:04,  6.98it/s]Train Iter: 3572/5000. LR: 0.0130. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9557. T_Loss: 4.6126. Mask: 0.9271. :  72%|███████▏  | 72/100 [00:17<00:03,  7.31it/s]Train Iter: 3573/5000. LR: 0.0129. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9553. T_Loss: 4.6056. Mask: 0.9264. :  72%|███████▏  | 72/100 [00:17<00:03,  7.31it/s]Train Iter: 3573/5000. LR: 0.0129. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9553. T_Loss: 4.6056. Mask: 0.9264. :  73%|███████▎  | 73/100 [00:17<00:03,  7.55it/s]Train Iter: 3574/5000. LR: 0.0129. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9541. T_Loss: 4.6003. Mask: 0.9261. :  73%|███████▎  | 73/100 [00:17<00:03,  7.55it/s]Train Iter: 3574/5000. LR: 0.0129. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9541. T_Loss: 4.6003. Mask: 0.9261. :  74%|███████▍  | 74/100 [00:17<00:03,  7.77it/s]Train Iter: 3575/5000. LR: 0.0129. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9542. T_Loss: 4.6012. Mask: 0.9254. :  74%|███████▍  | 74/100 [00:17<00:03,  7.77it/s]Train Iter: 3575/5000. LR: 0.0129. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9542. T_Loss: 4.6012. Mask: 0.9254. :  75%|███████▌  | 75/100 [00:17<00:03,  6.45it/s]total : 5000  current step :  3551
total : 5000  current step :  3552
total : 5000  current step :  3553
total : 5000  current step :  3554
total : 5000  current step :  3555
total : 5000  current step :  3556
total : 5000  current step :  3557
total : 5000  current step :  3558
total : 5000  current step :  3559
total : 5000  current step :  3560
total : 5000  current step :  3561
total : 5000  current step :  3562
total : 5000  current step :  3563
total : 5000  current step :  3564
total : 5000  current step :  3565
total : 5000  current step :  3566
total : 5000  current step :  3567
total : 5000  current step :  3568
total : 5000  current step :  3569
total : 5000  current step :  3570
total : 5000  current step :  3571
total : 5000  current step :  3572
total : 5000  current step :  3573
total : 5000  current step :  3574
total : 5000  current step :  3575
Train Iter: 3576/5000. LR: 0.0129. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9543. T_Loss: 4.6114. Mask: 0.9252. :  75%|███████▌  | 75/100 [00:19<00:03,  6.45it/s]Train Iter: 3576/5000. LR: 0.0129. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9543. T_Loss: 4.6114. Mask: 0.9252. :  76%|███████▌  | 76/100 [00:19<00:19,  1.23it/s]Train Iter: 3577/5000. LR: 0.0129. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9539. T_Loss: 4.6174. Mask: 0.9249. :  76%|███████▌  | 76/100 [00:20<00:19,  1.23it/s]Train Iter: 3577/5000. LR: 0.0129. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9539. T_Loss: 4.6174. Mask: 0.9249. :  77%|███████▋  | 77/100 [00:20<00:14,  1.64it/s]Train Iter: 3578/5000. LR: 0.0129. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9545. T_Loss: 4.6332. Mask: 0.9251. :  77%|███████▋  | 77/100 [00:20<00:14,  1.64it/s]Train Iter: 3578/5000. LR: 0.0129. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9545. T_Loss: 4.6332. Mask: 0.9251. :  78%|███████▊  | 78/100 [00:20<00:10,  2.13it/s]Train Iter: 3579/5000. LR: 0.0128. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9540. T_Loss: 4.6251. Mask: 0.9244. :  78%|███████▊  | 78/100 [00:20<00:10,  2.13it/s]Train Iter: 3579/5000. LR: 0.0128. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9540. T_Loss: 4.6251. Mask: 0.9244. :  79%|███████▉  | 79/100 [00:20<00:08,  2.42it/s]Train Iter: 3580/5000. LR: 0.0128. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9531. T_Loss: 4.6243. Mask: 0.9246. :  79%|███████▉  | 79/100 [00:20<00:08,  2.42it/s]Train Iter: 3580/5000. LR: 0.0128. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9531. T_Loss: 4.6243. Mask: 0.9246. :  80%|████████  | 80/100 [00:20<00:06,  3.07it/s]Train Iter: 3581/5000. LR: 0.0128. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9532. T_Loss: 4.6265. Mask: 0.9248. :  80%|████████  | 80/100 [00:20<00:06,  3.07it/s]Train Iter: 3581/5000. LR: 0.0128. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9532. T_Loss: 4.6265. Mask: 0.9248. :  81%|████████  | 81/100 [00:20<00:04,  3.82it/s]Train Iter: 3582/5000. LR: 0.0128. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9518. T_Loss: 4.6305. Mask: 0.9249. :  81%|████████  | 81/100 [00:20<00:04,  3.82it/s]Train Iter: 3582/5000. LR: 0.0128. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9518. T_Loss: 4.6305. Mask: 0.9249. :  82%|████████▏ | 82/100 [00:20<00:03,  4.54it/s]Train Iter: 3583/5000. LR: 0.0128. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9505. T_Loss: 4.6246. Mask: 0.9243. :  82%|████████▏ | 82/100 [00:20<00:03,  4.54it/s]Train Iter: 3583/5000. LR: 0.0128. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9505. T_Loss: 4.6246. Mask: 0.9243. :  83%|████████▎ | 83/100 [00:20<00:03,  5.24it/s]Train Iter: 3584/5000. LR: 0.0128. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9494. T_Loss: 4.6251. Mask: 0.9249. :  83%|████████▎ | 83/100 [00:21<00:03,  5.24it/s]Train Iter: 3584/5000. LR: 0.0128. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9494. T_Loss: 4.6251. Mask: 0.9249. :  84%|████████▍ | 84/100 [00:21<00:02,  5.89it/s]Train Iter: 3585/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.6288. Mask: 0.9254. :  84%|████████▍ | 84/100 [00:21<00:02,  5.89it/s]Train Iter: 3585/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.6288. Mask: 0.9254. :  85%|████████▌ | 85/100 [00:21<00:03,  4.43it/s]Train Iter: 3586/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.6206. Mask: 0.9241. :  85%|████████▌ | 85/100 [00:21<00:03,  4.43it/s]Train Iter: 3586/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.6206. Mask: 0.9241. :  86%|████████▌ | 86/100 [00:21<00:02,  5.15it/s]Train Iter: 3587/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9525. T_Loss: 4.6381. Mask: 0.9239. :  86%|████████▌ | 86/100 [00:21<00:02,  5.15it/s]Train Iter: 3587/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9525. T_Loss: 4.6381. Mask: 0.9239. :  87%|████████▋ | 87/100 [00:21<00:02,  5.86it/s]Train Iter: 3588/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9530. T_Loss: 4.6397. Mask: 0.9240. :  87%|████████▋ | 87/100 [00:21<00:02,  5.86it/s]Train Iter: 3588/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9530. T_Loss: 4.6397. Mask: 0.9240. :  88%|████████▊ | 88/100 [00:21<00:01,  6.44it/s]Train Iter: 3589/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9550. T_Loss: 4.6443. Mask: 0.9235. :  88%|████████▊ | 88/100 [00:22<00:01,  6.44it/s]Train Iter: 3589/5000. LR: 0.0127. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9550. T_Loss: 4.6443. Mask: 0.9235. :  89%|████████▉ | 89/100 [00:22<00:02,  5.31it/s]Train Iter: 3590/5000. LR: 0.0127. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9552. T_Loss: 4.6532. Mask: 0.9236. :  89%|████████▉ | 89/100 [00:22<00:02,  5.31it/s]Train Iter: 3590/5000. LR: 0.0127. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9552. T_Loss: 4.6532. Mask: 0.9236. :  90%|█████████ | 90/100 [00:22<00:01,  5.88it/s]Train Iter: 3591/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9547. T_Loss: 4.6534. Mask: 0.9238. :  90%|█████████ | 90/100 [00:22<00:01,  5.88it/s]Train Iter: 3591/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9547. T_Loss: 4.6534. Mask: 0.9238. :  91%|█████████ | 91/100 [00:22<00:01,  6.37it/s]Train Iter: 3592/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9551. T_Loss: 4.6614. Mask: 0.9243. :  91%|█████████ | 91/100 [00:22<00:01,  6.37it/s]Train Iter: 3592/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9551. T_Loss: 4.6614. Mask: 0.9243. :  92%|█████████▏| 92/100 [00:22<00:01,  6.80it/s]Train Iter: 3593/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9553. T_Loss: 4.6582. Mask: 0.9234. :  92%|█████████▏| 92/100 [00:22<00:01,  6.80it/s]Train Iter: 3593/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9553. T_Loss: 4.6582. Mask: 0.9234. :  93%|█████████▎| 93/100 [00:22<00:00,  7.22it/s]Train Iter: 3594/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9542. T_Loss: 4.6509. Mask: 0.9235. :  93%|█████████▎| 93/100 [00:22<00:00,  7.22it/s]Train Iter: 3594/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9542. T_Loss: 4.6509. Mask: 0.9235. :  94%|█████████▍| 94/100 [00:22<00:00,  7.40it/s]Train Iter: 3595/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9539. T_Loss: 4.6472. Mask: 0.9237. :  94%|█████████▍| 94/100 [00:22<00:00,  7.40it/s]Train Iter: 3595/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9539. T_Loss: 4.6472. Mask: 0.9237. :  95%|█████████▌| 95/100 [00:22<00:00,  5.55it/s]Train Iter: 3596/5000. LR: 0.0126. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9533. T_Loss: 4.6487. Mask: 0.9242. :  95%|█████████▌| 95/100 [00:23<00:00,  5.55it/s]Train Iter: 3597/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9556. T_Loss: 4.6672. Mask: 0.9243. :  96%|█████████▌| 96/100 [00:23<00:00,  5.55it/s]Train Iter: 3597/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9556. T_Loss: 4.6672. Mask: 0.9243. :  97%|█████████▋| 97/100 [00:23<00:00,  6.98it/s]Train Iter: 3598/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9548. T_Loss: 4.6748. Mask: 0.9251. :  97%|█████████▋| 97/100 [00:23<00:00,  6.98it/s]Train Iter: 3598/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9548. T_Loss: 4.6748. Mask: 0.9251. :  98%|█████████▊| 98/100 [00:23<00:00,  7.31it/s]Train Iter: 3599/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9543. T_Loss: 4.6685. Mask: 0.9242. :  98%|█████████▊| 98/100 [00:23<00:00,  7.31it/s]Train Iter: 3599/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9543. T_Loss: 4.6685. Mask: 0.9242. :  99%|█████████▉| 99/100 [00:23<00:00,  5.38it/s]Train Iter: 3600/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9542. T_Loss: 4.6712. Mask: 0.9247. :  99%|█████████▉| 99/100 [00:23<00:00,  5.38it/s]Train Iter: 3600/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9542. T_Loss: 4.6712. Mask: 0.9247. : 100%|██████████| 100/100 [00:23<00:00,  5.86it/s]Train Iter: 3600/5000. LR: 0.0125. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9542. T_Loss: 4.6712. Mask: 0.9247. : 100%|██████████| 100/100 [00:23<00:00,  4.22it/s]
total : 5000  current step :  3576
total : 5000  current step :  3577
total : 5000  current step :  3578
total : 5000  current step :  3579
total : 5000  current step :  3580
total : 5000  current step :  3581
total : 5000  current step :  3582
total : 5000  current step :  3583
total : 5000  current step :  3584
total : 5000  current step :  3585
total : 5000  current step :  3586
total : 5000  current step :  3587
total : 5000  current step :  3588
total : 5000  current step :  3589
total : 5000  current step :  3590
total : 5000  current step :  3591
total : 5000  current step :  3592
total : 5000  current step :  3593
total : 5000  current step :  3594
total : 5000  current step :  3595
total : 5000  current step :  3596
total : 5000  current step :  3597
total : 5000  current step :  3598
total : 5000  current step :  3599
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.79s. Loss: 0.8794. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.79s. Loss: 0.8794. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 0.8751. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.8444. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.8487. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8380. top1: 91.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.79s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8380. top1: 91.88. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8373. top1: 91.67. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8500. top1: 90.62. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8485. top1: 90.23. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8452. top1: 90.28. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8500. top1: 90.31. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8405. top1: 91.19. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8404. top1: 91.15. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8357. top1: 91.11. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8319. top1: 91.52. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.46it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8306. top1: 91.67. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:16,  3.46it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8306. top1: 91.67. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8311. top1: 91.80. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8295. top1: 91.54. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8295. top1: 91.67. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8285. top1: 91.78. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8279. top1: 91.88. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8310. top1: 91.96. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8286. top1: 92.19. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8256. top1: 92.53. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8237. top1: 92.71. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.57it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8237. top1: 92.71. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8213. top1: 92.88. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8251. top1: 92.79. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8255. top1: 92.82. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8288. top1: 92.75. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8263. top1: 92.89. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8261. top1: 92.81. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8260. top1: 92.84. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8472. top1: 91.70. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8593. top1: 91.10. top5: 99.91. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8736. top1: 90.17. top5: 99.82. :  38%|███▊      | 24/63 [00:02<00:01, 21.62it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8736. top1: 90.17. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8896. top1: 89.20. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9168. top1: 87.93. top5: 99.65. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9250. top1: 87.33. top5: 99.66. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9373. top1: 86.51. top5: 99.67. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9534. top1: 85.82. top5: 99.44. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9661. top1: 85.08. top5: 99.45. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9740. top1: 84.68. top5: 99.39. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9903. top1: 83.85. top5: 99.40. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0007. top1: 83.36. top5: 99.42. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0074. top1: 82.95. top5: 99.43. :  54%|█████▍    | 34/63 [00:02<00:00, 32.78it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0074. top1: 82.95. top5: 99.43. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0116. top1: 82.64. top5: 99.44. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0199. top1: 81.93. top5: 99.46. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0279. top1: 81.52. top5: 99.47. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0341. top1: 81.12. top5: 99.48. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0424. top1: 80.93. top5: 99.36. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0477. top1: 80.56. top5: 99.31. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0624. top1: 79.78. top5: 99.33. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0670. top1: 79.51. top5: 99.28. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0769. top1: 79.07. top5: 99.23. :  70%|██████▉   | 44/63 [00:02<00:00, 43.85it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0769. top1: 79.07. top5: 99.23. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0871. top1: 78.59. top5: 99.19. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0909. top1: 78.12. top5: 99.20. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0953. top1: 77.90. top5: 99.22. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1059. top1: 77.36. top5: 99.18. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1144. top1: 76.78. top5: 99.19. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1211. top1: 76.32. top5: 99.15. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1214. top1: 76.41. top5: 99.17. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1296. top1: 75.97. top5: 99.13. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1398. top1: 75.35. top5: 99.14. :  84%|████████▍ | 53/63 [00:02<00:00, 51.92it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1398. top1: 75.35. top5: 99.14. :  98%|█████████▊| 62/63 [00:02<00:00, 58.90it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1411. top1: 75.30. top5: 99.15. :  98%|█████████▊| 62/63 [00:02<00:00, 58.90it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1411. top1: 75.30. top5: 99.15. : 100%|██████████| 63/63 [00:02<00:00, 22.72it/s]
total : 5000  current step :  3600
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3601/5000. LR: 0.0125. Data: 1.77s. Batch: 1.90s. S_Loss: 0.8641. T_Loss: 4.0611. Mask: 0.9062. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 3601/5000. LR: 0.0125. Data: 1.77s. Batch: 1.90s. S_Loss: 0.8641. T_Loss: 4.0611. Mask: 0.9062. :   1%|          | 1/100 [00:01<03:07,  1.90s/it]Train Iter: 3602/5000. LR: 0.0125. Data: 0.89s. Batch: 1.01s. S_Loss: 0.9056. T_Loss: 4.3303. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:07,  1.90s/it]Train Iter: 3602/5000. LR: 0.0125. Data: 0.89s. Batch: 1.01s. S_Loss: 0.9056. T_Loss: 4.3303. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:23,  1.17it/s]Train Iter: 3603/5000. LR: 0.0125. Data: 0.59s. Batch: 0.71s. S_Loss: 0.9792. T_Loss: 4.6590. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:23,  1.17it/s]Train Iter: 3603/5000. LR: 0.0125. Data: 0.59s. Batch: 0.71s. S_Loss: 0.9792. T_Loss: 4.6590. Mask: 0.9167. :   3%|▎         | 3/100 [00:02<00:50,  1.93it/s]Train Iter: 3604/5000. LR: 0.0124. Data: 0.45s. Batch: 0.56s. S_Loss: 0.9455. T_Loss: 4.3837. Mask: 0.8984. :   3%|▎         | 3/100 [00:02<00:50,  1.93it/s]Train Iter: 3604/5000. LR: 0.0124. Data: 0.45s. Batch: 0.56s. S_Loss: 0.9455. T_Loss: 4.3837. Mask: 0.8984. :   4%|▍         | 4/100 [00:02<00:34,  2.77it/s]Train Iter: 3605/5000. LR: 0.0124. Data: 0.36s. Batch: 0.52s. S_Loss: 0.9401. T_Loss: 4.3555. Mask: 0.8938. :   4%|▍         | 4/100 [00:02<00:34,  2.77it/s]Train Iter: 3605/5000. LR: 0.0124. Data: 0.36s. Batch: 0.52s. S_Loss: 0.9401. T_Loss: 4.3555. Mask: 0.8938. :   5%|▌         | 5/100 [00:02<00:33,  2.87it/s]Train Iter: 3606/5000. LR: 0.0124. Data: 0.30s. Batch: 0.45s. S_Loss: 0.9286. T_Loss: 4.3916. Mask: 0.9062. :   5%|▌         | 5/100 [00:02<00:33,  2.87it/s]Train Iter: 3606/5000. LR: 0.0124. Data: 0.30s. Batch: 0.45s. S_Loss: 0.9286. T_Loss: 4.3916. Mask: 0.9062. :   6%|▌         | 6/100 [00:02<00:25,  3.66it/s]Train Iter: 3607/5000. LR: 0.0124. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9213. T_Loss: 4.3851. Mask: 0.9107. :   6%|▌         | 6/100 [00:02<00:25,  3.66it/s]Train Iter: 3607/5000. LR: 0.0124. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9213. T_Loss: 4.3851. Mask: 0.9107. :   7%|▋         | 7/100 [00:02<00:21,  4.30it/s]Train Iter: 3608/5000. LR: 0.0124. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9370. T_Loss: 4.4567. Mask: 0.9141. :   7%|▋         | 7/100 [00:02<00:21,  4.30it/s]Train Iter: 3608/5000. LR: 0.0124. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9370. T_Loss: 4.4567. Mask: 0.9141. :   8%|▊         | 8/100 [00:02<00:18,  5.03it/s]Train Iter: 3609/5000. LR: 0.0124. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9435. T_Loss: 4.4696. Mask: 0.9167. :   8%|▊         | 8/100 [00:03<00:18,  5.03it/s]Train Iter: 3609/5000. LR: 0.0124. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9435. T_Loss: 4.4696. Mask: 0.9167. :   9%|▉         | 9/100 [00:03<00:16,  5.38it/s]Train Iter: 3610/5000. LR: 0.0123. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9514. T_Loss: 4.4892. Mask: 0.9125. :   9%|▉         | 9/100 [00:03<00:16,  5.38it/s]Train Iter: 3610/5000. LR: 0.0123. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9514. T_Loss: 4.4892. Mask: 0.9125. :  10%|█         | 10/100 [00:03<00:15,  6.00it/s]Train Iter: 3611/5000. LR: 0.0123. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9481. T_Loss: 4.4221. Mask: 0.9062. :  10%|█         | 10/100 [00:03<00:15,  6.00it/s]Train Iter: 3611/5000. LR: 0.0123. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9481. T_Loss: 4.4221. Mask: 0.9062. :  11%|█         | 11/100 [00:03<00:13,  6.55it/s]Train Iter: 3612/5000. LR: 0.0123. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9532. T_Loss: 4.3836. Mask: 0.9036. :  11%|█         | 11/100 [00:03<00:13,  6.55it/s]Train Iter: 3612/5000. LR: 0.0123. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9532. T_Loss: 4.3836. Mask: 0.9036. :  12%|█▏        | 12/100 [00:03<00:12,  6.88it/s]Train Iter: 3613/5000. LR: 0.0123. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9611. T_Loss: 4.4240. Mask: 0.9014. :  12%|█▏        | 12/100 [00:03<00:12,  6.88it/s]Train Iter: 3613/5000. LR: 0.0123. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9611. T_Loss: 4.4240. Mask: 0.9014. :  13%|█▎        | 13/100 [00:03<00:12,  7.06it/s]Train Iter: 3614/5000. LR: 0.0123. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9576. T_Loss: 4.4322. Mask: 0.9040. :  13%|█▎        | 13/100 [00:03<00:12,  7.06it/s]Train Iter: 3614/5000. LR: 0.0123. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9576. T_Loss: 4.4322. Mask: 0.9040. :  14%|█▍        | 14/100 [00:03<00:12,  7.03it/s]Train Iter: 3615/5000. LR: 0.0123. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9592. T_Loss: 4.4491. Mask: 0.9021. :  14%|█▍        | 14/100 [00:04<00:12,  7.03it/s]Train Iter: 3615/5000. LR: 0.0123. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9592. T_Loss: 4.4491. Mask: 0.9021. :  15%|█▌        | 15/100 [00:04<00:14,  5.69it/s]Train Iter: 3616/5000. LR: 0.0122. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9639. T_Loss: 4.4950. Mask: 0.9062. :  15%|█▌        | 15/100 [00:04<00:14,  5.69it/s]Train Iter: 3616/5000. LR: 0.0122. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9639. T_Loss: 4.4950. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:13,  6.14it/s]Train Iter: 3617/5000. LR: 0.0122. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.5562. Mask: 0.9118. :  16%|█▌        | 16/100 [00:04<00:13,  6.14it/s]Train Iter: 3617/5000. LR: 0.0122. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9625. T_Loss: 4.5562. Mask: 0.9118. :  17%|█▋        | 17/100 [00:04<00:12,  6.63it/s]Train Iter: 3618/5000. LR: 0.0122. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.5176. Mask: 0.9097. :  17%|█▋        | 17/100 [00:04<00:12,  6.63it/s]Train Iter: 3618/5000. LR: 0.0122. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.5176. Mask: 0.9097. :  18%|█▊        | 18/100 [00:04<00:11,  6.93it/s]Train Iter: 3619/5000. LR: 0.0122. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9714. T_Loss: 4.5435. Mask: 0.9062. :  18%|█▊        | 18/100 [00:04<00:11,  6.93it/s]Train Iter: 3619/5000. LR: 0.0122. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9714. T_Loss: 4.5435. Mask: 0.9062. :  19%|█▉        | 19/100 [00:04<00:16,  4.88it/s]Train Iter: 3620/5000. LR: 0.0122. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9666. T_Loss: 4.4923. Mask: 0.9062. :  19%|█▉        | 19/100 [00:04<00:16,  4.88it/s]Train Iter: 3620/5000. LR: 0.0122. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9666. T_Loss: 4.4923. Mask: 0.9062. :  20%|██        | 20/100 [00:04<00:14,  5.53it/s]Train Iter: 3621/5000. LR: 0.0122. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9670. T_Loss: 4.5168. Mask: 0.9077. :  20%|██        | 20/100 [00:05<00:14,  5.53it/s]Train Iter: 3621/5000. LR: 0.0122. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9670. T_Loss: 4.5168. Mask: 0.9077. :  21%|██        | 21/100 [00:05<00:13,  6.07it/s]Train Iter: 3622/5000. LR: 0.0121. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9665. T_Loss: 4.5413. Mask: 0.9119. :  21%|██        | 21/100 [00:05<00:13,  6.07it/s]Train Iter: 3623/5000. LR: 0.0121. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9743. T_Loss: 4.6068. Mask: 0.9130. :  22%|██▏       | 22/100 [00:05<00:12,  6.07it/s]Train Iter: 3623/5000. LR: 0.0121. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9743. T_Loss: 4.6068. Mask: 0.9130. :  23%|██▎       | 23/100 [00:05<00:10,  7.45it/s]Train Iter: 3624/5000. LR: 0.0121. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9679. T_Loss: 4.5702. Mask: 0.9128. :  23%|██▎       | 23/100 [00:05<00:10,  7.45it/s]Train Iter: 3624/5000. LR: 0.0121. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9679. T_Loss: 4.5702. Mask: 0.9128. :  24%|██▍       | 24/100 [00:05<00:10,  7.53it/s]Train Iter: 3625/5000. LR: 0.0121. Data: 0.07s. Batch: 0.22s. S_Loss: 0.9647. T_Loss: 4.5410. Mask: 0.9137. :  24%|██▍       | 24/100 [00:05<00:10,  7.53it/s]Train Iter: 3625/5000. LR: 0.0121. Data: 0.07s. Batch: 0.22s. S_Loss: 0.9647. T_Loss: 4.5410. Mask: 0.9137. :  25%|██▌       | 25/100 [00:05<00:12,  6.25it/s]total : 5000  current step :  3601
total : 5000  current step :  3602
total : 5000  current step :  3603
total : 5000  current step :  3604
total : 5000  current step :  3605
total : 5000  current step :  3606
total : 5000  current step :  3607
total : 5000  current step :  3608
total : 5000  current step :  3609
total : 5000  current step :  3610
total : 5000  current step :  3611
total : 5000  current step :  3612
total : 5000  current step :  3613
total : 5000  current step :  3614
total : 5000  current step :  3615
total : 5000  current step :  3616
total : 5000  current step :  3617
total : 5000  current step :  3618
total : 5000  current step :  3619
total : 5000  current step :  3620
total : 5000  current step :  3621
total : 5000  current step :  3622
total : 5000  current step :  3623
total : 5000  current step :  3624
total : 5000  current step :  3625
Train Iter: 3626/5000. LR: 0.0121. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9642. T_Loss: 4.5502. Mask: 0.9159. :  25%|██▌       | 25/100 [00:07<00:12,  6.25it/s]Train Iter: 3626/5000. LR: 0.0121. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9642. T_Loss: 4.5502. Mask: 0.9159. :  26%|██▌       | 26/100 [00:07<00:52,  1.42it/s]Train Iter: 3627/5000. LR: 0.0121. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9649. T_Loss: 4.5584. Mask: 0.9155. :  26%|██▌       | 26/100 [00:07<00:52,  1.42it/s]Train Iter: 3627/5000. LR: 0.0121. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9649. T_Loss: 4.5584. Mask: 0.9155. :  27%|██▋       | 27/100 [00:07<00:39,  1.83it/s]Train Iter: 3628/5000. LR: 0.0120. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9651. T_Loss: 4.5609. Mask: 0.9152. :  27%|██▋       | 27/100 [00:08<00:39,  1.83it/s]Train Iter: 3628/5000. LR: 0.0120. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9651. T_Loss: 4.5609. Mask: 0.9152. :  28%|██▊       | 28/100 [00:08<00:32,  2.25it/s]Train Iter: 3629/5000. LR: 0.0120. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9656. T_Loss: 4.5590. Mask: 0.9159. :  28%|██▊       | 28/100 [00:08<00:32,  2.25it/s]Train Iter: 3629/5000. LR: 0.0120. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9656. T_Loss: 4.5590. Mask: 0.9159. :  29%|██▉       | 29/100 [00:08<00:29,  2.45it/s]Train Iter: 3630/5000. LR: 0.0120. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9642. T_Loss: 4.5784. Mask: 0.9177. :  29%|██▉       | 29/100 [00:08<00:29,  2.45it/s]Train Iter: 3630/5000. LR: 0.0120. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9642. T_Loss: 4.5784. Mask: 0.9177. :  30%|███       | 30/100 [00:08<00:22,  3.05it/s]Train Iter: 3631/5000. LR: 0.0120. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9616. T_Loss: 4.5660. Mask: 0.9183. :  30%|███       | 30/100 [00:08<00:22,  3.05it/s]Train Iter: 3631/5000. LR: 0.0120. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9616. T_Loss: 4.5660. Mask: 0.9183. :  31%|███       | 31/100 [00:08<00:18,  3.82it/s]Train Iter: 3632/5000. LR: 0.0120. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9624. T_Loss: 4.5582. Mask: 0.9170. :  31%|███       | 31/100 [00:08<00:18,  3.82it/s]Train Iter: 3632/5000. LR: 0.0120. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9624. T_Loss: 4.5582. Mask: 0.9170. :  32%|███▏      | 32/100 [00:08<00:15,  4.49it/s]Train Iter: 3633/5000. LR: 0.0120. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9650. T_Loss: 4.5813. Mask: 0.9167. :  32%|███▏      | 32/100 [00:08<00:15,  4.49it/s]Train Iter: 3633/5000. LR: 0.0120. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9650. T_Loss: 4.5813. Mask: 0.9167. :  33%|███▎      | 33/100 [00:08<00:13,  5.09it/s]Train Iter: 3634/5000. LR: 0.0120. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9653. T_Loss: 4.5945. Mask: 0.9173. :  33%|███▎      | 33/100 [00:09<00:13,  5.09it/s]Train Iter: 3634/5000. LR: 0.0120. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9653. T_Loss: 4.5945. Mask: 0.9173. :  34%|███▍      | 34/100 [00:09<00:11,  5.66it/s]Train Iter: 3635/5000. LR: 0.0119. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9682. T_Loss: 4.5846. Mask: 0.9161. :  34%|███▍      | 34/100 [00:09<00:11,  5.66it/s]Train Iter: 3635/5000. LR: 0.0119. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9682. T_Loss: 4.5846. Mask: 0.9161. :  35%|███▌      | 35/100 [00:09<00:14,  4.63it/s]Train Iter: 3636/5000. LR: 0.0119. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9713. T_Loss: 4.6111. Mask: 0.9149. :  35%|███▌      | 35/100 [00:09<00:14,  4.63it/s]Train Iter: 3636/5000. LR: 0.0119. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9713. T_Loss: 4.6111. Mask: 0.9149. :  36%|███▌      | 36/100 [00:09<00:12,  5.27it/s]Train Iter: 3637/5000. LR: 0.0119. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9682. T_Loss: 4.5941. Mask: 0.9155. :  36%|███▌      | 36/100 [00:09<00:12,  5.27it/s]Train Iter: 3637/5000. LR: 0.0119. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9682. T_Loss: 4.5941. Mask: 0.9155. :  37%|███▋      | 37/100 [00:09<00:10,  5.79it/s]Train Iter: 3638/5000. LR: 0.0119. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9686. T_Loss: 4.6134. Mask: 0.9153. :  37%|███▋      | 37/100 [00:09<00:10,  5.79it/s]Train Iter: 3638/5000. LR: 0.0119. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9686. T_Loss: 4.6134. Mask: 0.9153. :  38%|███▊      | 38/100 [00:09<00:09,  6.29it/s]Train Iter: 3639/5000. LR: 0.0119. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9671. T_Loss: 4.5924. Mask: 0.9143. :  38%|███▊      | 38/100 [00:10<00:09,  6.29it/s]Train Iter: 3639/5000. LR: 0.0119. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9671. T_Loss: 4.5924. Mask: 0.9143. :  39%|███▉      | 39/100 [00:10<00:13,  4.67it/s]Train Iter: 3640/5000. LR: 0.0119. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9646. T_Loss: 4.5691. Mask: 0.9148. :  39%|███▉      | 39/100 [00:10<00:13,  4.67it/s]Train Iter: 3640/5000. LR: 0.0119. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9646. T_Loss: 4.5691. Mask: 0.9148. :  40%|████      | 40/100 [00:10<00:11,  5.28it/s]Train Iter: 3641/5000. LR: 0.0118. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9618. T_Loss: 4.5573. Mask: 0.9162. :  40%|████      | 40/100 [00:10<00:11,  5.28it/s]Train Iter: 3641/5000. LR: 0.0118. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9618. T_Loss: 4.5573. Mask: 0.9162. :  41%|████      | 41/100 [00:10<00:10,  5.66it/s]Train Iter: 3642/5000. LR: 0.0118. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.5511. Mask: 0.9152. :  41%|████      | 41/100 [00:10<00:10,  5.66it/s]Train Iter: 3642/5000. LR: 0.0118. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.5511. Mask: 0.9152. :  42%|████▏     | 42/100 [00:10<00:09,  6.21it/s]Train Iter: 3643/5000. LR: 0.0118. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9602. T_Loss: 4.5407. Mask: 0.9150. :  42%|████▏     | 42/100 [00:10<00:09,  6.21it/s]Train Iter: 3643/5000. LR: 0.0118. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9602. T_Loss: 4.5407. Mask: 0.9150. :  43%|████▎     | 43/100 [00:10<00:08,  6.75it/s]Train Iter: 3644/5000. LR: 0.0118. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9603. T_Loss: 4.5258. Mask: 0.9148. :  43%|████▎     | 43/100 [00:10<00:08,  6.75it/s]Train Iter: 3645/5000. LR: 0.0118. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9602. T_Loss: 4.5215. Mask: 0.9160. :  44%|████▍     | 44/100 [00:10<00:08,  6.75it/s]Train Iter: 3645/5000. LR: 0.0118. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9602. T_Loss: 4.5215. Mask: 0.9160. :  45%|████▌     | 45/100 [00:10<00:07,  7.54it/s]Train Iter: 3646/5000. LR: 0.0118. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9578. T_Loss: 4.5122. Mask: 0.9164. :  45%|████▌     | 45/100 [00:10<00:07,  7.54it/s]Train Iter: 3646/5000. LR: 0.0118. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9578. T_Loss: 4.5122. Mask: 0.9164. :  46%|████▌     | 46/100 [00:10<00:06,  7.97it/s]Train Iter: 3647/5000. LR: 0.0117. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9573. T_Loss: 4.5202. Mask: 0.9176. :  46%|████▌     | 46/100 [00:11<00:06,  7.97it/s]Train Iter: 3647/5000. LR: 0.0117. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9573. T_Loss: 4.5202. Mask: 0.9176. :  47%|████▋     | 47/100 [00:11<00:06,  8.41it/s]Train Iter: 3648/5000. LR: 0.0117. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9552. T_Loss: 4.5229. Mask: 0.9173. :  47%|████▋     | 47/100 [00:11<00:06,  8.41it/s]Train Iter: 3648/5000. LR: 0.0117. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9552. T_Loss: 4.5229. Mask: 0.9173. :  48%|████▊     | 48/100 [00:11<00:06,  8.41it/s]Train Iter: 3649/5000. LR: 0.0117. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9560. T_Loss: 4.5343. Mask: 0.9190. :  48%|████▊     | 48/100 [00:11<00:06,  8.41it/s]Train Iter: 3649/5000. LR: 0.0117. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9560. T_Loss: 4.5343. Mask: 0.9190. :  49%|████▉     | 49/100 [00:11<00:09,  5.50it/s]Train Iter: 3650/5000. LR: 0.0117. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9548. T_Loss: 4.5087. Mask: 0.9187. :  49%|████▉     | 49/100 [00:11<00:09,  5.50it/s]total : 5000  current step :  3626
total : 5000  current step :  3627
total : 5000  current step :  3628
total : 5000  current step :  3629
total : 5000  current step :  3630
total : 5000  current step :  3631
total : 5000  current step :  3632
total : 5000  current step :  3633
total : 5000  current step :  3634
total : 5000  current step :  3635
total : 5000  current step :  3636
total : 5000  current step :  3637
total : 5000  current step :  3638
total : 5000  current step :  3639
total : 5000  current step :  3640
total : 5000  current step :  3641
total : 5000  current step :  3642
total : 5000  current step :  3643
total : 5000  current step :  3644
total : 5000  current step :  3645
total : 5000  current step :  3646
total : 5000  current step :  3647
total : 5000  current step :  3648
total : 5000  current step :  3649
total : 5000  current step :  3650
Train Iter: 3651/5000. LR: 0.0117. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9534. T_Loss: 4.5012. Mask: 0.9191. :  50%|█████     | 50/100 [00:14<00:09,  5.50it/s]Train Iter: 3651/5000. LR: 0.0117. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9534. T_Loss: 4.5012. Mask: 0.9191. :  51%|█████     | 51/100 [00:14<00:35,  1.40it/s]Train Iter: 3652/5000. LR: 0.0117. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9539. T_Loss: 4.5002. Mask: 0.9195. :  51%|█████     | 51/100 [00:14<00:35,  1.40it/s]Train Iter: 3652/5000. LR: 0.0117. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9539. T_Loss: 4.5002. Mask: 0.9195. :  52%|█████▏    | 52/100 [00:14<00:27,  1.75it/s]Train Iter: 3653/5000. LR: 0.0117. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9542. T_Loss: 4.4941. Mask: 0.9186. :  52%|█████▏    | 52/100 [00:14<00:27,  1.75it/s]Train Iter: 3654/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9530. T_Loss: 4.4836. Mask: 0.9178. :  53%|█████▎    | 53/100 [00:14<00:26,  1.75it/s]Train Iter: 3654/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9530. T_Loss: 4.4836. Mask: 0.9178. :  54%|█████▍    | 54/100 [00:14<00:17,  2.67it/s]Train Iter: 3655/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9534. T_Loss: 4.4833. Mask: 0.9187. :  54%|█████▍    | 54/100 [00:14<00:17,  2.67it/s]Train Iter: 3655/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9534. T_Loss: 4.4833. Mask: 0.9187. :  55%|█████▌    | 55/100 [00:14<00:16,  2.68it/s]Train Iter: 3656/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9558. T_Loss: 4.4895. Mask: 0.9196. :  55%|█████▌    | 55/100 [00:15<00:16,  2.68it/s]Train Iter: 3656/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9558. T_Loss: 4.4895. Mask: 0.9196. :  56%|█████▌    | 56/100 [00:15<00:13,  3.15it/s]Train Iter: 3657/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9556. T_Loss: 4.5151. Mask: 0.9211. :  56%|█████▌    | 56/100 [00:15<00:13,  3.15it/s]Train Iter: 3657/5000. LR: 0.0116. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9556. T_Loss: 4.5151. Mask: 0.9211. :  57%|█████▋    | 57/100 [00:15<00:11,  3.70it/s]Train Iter: 3658/5000. LR: 0.0116. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9551. T_Loss: 4.5164. Mask: 0.9224. :  57%|█████▋    | 57/100 [00:15<00:11,  3.70it/s]Train Iter: 3658/5000. LR: 0.0116. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9551. T_Loss: 4.5164. Mask: 0.9224. :  58%|█████▊    | 58/100 [00:15<00:09,  4.27it/s]Train Iter: 3659/5000. LR: 0.0116. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9556. T_Loss: 4.5246. Mask: 0.9221. :  58%|█████▊    | 58/100 [00:15<00:09,  4.27it/s]Train Iter: 3659/5000. LR: 0.0116. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9556. T_Loss: 4.5246. Mask: 0.9221. :  59%|█████▉    | 59/100 [00:15<00:08,  4.89it/s]Train Iter: 3660/5000. LR: 0.0115. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9563. T_Loss: 4.5402. Mask: 0.9224. :  59%|█████▉    | 59/100 [00:15<00:08,  4.89it/s]Train Iter: 3660/5000. LR: 0.0115. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9563. T_Loss: 4.5402. Mask: 0.9224. :  60%|██████    | 60/100 [00:15<00:07,  5.42it/s]Train Iter: 3661/5000. LR: 0.0115. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9574. T_Loss: 4.5305. Mask: 0.9216. :  60%|██████    | 60/100 [00:15<00:07,  5.42it/s]Train Iter: 3661/5000. LR: 0.0115. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9574. T_Loss: 4.5305. Mask: 0.9216. :  61%|██████    | 61/100 [00:15<00:06,  5.85it/s]Train Iter: 3662/5000. LR: 0.0115. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9571. T_Loss: 4.5159. Mask: 0.9204. :  61%|██████    | 61/100 [00:15<00:06,  5.85it/s]Train Iter: 3662/5000. LR: 0.0115. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9571. T_Loss: 4.5159. Mask: 0.9204. :  62%|██████▏   | 62/100 [00:15<00:06,  6.30it/s]Train Iter: 3663/5000. LR: 0.0115. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9561. T_Loss: 4.5108. Mask: 0.9206. :  62%|██████▏   | 62/100 [00:16<00:06,  6.30it/s]Train Iter: 3663/5000. LR: 0.0115. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9561. T_Loss: 4.5108. Mask: 0.9206. :  63%|██████▎   | 63/100 [00:16<00:05,  6.57it/s]Train Iter: 3664/5000. LR: 0.0115. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9555. T_Loss: 4.5120. Mask: 0.9209. :  63%|██████▎   | 63/100 [00:16<00:05,  6.57it/s]Train Iter: 3664/5000. LR: 0.0115. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9555. T_Loss: 4.5120. Mask: 0.9209. :  64%|██████▍   | 64/100 [00:16<00:05,  6.76it/s]Train Iter: 3665/5000. LR: 0.0115. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9541. T_Loss: 4.5051. Mask: 0.9207. :  64%|██████▍   | 64/100 [00:16<00:05,  6.76it/s]Train Iter: 3665/5000. LR: 0.0115. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9541. T_Loss: 4.5051. Mask: 0.9207. :  65%|██████▌   | 65/100 [00:16<00:07,  4.87it/s]Train Iter: 3666/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9551. T_Loss: 4.5109. Mask: 0.9200. :  65%|██████▌   | 65/100 [00:16<00:07,  4.87it/s]Train Iter: 3666/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9551. T_Loss: 4.5109. Mask: 0.9200. :  66%|██████▌   | 66/100 [00:16<00:06,  5.23it/s]Train Iter: 3667/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9540. T_Loss: 4.5043. Mask: 0.9202. :  66%|██████▌   | 66/100 [00:16<00:06,  5.23it/s]Train Iter: 3667/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9540. T_Loss: 4.5043. Mask: 0.9202. :  67%|██████▋   | 67/100 [00:16<00:05,  5.83it/s]Train Iter: 3668/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9547. T_Loss: 4.5012. Mask: 0.9196. :  67%|██████▋   | 67/100 [00:16<00:05,  5.83it/s]Train Iter: 3668/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9547. T_Loss: 4.5012. Mask: 0.9196. :  68%|██████▊   | 68/100 [00:16<00:05,  6.30it/s]Train Iter: 3669/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9559. T_Loss: 4.4935. Mask: 0.9194. :  68%|██████▊   | 68/100 [00:17<00:05,  6.30it/s]Train Iter: 3669/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9559. T_Loss: 4.4935. Mask: 0.9194. :  69%|██████▉   | 69/100 [00:17<00:06,  4.63it/s]Train Iter: 3670/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9557. T_Loss: 4.4927. Mask: 0.9196. :  69%|██████▉   | 69/100 [00:17<00:06,  4.63it/s]Train Iter: 3670/5000. LR: 0.0114. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9557. T_Loss: 4.4927. Mask: 0.9196. :  70%|███████   | 70/100 [00:17<00:05,  5.28it/s]Train Iter: 3671/5000. LR: 0.0114. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9549. T_Loss: 4.4827. Mask: 0.9195. :  70%|███████   | 70/100 [00:17<00:05,  5.28it/s]Train Iter: 3672/5000. LR: 0.0114. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9535. T_Loss: 4.4741. Mask: 0.9197. :  71%|███████   | 71/100 [00:17<00:05,  5.28it/s]Train Iter: 3672/5000. LR: 0.0114. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9535. T_Loss: 4.4741. Mask: 0.9197. :  72%|███████▏  | 72/100 [00:17<00:04,  6.94it/s]Train Iter: 3673/5000. LR: 0.0113. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9536. T_Loss: 4.4648. Mask: 0.9187. :  72%|███████▏  | 72/100 [00:17<00:04,  6.94it/s]Train Iter: 3673/5000. LR: 0.0113. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9536. T_Loss: 4.4648. Mask: 0.9187. :  73%|███████▎  | 73/100 [00:17<00:03,  6.94it/s]Train Iter: 3674/5000. LR: 0.0113. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9527. T_Loss: 4.4548. Mask: 0.9185. :  73%|███████▎  | 73/100 [00:17<00:03,  6.94it/s]Train Iter: 3674/5000. LR: 0.0113. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9527. T_Loss: 4.4548. Mask: 0.9185. :  74%|███████▍  | 74/100 [00:17<00:03,  7.12it/s]Train Iter: 3675/5000. LR: 0.0113. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9513. T_Loss: 4.4487. Mask: 0.9196. :  74%|███████▍  | 74/100 [00:18<00:03,  7.12it/s]Train Iter: 3675/5000. LR: 0.0113. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9513. T_Loss: 4.4487. Mask: 0.9196. :  75%|███████▌  | 75/100 [00:18<00:04,  5.15it/s]total : 5000  current step :  3651
total : 5000  current step :  3652
total : 5000  current step :  3653
total : 5000  current step :  3654
total : 5000  current step :  3655
total : 5000  current step :  3656
total : 5000  current step :  3657
total : 5000  current step :  3658
total : 5000  current step :  3659
total : 5000  current step :  3660
total : 5000  current step :  3661
total : 5000  current step :  3662
total : 5000  current step :  3663
total : 5000  current step :  3664
total : 5000  current step :  3665
total : 5000  current step :  3666
total : 5000  current step :  3667
total : 5000  current step :  3668
total : 5000  current step :  3669
total : 5000  current step :  3670
total : 5000  current step :  3671
total : 5000  current step :  3672
total : 5000  current step :  3673
total : 5000  current step :  3674
total : 5000  current step :  3675
Train Iter: 3676/5000. LR: 0.0113. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9504. T_Loss: 4.4416. Mask: 0.9194. :  75%|███████▌  | 75/100 [00:20<00:04,  5.15it/s]Train Iter: 3676/5000. LR: 0.0113. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9504. T_Loss: 4.4416. Mask: 0.9194. :  76%|███████▌  | 76/100 [00:20<00:18,  1.30it/s]Train Iter: 3677/5000. LR: 0.0113. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9505. T_Loss: 4.4396. Mask: 0.9196. :  76%|███████▌  | 76/100 [00:20<00:18,  1.30it/s]Train Iter: 3677/5000. LR: 0.0113. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9505. T_Loss: 4.4396. Mask: 0.9196. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 3678/5000. LR: 0.0113. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9514. T_Loss: 4.4367. Mask: 0.9195. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 3678/5000. LR: 0.0113. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9514. T_Loss: 4.4367. Mask: 0.9195. :  78%|███████▊  | 78/100 [00:20<00:10,  2.15it/s]Train Iter: 3679/5000. LR: 0.0112. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9495. T_Loss: 4.4345. Mask: 0.9205. :  78%|███████▊  | 78/100 [00:21<00:10,  2.15it/s]Train Iter: 3679/5000. LR: 0.0112. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9495. T_Loss: 4.4345. Mask: 0.9205. :  79%|███████▉  | 79/100 [00:21<00:09,  2.26it/s]Train Iter: 3680/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9495. T_Loss: 4.4230. Mask: 0.9199. :  79%|███████▉  | 79/100 [00:21<00:09,  2.26it/s]Train Iter: 3680/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9495. T_Loss: 4.4230. Mask: 0.9199. :  80%|████████  | 80/100 [00:21<00:06,  2.87it/s]Train Iter: 3681/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9490. T_Loss: 4.4268. Mask: 0.9201. :  80%|████████  | 80/100 [00:21<00:06,  2.87it/s]Train Iter: 3681/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9490. T_Loss: 4.4268. Mask: 0.9201. :  81%|████████  | 81/100 [00:21<00:05,  3.48it/s]Train Iter: 3682/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9478. T_Loss: 4.4198. Mask: 0.9207. :  81%|████████  | 81/100 [00:21<00:05,  3.48it/s]Train Iter: 3682/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9478. T_Loss: 4.4198. Mask: 0.9207. :  82%|████████▏ | 82/100 [00:21<00:04,  4.14it/s]Train Iter: 3683/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9484. T_Loss: 4.4342. Mask: 0.9213. :  82%|████████▏ | 82/100 [00:21<00:04,  4.14it/s]Train Iter: 3684/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9490. T_Loss: 4.4280. Mask: 0.9211. :  83%|████████▎ | 83/100 [00:21<00:04,  4.14it/s]Train Iter: 3684/5000. LR: 0.0112. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9490. T_Loss: 4.4280. Mask: 0.9211. :  84%|████████▍ | 84/100 [00:21<00:02,  5.59it/s]Train Iter: 3685/5000. LR: 0.0111. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9495. T_Loss: 4.4291. Mask: 0.9213. :  84%|████████▍ | 84/100 [00:22<00:02,  5.59it/s]Train Iter: 3685/5000. LR: 0.0111. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9495. T_Loss: 4.4291. Mask: 0.9213. :  85%|████████▌ | 85/100 [00:22<00:03,  4.61it/s]Train Iter: 3686/5000. LR: 0.0111. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9504. T_Loss: 4.4412. Mask: 0.9222. :  85%|████████▌ | 85/100 [00:22<00:03,  4.61it/s]Train Iter: 3687/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9499. T_Loss: 4.4355. Mask: 0.9221. :  86%|████████▌ | 86/100 [00:22<00:03,  4.61it/s]Train Iter: 3687/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9499. T_Loss: 4.4355. Mask: 0.9221. :  87%|████████▋ | 87/100 [00:22<00:02,  6.06it/s]Train Iter: 3688/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9512. T_Loss: 4.4408. Mask: 0.9229. :  87%|████████▋ | 87/100 [00:22<00:02,  6.06it/s]Train Iter: 3689/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9538. T_Loss: 4.4598. Mask: 0.9235. :  88%|████████▊ | 88/100 [00:22<00:01,  6.06it/s]Train Iter: 3689/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9538. T_Loss: 4.4598. Mask: 0.9235. :  89%|████████▉ | 89/100 [00:22<00:01,  6.73it/s]Train Iter: 3690/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9547. T_Loss: 4.4602. Mask: 0.9229. :  89%|████████▉ | 89/100 [00:22<00:01,  6.73it/s]Train Iter: 3690/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9547. T_Loss: 4.4602. Mask: 0.9229. :  90%|█████████ | 90/100 [00:22<00:01,  6.94it/s]Train Iter: 3691/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9534. T_Loss: 4.4520. Mask: 0.9234. :  90%|█████████ | 90/100 [00:22<00:01,  6.94it/s]Train Iter: 3691/5000. LR: 0.0111. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9534. T_Loss: 4.4520. Mask: 0.9234. :  91%|█████████ | 91/100 [00:22<00:01,  6.84it/s]Train Iter: 3692/5000. LR: 0.0110. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9531. T_Loss: 4.4497. Mask: 0.9229. :  91%|█████████ | 91/100 [00:22<00:01,  6.84it/s]Train Iter: 3692/5000. LR: 0.0110. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9531. T_Loss: 4.4497. Mask: 0.9229. :  92%|█████████▏| 92/100 [00:22<00:01,  6.90it/s]Train Iter: 3693/5000. LR: 0.0110. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9521. T_Loss: 4.4508. Mask: 0.9234. :  92%|█████████▏| 92/100 [00:23<00:01,  6.90it/s]Train Iter: 3693/5000. LR: 0.0110. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9521. T_Loss: 4.4508. Mask: 0.9234. :  93%|█████████▎| 93/100 [00:23<00:00,  7.19it/s]Train Iter: 3694/5000. LR: 0.0110. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.4529. Mask: 0.9239. :  93%|█████████▎| 93/100 [00:23<00:00,  7.19it/s]Train Iter: 3694/5000. LR: 0.0110. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.4529. Mask: 0.9239. :  94%|█████████▍| 94/100 [00:23<00:00,  7.27it/s]Train Iter: 3695/5000. LR: 0.0110. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9501. T_Loss: 4.4537. Mask: 0.9240. :  94%|█████████▍| 94/100 [00:23<00:00,  7.27it/s]Train Iter: 3695/5000. LR: 0.0110. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9501. T_Loss: 4.4537. Mask: 0.9240. :  95%|█████████▌| 95/100 [00:23<00:00,  5.55it/s]Train Iter: 3696/5000. LR: 0.0110. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9489. T_Loss: 4.4515. Mask: 0.9242. :  95%|█████████▌| 95/100 [00:23<00:00,  5.55it/s]Train Iter: 3697/5000. LR: 0.0110. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9500. T_Loss: 4.4538. Mask: 0.9236. :  96%|█████████▌| 96/100 [00:23<00:00,  5.55it/s]Train Iter: 3697/5000. LR: 0.0110. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9500. T_Loss: 4.4538. Mask: 0.9236. :  97%|█████████▋| 97/100 [00:23<00:00,  7.35it/s]Train Iter: 3698/5000. LR: 0.0109. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9509. T_Loss: 4.4640. Mask: 0.9238. :  97%|█████████▋| 97/100 [00:23<00:00,  7.35it/s]Train Iter: 3699/5000. LR: 0.0109. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9519. T_Loss: 4.4810. Mask: 0.9239. :  98%|█████████▊| 98/100 [00:23<00:00,  7.35it/s]Train Iter: 3699/5000. LR: 0.0109. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9519. T_Loss: 4.4810. Mask: 0.9239. :  99%|█████████▉| 99/100 [00:23<00:00,  6.27it/s]Train Iter: 3700/5000. LR: 0.0109. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9524. T_Loss: 4.4823. Mask: 0.9228. :  99%|█████████▉| 99/100 [00:24<00:00,  6.27it/s]Train Iter: 3700/5000. LR: 0.0109. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9524. T_Loss: 4.4823. Mask: 0.9228. : 100%|██████████| 100/100 [00:24<00:00,  4.15it/s]
total : 5000  current step :  3676
total : 5000  current step :  3677
total : 5000  current step :  3678
total : 5000  current step :  3679
total : 5000  current step :  3680
total : 5000  current step :  3681
total : 5000  current step :  3682
total : 5000  current step :  3683
total : 5000  current step :  3684
total : 5000  current step :  3685
total : 5000  current step :  3686
total : 5000  current step :  3687
total : 5000  current step :  3688
total : 5000  current step :  3689
total : 5000  current step :  3690
total : 5000  current step :  3691
total : 5000  current step :  3692
total : 5000  current step :  3693
total : 5000  current step :  3694
total : 5000  current step :  3695
total : 5000  current step :  3696
total : 5000  current step :  3697
total : 5000  current step :  3698
total : 5000  current step :  3699
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.87s. Loss: 0.8927. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.87s. Loss: 0.8927. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.95s. Loss: 0.8890. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.8555. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.8595. top1: 89.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 0.8466. top1: 91.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8455. top1: 91.15. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8588. top1: 90.18. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8572. top1: 89.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.87s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8572. top1: 89.84. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:10,  5.45it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8539. top1: 89.93. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:10,  5.45it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8586. top1: 90.00. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.45it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8480. top1: 90.91. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.45it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8480. top1: 90.89. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.45it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8429. top1: 90.87. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.45it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8390. top1: 91.07. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.45it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8375. top1: 91.25. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.45it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8384. top1: 91.21. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.45it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8384. top1: 91.21. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8367. top1: 90.99. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8368. top1: 91.15. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8359. top1: 91.12. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8354. top1: 91.25. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8386. top1: 91.37. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8362. top1: 91.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8329. top1: 91.98. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8307. top1: 92.19. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.20it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8307. top1: 92.19. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8281. top1: 92.25. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8323. top1: 91.83. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8327. top1: 91.90. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8361. top1: 91.85. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8336. top1: 92.03. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8333. top1: 91.88. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8334. top1: 91.94. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8543. top1: 90.82. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8654. top1: 90.15. top5: 99.91. :  38%|███▊      | 24/63 [00:02<00:01, 19.82it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8654. top1: 90.15. top5: 99.91. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8790. top1: 89.34. top5: 99.82. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8941. top1: 88.30. top5: 99.82. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9211. top1: 87.33. top5: 99.65. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9289. top1: 86.82. top5: 99.66. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9401. top1: 86.18. top5: 99.67. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9559. top1: 85.58. top5: 99.44. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9678. top1: 84.84. top5: 99.45. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9750. top1: 84.45. top5: 99.39. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9908. top1: 83.63. top5: 99.40. :  52%|█████▏    | 33/63 [00:02<00:01, 29.60it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9908. top1: 83.63. top5: 99.40. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0010. top1: 83.14. top5: 99.42. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0072. top1: 82.74. top5: 99.36. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0109. top1: 82.43. top5: 99.38. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0189. top1: 81.86. top5: 99.39. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0262. top1: 81.45. top5: 99.40. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0323. top1: 81.05. top5: 99.41. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0402. top1: 80.80. top5: 99.30. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0451. top1: 80.44. top5: 99.25. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0593. top1: 79.72. top5: 99.26. :  67%|██████▋   | 42/63 [00:02<00:00, 39.55it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0593. top1: 79.72. top5: 99.26. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0638. top1: 79.63. top5: 99.22. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0732. top1: 79.25. top5: 99.17. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0832. top1: 78.76. top5: 99.13. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0866. top1: 78.35. top5: 99.15. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0905. top1: 78.18. top5: 99.16. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1009. top1: 77.63. top5: 99.12. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1091. top1: 77.05. top5: 99.14. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1157. top1: 76.69. top5: 99.10. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1157. top1: 76.82. top5: 99.11. :  81%|████████  | 51/63 [00:02<00:00, 49.11it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1157. top1: 76.82. top5: 99.11. :  95%|█████████▌| 60/63 [00:02<00:00, 57.41it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1235. top1: 76.38. top5: 99.08. :  95%|█████████▌| 60/63 [00:02<00:00, 57.41it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1332. top1: 75.76. top5: 99.09. :  95%|█████████▌| 60/63 [00:02<00:00, 57.41it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1345. top1: 75.70. top5: 99.10. :  95%|█████████▌| 60/63 [00:02<00:00, 57.41it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1345. top1: 75.70. top5: 99.10. : 100%|██████████| 63/63 [00:02<00:00, 22.72it/s]
total : 5000  current step :  3700
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3701/5000. LR: 0.0109. Data: 2.03s. Batch: 2.15s. S_Loss: 0.9118. T_Loss: 3.7994. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 3701/5000. LR: 0.0109. Data: 2.03s. Batch: 2.15s. S_Loss: 0.9118. T_Loss: 3.7994. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:33,  2.15s/it]Train Iter: 3702/5000. LR: 0.0109. Data: 1.02s. Batch: 1.14s. S_Loss: 0.9559. T_Loss: 3.9516. Mask: 0.8594. :   1%|          | 1/100 [00:02<03:33,  2.15s/it]Train Iter: 3702/5000. LR: 0.0109. Data: 1.02s. Batch: 1.14s. S_Loss: 0.9559. T_Loss: 3.9516. Mask: 0.8594. :   2%|▏         | 2/100 [00:02<01:34,  1.04it/s]Train Iter: 3703/5000. LR: 0.0109. Data: 0.68s. Batch: 0.80s. S_Loss: 0.9488. T_Loss: 3.8088. Mask: 0.8438. :   2%|▏         | 2/100 [00:02<01:34,  1.04it/s]Train Iter: 3703/5000. LR: 0.0109. Data: 0.68s. Batch: 0.80s. S_Loss: 0.9488. T_Loss: 3.8088. Mask: 0.8438. :   3%|▎         | 3/100 [00:02<00:56,  1.71it/s]Train Iter: 3704/5000. LR: 0.0109. Data: 0.51s. Batch: 0.64s. S_Loss: 0.9499. T_Loss: 4.0712. Mask: 0.8594. :   3%|▎         | 3/100 [00:02<00:56,  1.71it/s]Train Iter: 3704/5000. LR: 0.0109. Data: 0.51s. Batch: 0.64s. S_Loss: 0.9499. T_Loss: 4.0712. Mask: 0.8594. :   4%|▍         | 4/100 [00:02<00:39,  2.43it/s]Train Iter: 3705/5000. LR: 0.0108. Data: 0.41s. Batch: 0.57s. S_Loss: 0.9675. T_Loss: 4.1859. Mask: 0.8625. :   4%|▍         | 4/100 [00:02<00:39,  2.43it/s]Train Iter: 3705/5000. LR: 0.0108. Data: 0.41s. Batch: 0.57s. S_Loss: 0.9675. T_Loss: 4.1859. Mask: 0.8625. :   5%|▌         | 5/100 [00:02<00:35,  2.65it/s]Train Iter: 3706/5000. LR: 0.0108. Data: 0.34s. Batch: 0.49s. S_Loss: 0.9703. T_Loss: 4.2245. Mask: 0.8646. :   5%|▌         | 5/100 [00:02<00:35,  2.65it/s]Train Iter: 3707/5000. LR: 0.0108. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9742. T_Loss: 4.1434. Mask: 0.8482. :   6%|▌         | 6/100 [00:03<00:35,  2.65it/s]Train Iter: 3707/5000. LR: 0.0108. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9742. T_Loss: 4.1434. Mask: 0.8482. :   7%|▋         | 7/100 [00:03<00:22,  4.04it/s]Train Iter: 3708/5000. LR: 0.0108. Data: 0.26s. Batch: 0.40s. S_Loss: 0.9729. T_Loss: 4.2690. Mask: 0.8633. :   7%|▋         | 7/100 [00:03<00:22,  4.04it/s]Train Iter: 3708/5000. LR: 0.0108. Data: 0.26s. Batch: 0.40s. S_Loss: 0.9729. T_Loss: 4.2690. Mask: 0.8633. :   8%|▊         | 8/100 [00:03<00:19,  4.70it/s]Train Iter: 3709/5000. LR: 0.0108. Data: 0.23s. Batch: 0.39s. S_Loss: 0.9754. T_Loss: 4.3239. Mask: 0.8681. :   8%|▊         | 8/100 [00:03<00:19,  4.70it/s]Train Iter: 3709/5000. LR: 0.0108. Data: 0.23s. Batch: 0.39s. S_Loss: 0.9754. T_Loss: 4.3239. Mask: 0.8681. :   9%|▉         | 9/100 [00:03<00:21,  4.33it/s]Train Iter: 3710/5000. LR: 0.0108. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9590. T_Loss: 4.3603. Mask: 0.8781. :   9%|▉         | 9/100 [00:03<00:21,  4.33it/s]Train Iter: 3710/5000. LR: 0.0108. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9590. T_Loss: 4.3603. Mask: 0.8781. :  10%|█         | 10/100 [00:03<00:18,  4.99it/s]Train Iter: 3711/5000. LR: 0.0107. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9580. T_Loss: 4.3478. Mask: 0.8693. :  10%|█         | 10/100 [00:03<00:18,  4.99it/s]Train Iter: 3711/5000. LR: 0.0107. Data: 0.19s. Batch: 0.34s. S_Loss: 0.9580. T_Loss: 4.3478. Mask: 0.8693. :  11%|█         | 11/100 [00:03<00:16,  5.47it/s]Train Iter: 3712/5000. LR: 0.0107. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9597. T_Loss: 4.3490. Mask: 0.8724. :  11%|█         | 11/100 [00:03<00:16,  5.47it/s]Train Iter: 3712/5000. LR: 0.0107. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9597. T_Loss: 4.3490. Mask: 0.8724. :  12%|█▏        | 12/100 [00:03<00:14,  6.03it/s]Train Iter: 3713/5000. LR: 0.0107. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9603. T_Loss: 4.3450. Mask: 0.8726. :  12%|█▏        | 12/100 [00:04<00:14,  6.03it/s]Train Iter: 3713/5000. LR: 0.0107. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9603. T_Loss: 4.3450. Mask: 0.8726. :  13%|█▎        | 13/100 [00:04<00:13,  6.42it/s]Train Iter: 3714/5000. LR: 0.0107. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9584. T_Loss: 4.3947. Mask: 0.8772. :  13%|█▎        | 13/100 [00:04<00:13,  6.42it/s]Train Iter: 3714/5000. LR: 0.0107. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9584. T_Loss: 4.3947. Mask: 0.8772. :  14%|█▍        | 14/100 [00:04<00:12,  6.84it/s]Train Iter: 3715/5000. LR: 0.0107. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9595. T_Loss: 4.4350. Mask: 0.8812. :  14%|█▍        | 14/100 [00:04<00:12,  6.84it/s]Train Iter: 3715/5000. LR: 0.0107. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9595. T_Loss: 4.4350. Mask: 0.8812. :  15%|█▌        | 15/100 [00:04<00:16,  5.03it/s]Train Iter: 3716/5000. LR: 0.0107. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9574. T_Loss: 4.4600. Mask: 0.8809. :  15%|█▌        | 15/100 [00:04<00:16,  5.03it/s]Train Iter: 3716/5000. LR: 0.0107. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9574. T_Loss: 4.4600. Mask: 0.8809. :  16%|█▌        | 16/100 [00:04<00:15,  5.51it/s]Train Iter: 3717/5000. LR: 0.0107. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9551. T_Loss: 4.4693. Mask: 0.8860. :  16%|█▌        | 16/100 [00:04<00:15,  5.51it/s]Train Iter: 3717/5000. LR: 0.0107. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9551. T_Loss: 4.4693. Mask: 0.8860. :  17%|█▋        | 17/100 [00:04<00:13,  6.07it/s]Train Iter: 3718/5000. LR: 0.0106. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9648. T_Loss: 4.5275. Mask: 0.8854. :  17%|█▋        | 17/100 [00:04<00:13,  6.07it/s]Train Iter: 3718/5000. LR: 0.0106. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9648. T_Loss: 4.5275. Mask: 0.8854. :  18%|█▊        | 18/100 [00:04<00:11,  6.84it/s]Train Iter: 3719/5000. LR: 0.0106. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9626. T_Loss: 4.5467. Mask: 0.8865. :  18%|█▊        | 18/100 [00:05<00:11,  6.84it/s]Train Iter: 3719/5000. LR: 0.0106. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9626. T_Loss: 4.5467. Mask: 0.8865. :  19%|█▉        | 19/100 [00:05<00:17,  4.66it/s]Train Iter: 3720/5000. LR: 0.0106. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9582. T_Loss: 4.5075. Mask: 0.8875. :  19%|█▉        | 19/100 [00:05<00:17,  4.66it/s]Train Iter: 3720/5000. LR: 0.0106. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9582. T_Loss: 4.5075. Mask: 0.8875. :  20%|██        | 20/100 [00:05<00:15,  5.27it/s]Train Iter: 3721/5000. LR: 0.0106. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9603. T_Loss: 4.4876. Mask: 0.8869. :  20%|██        | 20/100 [00:05<00:15,  5.27it/s]Train Iter: 3721/5000. LR: 0.0106. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9603. T_Loss: 4.4876. Mask: 0.8869. :  21%|██        | 21/100 [00:05<00:13,  5.77it/s]Train Iter: 3722/5000. LR: 0.0106. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9575. T_Loss: 4.4878. Mask: 0.8878. :  21%|██        | 21/100 [00:05<00:13,  5.77it/s]Train Iter: 3722/5000. LR: 0.0106. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9575. T_Loss: 4.4878. Mask: 0.8878. :  22%|██▏       | 22/100 [00:05<00:12,  6.28it/s]Train Iter: 3723/5000. LR: 0.0106. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9537. T_Loss: 4.4703. Mask: 0.8913. :  22%|██▏       | 22/100 [00:05<00:12,  6.28it/s]Train Iter: 3723/5000. LR: 0.0106. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9537. T_Loss: 4.4703. Mask: 0.8913. :  23%|██▎       | 23/100 [00:05<00:11,  6.53it/s]Train Iter: 3724/5000. LR: 0.0105. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9508. T_Loss: 4.4774. Mask: 0.8945. :  23%|██▎       | 23/100 [00:05<00:11,  6.53it/s]Train Iter: 3724/5000. LR: 0.0105. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9508. T_Loss: 4.4774. Mask: 0.8945. :  24%|██▍       | 24/100 [00:05<00:10,  7.06it/s]Train Iter: 3725/5000. LR: 0.0105. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9486. T_Loss: 4.4655. Mask: 0.8950. :  24%|██▍       | 24/100 [00:06<00:10,  7.06it/s]Train Iter: 3725/5000. LR: 0.0105. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9486. T_Loss: 4.4655. Mask: 0.8950. :  25%|██▌       | 25/100 [00:06<00:10,  7.17it/s]total : 5000  current step :  3701
total : 5000  current step :  3702
total : 5000  current step :  3703
total : 5000  current step :  3704
total : 5000  current step :  3705
total : 5000  current step :  3706
total : 5000  current step :  3707
total : 5000  current step :  3708
total : 5000  current step :  3709
total : 5000  current step :  3710
total : 5000  current step :  3711
total : 5000  current step :  3712
total : 5000  current step :  3713
total : 5000  current step :  3714
total : 5000  current step :  3715
total : 5000  current step :  3716
total : 5000  current step :  3717
total : 5000  current step :  3718
total : 5000  current step :  3719
total : 5000  current step :  3720
total : 5000  current step :  3721
total : 5000  current step :  3722
total : 5000  current step :  3723
total : 5000  current step :  3724
total : 5000  current step :  3725
Train Iter: 3726/5000. LR: 0.0105. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9431. T_Loss: 4.4351. Mask: 0.8942. :  25%|██▌       | 25/100 [00:08<00:10,  7.17it/s]Train Iter: 3726/5000. LR: 0.0105. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9431. T_Loss: 4.4351. Mask: 0.8942. :  26%|██▌       | 26/100 [00:08<00:56,  1.31it/s]Train Iter: 3727/5000. LR: 0.0105. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9407. T_Loss: 4.4378. Mask: 0.8958. :  26%|██▌       | 26/100 [00:08<00:56,  1.31it/s]Train Iter: 3727/5000. LR: 0.0105. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9407. T_Loss: 4.4378. Mask: 0.8958. :  27%|██▋       | 27/100 [00:08<00:41,  1.76it/s]Train Iter: 3728/5000. LR: 0.0105. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9404. T_Loss: 4.4548. Mask: 0.8984. :  27%|██▋       | 27/100 [00:08<00:41,  1.76it/s]Train Iter: 3728/5000. LR: 0.0105. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9404. T_Loss: 4.4548. Mask: 0.8984. :  28%|██▊       | 28/100 [00:08<00:31,  2.30it/s]Train Iter: 3729/5000. LR: 0.0105. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9422. T_Loss: 4.4410. Mask: 0.8987. :  28%|██▊       | 28/100 [00:08<00:31,  2.30it/s]Train Iter: 3729/5000. LR: 0.0105. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9422. T_Loss: 4.4410. Mask: 0.8987. :  29%|██▉       | 29/100 [00:08<00:30,  2.32it/s]Train Iter: 3730/5000. LR: 0.0105. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9398. T_Loss: 4.4348. Mask: 0.9000. :  29%|██▉       | 29/100 [00:09<00:30,  2.32it/s]Train Iter: 3730/5000. LR: 0.0105. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9398. T_Loss: 4.4348. Mask: 0.9000. :  30%|███       | 30/100 [00:09<00:23,  2.93it/s]Train Iter: 3731/5000. LR: 0.0104. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9377. T_Loss: 4.4333. Mask: 0.9022. :  30%|███       | 30/100 [00:09<00:23,  2.93it/s]Train Iter: 3731/5000. LR: 0.0104. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9377. T_Loss: 4.4333. Mask: 0.9022. :  31%|███       | 31/100 [00:09<00:19,  3.61it/s]Train Iter: 3732/5000. LR: 0.0104. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9410. T_Loss: 4.4651. Mask: 0.9043. :  31%|███       | 31/100 [00:09<00:19,  3.61it/s]Train Iter: 3732/5000. LR: 0.0104. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9410. T_Loss: 4.4651. Mask: 0.9043. :  32%|███▏      | 32/100 [00:09<00:15,  4.31it/s]Train Iter: 3733/5000. LR: 0.0104. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9403. T_Loss: 4.4737. Mask: 0.9062. :  32%|███▏      | 32/100 [00:09<00:15,  4.31it/s]Train Iter: 3733/5000. LR: 0.0104. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9403. T_Loss: 4.4737. Mask: 0.9062. :  33%|███▎      | 33/100 [00:09<00:13,  5.01it/s]Train Iter: 3734/5000. LR: 0.0104. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9418. T_Loss: 4.4639. Mask: 0.9044. :  33%|███▎      | 33/100 [00:09<00:13,  5.01it/s]Train Iter: 3734/5000. LR: 0.0104. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9418. T_Loss: 4.4639. Mask: 0.9044. :  34%|███▍      | 34/100 [00:09<00:11,  5.65it/s]Train Iter: 3735/5000. LR: 0.0104. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9431. T_Loss: 4.4846. Mask: 0.9045. :  34%|███▍      | 34/100 [00:09<00:11,  5.65it/s]Train Iter: 3735/5000. LR: 0.0104. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9431. T_Loss: 4.4846. Mask: 0.9045. :  35%|███▌      | 35/100 [00:09<00:15,  4.13it/s]Train Iter: 3736/5000. LR: 0.0104. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9447. T_Loss: 4.4849. Mask: 0.9054. :  35%|███▌      | 35/100 [00:10<00:15,  4.13it/s]Train Iter: 3736/5000. LR: 0.0104. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9447. T_Loss: 4.4849. Mask: 0.9054. :  36%|███▌      | 36/100 [00:10<00:13,  4.71it/s]Train Iter: 3737/5000. LR: 0.0104. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9468. T_Loss: 4.4987. Mask: 0.9071. :  36%|███▌      | 36/100 [00:10<00:13,  4.71it/s]Train Iter: 3737/5000. LR: 0.0104. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9468. T_Loss: 4.4987. Mask: 0.9071. :  37%|███▋      | 37/100 [00:10<00:11,  5.41it/s]Train Iter: 3738/5000. LR: 0.0103. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9480. T_Loss: 4.4916. Mask: 0.9071. :  37%|███▋      | 37/100 [00:10<00:11,  5.41it/s]Train Iter: 3738/5000. LR: 0.0103. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9480. T_Loss: 4.4916. Mask: 0.9071. :  38%|███▊      | 38/100 [00:10<00:10,  6.03it/s]Train Iter: 3739/5000. LR: 0.0103. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9470. T_Loss: 4.4926. Mask: 0.9087. :  38%|███▊      | 38/100 [00:10<00:10,  6.03it/s]Train Iter: 3739/5000. LR: 0.0103. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9470. T_Loss: 4.4926. Mask: 0.9087. :  39%|███▉      | 39/100 [00:10<00:13,  4.60it/s]Train Iter: 3740/5000. LR: 0.0103. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9469. T_Loss: 4.4844. Mask: 0.9086. :  39%|███▉      | 39/100 [00:10<00:13,  4.60it/s]Train Iter: 3740/5000. LR: 0.0103. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9469. T_Loss: 4.4844. Mask: 0.9086. :  40%|████      | 40/100 [00:10<00:11,  5.23it/s]Train Iter: 3741/5000. LR: 0.0103. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9479. T_Loss: 4.4681. Mask: 0.9085. :  40%|████      | 40/100 [00:10<00:11,  5.23it/s]Train Iter: 3741/5000. LR: 0.0103. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9479. T_Loss: 4.4681. Mask: 0.9085. :  41%|████      | 41/100 [00:10<00:10,  5.76it/s]Train Iter: 3742/5000. LR: 0.0103. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9459. T_Loss: 4.4657. Mask: 0.9100. :  41%|████      | 41/100 [00:11<00:10,  5.76it/s]Train Iter: 3742/5000. LR: 0.0103. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9459. T_Loss: 4.4657. Mask: 0.9100. :  42%|████▏     | 42/100 [00:11<00:09,  6.30it/s]Train Iter: 3743/5000. LR: 0.0103. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9440. T_Loss: 4.4732. Mask: 0.9113. :  42%|████▏     | 42/100 [00:11<00:09,  6.30it/s]Train Iter: 3743/5000. LR: 0.0103. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9440. T_Loss: 4.4732. Mask: 0.9113. :  43%|████▎     | 43/100 [00:11<00:08,  6.62it/s]Train Iter: 3744/5000. LR: 0.0102. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9423. T_Loss: 4.4568. Mask: 0.9126. :  43%|████▎     | 43/100 [00:11<00:08,  6.62it/s]Train Iter: 3744/5000. LR: 0.0102. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9423. T_Loss: 4.4568. Mask: 0.9126. :  44%|████▍     | 44/100 [00:11<00:08,  6.85it/s]Train Iter: 3745/5000. LR: 0.0102. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9431. T_Loss: 4.4492. Mask: 0.9125. :  44%|████▍     | 44/100 [00:11<00:08,  6.85it/s]Train Iter: 3745/5000. LR: 0.0102. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9431. T_Loss: 4.4492. Mask: 0.9125. :  45%|████▌     | 45/100 [00:11<00:09,  5.64it/s]Train Iter: 3746/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9430. T_Loss: 4.4401. Mask: 0.9117. :  45%|████▌     | 45/100 [00:11<00:09,  5.64it/s]Train Iter: 3746/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9430. T_Loss: 4.4401. Mask: 0.9117. :  46%|████▌     | 46/100 [00:11<00:08,  6.23it/s]Train Iter: 3747/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9422. T_Loss: 4.4401. Mask: 0.9136. :  46%|████▌     | 46/100 [00:11<00:08,  6.23it/s]Train Iter: 3747/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9422. T_Loss: 4.4401. Mask: 0.9136. :  47%|████▋     | 47/100 [00:11<00:07,  6.71it/s]Train Iter: 3748/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9442. T_Loss: 4.4509. Mask: 0.9108. :  47%|████▋     | 47/100 [00:11<00:07,  6.71it/s]Train Iter: 3748/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9442. T_Loss: 4.4509. Mask: 0.9108. :  48%|████▊     | 48/100 [00:11<00:07,  7.17it/s]Train Iter: 3749/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9456. T_Loss: 4.4761. Mask: 0.9114. :  48%|████▊     | 48/100 [00:12<00:07,  7.17it/s]Train Iter: 3749/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9456. T_Loss: 4.4761. Mask: 0.9114. :  49%|████▉     | 49/100 [00:12<00:09,  5.18it/s]Train Iter: 3750/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9467. T_Loss: 4.4759. Mask: 0.9113. :  49%|████▉     | 49/100 [00:12<00:09,  5.18it/s]Train Iter: 3750/5000. LR: 0.0102. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9467. T_Loss: 4.4759. Mask: 0.9113. :  50%|█████     | 50/100 [00:12<00:08,  5.77it/s]total : 5000  current step :  3726
total : 5000  current step :  3727
total : 5000  current step :  3728
total : 5000  current step :  3729
total : 5000  current step :  3730
total : 5000  current step :  3731
total : 5000  current step :  3732
total : 5000  current step :  3733
total : 5000  current step :  3734
total : 5000  current step :  3735
total : 5000  current step :  3736
total : 5000  current step :  3737
total : 5000  current step :  3738
total : 5000  current step :  3739
total : 5000  current step :  3740
total : 5000  current step :  3741
total : 5000  current step :  3742
total : 5000  current step :  3743
total : 5000  current step :  3744
total : 5000  current step :  3745
total : 5000  current step :  3746
total : 5000  current step :  3747
total : 5000  current step :  3748
total : 5000  current step :  3749
total : 5000  current step :  3750
Train Iter: 3751/5000. LR: 0.0101. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9469. T_Loss: 4.4767. Mask: 0.9105. :  50%|█████     | 50/100 [00:14<00:08,  5.77it/s]Train Iter: 3751/5000. LR: 0.0101. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9469. T_Loss: 4.4767. Mask: 0.9105. :  51%|█████     | 51/100 [00:14<00:35,  1.40it/s]Train Iter: 3752/5000. LR: 0.0101. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9457. T_Loss: 4.4748. Mask: 0.9117. :  51%|█████     | 51/100 [00:14<00:35,  1.40it/s]Train Iter: 3752/5000. LR: 0.0101. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9457. T_Loss: 4.4748. Mask: 0.9117. :  52%|█████▏    | 52/100 [00:14<00:25,  1.87it/s]Train Iter: 3753/5000. LR: 0.0101. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9454. T_Loss: 4.4684. Mask: 0.9116. :  52%|█████▏    | 52/100 [00:14<00:25,  1.87it/s]Train Iter: 3753/5000. LR: 0.0101. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9454. T_Loss: 4.4684. Mask: 0.9116. :  53%|█████▎    | 53/100 [00:14<00:19,  2.42it/s]Train Iter: 3754/5000. LR: 0.0101. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9430. T_Loss: 4.4677. Mask: 0.9132. :  53%|█████▎    | 53/100 [00:14<00:19,  2.42it/s]Train Iter: 3754/5000. LR: 0.0101. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9430. T_Loss: 4.4677. Mask: 0.9132. :  54%|█████▍    | 54/100 [00:14<00:15,  3.06it/s]Train Iter: 3755/5000. LR: 0.0101. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9422. T_Loss: 4.4547. Mask: 0.9125. :  54%|█████▍    | 54/100 [00:14<00:15,  3.06it/s]Train Iter: 3755/5000. LR: 0.0101. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9422. T_Loss: 4.4547. Mask: 0.9125. :  55%|█████▌    | 55/100 [00:14<00:14,  3.15it/s]total : 5000  current step :  3751
total : 5000  current step :  3752
total : 5000  current step :  3753
total : 5000  current step :  3754
total : 5000  current step :  3755
Train Iter: 3756/5000. LR: 0.0101. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9410. T_Loss: 4.4516. Mask: 0.9129. :  55%|█████▌    | 55/100 [00:16<00:14,  3.15it/s]Train Iter: 3756/5000. LR: 0.0101. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9410. T_Loss: 4.4516. Mask: 0.9129. :  56%|█████▌    | 56/100 [00:16<00:36,  1.22it/s]Train Iter: 3757/5000. LR: 0.0100. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9445. T_Loss: 4.5042. Mask: 0.9145. :  56%|█████▌    | 56/100 [00:17<00:36,  1.22it/s]Train Iter: 3757/5000. LR: 0.0100. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9445. T_Loss: 4.5042. Mask: 0.9145. :  57%|█████▋    | 57/100 [00:17<00:26,  1.62it/s]Train Iter: 3758/5000. LR: 0.0100. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9451. T_Loss: 4.5057. Mask: 0.9149. :  57%|█████▋    | 57/100 [00:17<00:26,  1.62it/s]Train Iter: 3758/5000. LR: 0.0100. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9451. T_Loss: 4.5057. Mask: 0.9149. :  58%|█████▊    | 58/100 [00:17<00:19,  2.13it/s]Train Iter: 3759/5000. LR: 0.0100. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9447. T_Loss: 4.5112. Mask: 0.9147. :  58%|█████▊    | 58/100 [00:17<00:19,  2.13it/s]Train Iter: 3759/5000. LR: 0.0100. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9447. T_Loss: 4.5112. Mask: 0.9147. :  59%|█████▉    | 59/100 [00:17<00:17,  2.38it/s]Train Iter: 3760/5000. LR: 0.0100. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9468. T_Loss: 4.5224. Mask: 0.9135. :  59%|█████▉    | 59/100 [00:17<00:17,  2.38it/s]Train Iter: 3760/5000. LR: 0.0100. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9468. T_Loss: 4.5224. Mask: 0.9135. :  60%|██████    | 60/100 [00:17<00:13,  2.98it/s]Train Iter: 3761/5000. LR: 0.0100. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9460. T_Loss: 4.5170. Mask: 0.9139. :  60%|██████    | 60/100 [00:17<00:13,  2.98it/s]Train Iter: 3761/5000. LR: 0.0100. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9460. T_Loss: 4.5170. Mask: 0.9139. :  61%|██████    | 61/100 [00:17<00:10,  3.62it/s]Train Iter: 3762/5000. LR: 0.0100. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9453. T_Loss: 4.5261. Mask: 0.9153. :  61%|██████    | 61/100 [00:17<00:10,  3.62it/s]Train Iter: 3762/5000. LR: 0.0100. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9453. T_Loss: 4.5261. Mask: 0.9153. :  62%|██████▏   | 62/100 [00:17<00:08,  4.31it/s]Train Iter: 3763/5000. LR: 0.0100. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9441. T_Loss: 4.5275. Mask: 0.9162. :  62%|██████▏   | 62/100 [00:18<00:08,  4.31it/s]Train Iter: 3763/5000. LR: 0.0100. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9441. T_Loss: 4.5275. Mask: 0.9162. :  63%|██████▎   | 63/100 [00:18<00:07,  5.09it/s]Train Iter: 3764/5000. LR: 0.0099. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9448. T_Loss: 4.5433. Mask: 0.9175. :  63%|██████▎   | 63/100 [00:18<00:07,  5.09it/s]Train Iter: 3764/5000. LR: 0.0099. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9448. T_Loss: 4.5433. Mask: 0.9175. :  64%|██████▍   | 64/100 [00:18<00:06,  5.94it/s]Train Iter: 3765/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9437. T_Loss: 4.5394. Mask: 0.9168. :  64%|██████▍   | 64/100 [00:18<00:06,  5.94it/s]Train Iter: 3765/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9437. T_Loss: 4.5394. Mask: 0.9168. :  65%|██████▌   | 65/100 [00:18<00:07,  4.71it/s]Train Iter: 3766/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9425. T_Loss: 4.5382. Mask: 0.9171. :  65%|██████▌   | 65/100 [00:18<00:07,  4.71it/s]Train Iter: 3766/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9425. T_Loss: 4.5382. Mask: 0.9171. :  66%|██████▌   | 66/100 [00:18<00:06,  5.12it/s]Train Iter: 3767/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9450. T_Loss: 4.5480. Mask: 0.9160. :  66%|██████▌   | 66/100 [00:18<00:06,  5.12it/s]Train Iter: 3767/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9450. T_Loss: 4.5480. Mask: 0.9160. :  67%|██████▋   | 67/100 [00:18<00:05,  5.86it/s]Train Iter: 3768/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9449. T_Loss: 4.5407. Mask: 0.9154. :  67%|██████▋   | 67/100 [00:18<00:05,  5.86it/s]Train Iter: 3768/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9449. T_Loss: 4.5407. Mask: 0.9154. :  68%|██████▊   | 68/100 [00:18<00:05,  6.35it/s]Train Iter: 3769/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9433. T_Loss: 4.5381. Mask: 0.9158. :  68%|██████▊   | 68/100 [00:19<00:05,  6.35it/s]Train Iter: 3769/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9433. T_Loss: 4.5381. Mask: 0.9158. :  69%|██████▉   | 69/100 [00:19<00:06,  4.70it/s]Train Iter: 3770/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9423. T_Loss: 4.5383. Mask: 0.9165. :  69%|██████▉   | 69/100 [00:19<00:06,  4.70it/s]Train Iter: 3770/5000. LR: 0.0099. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9423. T_Loss: 4.5383. Mask: 0.9165. :  70%|███████   | 70/100 [00:19<00:05,  5.27it/s]Train Iter: 3771/5000. LR: 0.0098. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9434. T_Loss: 4.5365. Mask: 0.9151. :  70%|███████   | 70/100 [00:19<00:05,  5.27it/s]Train Iter: 3771/5000. LR: 0.0098. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9434. T_Loss: 4.5365. Mask: 0.9151. :  71%|███████   | 71/100 [00:19<00:04,  5.83it/s]Train Iter: 3772/5000. LR: 0.0098. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9437. T_Loss: 4.5362. Mask: 0.9149. :  71%|███████   | 71/100 [00:19<00:04,  5.83it/s]Train Iter: 3772/5000. LR: 0.0098. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9437. T_Loss: 4.5362. Mask: 0.9149. :  72%|███████▏  | 72/100 [00:19<00:04,  6.22it/s]Train Iter: 3773/5000. LR: 0.0098. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9439. T_Loss: 4.5409. Mask: 0.9157. :  72%|███████▏  | 72/100 [00:19<00:04,  6.22it/s]Train Iter: 3773/5000. LR: 0.0098. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9439. T_Loss: 4.5409. Mask: 0.9157. :  73%|███████▎  | 73/100 [00:19<00:03,  6.77it/s]Train Iter: 3774/5000. LR: 0.0098. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9450. T_Loss: 4.5437. Mask: 0.9155. :  73%|███████▎  | 73/100 [00:19<00:03,  6.77it/s]Train Iter: 3775/5000. LR: 0.0098. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5438. Mask: 0.9158. :  74%|███████▍  | 74/100 [00:19<00:03,  6.77it/s]Train Iter: 3775/5000. LR: 0.0098. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5438. Mask: 0.9158. :  75%|███████▌  | 75/100 [00:19<00:03,  7.75it/s]total : 5000  current step :  3756
total : 5000  current step :  3757
total : 5000  current step :  3758
total : 5000  current step :  3759
total : 5000  current step :  3760
total : 5000  current step :  3761
total : 5000  current step :  3762
total : 5000  current step :  3763
total : 5000  current step :  3764
total : 5000  current step :  3765
total : 5000  current step :  3766
total : 5000  current step :  3767
total : 5000  current step :  3768
total : 5000  current step :  3769
total : 5000  current step :  3770
total : 5000  current step :  3771
total : 5000  current step :  3772
total : 5000  current step :  3773
total : 5000  current step :  3774
total : 5000  current step :  3775
Train Iter: 3776/5000. LR: 0.0098. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9443. T_Loss: 4.5457. Mask: 0.9165. :  75%|███████▌  | 75/100 [00:22<00:03,  7.75it/s]Train Iter: 3776/5000. LR: 0.0098. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9443. T_Loss: 4.5457. Mask: 0.9165. :  76%|███████▌  | 76/100 [00:22<00:15,  1.54it/s]Train Iter: 3777/5000. LR: 0.0098. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9450. T_Loss: 4.5524. Mask: 0.9168. :  76%|███████▌  | 76/100 [00:22<00:15,  1.54it/s]Train Iter: 3777/5000. LR: 0.0098. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9450. T_Loss: 4.5524. Mask: 0.9168. :  77%|███████▋  | 77/100 [00:22<00:11,  1.96it/s]Train Iter: 3778/5000. LR: 0.0097. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9464. T_Loss: 4.5543. Mask: 0.9159. :  77%|███████▋  | 77/100 [00:22<00:11,  1.96it/s]Train Iter: 3778/5000. LR: 0.0097. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9464. T_Loss: 4.5543. Mask: 0.9159. :  78%|███████▊  | 78/100 [00:22<00:09,  2.44it/s]Train Iter: 3779/5000. LR: 0.0097. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9452. T_Loss: 4.5450. Mask: 0.9165. :  78%|███████▊  | 78/100 [00:22<00:09,  2.44it/s]Train Iter: 3779/5000. LR: 0.0097. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9452. T_Loss: 4.5450. Mask: 0.9165. :  79%|███████▉  | 79/100 [00:22<00:08,  2.46it/s]Train Iter: 3780/5000. LR: 0.0097. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9473. T_Loss: 4.5648. Mask: 0.9176. :  79%|███████▉  | 79/100 [00:22<00:08,  2.46it/s]Train Iter: 3780/5000. LR: 0.0097. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9473. T_Loss: 4.5648. Mask: 0.9176. :  80%|████████  | 80/100 [00:22<00:06,  3.08it/s]Train Iter: 3781/5000. LR: 0.0097. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9469. T_Loss: 4.5598. Mask: 0.9174. :  80%|████████  | 80/100 [00:23<00:06,  3.08it/s]Train Iter: 3781/5000. LR: 0.0097. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9469. T_Loss: 4.5598. Mask: 0.9174. :  81%|████████  | 81/100 [00:23<00:05,  3.77it/s]Train Iter: 3782/5000. LR: 0.0097. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9464. T_Loss: 4.5644. Mask: 0.9177. :  81%|████████  | 81/100 [00:23<00:05,  3.77it/s]Train Iter: 3782/5000. LR: 0.0097. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9464. T_Loss: 4.5644. Mask: 0.9177. :  82%|████████▏ | 82/100 [00:23<00:04,  4.48it/s]Train Iter: 3783/5000. LR: 0.0097. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9468. T_Loss: 4.5663. Mask: 0.9175. :  82%|████████▏ | 82/100 [00:23<00:04,  4.48it/s]Train Iter: 3783/5000. LR: 0.0097. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9468. T_Loss: 4.5663. Mask: 0.9175. :  83%|████████▎ | 83/100 [00:23<00:03,  5.14it/s]Train Iter: 3784/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9463. T_Loss: 4.5628. Mask: 0.9178. :  83%|████████▎ | 83/100 [00:23<00:03,  5.14it/s]Train Iter: 3784/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9463. T_Loss: 4.5628. Mask: 0.9178. :  84%|████████▍ | 84/100 [00:23<00:02,  5.86it/s]Train Iter: 3785/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9451. T_Loss: 4.5611. Mask: 0.9187. :  84%|████████▍ | 84/100 [00:23<00:02,  5.86it/s]Train Iter: 3785/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9451. T_Loss: 4.5611. Mask: 0.9187. :  85%|████████▌ | 85/100 [00:23<00:03,  4.16it/s]Train Iter: 3786/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9447. T_Loss: 4.5605. Mask: 0.9186. :  85%|████████▌ | 85/100 [00:23<00:03,  4.16it/s]Train Iter: 3786/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9447. T_Loss: 4.5605. Mask: 0.9186. :  86%|████████▌ | 86/100 [00:23<00:02,  4.90it/s]Train Iter: 3787/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9459. T_Loss: 4.5688. Mask: 0.9192. :  86%|████████▌ | 86/100 [00:24<00:02,  4.90it/s]Train Iter: 3787/5000. LR: 0.0096. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9459. T_Loss: 4.5688. Mask: 0.9192. :  87%|████████▋ | 87/100 [00:24<00:02,  5.59it/s]Train Iter: 3788/5000. LR: 0.0096. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9455. T_Loss: 4.5642. Mask: 0.9183. :  87%|████████▋ | 87/100 [00:24<00:02,  5.59it/s]Train Iter: 3788/5000. LR: 0.0096. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9455. T_Loss: 4.5642. Mask: 0.9183. :  88%|████████▊ | 88/100 [00:24<00:01,  6.17it/s]Train Iter: 3789/5000. LR: 0.0096. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9466. T_Loss: 4.5652. Mask: 0.9182. :  88%|████████▊ | 88/100 [00:24<00:01,  6.17it/s]Train Iter: 3789/5000. LR: 0.0096. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9466. T_Loss: 4.5652. Mask: 0.9182. :  89%|████████▉ | 89/100 [00:24<00:02,  4.55it/s]Train Iter: 3790/5000. LR: 0.0096. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9469. T_Loss: 4.5603. Mask: 0.9174. :  89%|████████▉ | 89/100 [00:24<00:02,  4.55it/s]Train Iter: 3790/5000. LR: 0.0096. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9469. T_Loss: 4.5603. Mask: 0.9174. :  90%|█████████ | 90/100 [00:24<00:01,  5.18it/s]Train Iter: 3791/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9460. T_Loss: 4.5567. Mask: 0.9172. :  90%|█████████ | 90/100 [00:24<00:01,  5.18it/s]Train Iter: 3791/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9460. T_Loss: 4.5567. Mask: 0.9172. :  91%|█████████ | 91/100 [00:24<00:01,  5.56it/s]Train Iter: 3792/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9458. T_Loss: 4.5515. Mask: 0.9178. :  91%|█████████ | 91/100 [00:24<00:01,  5.56it/s]Train Iter: 3792/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9458. T_Loss: 4.5515. Mask: 0.9178. :  92%|█████████▏| 92/100 [00:24<00:01,  6.21it/s]Train Iter: 3793/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9468. T_Loss: 4.5565. Mask: 0.9183. :  92%|█████████▏| 92/100 [00:25<00:01,  6.21it/s]Train Iter: 3793/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9468. T_Loss: 4.5565. Mask: 0.9183. :  93%|█████████▎| 93/100 [00:25<00:01,  6.68it/s]Train Iter: 3794/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9451. T_Loss: 4.5543. Mask: 0.9186. :  93%|█████████▎| 93/100 [00:25<00:01,  6.68it/s]Train Iter: 3794/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9451. T_Loss: 4.5543. Mask: 0.9186. :  94%|█████████▍| 94/100 [00:25<00:00,  6.94it/s]Train Iter: 3795/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9460. T_Loss: 4.5606. Mask: 0.9187. :  94%|█████████▍| 94/100 [00:25<00:00,  6.94it/s]Train Iter: 3795/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9460. T_Loss: 4.5606. Mask: 0.9187. :  95%|█████████▌| 95/100 [00:25<00:00,  5.19it/s]Train Iter: 3796/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9466. T_Loss: 4.5590. Mask: 0.9183. :  95%|█████████▌| 95/100 [00:25<00:00,  5.19it/s]Train Iter: 3796/5000. LR: 0.0095. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9466. T_Loss: 4.5590. Mask: 0.9183. :  96%|█████████▌| 96/100 [00:25<00:00,  5.82it/s]Train Iter: 3797/5000. LR: 0.0095. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9468. T_Loss: 4.5642. Mask: 0.9178. :  96%|█████████▌| 96/100 [00:25<00:00,  5.82it/s]Train Iter: 3797/5000. LR: 0.0095. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9468. T_Loss: 4.5642. Mask: 0.9178. :  97%|█████████▋| 97/100 [00:25<00:00,  6.31it/s]Train Iter: 3798/5000. LR: 0.0094. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9471. T_Loss: 4.5644. Mask: 0.9177. :  97%|█████████▋| 97/100 [00:25<00:00,  6.31it/s]Train Iter: 3798/5000. LR: 0.0094. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9471. T_Loss: 4.5644. Mask: 0.9177. :  98%|█████████▊| 98/100 [00:25<00:00,  6.75it/s]Train Iter: 3799/5000. LR: 0.0094. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9466. T_Loss: 4.5671. Mask: 0.9182. :  98%|█████████▊| 98/100 [00:26<00:00,  6.75it/s]Train Iter: 3799/5000. LR: 0.0094. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9466. T_Loss: 4.5671. Mask: 0.9182. :  99%|█████████▉| 99/100 [00:26<00:00,  5.23it/s]Train Iter: 3800/5000. LR: 0.0094. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9467. T_Loss: 4.5700. Mask: 0.9181. :  99%|█████████▉| 99/100 [00:26<00:00,  5.23it/s]Train Iter: 3800/5000. LR: 0.0094. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9467. T_Loss: 4.5700. Mask: 0.9181. : 100%|██████████| 100/100 [00:26<00:00,  5.90it/s]Train Iter: 3800/5000. LR: 0.0094. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9467. T_Loss: 4.5700. Mask: 0.9181. : 100%|██████████| 100/100 [00:26<00:00,  3.80it/s]
total : 5000  current step :  3776
total : 5000  current step :  3777
total : 5000  current step :  3778
total : 5000  current step :  3779
total : 5000  current step :  3780
total : 5000  current step :  3781
total : 5000  current step :  3782
total : 5000  current step :  3783
total : 5000  current step :  3784
total : 5000  current step :  3785
total : 5000  current step :  3786
total : 5000  current step :  3787
total : 5000  current step :  3788
total : 5000  current step :  3789
total : 5000  current step :  3790
total : 5000  current step :  3791
total : 5000  current step :  3792
total : 5000  current step :  3793
total : 5000  current step :  3794
total : 5000  current step :  3795
total : 5000  current step :  3796
total : 5000  current step :  3797
total : 5000  current step :  3798
total : 5000  current step :  3799
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.62s. Loss: 0.8914. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.62s. Loss: 0.8914. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.83s. Loss: 0.8865. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.8535. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.8549. top1: 89.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.8431. top1: 91.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8421. top1: 91.15. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8556. top1: 90.18. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8547. top1: 89.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8547. top1: 89.84. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8513. top1: 89.93. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8570. top1: 90.00. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8464. top1: 90.91. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8461. top1: 90.89. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8409. top1: 90.87. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8372. top1: 91.07. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8360. top1: 91.25. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8376. top1: 91.21. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.21it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8376. top1: 91.21. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8356. top1: 91.18. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8358. top1: 91.32. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8353. top1: 91.28. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8347. top1: 91.41. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8381. top1: 91.37. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8357. top1: 91.62. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8320. top1: 91.98. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8296. top1: 92.19. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8270. top1: 92.25. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.56it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8270. top1: 92.25. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 23.04it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8313. top1: 91.83. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 23.04it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8314. top1: 91.90. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 23.04it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8349. top1: 91.85. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 23.04it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8324. top1: 92.03. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 23.04it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8322. top1: 91.88. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 23.04it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8320. top1: 91.94. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 23.04it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8536. top1: 90.92. top5: 99.90. :  40%|███▉      | 25/63 [00:02<00:01, 23.04it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8652. top1: 90.25. top5: 99.81. :  40%|███▉      | 25/63 [00:02<00:01, 23.04it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8785. top1: 89.43. top5: 99.72. :  40%|███▉      | 25/63 [00:02<00:01, 23.04it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8943. top1: 88.39. top5: 99.73. :  40%|███▉      | 25/63 [00:02<00:01, 23.04it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9210. top1: 87.33. top5: 99.57. :  40%|███▉      | 25/63 [00:02<00:01, 23.04it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9210. top1: 87.33. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9294. top1: 86.82. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9412. top1: 86.18. top5: 99.59. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9568. top1: 85.58. top5: 99.36. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9687. top1: 84.84. top5: 99.38. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9760. top1: 84.38. top5: 99.31. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9928. top1: 83.56. top5: 99.33. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0037. top1: 83.07. top5: 99.35. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0100. top1: 82.74. top5: 99.36. :  57%|█████▋    | 36/63 [00:02<00:00, 35.83it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0100. top1: 82.74. top5: 99.36. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0136. top1: 82.50. top5: 99.38. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0223. top1: 81.93. top5: 99.39. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0295. top1: 81.52. top5: 99.40. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0361. top1: 81.12. top5: 99.41. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0439. top1: 80.87. top5: 99.30. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0492. top1: 80.44. top5: 99.25. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0631. top1: 79.66. top5: 99.26. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0678. top1: 79.45. top5: 99.22. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0775. top1: 79.07. top5: 99.17. :  70%|██████▉   | 44/63 [00:02<00:00, 42.74it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0775. top1: 79.07. top5: 99.17. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0874. top1: 78.59. top5: 99.13. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0908. top1: 78.24. top5: 99.15. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0947. top1: 78.12. top5: 99.16. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1049. top1: 77.58. top5: 99.12. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1135. top1: 77.05. top5: 99.14. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1200. top1: 76.64. top5: 99.10. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1201. top1: 76.72. top5: 99.11. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1282. top1: 76.28. top5: 99.08. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1378. top1: 75.71. top5: 99.09. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1390. top1: 75.65. top5: 99.10. :  84%|████████▍ | 53/63 [00:02<00:00, 52.04it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1390. top1: 75.65. top5: 99.10. : 100%|██████████| 63/63 [00:02<00:00, 61.21it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1390. top1: 75.65. top5: 99.10. : 100%|██████████| 63/63 [00:02<00:00, 24.27it/s]
total : 5000  current step :  3800
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3801/5000. LR: 0.0094. Data: 1.90s. Batch: 2.04s. S_Loss: 1.1242. T_Loss: 5.4344. Mask: 0.8750. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 3801/5000. LR: 0.0094. Data: 1.90s. Batch: 2.04s. S_Loss: 1.1242. T_Loss: 5.4344. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:22,  2.04s/it]Train Iter: 3802/5000. LR: 0.0094. Data: 0.96s. Batch: 1.09s. S_Loss: 1.0420. T_Loss: 4.7216. Mask: 0.8906. :   1%|          | 1/100 [00:02<03:22,  2.04s/it]Train Iter: 3802/5000. LR: 0.0094. Data: 0.96s. Batch: 1.09s. S_Loss: 1.0420. T_Loss: 4.7216. Mask: 0.8906. :   2%|▏         | 2/100 [00:02<01:30,  1.09it/s]Train Iter: 3803/5000. LR: 0.0094. Data: 0.64s. Batch: 0.77s. S_Loss: 0.9981. T_Loss: 4.3947. Mask: 0.8542. :   2%|▏         | 2/100 [00:02<01:30,  1.09it/s]Train Iter: 3803/5000. LR: 0.0094. Data: 0.64s. Batch: 0.77s. S_Loss: 0.9981. T_Loss: 4.3947. Mask: 0.8542. :   3%|▎         | 3/100 [00:02<00:54,  1.79it/s]Train Iter: 3804/5000. LR: 0.0094. Data: 0.48s. Batch: 0.61s. S_Loss: 0.9535. T_Loss: 4.1506. Mask: 0.8594. :   3%|▎         | 3/100 [00:02<00:54,  1.79it/s]Train Iter: 3804/5000. LR: 0.0094. Data: 0.48s. Batch: 0.61s. S_Loss: 0.9535. T_Loss: 4.1506. Mask: 0.8594. :   4%|▍         | 4/100 [00:02<00:37,  2.57it/s]Train Iter: 3805/5000. LR: 0.0093. Data: 0.38s. Batch: 0.54s. S_Loss: 0.9432. T_Loss: 4.0877. Mask: 0.8625. :   4%|▍         | 4/100 [00:02<00:37,  2.57it/s]Train Iter: 3805/5000. LR: 0.0093. Data: 0.38s. Batch: 0.54s. S_Loss: 0.9432. T_Loss: 4.0877. Mask: 0.8625. :   5%|▌         | 5/100 [00:02<00:32,  2.92it/s]Train Iter: 3806/5000. LR: 0.0093. Data: 0.32s. Batch: 0.47s. S_Loss: 0.9403. T_Loss: 4.3172. Mask: 0.8802. :   5%|▌         | 5/100 [00:02<00:32,  2.92it/s]Train Iter: 3806/5000. LR: 0.0093. Data: 0.32s. Batch: 0.47s. S_Loss: 0.9403. T_Loss: 4.3172. Mask: 0.8802. :   6%|▌         | 6/100 [00:02<00:25,  3.69it/s]Train Iter: 3807/5000. LR: 0.0093. Data: 0.28s. Batch: 0.42s. S_Loss: 0.9343. T_Loss: 4.2638. Mask: 0.8795. :   6%|▌         | 6/100 [00:02<00:25,  3.69it/s]Train Iter: 3807/5000. LR: 0.0093. Data: 0.28s. Batch: 0.42s. S_Loss: 0.9343. T_Loss: 4.2638. Mask: 0.8795. :   7%|▋         | 7/100 [00:02<00:21,  4.42it/s]Train Iter: 3808/5000. LR: 0.0093. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9452. T_Loss: 4.2421. Mask: 0.8789. :   7%|▋         | 7/100 [00:03<00:21,  4.42it/s]Train Iter: 3808/5000. LR: 0.0093. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9452. T_Loss: 4.2421. Mask: 0.8789. :   8%|▊         | 8/100 [00:03<00:18,  5.01it/s]Train Iter: 3809/5000. LR: 0.0093. Data: 0.22s. Batch: 0.38s. S_Loss: 0.9490. T_Loss: 4.3452. Mask: 0.8889. :   8%|▊         | 8/100 [00:03<00:18,  5.01it/s]Train Iter: 3809/5000. LR: 0.0093. Data: 0.22s. Batch: 0.38s. S_Loss: 0.9490. T_Loss: 4.3452. Mask: 0.8889. :   9%|▉         | 9/100 [00:03<00:22,  4.10it/s]Train Iter: 3810/5000. LR: 0.0093. Data: 0.19s. Batch: 0.36s. S_Loss: 0.9454. T_Loss: 4.4682. Mask: 0.8938. :   9%|▉         | 9/100 [00:03<00:22,  4.10it/s]Train Iter: 3810/5000. LR: 0.0093. Data: 0.19s. Batch: 0.36s. S_Loss: 0.9454. T_Loss: 4.4682. Mask: 0.8938. :  10%|█         | 10/100 [00:03<00:18,  4.75it/s]Train Iter: 3811/5000. LR: 0.0093. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9471. T_Loss: 4.4928. Mask: 0.8977. :  10%|█         | 10/100 [00:03<00:18,  4.75it/s]Train Iter: 3811/5000. LR: 0.0093. Data: 0.18s. Batch: 0.34s. S_Loss: 0.9471. T_Loss: 4.4928. Mask: 0.8977. :  11%|█         | 11/100 [00:03<00:16,  5.39it/s]Train Iter: 3812/5000. LR: 0.0092. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9435. T_Loss: 4.4874. Mask: 0.9062. :  11%|█         | 11/100 [00:03<00:16,  5.39it/s]Train Iter: 3812/5000. LR: 0.0092. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9435. T_Loss: 4.4874. Mask: 0.9062. :  12%|█▏        | 12/100 [00:03<00:15,  5.75it/s]Train Iter: 3813/5000. LR: 0.0092. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9389. T_Loss: 4.5156. Mask: 0.9111. :  12%|█▏        | 12/100 [00:03<00:15,  5.75it/s]Train Iter: 3813/5000. LR: 0.0092. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9389. T_Loss: 4.5156. Mask: 0.9111. :  13%|█▎        | 13/100 [00:03<00:14,  6.08it/s]Train Iter: 3814/5000. LR: 0.0092. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9483. T_Loss: 4.5949. Mask: 0.9129. :  13%|█▎        | 13/100 [00:04<00:14,  6.08it/s]Train Iter: 3814/5000. LR: 0.0092. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9483. T_Loss: 4.5949. Mask: 0.9129. :  14%|█▍        | 14/100 [00:04<00:12,  6.62it/s]Train Iter: 3815/5000. LR: 0.0092. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9501. T_Loss: 4.6464. Mask: 0.9125. :  14%|█▍        | 14/100 [00:04<00:12,  6.62it/s]Train Iter: 3815/5000. LR: 0.0092. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9501. T_Loss: 4.6464. Mask: 0.9125. :  15%|█▌        | 15/100 [00:04<00:18,  4.70it/s]Train Iter: 3816/5000. LR: 0.0092. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9607. T_Loss: 4.6942. Mask: 0.9141. :  15%|█▌        | 15/100 [00:04<00:18,  4.70it/s]Train Iter: 3816/5000. LR: 0.0092. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9607. T_Loss: 4.6942. Mask: 0.9141. :  16%|█▌        | 16/100 [00:04<00:16,  5.17it/s]Train Iter: 3817/5000. LR: 0.0092. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9624. T_Loss: 4.7000. Mask: 0.9136. :  16%|█▌        | 16/100 [00:04<00:16,  5.17it/s]Train Iter: 3817/5000. LR: 0.0092. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9624. T_Loss: 4.7000. Mask: 0.9136. :  17%|█▋        | 17/100 [00:04<00:14,  5.70it/s]Train Iter: 3818/5000. LR: 0.0092. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9617. T_Loss: 4.6856. Mask: 0.9115. :  17%|█▋        | 17/100 [00:04<00:14,  5.70it/s]Train Iter: 3818/5000. LR: 0.0092. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9617. T_Loss: 4.6856. Mask: 0.9115. :  18%|█▊        | 18/100 [00:04<00:13,  6.15it/s]Train Iter: 3819/5000. LR: 0.0091. Data: 0.10s. Batch: 0.28s. S_Loss: 0.9690. T_Loss: 4.7274. Mask: 0.9112. :  18%|█▊        | 18/100 [00:05<00:13,  6.15it/s]Train Iter: 3819/5000. LR: 0.0091. Data: 0.10s. Batch: 0.28s. S_Loss: 0.9690. T_Loss: 4.7274. Mask: 0.9112. :  19%|█▉        | 19/100 [00:05<00:19,  4.24it/s]Train Iter: 3820/5000. LR: 0.0091. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9775. T_Loss: 4.7423. Mask: 0.9078. :  19%|█▉        | 19/100 [00:05<00:19,  4.24it/s]Train Iter: 3820/5000. LR: 0.0091. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9775. T_Loss: 4.7423. Mask: 0.9078. :  20%|██        | 20/100 [00:05<00:16,  4.81it/s]Train Iter: 3821/5000. LR: 0.0091. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9725. T_Loss: 4.7155. Mask: 0.9062. :  20%|██        | 20/100 [00:05<00:16,  4.81it/s]Train Iter: 3822/5000. LR: 0.0091. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9669. T_Loss: 4.7042. Mask: 0.9105. :  21%|██        | 21/100 [00:05<00:16,  4.81it/s]Train Iter: 3822/5000. LR: 0.0091. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9669. T_Loss: 4.7042. Mask: 0.9105. :  22%|██▏       | 22/100 [00:05<00:12,  6.17it/s]Train Iter: 3823/5000. LR: 0.0091. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9647. T_Loss: 4.7264. Mask: 0.9144. :  22%|██▏       | 22/100 [00:05<00:12,  6.17it/s]Train Iter: 3823/5000. LR: 0.0091. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9647. T_Loss: 4.7264. Mask: 0.9144. :  23%|██▎       | 23/100 [00:05<00:11,  6.53it/s]Train Iter: 3824/5000. LR: 0.0091. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9631. T_Loss: 4.7603. Mask: 0.9167. :  23%|██▎       | 23/100 [00:05<00:11,  6.53it/s]Train Iter: 3824/5000. LR: 0.0091. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9631. T_Loss: 4.7603. Mask: 0.9167. :  24%|██▍       | 24/100 [00:05<00:11,  6.85it/s]Train Iter: 3825/5000. LR: 0.0090. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9629. T_Loss: 4.7482. Mask: 0.9175. :  24%|██▍       | 24/100 [00:06<00:11,  6.85it/s]Train Iter: 3825/5000. LR: 0.0090. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9629. T_Loss: 4.7482. Mask: 0.9175. :  25%|██▌       | 25/100 [00:06<00:10,  7.20it/s]total : 5000  current step :  3801
total : 5000  current step :  3802
total : 5000  current step :  3803
total : 5000  current step :  3804
total : 5000  current step :  3805
total : 5000  current step :  3806
total : 5000  current step :  3807
total : 5000  current step :  3808
total : 5000  current step :  3809
total : 5000  current step :  3810
total : 5000  current step :  3811
total : 5000  current step :  3812
total : 5000  current step :  3813
total : 5000  current step :  3814
total : 5000  current step :  3815
total : 5000  current step :  3816
total : 5000  current step :  3817
total : 5000  current step :  3818
total : 5000  current step :  3819
total : 5000  current step :  3820
total : 5000  current step :  3821
total : 5000  current step :  3822
total : 5000  current step :  3823
total : 5000  current step :  3824
total : 5000  current step :  3825
Train Iter: 3826/5000. LR: 0.0090. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9623. T_Loss: 4.7781. Mask: 0.9183. :  25%|██▌       | 25/100 [00:08<00:10,  7.20it/s]Train Iter: 3826/5000. LR: 0.0090. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9623. T_Loss: 4.7781. Mask: 0.9183. :  26%|██▌       | 26/100 [00:08<00:50,  1.45it/s]Train Iter: 3827/5000. LR: 0.0090. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9642. T_Loss: 4.7649. Mask: 0.9167. :  26%|██▌       | 26/100 [00:08<00:50,  1.45it/s]Train Iter: 3827/5000. LR: 0.0090. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9642. T_Loss: 4.7649. Mask: 0.9167. :  27%|██▋       | 27/100 [00:08<00:38,  1.87it/s]Train Iter: 3828/5000. LR: 0.0090. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9651. T_Loss: 4.8170. Mask: 0.9196. :  27%|██▋       | 27/100 [00:08<00:38,  1.87it/s]Train Iter: 3828/5000. LR: 0.0090. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9651. T_Loss: 4.8170. Mask: 0.9196. :  28%|██▊       | 28/100 [00:08<00:30,  2.39it/s]Train Iter: 3829/5000. LR: 0.0090. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9699. T_Loss: 4.8377. Mask: 0.9224. :  28%|██▊       | 28/100 [00:08<00:30,  2.39it/s]Train Iter: 3829/5000. LR: 0.0090. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9699. T_Loss: 4.8377. Mask: 0.9224. :  29%|██▉       | 29/100 [00:08<00:28,  2.47it/s]Train Iter: 3830/5000. LR: 0.0090. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9748. T_Loss: 4.8599. Mask: 0.9219. :  29%|██▉       | 29/100 [00:08<00:28,  2.47it/s]Train Iter: 3830/5000. LR: 0.0090. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9748. T_Loss: 4.8599. Mask: 0.9219. :  30%|███       | 30/100 [00:08<00:22,  3.11it/s]Train Iter: 3831/5000. LR: 0.0090. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9753. T_Loss: 4.8759. Mask: 0.9234. :  30%|███       | 30/100 [00:09<00:22,  3.11it/s]Train Iter: 3832/5000. LR: 0.0089. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9727. T_Loss: 4.8774. Mask: 0.9229. :  31%|███       | 31/100 [00:09<00:22,  3.11it/s]Train Iter: 3832/5000. LR: 0.0089. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9727. T_Loss: 4.8774. Mask: 0.9229. :  32%|███▏      | 32/100 [00:09<00:15,  4.48it/s]Train Iter: 3833/5000. LR: 0.0089. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9712. T_Loss: 4.8440. Mask: 0.9214. :  32%|███▏      | 32/100 [00:09<00:15,  4.48it/s]Train Iter: 3833/5000. LR: 0.0089. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9712. T_Loss: 4.8440. Mask: 0.9214. :  33%|███▎      | 33/100 [00:09<00:13,  4.96it/s]Train Iter: 3834/5000. LR: 0.0089. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9719. T_Loss: 4.8653. Mask: 0.9237. :  33%|███▎      | 33/100 [00:09<00:13,  4.96it/s]Train Iter: 3834/5000. LR: 0.0089. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9719. T_Loss: 4.8653. Mask: 0.9237. :  34%|███▍      | 34/100 [00:09<00:11,  5.63it/s]Train Iter: 3835/5000. LR: 0.0089. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9730. T_Loss: 4.8698. Mask: 0.9232. :  34%|███▍      | 34/100 [00:09<00:11,  5.63it/s]Train Iter: 3835/5000. LR: 0.0089. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9730. T_Loss: 4.8698. Mask: 0.9232. :  35%|███▌      | 35/100 [00:09<00:10,  6.01it/s]Train Iter: 3836/5000. LR: 0.0089. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9720. T_Loss: 4.8600. Mask: 0.9210. :  35%|███▌      | 35/100 [00:09<00:10,  6.01it/s]Train Iter: 3837/5000. LR: 0.0089. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9707. T_Loss: 4.8504. Mask: 0.9198. :  36%|███▌      | 36/100 [00:09<00:10,  6.01it/s]Train Iter: 3837/5000. LR: 0.0089. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9707. T_Loss: 4.8504. Mask: 0.9198. :  37%|███▋      | 37/100 [00:09<00:08,  7.32it/s]Train Iter: 3838/5000. LR: 0.0089. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9731. T_Loss: 4.8810. Mask: 0.9211. :  37%|███▋      | 37/100 [00:09<00:08,  7.32it/s]Train Iter: 3838/5000. LR: 0.0089. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9731. T_Loss: 4.8810. Mask: 0.9211. :  38%|███▊      | 38/100 [00:09<00:08,  7.67it/s]Train Iter: 3839/5000. LR: 0.0088. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9729. T_Loss: 4.8761. Mask: 0.9215. :  38%|███▊      | 38/100 [00:10<00:08,  7.67it/s]Train Iter: 3839/5000. LR: 0.0088. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9729. T_Loss: 4.8761. Mask: 0.9215. :  39%|███▉      | 39/100 [00:10<00:10,  5.83it/s]Train Iter: 3840/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9746. T_Loss: 4.8822. Mask: 0.9211. :  39%|███▉      | 39/100 [00:10<00:10,  5.83it/s]Train Iter: 3840/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9746. T_Loss: 4.8822. Mask: 0.9211. :  40%|████      | 40/100 [00:10<00:09,  6.33it/s]Train Iter: 3841/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9768. T_Loss: 4.8992. Mask: 0.9223. :  40%|████      | 40/100 [00:10<00:09,  6.33it/s]Train Iter: 3841/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9768. T_Loss: 4.8992. Mask: 0.9223. :  41%|████      | 41/100 [00:10<00:08,  6.61it/s]Train Iter: 3842/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.8982. Mask: 0.9211. :  41%|████      | 41/100 [00:10<00:08,  6.61it/s]Train Iter: 3842/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.8982. Mask: 0.9211. :  42%|████▏     | 42/100 [00:10<00:08,  6.91it/s]Train Iter: 3843/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9748. T_Loss: 4.8838. Mask: 0.9215. :  42%|████▏     | 42/100 [00:10<00:08,  6.91it/s]Train Iter: 3843/5000. LR: 0.0088. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9748. T_Loss: 4.8838. Mask: 0.9215. :  43%|████▎     | 43/100 [00:10<00:07,  7.13it/s]Train Iter: 3844/5000. LR: 0.0088. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9744. T_Loss: 4.8902. Mask: 0.9219. :  43%|████▎     | 43/100 [00:10<00:07,  7.13it/s]Train Iter: 3844/5000. LR: 0.0088. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9744. T_Loss: 4.8902. Mask: 0.9219. :  44%|████▍     | 44/100 [00:10<00:07,  7.58it/s]Train Iter: 3845/5000. LR: 0.0088. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9754. T_Loss: 4.8882. Mask: 0.9208. :  44%|████▍     | 44/100 [00:11<00:07,  7.58it/s]Train Iter: 3845/5000. LR: 0.0088. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9754. T_Loss: 4.8882. Mask: 0.9208. :  45%|████▌     | 45/100 [00:11<00:11,  4.93it/s]Train Iter: 3846/5000. LR: 0.0087. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9775. T_Loss: 4.8883. Mask: 0.9198. :  45%|████▌     | 45/100 [00:11<00:11,  4.93it/s]Train Iter: 3846/5000. LR: 0.0087. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9775. T_Loss: 4.8883. Mask: 0.9198. :  46%|████▌     | 46/100 [00:11<00:09,  5.70it/s]Train Iter: 3847/5000. LR: 0.0087. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9748. T_Loss: 4.8939. Mask: 0.9209. :  46%|████▌     | 46/100 [00:11<00:09,  5.70it/s]Train Iter: 3847/5000. LR: 0.0087. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9748. T_Loss: 4.8939. Mask: 0.9209. :  47%|████▋     | 47/100 [00:11<00:08,  6.40it/s]Train Iter: 3848/5000. LR: 0.0087. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9742. T_Loss: 4.8849. Mask: 0.9206. :  47%|████▋     | 47/100 [00:11<00:08,  6.40it/s]Train Iter: 3848/5000. LR: 0.0087. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9742. T_Loss: 4.8849. Mask: 0.9206. :  48%|████▊     | 48/100 [00:11<00:07,  6.79it/s]Train Iter: 3849/5000. LR: 0.0087. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9753. T_Loss: 4.8745. Mask: 0.9196. :  48%|████▊     | 48/100 [00:11<00:07,  6.79it/s]Train Iter: 3849/5000. LR: 0.0087. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9753. T_Loss: 4.8745. Mask: 0.9196. :  49%|████▉     | 49/100 [00:11<00:10,  4.85it/s]Train Iter: 3850/5000. LR: 0.0087. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9745. T_Loss: 4.8636. Mask: 0.9194. :  49%|████▉     | 49/100 [00:11<00:10,  4.85it/s]Train Iter: 3850/5000. LR: 0.0087. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9745. T_Loss: 4.8636. Mask: 0.9194. :  50%|█████     | 50/100 [00:11<00:09,  5.38it/s]total : 5000  current step :  3826
total : 5000  current step :  3827
total : 5000  current step :  3828
total : 5000  current step :  3829
total : 5000  current step :  3830
total : 5000  current step :  3831
total : 5000  current step :  3832
total : 5000  current step :  3833
total : 5000  current step :  3834
total : 5000  current step :  3835
total : 5000  current step :  3836
total : 5000  current step :  3837
total : 5000  current step :  3838
total : 5000  current step :  3839
total : 5000  current step :  3840
total : 5000  current step :  3841
total : 5000  current step :  3842
total : 5000  current step :  3843
total : 5000  current step :  3844
total : 5000  current step :  3845
total : 5000  current step :  3846
total : 5000  current step :  3847
total : 5000  current step :  3848
total : 5000  current step :  3849
total : 5000  current step :  3850
Train Iter: 3851/5000. LR: 0.0087. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9754. T_Loss: 4.8711. Mask: 0.9203. :  50%|█████     | 50/100 [00:13<00:09,  5.38it/s]Train Iter: 3851/5000. LR: 0.0087. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9754. T_Loss: 4.8711. Mask: 0.9203. :  51%|█████     | 51/100 [00:13<00:34,  1.41it/s]Train Iter: 3852/5000. LR: 0.0087. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9728. T_Loss: 4.8613. Mask: 0.9213. :  51%|█████     | 51/100 [00:14<00:34,  1.41it/s]Train Iter: 3852/5000. LR: 0.0087. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9728. T_Loss: 4.8613. Mask: 0.9213. :  52%|█████▏    | 52/100 [00:14<00:26,  1.80it/s]Train Iter: 3853/5000. LR: 0.0087. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9729. T_Loss: 4.8622. Mask: 0.9216. :  52%|█████▏    | 52/100 [00:14<00:26,  1.80it/s]Train Iter: 3853/5000. LR: 0.0087. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9729. T_Loss: 4.8622. Mask: 0.9216. :  53%|█████▎    | 53/100 [00:14<00:20,  2.32it/s]Train Iter: 3854/5000. LR: 0.0086. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9739. T_Loss: 4.8743. Mask: 0.9230. :  53%|█████▎    | 53/100 [00:14<00:20,  2.32it/s]Train Iter: 3854/5000. LR: 0.0086. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9739. T_Loss: 4.8743. Mask: 0.9230. :  54%|█████▍    | 54/100 [00:14<00:15,  2.97it/s]Train Iter: 3855/5000. LR: 0.0086. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9721. T_Loss: 4.8575. Mask: 0.9222. :  54%|█████▍    | 54/100 [00:14<00:15,  2.97it/s]Train Iter: 3855/5000. LR: 0.0086. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9721. T_Loss: 4.8575. Mask: 0.9222. :  55%|█████▌    | 55/100 [00:14<00:15,  2.84it/s]Train Iter: 3856/5000. LR: 0.0086. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9724. T_Loss: 4.8501. Mask: 0.9213. :  55%|█████▌    | 55/100 [00:14<00:15,  2.84it/s]Train Iter: 3856/5000. LR: 0.0086. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9724. T_Loss: 4.8501. Mask: 0.9213. :  56%|█████▌    | 56/100 [00:14<00:12,  3.47it/s]Train Iter: 3857/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9733. T_Loss: 4.8412. Mask: 0.9205. :  56%|█████▌    | 56/100 [00:14<00:12,  3.47it/s]Train Iter: 3857/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9733. T_Loss: 4.8412. Mask: 0.9205. :  57%|█████▋    | 57/100 [00:14<00:10,  4.19it/s]Train Iter: 3858/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9715. T_Loss: 4.8315. Mask: 0.9203. :  57%|█████▋    | 57/100 [00:15<00:10,  4.19it/s]Train Iter: 3858/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9715. T_Loss: 4.8315. Mask: 0.9203. :  58%|█████▊    | 58/100 [00:15<00:08,  4.87it/s]Train Iter: 3859/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9729. T_Loss: 4.8460. Mask: 0.9206. :  58%|█████▊    | 58/100 [00:15<00:08,  4.87it/s]Train Iter: 3859/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9729. T_Loss: 4.8460. Mask: 0.9206. :  59%|█████▉    | 59/100 [00:15<00:08,  5.10it/s]Train Iter: 3860/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9715. T_Loss: 4.8464. Mask: 0.9214. :  59%|█████▉    | 59/100 [00:15<00:08,  5.10it/s]Train Iter: 3860/5000. LR: 0.0086. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9715. T_Loss: 4.8464. Mask: 0.9214. :  60%|██████    | 60/100 [00:15<00:06,  5.72it/s]Train Iter: 3861/5000. LR: 0.0085. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9708. T_Loss: 4.8501. Mask: 0.9221. :  60%|██████    | 60/100 [00:15<00:06,  5.72it/s]Train Iter: 3861/5000. LR: 0.0085. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9708. T_Loss: 4.8501. Mask: 0.9221. :  61%|██████    | 61/100 [00:15<00:06,  6.07it/s]Train Iter: 3862/5000. LR: 0.0085. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9699. T_Loss: 4.8446. Mask: 0.9224. :  61%|██████    | 61/100 [00:15<00:06,  6.07it/s]Train Iter: 3862/5000. LR: 0.0085. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9699. T_Loss: 4.8446. Mask: 0.9224. :  62%|██████▏   | 62/100 [00:15<00:05,  6.47it/s]Train Iter: 3863/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9697. T_Loss: 4.8423. Mask: 0.9211. :  62%|██████▏   | 62/100 [00:15<00:05,  6.47it/s]Train Iter: 3863/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9697. T_Loss: 4.8423. Mask: 0.9211. :  63%|██████▎   | 63/100 [00:15<00:05,  6.90it/s]Train Iter: 3864/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9699. T_Loss: 4.8333. Mask: 0.9209. :  63%|██████▎   | 63/100 [00:15<00:05,  6.90it/s]Train Iter: 3864/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9699. T_Loss: 4.8333. Mask: 0.9209. :  64%|██████▍   | 64/100 [00:15<00:05,  7.18it/s]Train Iter: 3865/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9689. T_Loss: 4.8297. Mask: 0.9221. :  64%|██████▍   | 64/100 [00:16<00:05,  7.18it/s]Train Iter: 3865/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9689. T_Loss: 4.8297. Mask: 0.9221. :  65%|██████▌   | 65/100 [00:16<00:06,  5.49it/s]Train Iter: 3866/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9689. T_Loss: 4.8277. Mask: 0.9223. :  65%|██████▌   | 65/100 [00:16<00:06,  5.49it/s]Train Iter: 3866/5000. LR: 0.0085. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9689. T_Loss: 4.8277. Mask: 0.9223. :  66%|██████▌   | 66/100 [00:16<00:05,  5.86it/s]Train Iter: 3867/5000. LR: 0.0085. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9689. T_Loss: 4.8320. Mask: 0.9230. :  66%|██████▌   | 66/100 [00:16<00:05,  5.86it/s]Train Iter: 3867/5000. LR: 0.0085. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9689. T_Loss: 4.8320. Mask: 0.9230. :  67%|██████▋   | 67/100 [00:16<00:05,  6.25it/s]Train Iter: 3868/5000. LR: 0.0084. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9707. T_Loss: 4.8333. Mask: 0.9233. :  67%|██████▋   | 67/100 [00:16<00:05,  6.25it/s]Train Iter: 3868/5000. LR: 0.0084. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9707. T_Loss: 4.8333. Mask: 0.9233. :  68%|██████▊   | 68/100 [00:16<00:04,  6.71it/s]Train Iter: 3869/5000. LR: 0.0084. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9722. T_Loss: 4.8312. Mask: 0.9221. :  68%|██████▊   | 68/100 [00:16<00:04,  6.71it/s]Train Iter: 3869/5000. LR: 0.0084. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9722. T_Loss: 4.8312. Mask: 0.9221. :  69%|██████▉   | 69/100 [00:16<00:06,  4.70it/s]Train Iter: 3870/5000. LR: 0.0084. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9715. T_Loss: 4.8232. Mask: 0.9214. :  69%|██████▉   | 69/100 [00:17<00:06,  4.70it/s]Train Iter: 3870/5000. LR: 0.0084. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9715. T_Loss: 4.8232. Mask: 0.9214. :  70%|███████   | 70/100 [00:17<00:05,  5.52it/s]Train Iter: 3871/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9706. T_Loss: 4.8158. Mask: 0.9217. :  70%|███████   | 70/100 [00:17<00:05,  5.52it/s]Train Iter: 3871/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9706. T_Loss: 4.8158. Mask: 0.9217. :  71%|███████   | 71/100 [00:17<00:04,  6.08it/s]Train Iter: 3872/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9695. T_Loss: 4.8076. Mask: 0.9210. :  71%|███████   | 71/100 [00:17<00:04,  6.08it/s]Train Iter: 3872/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9695. T_Loss: 4.8076. Mask: 0.9210. :  72%|███████▏  | 72/100 [00:17<00:04,  6.47it/s]Train Iter: 3873/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9692. T_Loss: 4.8051. Mask: 0.9204. :  72%|███████▏  | 72/100 [00:17<00:04,  6.47it/s]Train Iter: 3873/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9692. T_Loss: 4.8051. Mask: 0.9204. :  73%|███████▎  | 73/100 [00:17<00:03,  6.76it/s]Train Iter: 3874/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9689. T_Loss: 4.8009. Mask: 0.9206. :  73%|███████▎  | 73/100 [00:17<00:03,  6.76it/s]Train Iter: 3874/5000. LR: 0.0084. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9689. T_Loss: 4.8009. Mask: 0.9206. :  74%|███████▍  | 74/100 [00:17<00:03,  7.02it/s]Train Iter: 3875/5000. LR: 0.0083. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9703. T_Loss: 4.7990. Mask: 0.9204. :  74%|███████▍  | 74/100 [00:17<00:03,  7.02it/s]Train Iter: 3875/5000. LR: 0.0083. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9703. T_Loss: 4.7990. Mask: 0.9204. :  75%|███████▌  | 75/100 [00:17<00:05,  4.82it/s]total : 5000  current step :  3851
total : 5000  current step :  3852
total : 5000  current step :  3853
total : 5000  current step :  3854
total : 5000  current step :  3855
total : 5000  current step :  3856
total : 5000  current step :  3857
total : 5000  current step :  3858
total : 5000  current step :  3859
total : 5000  current step :  3860
total : 5000  current step :  3861
total : 5000  current step :  3862
total : 5000  current step :  3863
total : 5000  current step :  3864
total : 5000  current step :  3865
total : 5000  current step :  3866
total : 5000  current step :  3867
total : 5000  current step :  3868
total : 5000  current step :  3869
total : 5000  current step :  3870
total : 5000  current step :  3871
total : 5000  current step :  3872
total : 5000  current step :  3873
total : 5000  current step :  3874
total : 5000  current step :  3875
Train Iter: 3876/5000. LR: 0.0083. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9698. T_Loss: 4.7924. Mask: 0.9206. :  75%|███████▌  | 75/100 [00:20<00:05,  4.82it/s]Train Iter: 3876/5000. LR: 0.0083. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9698. T_Loss: 4.7924. Mask: 0.9206. :  76%|███████▌  | 76/100 [00:20<00:19,  1.26it/s]Train Iter: 3877/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9679. T_Loss: 4.7892. Mask: 0.9205. :  76%|███████▌  | 76/100 [00:20<00:19,  1.26it/s]Train Iter: 3877/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9679. T_Loss: 4.7892. Mask: 0.9205. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 3878/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9673. T_Loss: 4.7784. Mask: 0.9207. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 3878/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9673. T_Loss: 4.7784. Mask: 0.9207. :  78%|███████▊  | 78/100 [00:20<00:09,  2.25it/s]Train Iter: 3879/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9680. T_Loss: 4.7834. Mask: 0.9205. :  78%|███████▊  | 78/100 [00:20<00:09,  2.25it/s]Train Iter: 3879/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9680. T_Loss: 4.7834. Mask: 0.9205. :  79%|███████▉  | 79/100 [00:20<00:08,  2.41it/s]Train Iter: 3880/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9673. T_Loss: 4.7775. Mask: 0.9211. :  79%|███████▉  | 79/100 [00:20<00:08,  2.41it/s]Train Iter: 3881/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9702. T_Loss: 4.7821. Mask: 0.9205. :  80%|████████  | 80/100 [00:20<00:08,  2.41it/s]Train Iter: 3881/5000. LR: 0.0083. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9702. T_Loss: 4.7821. Mask: 0.9205. :  81%|████████  | 81/100 [00:20<00:05,  3.68it/s]Train Iter: 3882/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9694. T_Loss: 4.7727. Mask: 0.9204. :  81%|████████  | 81/100 [00:20<00:05,  3.68it/s]Train Iter: 3882/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9694. T_Loss: 4.7727. Mask: 0.9204. :  82%|████████▏ | 82/100 [00:20<00:04,  4.32it/s]Train Iter: 3883/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9683. T_Loss: 4.7672. Mask: 0.9209. :  82%|████████▏ | 82/100 [00:21<00:04,  4.32it/s]Train Iter: 3883/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9683. T_Loss: 4.7672. Mask: 0.9209. :  83%|████████▎ | 83/100 [00:21<00:03,  5.03it/s]Train Iter: 3884/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.7554. Mask: 0.9211. :  83%|████████▎ | 83/100 [00:21<00:03,  5.03it/s]Train Iter: 3884/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.7554. Mask: 0.9211. :  84%|████████▍ | 84/100 [00:21<00:02,  5.64it/s]Train Iter: 3885/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9664. T_Loss: 4.7523. Mask: 0.9213. :  84%|████████▍ | 84/100 [00:21<00:02,  5.64it/s]Train Iter: 3885/5000. LR: 0.0082. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9664. T_Loss: 4.7523. Mask: 0.9213. :  85%|████████▌ | 85/100 [00:21<00:02,  5.12it/s]Train Iter: 3886/5000. LR: 0.0082. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9682. T_Loss: 4.7552. Mask: 0.9208. :  85%|████████▌ | 85/100 [00:21<00:02,  5.12it/s]Train Iter: 3886/5000. LR: 0.0082. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9682. T_Loss: 4.7552. Mask: 0.9208. :  86%|████████▌ | 86/100 [00:21<00:02,  5.67it/s]Train Iter: 3887/5000. LR: 0.0082. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9676. T_Loss: 4.7492. Mask: 0.9206. :  86%|████████▌ | 86/100 [00:21<00:02,  5.67it/s]Train Iter: 3887/5000. LR: 0.0082. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9676. T_Loss: 4.7492. Mask: 0.9206. :  87%|████████▋ | 87/100 [00:21<00:02,  5.99it/s]Train Iter: 3888/5000. LR: 0.0082. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.7351. Mask: 0.9201. :  87%|████████▋ | 87/100 [00:21<00:02,  5.99it/s]Train Iter: 3888/5000. LR: 0.0082. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9666. T_Loss: 4.7351. Mask: 0.9201. :  88%|████████▊ | 88/100 [00:21<00:01,  6.45it/s]Train Iter: 3889/5000. LR: 0.0081. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9658. T_Loss: 4.7341. Mask: 0.9206. :  88%|████████▊ | 88/100 [00:22<00:01,  6.45it/s]Train Iter: 3889/5000. LR: 0.0081. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9658. T_Loss: 4.7341. Mask: 0.9206. :  89%|████████▉ | 89/100 [00:22<00:01,  6.06it/s]Train Iter: 3890/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9663. T_Loss: 4.7410. Mask: 0.9208. :  89%|████████▉ | 89/100 [00:22<00:01,  6.06it/s]Train Iter: 3890/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9663. T_Loss: 4.7410. Mask: 0.9208. :  90%|█████████ | 90/100 [00:22<00:01,  6.55it/s]Train Iter: 3891/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9661. T_Loss: 4.7295. Mask: 0.9196. :  90%|█████████ | 90/100 [00:22<00:01,  6.55it/s]Train Iter: 3891/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9661. T_Loss: 4.7295. Mask: 0.9196. :  91%|█████████ | 91/100 [00:22<00:01,  6.92it/s]Train Iter: 3892/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9662. T_Loss: 4.7373. Mask: 0.9202. :  91%|█████████ | 91/100 [00:22<00:01,  6.92it/s]Train Iter: 3892/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9662. T_Loss: 4.7373. Mask: 0.9202. :  92%|█████████▏| 92/100 [00:22<00:01,  6.91it/s]Train Iter: 3893/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9679. T_Loss: 4.7419. Mask: 0.9200. :  92%|█████████▏| 92/100 [00:22<00:01,  6.91it/s]Train Iter: 3893/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9679. T_Loss: 4.7419. Mask: 0.9200. :  93%|█████████▎| 93/100 [00:22<00:00,  7.14it/s]Train Iter: 3894/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9676. T_Loss: 4.7413. Mask: 0.9199. :  93%|█████████▎| 93/100 [00:22<00:00,  7.14it/s]Train Iter: 3894/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9676. T_Loss: 4.7413. Mask: 0.9199. :  94%|█████████▍| 94/100 [00:22<00:00,  7.37it/s]Train Iter: 3895/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9683. T_Loss: 4.7436. Mask: 0.9197. :  94%|█████████▍| 94/100 [00:22<00:00,  7.37it/s]Train Iter: 3895/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9683. T_Loss: 4.7436. Mask: 0.9197. :  95%|█████████▌| 95/100 [00:22<00:00,  5.47it/s]Train Iter: 3896/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9685. T_Loss: 4.7384. Mask: 0.9183. :  95%|█████████▌| 95/100 [00:23<00:00,  5.47it/s]Train Iter: 3896/5000. LR: 0.0081. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9685. T_Loss: 4.7384. Mask: 0.9183. :  96%|█████████▌| 96/100 [00:23<00:00,  5.97it/s]Train Iter: 3897/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9685. T_Loss: 4.7433. Mask: 0.9188. :  96%|█████████▌| 96/100 [00:23<00:00,  5.97it/s]Train Iter: 3897/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9685. T_Loss: 4.7433. Mask: 0.9188. :  97%|█████████▋| 97/100 [00:23<00:00,  6.39it/s]Train Iter: 3898/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9693. T_Loss: 4.7394. Mask: 0.9180. :  97%|█████████▋| 97/100 [00:23<00:00,  6.39it/s]Train Iter: 3898/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9693. T_Loss: 4.7394. Mask: 0.9180. :  98%|█████████▊| 98/100 [00:23<00:00,  6.55it/s]Train Iter: 3899/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9698. T_Loss: 4.7453. Mask: 0.9182. :  98%|█████████▊| 98/100 [00:23<00:00,  6.55it/s]Train Iter: 3899/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9698. T_Loss: 4.7453. Mask: 0.9182. :  99%|█████████▉| 99/100 [00:23<00:00,  5.57it/s]Train Iter: 3900/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9685. T_Loss: 4.7400. Mask: 0.9184. :  99%|█████████▉| 99/100 [00:23<00:00,  5.57it/s]Train Iter: 3900/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9685. T_Loss: 4.7400. Mask: 0.9184. : 100%|██████████| 100/100 [00:23<00:00,  5.98it/s]Train Iter: 3900/5000. LR: 0.0080. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9685. T_Loss: 4.7400. Mask: 0.9184. : 100%|██████████| 100/100 [00:23<00:00,  4.20it/s]
total : 5000  current step :  3876
total : 5000  current step :  3877
total : 5000  current step :  3878
total : 5000  current step :  3879
total : 5000  current step :  3880
total : 5000  current step :  3881
total : 5000  current step :  3882
total : 5000  current step :  3883
total : 5000  current step :  3884
total : 5000  current step :  3885
total : 5000  current step :  3886
total : 5000  current step :  3887
total : 5000  current step :  3888
total : 5000  current step :  3889
total : 5000  current step :  3890
total : 5000  current step :  3891
total : 5000  current step :  3892
total : 5000  current step :  3893
total : 5000  current step :  3894
total : 5000  current step :  3895
total : 5000  current step :  3896
total : 5000  current step :  3897
total : 5000  current step :  3898
total : 5000  current step :  3899
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 0.8724. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 0.8724. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.93s. Loss: 0.8637. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.8369. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.8366. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8269. top1: 91.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8255. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8393. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8388. top1: 90.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8366. top1: 90.28. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8421. top1: 90.31. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8421. top1: 90.31. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.94it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8324. top1: 91.19. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.94it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8331. top1: 91.15. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.94it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8277. top1: 91.35. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.94it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8244. top1: 91.52. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.94it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8233. top1: 91.67. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.94it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8254. top1: 91.60. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.94it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8234. top1: 91.73. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.94it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8240. top1: 91.84. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.94it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8240. top1: 91.84. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8233. top1: 91.94. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8227. top1: 92.03. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8257. top1: 91.96. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8238. top1: 92.19. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8202. top1: 92.53. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8176. top1: 92.71. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8152. top1: 92.75. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8192. top1: 92.43. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8190. top1: 92.59. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8221. top1: 92.52. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.64it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8221. top1: 92.52. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8198. top1: 92.67. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8196. top1: 92.71. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8192. top1: 92.84. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8423. top1: 91.70. top5: 99.90. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8558. top1: 90.72. top5: 99.91. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8703. top1: 89.80. top5: 99.91. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8886. top1: 88.66. top5: 99.91. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9161. top1: 87.50. top5: 99.65. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9264. top1: 86.82. top5: 99.66. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9394. top1: 86.02. top5: 99.67. :  44%|████▍     | 28/63 [00:02<00:01, 23.66it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9394. top1: 86.02. top5: 99.67. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9557. top1: 85.26. top5: 99.44. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9683. top1: 84.61. top5: 99.45. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9765. top1: 84.07. top5: 99.39. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9944. top1: 83.18. top5: 99.40. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0063. top1: 82.70. top5: 99.42. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0135. top1: 82.39. top5: 99.36. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0180. top1: 82.15. top5: 99.38. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0276. top1: 81.52. top5: 99.39. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0356. top1: 80.98. top5: 99.40. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0431. top1: 80.53. top5: 99.41. :  60%|██████    | 38/63 [00:02<00:00, 34.04it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0431. top1: 80.53. top5: 99.41. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0511. top1: 80.23. top5: 99.36. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0577. top1: 79.75. top5: 99.31. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0725. top1: 78.92. top5: 99.33. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0777. top1: 78.61. top5: 99.28. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0875. top1: 78.12. top5: 99.23. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0982. top1: 77.60. top5: 99.19. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1022. top1: 77.16. top5: 99.20. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1070. top1: 76.84. top5: 99.22. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1177. top1: 76.32. top5: 99.18. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1273. top1: 75.81. top5: 99.14. :  76%|███████▌  | 48/63 [00:02<00:00, 44.21it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1273. top1: 75.81. top5: 99.14. :  92%|█████████▏| 58/63 [00:02<00:00, 53.97it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1341. top1: 75.37. top5: 99.10. :  92%|█████████▏| 58/63 [00:02<00:00, 53.97it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1349. top1: 75.36. top5: 99.11. :  92%|█████████▏| 58/63 [00:02<00:00, 53.97it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1436. top1: 74.95. top5: 99.08. :  92%|█████████▏| 58/63 [00:02<00:00, 53.97it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1538. top1: 74.29. top5: 99.09. :  92%|█████████▏| 58/63 [00:02<00:00, 53.97it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1552. top1: 74.20. top5: 99.10. :  92%|█████████▏| 58/63 [00:02<00:00, 53.97it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1552. top1: 74.20. top5: 99.10. : 100%|██████████| 63/63 [00:02<00:00, 22.67it/s]
total : 5000  current step :  3900
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 3901/5000. LR: 0.0080. Data: 2.02s. Batch: 2.14s. S_Loss: 1.0366. T_Loss: 5.0584. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 3901/5000. LR: 0.0080. Data: 2.02s. Batch: 2.14s. S_Loss: 1.0366. T_Loss: 5.0584. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:32,  2.14s/it]Train Iter: 3902/5000. LR: 0.0080. Data: 1.02s. Batch: 1.15s. S_Loss: 0.9984. T_Loss: 4.9412. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:32,  2.14s/it]Train Iter: 3902/5000. LR: 0.0080. Data: 1.02s. Batch: 1.15s. S_Loss: 0.9984. T_Loss: 4.9412. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:35,  1.02it/s]Train Iter: 3903/5000. LR: 0.0080. Data: 0.68s. Batch: 0.81s. S_Loss: 0.9708. T_Loss: 4.6795. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:35,  1.02it/s]Train Iter: 3903/5000. LR: 0.0080. Data: 0.68s. Batch: 0.81s. S_Loss: 0.9708. T_Loss: 4.6795. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 3904/5000. LR: 0.0079. Data: 0.51s. Batch: 0.64s. S_Loss: 0.9651. T_Loss: 4.3838. Mask: 0.8906. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 3904/5000. LR: 0.0079. Data: 0.51s. Batch: 0.64s. S_Loss: 0.9651. T_Loss: 4.3838. Mask: 0.8906. :   4%|▍         | 4/100 [00:02<00:39,  2.46it/s]Train Iter: 3905/5000. LR: 0.0079. Data: 0.41s. Batch: 0.58s. S_Loss: 0.9814. T_Loss: 4.4207. Mask: 0.9000. :   4%|▍         | 4/100 [00:02<00:39,  2.46it/s]Train Iter: 3905/5000. LR: 0.0079. Data: 0.41s. Batch: 0.58s. S_Loss: 0.9814. T_Loss: 4.4207. Mask: 0.9000. :   5%|▌         | 5/100 [00:02<00:36,  2.58it/s]Train Iter: 3906/5000. LR: 0.0079. Data: 0.34s. Batch: 0.50s. S_Loss: 0.9813. T_Loss: 4.4485. Mask: 0.9115. :   5%|▌         | 5/100 [00:03<00:36,  2.58it/s]Train Iter: 3906/5000. LR: 0.0079. Data: 0.34s. Batch: 0.50s. S_Loss: 0.9813. T_Loss: 4.4485. Mask: 0.9115. :   6%|▌         | 6/100 [00:03<00:27,  3.42it/s]Train Iter: 3907/5000. LR: 0.0079. Data: 0.29s. Batch: 0.45s. S_Loss: 0.9684. T_Loss: 4.3495. Mask: 0.9152. :   6%|▌         | 6/100 [00:03<00:27,  3.42it/s]Train Iter: 3907/5000. LR: 0.0079. Data: 0.29s. Batch: 0.45s. S_Loss: 0.9684. T_Loss: 4.3495. Mask: 0.9152. :   7%|▋         | 7/100 [00:03<00:22,  4.20it/s]Train Iter: 3908/5000. LR: 0.0079. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9697. T_Loss: 4.3500. Mask: 0.9141. :   7%|▋         | 7/100 [00:03<00:22,  4.20it/s]Train Iter: 3908/5000. LR: 0.0079. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9697. T_Loss: 4.3500. Mask: 0.9141. :   8%|▊         | 8/100 [00:03<00:19,  4.76it/s]Train Iter: 3909/5000. LR: 0.0079. Data: 0.23s. Batch: 0.40s. S_Loss: 0.9613. T_Loss: 4.3645. Mask: 0.9201. :   8%|▊         | 8/100 [00:03<00:19,  4.76it/s]Train Iter: 3909/5000. LR: 0.0079. Data: 0.23s. Batch: 0.40s. S_Loss: 0.9613. T_Loss: 4.3645. Mask: 0.9201. :   9%|▉         | 9/100 [00:03<00:21,  4.18it/s]Train Iter: 3910/5000. LR: 0.0079. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9528. T_Loss: 4.4024. Mask: 0.9281. :   9%|▉         | 9/100 [00:03<00:21,  4.18it/s]Train Iter: 3910/5000. LR: 0.0079. Data: 0.21s. Batch: 0.37s. S_Loss: 0.9528. T_Loss: 4.4024. Mask: 0.9281. :  10%|█         | 10/100 [00:03<00:18,  4.75it/s]Train Iter: 3911/5000. LR: 0.0078. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9557. T_Loss: 4.4895. Mask: 0.9318. :  10%|█         | 10/100 [00:03<00:18,  4.75it/s]Train Iter: 3911/5000. LR: 0.0078. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9557. T_Loss: 4.4895. Mask: 0.9318. :  11%|█         | 11/100 [00:03<00:16,  5.24it/s]Train Iter: 3912/5000. LR: 0.0078. Data: 0.17s. Batch: 0.34s. S_Loss: 0.9540. T_Loss: 4.4942. Mask: 0.9323. :  11%|█         | 11/100 [00:04<00:16,  5.24it/s]Train Iter: 3912/5000. LR: 0.0078. Data: 0.17s. Batch: 0.34s. S_Loss: 0.9540. T_Loss: 4.4942. Mask: 0.9323. :  12%|█▏        | 12/100 [00:04<00:15,  5.64it/s]Train Iter: 3913/5000. LR: 0.0078. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9499. T_Loss: 4.5333. Mask: 0.9351. :  12%|█▏        | 12/100 [00:04<00:15,  5.64it/s]Train Iter: 3913/5000. LR: 0.0078. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9499. T_Loss: 4.5333. Mask: 0.9351. :  13%|█▎        | 13/100 [00:04<00:14,  6.11it/s]Train Iter: 3914/5000. LR: 0.0078. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9455. T_Loss: 4.4972. Mask: 0.9330. :  13%|█▎        | 13/100 [00:04<00:14,  6.11it/s]Train Iter: 3914/5000. LR: 0.0078. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9455. T_Loss: 4.4972. Mask: 0.9330. :  14%|█▍        | 14/100 [00:04<00:12,  6.64it/s]Train Iter: 3915/5000. LR: 0.0078. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9470. T_Loss: 4.4849. Mask: 0.9313. :  14%|█▍        | 14/100 [00:04<00:12,  6.64it/s]Train Iter: 3915/5000. LR: 0.0078. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9470. T_Loss: 4.4849. Mask: 0.9313. :  15%|█▌        | 15/100 [00:04<00:16,  5.13it/s]Train Iter: 3916/5000. LR: 0.0078. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9386. T_Loss: 4.4626. Mask: 0.9336. :  15%|█▌        | 15/100 [00:04<00:16,  5.13it/s]Train Iter: 3916/5000. LR: 0.0078. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9386. T_Loss: 4.4626. Mask: 0.9336. :  16%|█▌        | 16/100 [00:04<00:14,  5.63it/s]Train Iter: 3917/5000. LR: 0.0078. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9462. T_Loss: 4.4960. Mask: 0.9301. :  16%|█▌        | 16/100 [00:04<00:14,  5.63it/s]Train Iter: 3917/5000. LR: 0.0078. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9462. T_Loss: 4.4960. Mask: 0.9301. :  17%|█▋        | 17/100 [00:04<00:13,  6.16it/s]Train Iter: 3918/5000. LR: 0.0078. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9485. T_Loss: 4.4965. Mask: 0.9306. :  17%|█▋        | 17/100 [00:04<00:13,  6.16it/s]Train Iter: 3918/5000. LR: 0.0078. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9485. T_Loss: 4.4965. Mask: 0.9306. :  18%|█▊        | 18/100 [00:04<00:12,  6.39it/s]Train Iter: 3919/5000. LR: 0.0077. Data: 0.11s. Batch: 0.29s. S_Loss: 0.9491. T_Loss: 4.5057. Mask: 0.9293. :  18%|█▊        | 18/100 [00:05<00:12,  6.39it/s]Train Iter: 3919/5000. LR: 0.0077. Data: 0.11s. Batch: 0.29s. S_Loss: 0.9491. T_Loss: 4.5057. Mask: 0.9293. :  19%|█▉        | 19/100 [00:05<00:21,  3.77it/s]Train Iter: 3920/5000. LR: 0.0077. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9449. T_Loss: 4.4874. Mask: 0.9281. :  19%|█▉        | 19/100 [00:05<00:21,  3.77it/s]Train Iter: 3920/5000. LR: 0.0077. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9449. T_Loss: 4.4874. Mask: 0.9281. :  20%|██        | 20/100 [00:05<00:17,  4.47it/s]Train Iter: 3921/5000. LR: 0.0077. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9454. T_Loss: 4.4878. Mask: 0.9301. :  20%|██        | 20/100 [00:05<00:17,  4.47it/s]Train Iter: 3921/5000. LR: 0.0077. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9454. T_Loss: 4.4878. Mask: 0.9301. :  21%|██        | 21/100 [00:05<00:15,  5.17it/s]Train Iter: 3922/5000. LR: 0.0077. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9428. T_Loss: 4.4637. Mask: 0.9318. :  21%|██        | 21/100 [00:05<00:15,  5.17it/s]Train Iter: 3922/5000. LR: 0.0077. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9428. T_Loss: 4.4637. Mask: 0.9318. :  22%|██▏       | 22/100 [00:05<00:13,  5.82it/s]Train Iter: 3923/5000. LR: 0.0077. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9453. T_Loss: 4.4630. Mask: 0.9307. :  22%|██▏       | 22/100 [00:06<00:13,  5.82it/s]Train Iter: 3923/5000. LR: 0.0077. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9453. T_Loss: 4.4630. Mask: 0.9307. :  23%|██▎       | 23/100 [00:06<00:12,  6.30it/s]Train Iter: 3924/5000. LR: 0.0077. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9471. T_Loss: 4.4988. Mask: 0.9310. :  23%|██▎       | 23/100 [00:06<00:12,  6.30it/s]Train Iter: 3924/5000. LR: 0.0077. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9471. T_Loss: 4.4988. Mask: 0.9310. :  24%|██▍       | 24/100 [00:06<00:11,  6.68it/s]Train Iter: 3925/5000. LR: 0.0077. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9465. T_Loss: 4.4908. Mask: 0.9313. :  24%|██▍       | 24/100 [00:06<00:11,  6.68it/s]Train Iter: 3925/5000. LR: 0.0077. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9465. T_Loss: 4.4908. Mask: 0.9313. :  25%|██▌       | 25/100 [00:06<00:16,  4.62it/s]total : 5000  current step :  3901
total : 5000  current step :  3902
total : 5000  current step :  3903
total : 5000  current step :  3904
total : 5000  current step :  3905
total : 5000  current step :  3906
total : 5000  current step :  3907
total : 5000  current step :  3908
total : 5000  current step :  3909
total : 5000  current step :  3910
total : 5000  current step :  3911
total : 5000  current step :  3912
total : 5000  current step :  3913
total : 5000  current step :  3914
total : 5000  current step :  3915
total : 5000  current step :  3916
total : 5000  current step :  3917
total : 5000  current step :  3918
total : 5000  current step :  3919
total : 5000  current step :  3920
total : 5000  current step :  3921
total : 5000  current step :  3922
total : 5000  current step :  3923
total : 5000  current step :  3924
total : 5000  current step :  3925
Train Iter: 3926/5000. LR: 0.0076. Data: 0.16s. Batch: 0.33s. S_Loss: 0.9483. T_Loss: 4.4525. Mask: 0.9255. :  25%|██▌       | 25/100 [00:08<00:16,  4.62it/s]Train Iter: 3926/5000. LR: 0.0076. Data: 0.16s. Batch: 0.33s. S_Loss: 0.9483. T_Loss: 4.4525. Mask: 0.9255. :  26%|██▌       | 26/100 [00:08<00:58,  1.27it/s]Train Iter: 3927/5000. LR: 0.0076. Data: 0.15s. Batch: 0.32s. S_Loss: 0.9464. T_Loss: 4.4469. Mask: 0.9271. :  26%|██▌       | 26/100 [00:08<00:58,  1.27it/s]Train Iter: 3927/5000. LR: 0.0076. Data: 0.15s. Batch: 0.32s. S_Loss: 0.9464. T_Loss: 4.4469. Mask: 0.9271. :  27%|██▋       | 27/100 [00:08<00:42,  1.70it/s]Train Iter: 3928/5000. LR: 0.0076. Data: 0.15s. Batch: 0.32s. S_Loss: 0.9486. T_Loss: 4.4518. Mask: 0.9286. :  27%|██▋       | 27/100 [00:08<00:42,  1.70it/s]Train Iter: 3928/5000. LR: 0.0076. Data: 0.15s. Batch: 0.32s. S_Loss: 0.9486. T_Loss: 4.4518. Mask: 0.9286. :  28%|██▊       | 28/100 [00:08<00:32,  2.22it/s]Train Iter: 3929/5000. LR: 0.0076. Data: 0.14s. Batch: 0.31s. S_Loss: 0.9453. T_Loss: 4.4524. Mask: 0.9300. :  28%|██▊       | 28/100 [00:09<00:32,  2.22it/s]Train Iter: 3929/5000. LR: 0.0076. Data: 0.14s. Batch: 0.31s. S_Loss: 0.9453. T_Loss: 4.4524. Mask: 0.9300. :  29%|██▉       | 29/100 [00:09<00:28,  2.50it/s]Train Iter: 3930/5000. LR: 0.0076. Data: 0.14s. Batch: 0.31s. S_Loss: 0.9411. T_Loss: 4.4331. Mask: 0.9313. :  29%|██▉       | 29/100 [00:09<00:28,  2.50it/s]Train Iter: 3930/5000. LR: 0.0076. Data: 0.14s. Batch: 0.31s. S_Loss: 0.9411. T_Loss: 4.4331. Mask: 0.9313. :  30%|███       | 30/100 [00:09<00:22,  3.14it/s]Train Iter: 3931/5000. LR: 0.0076. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9421. T_Loss: 4.4376. Mask: 0.9315. :  30%|███       | 30/100 [00:09<00:22,  3.14it/s]Train Iter: 3931/5000. LR: 0.0076. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9421. T_Loss: 4.4376. Mask: 0.9315. :  31%|███       | 31/100 [00:09<00:18,  3.78it/s]Train Iter: 3932/5000. LR: 0.0076. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9446. T_Loss: 4.4420. Mask: 0.9277. :  31%|███       | 31/100 [00:09<00:18,  3.78it/s]Train Iter: 3932/5000. LR: 0.0076. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9446. T_Loss: 4.4420. Mask: 0.9277. :  32%|███▏      | 32/100 [00:09<00:15,  4.49it/s]Train Iter: 3933/5000. LR: 0.0075. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9446. T_Loss: 4.4258. Mask: 0.9280. :  32%|███▏      | 32/100 [00:09<00:15,  4.49it/s]Train Iter: 3933/5000. LR: 0.0075. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9446. T_Loss: 4.4258. Mask: 0.9280. :  33%|███▎      | 33/100 [00:09<00:13,  5.13it/s]Train Iter: 3934/5000. LR: 0.0075. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9438. T_Loss: 4.4134. Mask: 0.9274. :  33%|███▎      | 33/100 [00:09<00:13,  5.13it/s]Train Iter: 3934/5000. LR: 0.0075. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9438. T_Loss: 4.4134. Mask: 0.9274. :  34%|███▍      | 34/100 [00:09<00:11,  5.69it/s]Train Iter: 3935/5000. LR: 0.0075. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9432. T_Loss: 4.3915. Mask: 0.9277. :  34%|███▍      | 34/100 [00:10<00:11,  5.69it/s]Train Iter: 3935/5000. LR: 0.0075. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9432. T_Loss: 4.3915. Mask: 0.9277. :  35%|███▌      | 35/100 [00:10<00:13,  4.81it/s]Train Iter: 3936/5000. LR: 0.0075. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9397. T_Loss: 4.3848. Mask: 0.9288. :  35%|███▌      | 35/100 [00:10<00:13,  4.81it/s]Train Iter: 3936/5000. LR: 0.0075. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9397. T_Loss: 4.3848. Mask: 0.9288. :  36%|███▌      | 36/100 [00:10<00:11,  5.61it/s]Train Iter: 3937/5000. LR: 0.0075. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9382. T_Loss: 4.3841. Mask: 0.9299. :  36%|███▌      | 36/100 [00:10<00:11,  5.61it/s]Train Iter: 3937/5000. LR: 0.0075. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9382. T_Loss: 4.3841. Mask: 0.9299. :  37%|███▋      | 37/100 [00:10<00:10,  6.20it/s]Train Iter: 3938/5000. LR: 0.0075. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9380. T_Loss: 4.3766. Mask: 0.9268. :  37%|███▋      | 37/100 [00:10<00:10,  6.20it/s]Train Iter: 3938/5000. LR: 0.0075. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9380. T_Loss: 4.3766. Mask: 0.9268. :  38%|███▊      | 38/100 [00:10<00:08,  6.92it/s]Train Iter: 3939/5000. LR: 0.0075. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9398. T_Loss: 4.3959. Mask: 0.9279. :  38%|███▊      | 38/100 [00:10<00:08,  6.92it/s]Train Iter: 3939/5000. LR: 0.0075. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9398. T_Loss: 4.3959. Mask: 0.9279. :  39%|███▉      | 39/100 [00:10<00:08,  7.50it/s]Train Iter: 3940/5000. LR: 0.0075. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9366. T_Loss: 4.3764. Mask: 0.9297. :  39%|███▉      | 39/100 [00:10<00:08,  7.50it/s]Train Iter: 3940/5000. LR: 0.0075. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9366. T_Loss: 4.3764. Mask: 0.9297. :  40%|████      | 40/100 [00:10<00:07,  7.73it/s]Train Iter: 3941/5000. LR: 0.0074. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9397. T_Loss: 4.3926. Mask: 0.9299. :  40%|████      | 40/100 [00:10<00:07,  7.73it/s]Train Iter: 3941/5000. LR: 0.0074. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9397. T_Loss: 4.3926. Mask: 0.9299. :  41%|████      | 41/100 [00:10<00:07,  7.42it/s]Train Iter: 3942/5000. LR: 0.0074. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9412. T_Loss: 4.4031. Mask: 0.9308. :  41%|████      | 41/100 [00:10<00:07,  7.42it/s]Train Iter: 3942/5000. LR: 0.0074. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9412. T_Loss: 4.4031. Mask: 0.9308. :  42%|████▏     | 42/100 [00:10<00:07,  7.52it/s]Train Iter: 3943/5000. LR: 0.0074. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9403. T_Loss: 4.3958. Mask: 0.9295. :  42%|████▏     | 42/100 [00:11<00:07,  7.52it/s]Train Iter: 3943/5000. LR: 0.0074. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9403. T_Loss: 4.3958. Mask: 0.9295. :  43%|████▎     | 43/100 [00:11<00:07,  7.69it/s]Train Iter: 3944/5000. LR: 0.0074. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9390. T_Loss: 4.4020. Mask: 0.9304. :  43%|████▎     | 43/100 [00:11<00:07,  7.69it/s]Train Iter: 3944/5000. LR: 0.0074. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9390. T_Loss: 4.4020. Mask: 0.9304. :  44%|████▍     | 44/100 [00:11<00:07,  7.59it/s]Train Iter: 3945/5000. LR: 0.0074. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9387. T_Loss: 4.3945. Mask: 0.9306. :  44%|████▍     | 44/100 [00:11<00:07,  7.59it/s]Train Iter: 3945/5000. LR: 0.0074. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9387. T_Loss: 4.3945. Mask: 0.9306. :  45%|████▌     | 45/100 [00:11<00:08,  6.20it/s]Train Iter: 3946/5000. LR: 0.0074. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9398. T_Loss: 4.4183. Mask: 0.9314. :  45%|████▌     | 45/100 [00:11<00:08,  6.20it/s]Train Iter: 3946/5000. LR: 0.0074. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9398. T_Loss: 4.4183. Mask: 0.9314. :  46%|████▌     | 46/100 [00:11<00:08,  6.73it/s]Train Iter: 3947/5000. LR: 0.0074. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9394. T_Loss: 4.4186. Mask: 0.9315. :  46%|████▌     | 46/100 [00:11<00:08,  6.73it/s]Train Iter: 3947/5000. LR: 0.0074. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9394. T_Loss: 4.4186. Mask: 0.9315. :  47%|████▋     | 47/100 [00:11<00:07,  7.23it/s]Train Iter: 3948/5000. LR: 0.0073. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9398. T_Loss: 4.4208. Mask: 0.9316. :  47%|████▋     | 47/100 [00:11<00:07,  7.23it/s]Train Iter: 3948/5000. LR: 0.0073. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9398. T_Loss: 4.4208. Mask: 0.9316. :  48%|████▊     | 48/100 [00:11<00:06,  7.77it/s]Train Iter: 3949/5000. LR: 0.0073. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9388. T_Loss: 4.4228. Mask: 0.9324. :  48%|████▊     | 48/100 [00:12<00:06,  7.77it/s]Train Iter: 3949/5000. LR: 0.0073. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9388. T_Loss: 4.4228. Mask: 0.9324. :  49%|████▉     | 49/100 [00:12<00:09,  5.16it/s]Train Iter: 3950/5000. LR: 0.0073. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9392. T_Loss: 4.4271. Mask: 0.9331. :  49%|████▉     | 49/100 [00:12<00:09,  5.16it/s]Train Iter: 3950/5000. LR: 0.0073. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9392. T_Loss: 4.4271. Mask: 0.9331. :  50%|█████     | 50/100 [00:12<00:08,  5.79it/s]total : 5000  current step :  3926
total : 5000  current step :  3927
total : 5000  current step :  3928
total : 5000  current step :  3929
total : 5000  current step :  3930
total : 5000  current step :  3931
total : 5000  current step :  3932
total : 5000  current step :  3933
total : 5000  current step :  3934
total : 5000  current step :  3935
total : 5000  current step :  3936
total : 5000  current step :  3937
total : 5000  current step :  3938
total : 5000  current step :  3939
total : 5000  current step :  3940
total : 5000  current step :  3941
total : 5000  current step :  3942
total : 5000  current step :  3943
total : 5000  current step :  3944
total : 5000  current step :  3945
total : 5000  current step :  3946
total : 5000  current step :  3947
total : 5000  current step :  3948
total : 5000  current step :  3949
total : 5000  current step :  3950
Train Iter: 3951/5000. LR: 0.0073. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9397. T_Loss: 4.4354. Mask: 0.9326. :  50%|█████     | 50/100 [00:14<00:08,  5.79it/s]Train Iter: 3951/5000. LR: 0.0073. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9397. T_Loss: 4.4354. Mask: 0.9326. :  51%|█████     | 51/100 [00:14<00:36,  1.35it/s]Train Iter: 3952/5000. LR: 0.0073. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9395. T_Loss: 4.4460. Mask: 0.9321. :  51%|█████     | 51/100 [00:14<00:36,  1.35it/s]Train Iter: 3952/5000. LR: 0.0073. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9395. T_Loss: 4.4460. Mask: 0.9321. :  52%|█████▏    | 52/100 [00:14<00:26,  1.78it/s]Train Iter: 3953/5000. LR: 0.0073. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9395. T_Loss: 4.4414. Mask: 0.9316. :  52%|█████▏    | 52/100 [00:14<00:26,  1.78it/s]Train Iter: 3953/5000. LR: 0.0073. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9395. T_Loss: 4.4414. Mask: 0.9316. :  53%|█████▎    | 53/100 [00:14<00:20,  2.30it/s]Train Iter: 3954/5000. LR: 0.0073. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9392. T_Loss: 4.4327. Mask: 0.9317. :  53%|█████▎    | 53/100 [00:14<00:20,  2.30it/s]Train Iter: 3954/5000. LR: 0.0073. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9392. T_Loss: 4.4327. Mask: 0.9317. :  54%|█████▍    | 54/100 [00:14<00:15,  2.92it/s]Train Iter: 3955/5000. LR: 0.0073. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9380. T_Loss: 4.4227. Mask: 0.9324. :  54%|█████▍    | 54/100 [00:15<00:15,  2.92it/s]Train Iter: 3955/5000. LR: 0.0073. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9380. T_Loss: 4.4227. Mask: 0.9324. :  55%|█████▌    | 55/100 [00:15<00:15,  2.97it/s]Train Iter: 3956/5000. LR: 0.0072. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9399. T_Loss: 4.4379. Mask: 0.9325. :  55%|█████▌    | 55/100 [00:15<00:15,  2.97it/s]Train Iter: 3956/5000. LR: 0.0072. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9399. T_Loss: 4.4379. Mask: 0.9325. :  56%|█████▌    | 56/100 [00:15<00:12,  3.67it/s]Train Iter: 3957/5000. LR: 0.0072. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9377. T_Loss: 4.4372. Mask: 0.9331. :  56%|█████▌    | 56/100 [00:15<00:12,  3.67it/s]Train Iter: 3957/5000. LR: 0.0072. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9377. T_Loss: 4.4372. Mask: 0.9331. :  57%|█████▋    | 57/100 [00:15<00:09,  4.35it/s]Train Iter: 3958/5000. LR: 0.0072. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9385. T_Loss: 4.4405. Mask: 0.9321. :  57%|█████▋    | 57/100 [00:15<00:09,  4.35it/s]Train Iter: 3958/5000. LR: 0.0072. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9385. T_Loss: 4.4405. Mask: 0.9321. :  58%|█████▊    | 58/100 [00:15<00:08,  5.04it/s]Train Iter: 3959/5000. LR: 0.0072. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9360. T_Loss: 4.4230. Mask: 0.9322. :  58%|█████▊    | 58/100 [00:15<00:08,  5.04it/s]Train Iter: 3959/5000. LR: 0.0072. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9360. T_Loss: 4.4230. Mask: 0.9322. :  59%|█████▉    | 59/100 [00:15<00:09,  4.32it/s]Train Iter: 3960/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9363. T_Loss: 4.4238. Mask: 0.9323. :  59%|█████▉    | 59/100 [00:15<00:09,  4.32it/s]Train Iter: 3960/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9363. T_Loss: 4.4238. Mask: 0.9323. :  60%|██████    | 60/100 [00:15<00:08,  4.96it/s]Train Iter: 3961/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9377. T_Loss: 4.4303. Mask: 0.9329. :  60%|██████    | 60/100 [00:15<00:08,  4.96it/s]Train Iter: 3961/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9377. T_Loss: 4.4303. Mask: 0.9329. :  61%|██████    | 61/100 [00:15<00:07,  5.56it/s]Train Iter: 3962/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9384. T_Loss: 4.4260. Mask: 0.9315. :  61%|██████    | 61/100 [00:16<00:07,  5.56it/s]Train Iter: 3962/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9384. T_Loss: 4.4260. Mask: 0.9315. :  62%|██████▏   | 62/100 [00:16<00:06,  6.01it/s]Train Iter: 3963/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9378. T_Loss: 4.4219. Mask: 0.9315. :  62%|██████▏   | 62/100 [00:16<00:06,  6.01it/s]Train Iter: 3963/5000. LR: 0.0072. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9378. T_Loss: 4.4219. Mask: 0.9315. :  63%|██████▎   | 63/100 [00:16<00:05,  6.79it/s]Train Iter: 3964/5000. LR: 0.0071. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9362. T_Loss: 4.4163. Mask: 0.9321. :  63%|██████▎   | 63/100 [00:16<00:05,  6.79it/s]Train Iter: 3965/5000. LR: 0.0071. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9358. T_Loss: 4.4205. Mask: 0.9332. :  64%|██████▍   | 64/100 [00:16<00:05,  6.79it/s]Train Iter: 3965/5000. LR: 0.0071. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9358. T_Loss: 4.4205. Mask: 0.9332. :  65%|██████▌   | 65/100 [00:16<00:04,  7.88it/s]Train Iter: 3966/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9372. T_Loss: 4.4185. Mask: 0.9309. :  65%|██████▌   | 65/100 [00:16<00:04,  7.88it/s]Train Iter: 3966/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9372. T_Loss: 4.4185. Mask: 0.9309. :  66%|██████▌   | 66/100 [00:16<00:04,  7.65it/s]Train Iter: 3967/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9372. T_Loss: 4.4173. Mask: 0.9314. :  66%|██████▌   | 66/100 [00:16<00:04,  7.65it/s]Train Iter: 3967/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9372. T_Loss: 4.4173. Mask: 0.9314. :  67%|██████▋   | 67/100 [00:16<00:04,  7.94it/s]Train Iter: 3968/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9368. T_Loss: 4.4172. Mask: 0.9315. :  67%|██████▋   | 67/100 [00:16<00:04,  7.94it/s]Train Iter: 3968/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9368. T_Loss: 4.4172. Mask: 0.9315. :  68%|██████▊   | 68/100 [00:16<00:04,  7.60it/s]Train Iter: 3969/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9363. T_Loss: 4.4123. Mask: 0.9316. :  68%|██████▊   | 68/100 [00:17<00:04,  7.60it/s]Train Iter: 3969/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9363. T_Loss: 4.4123. Mask: 0.9316. :  69%|██████▉   | 69/100 [00:17<00:05,  5.37it/s]Train Iter: 3970/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9365. T_Loss: 4.4101. Mask: 0.9308. :  69%|██████▉   | 69/100 [00:17<00:05,  5.37it/s]Train Iter: 3970/5000. LR: 0.0071. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9365. T_Loss: 4.4101. Mask: 0.9308. :  70%|███████   | 70/100 [00:17<00:05,  5.95it/s]Train Iter: 3971/5000. LR: 0.0070. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9383. T_Loss: 4.4227. Mask: 0.9313. :  70%|███████   | 70/100 [00:17<00:05,  5.95it/s]Train Iter: 3971/5000. LR: 0.0070. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9383. T_Loss: 4.4227. Mask: 0.9313. :  71%|███████   | 71/100 [00:17<00:04,  6.54it/s]Train Iter: 3972/5000. LR: 0.0070. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9393. T_Loss: 4.4403. Mask: 0.9319. :  71%|███████   | 71/100 [00:17<00:04,  6.54it/s]Train Iter: 3973/5000. LR: 0.0070. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9391. T_Loss: 4.4420. Mask: 0.9324. :  72%|███████▏  | 72/100 [00:17<00:04,  6.54it/s]Train Iter: 3973/5000. LR: 0.0070. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9391. T_Loss: 4.4420. Mask: 0.9324. :  73%|███████▎  | 73/100 [00:17<00:03,  8.30it/s]Train Iter: 3974/5000. LR: 0.0070. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9404. T_Loss: 4.4392. Mask: 0.9324. :  73%|███████▎  | 73/100 [00:17<00:03,  8.30it/s]Train Iter: 3975/5000. LR: 0.0070. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9401. T_Loss: 4.4396. Mask: 0.9329. :  74%|███████▍  | 74/100 [00:17<00:03,  8.30it/s]Train Iter: 3975/5000. LR: 0.0070. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9401. T_Loss: 4.4396. Mask: 0.9329. :  75%|███████▌  | 75/100 [00:17<00:03,  6.41it/s]total : 5000  current step :  3951
total : 5000  current step :  3952
total : 5000  current step :  3953
total : 5000  current step :  3954
total : 5000  current step :  3955
total : 5000  current step :  3956
total : 5000  current step :  3957
total : 5000  current step :  3958
total : 5000  current step :  3959
total : 5000  current step :  3960
total : 5000  current step :  3961
total : 5000  current step :  3962
total : 5000  current step :  3963
total : 5000  current step :  3964
total : 5000  current step :  3965
total : 5000  current step :  3966
total : 5000  current step :  3967
total : 5000  current step :  3968
total : 5000  current step :  3969
total : 5000  current step :  3970
total : 5000  current step :  3971
total : 5000  current step :  3972
total : 5000  current step :  3973
total : 5000  current step :  3974
total : 5000  current step :  3975
Train Iter: 3976/5000. LR: 0.0070. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9415. T_Loss: 4.4407. Mask: 0.9330. :  75%|███████▌  | 75/100 [00:19<00:03,  6.41it/s]Train Iter: 3976/5000. LR: 0.0070. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9415. T_Loss: 4.4407. Mask: 0.9330. :  76%|███████▌  | 76/100 [00:19<00:13,  1.84it/s]Train Iter: 3977/5000. LR: 0.0070. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9403. T_Loss: 4.4337. Mask: 0.9326. :  76%|███████▌  | 76/100 [00:20<00:13,  1.84it/s]Train Iter: 3977/5000. LR: 0.0070. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9403. T_Loss: 4.4337. Mask: 0.9326. :  77%|███████▋  | 77/100 [00:20<00:10,  2.22it/s]Train Iter: 3978/5000. LR: 0.0070. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9409. T_Loss: 4.4485. Mask: 0.9327. :  77%|███████▋  | 77/100 [00:20<00:10,  2.22it/s]Train Iter: 3978/5000. LR: 0.0070. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9409. T_Loss: 4.4485. Mask: 0.9327. :  78%|███████▊  | 78/100 [00:20<00:08,  2.72it/s]Train Iter: 3979/5000. LR: 0.0069. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9402. T_Loss: 4.4443. Mask: 0.9328. :  78%|███████▊  | 78/100 [00:20<00:08,  2.72it/s]Train Iter: 3979/5000. LR: 0.0069. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9402. T_Loss: 4.4443. Mask: 0.9328. :  79%|███████▉  | 79/100 [00:20<00:07,  2.73it/s]Train Iter: 3980/5000. LR: 0.0069. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9406. T_Loss: 4.4494. Mask: 0.9320. :  79%|███████▉  | 79/100 [00:20<00:07,  2.73it/s]Train Iter: 3980/5000. LR: 0.0069. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9406. T_Loss: 4.4494. Mask: 0.9320. :  80%|████████  | 80/100 [00:20<00:06,  3.31it/s]Train Iter: 3981/5000. LR: 0.0069. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9410. T_Loss: 4.4427. Mask: 0.9317. :  80%|████████  | 80/100 [00:20<00:06,  3.31it/s]Train Iter: 3981/5000. LR: 0.0069. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9410. T_Loss: 4.4427. Mask: 0.9317. :  81%|████████  | 81/100 [00:20<00:04,  3.93it/s]Train Iter: 3982/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9413. T_Loss: 4.4411. Mask: 0.9318. :  81%|████████  | 81/100 [00:20<00:04,  3.93it/s]Train Iter: 3982/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9413. T_Loss: 4.4411. Mask: 0.9318. :  82%|████████▏ | 82/100 [00:20<00:03,  4.66it/s]Train Iter: 3983/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9408. T_Loss: 4.4446. Mask: 0.9326. :  82%|████████▏ | 82/100 [00:21<00:03,  4.66it/s]Train Iter: 3983/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9408. T_Loss: 4.4446. Mask: 0.9326. :  83%|████████▎ | 83/100 [00:21<00:03,  5.52it/s]Train Iter: 3984/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9410. T_Loss: 4.4434. Mask: 0.9330. :  83%|████████▎ | 83/100 [00:21<00:03,  5.52it/s]Train Iter: 3984/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9410. T_Loss: 4.4434. Mask: 0.9330. :  84%|████████▍ | 84/100 [00:21<00:02,  6.16it/s]Train Iter: 3985/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9419. T_Loss: 4.4531. Mask: 0.9316. :  84%|████████▍ | 84/100 [00:21<00:02,  6.16it/s]Train Iter: 3985/5000. LR: 0.0069. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9419. T_Loss: 4.4531. Mask: 0.9316. :  85%|████████▌ | 85/100 [00:21<00:03,  4.33it/s]Train Iter: 3986/5000. LR: 0.0069. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9405. T_Loss: 4.4465. Mask: 0.9324. :  85%|████████▌ | 85/100 [00:21<00:03,  4.33it/s]Train Iter: 3986/5000. LR: 0.0069. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9405. T_Loss: 4.4465. Mask: 0.9324. :  86%|████████▌ | 86/100 [00:21<00:02,  4.97it/s]Train Iter: 3987/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9407. T_Loss: 4.4400. Mask: 0.9325. :  86%|████████▌ | 86/100 [00:21<00:02,  4.97it/s]Train Iter: 3987/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9407. T_Loss: 4.4400. Mask: 0.9325. :  87%|████████▋ | 87/100 [00:21<00:02,  5.64it/s]Train Iter: 3988/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9402. T_Loss: 4.4369. Mask: 0.9325. :  87%|████████▋ | 87/100 [00:21<00:02,  5.64it/s]Train Iter: 3988/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9402. T_Loss: 4.4369. Mask: 0.9325. :  88%|████████▊ | 88/100 [00:21<00:01,  6.20it/s]Train Iter: 3989/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9400. T_Loss: 4.4404. Mask: 0.9329. :  88%|████████▊ | 88/100 [00:22<00:01,  6.20it/s]Train Iter: 3989/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9400. T_Loss: 4.4404. Mask: 0.9329. :  89%|████████▉ | 89/100 [00:22<00:01,  5.72it/s]Train Iter: 3990/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9406. T_Loss: 4.4380. Mask: 0.9323. :  89%|████████▉ | 89/100 [00:22<00:01,  5.72it/s]Train Iter: 3990/5000. LR: 0.0068. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9406. T_Loss: 4.4380. Mask: 0.9323. :  90%|█████████ | 90/100 [00:22<00:01,  6.51it/s]Train Iter: 3991/5000. LR: 0.0068. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9402. T_Loss: 4.4295. Mask: 0.9313. :  90%|█████████ | 90/100 [00:22<00:01,  6.51it/s]Train Iter: 3992/5000. LR: 0.0068. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9421. T_Loss: 4.4310. Mask: 0.9310. :  91%|█████████ | 91/100 [00:22<00:01,  6.51it/s]Train Iter: 3992/5000. LR: 0.0068. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9421. T_Loss: 4.4310. Mask: 0.9310. :  92%|█████████▏| 92/100 [00:22<00:00,  8.36it/s]Train Iter: 3993/5000. LR: 0.0068. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9421. T_Loss: 4.4300. Mask: 0.9311. :  92%|█████████▏| 92/100 [00:22<00:00,  8.36it/s]Train Iter: 3994/5000. LR: 0.0068. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9422. T_Loss: 4.4322. Mask: 0.9315. :  93%|█████████▎| 93/100 [00:22<00:00,  8.36it/s]Train Iter: 3994/5000. LR: 0.0068. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9422. T_Loss: 4.4322. Mask: 0.9315. :  94%|█████████▍| 94/100 [00:22<00:00,  9.72it/s]Train Iter: 3995/5000. LR: 0.0067. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9416. T_Loss: 4.4246. Mask: 0.9316. :  94%|█████████▍| 94/100 [00:22<00:00,  9.72it/s]Train Iter: 3996/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9418. T_Loss: 4.4281. Mask: 0.9316. :  95%|█████████▌| 95/100 [00:23<00:00,  9.72it/s]Train Iter: 3996/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9418. T_Loss: 4.4281. Mask: 0.9316. :  96%|█████████▌| 96/100 [00:23<00:00,  6.32it/s]Train Iter: 3997/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9411. T_Loss: 4.4233. Mask: 0.9311. :  96%|█████████▌| 96/100 [00:23<00:00,  6.32it/s]Train Iter: 3997/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9411. T_Loss: 4.4233. Mask: 0.9311. :  97%|█████████▋| 97/100 [00:23<00:00,  6.63it/s]Train Iter: 3998/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9430. T_Loss: 4.4333. Mask: 0.9302. :  97%|█████████▋| 97/100 [00:23<00:00,  6.63it/s]Train Iter: 3998/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9430. T_Loss: 4.4333. Mask: 0.9302. :  98%|█████████▊| 98/100 [00:23<00:00,  6.89it/s]Train Iter: 3999/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9431. T_Loss: 4.4309. Mask: 0.9302. :  98%|█████████▊| 98/100 [00:23<00:00,  6.89it/s]Train Iter: 3999/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9431. T_Loss: 4.4309. Mask: 0.9302. :  99%|█████████▉| 99/100 [00:23<00:00,  4.84it/s]Train Iter: 4000/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9432. T_Loss: 4.4284. Mask: 0.9300. :  99%|█████████▉| 99/100 [00:23<00:00,  4.84it/s]Train Iter: 4000/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9432. T_Loss: 4.4284. Mask: 0.9300. : 100%|██████████| 100/100 [00:23<00:00,  5.29it/s]Train Iter: 4000/5000. LR: 0.0067. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9432. T_Loss: 4.4284. Mask: 0.9300. : 100%|██████████| 100/100 [00:23<00:00,  4.20it/s]
total : 5000  current step :  3976
total : 5000  current step :  3977
total : 5000  current step :  3978
total : 5000  current step :  3979
total : 5000  current step :  3980
total : 5000  current step :  3981
total : 5000  current step :  3982
total : 5000  current step :  3983
total : 5000  current step :  3984
total : 5000  current step :  3985
total : 5000  current step :  3986
total : 5000  current step :  3987
total : 5000  current step :  3988
total : 5000  current step :  3989
total : 5000  current step :  3990
total : 5000  current step :  3991
total : 5000  current step :  3992
total : 5000  current step :  3993
total : 5000  current step :  3994
total : 5000  current step :  3995
total : 5000  current step :  3996
total : 5000  current step :  3997
total : 5000  current step :  3998
total : 5000  current step :  3999
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 0.8588. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 0.8588. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.88s. Loss: 0.8474. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.59s. Loss: 0.8271. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.8285. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 0.8189. top1: 91.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8168. top1: 92.71. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.8315. top1: 91.96. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8307. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8290. top1: 91.32. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8344. top1: 91.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8344. top1: 91.25. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8252. top1: 92.05. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8262. top1: 91.93. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8213. top1: 92.07. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8177. top1: 92.41. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8171. top1: 92.50. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8187. top1: 92.38. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8166. top1: 92.46. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8168. top1: 92.53. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8160. top1: 92.60. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.31it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8160. top1: 92.60. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.22it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8155. top1: 92.66. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.22it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8183. top1: 92.56. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.22it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8168. top1: 92.76. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.22it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8134. top1: 93.07. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.22it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8108. top1: 93.23. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.22it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8086. top1: 93.25. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.22it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8122. top1: 93.03. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.22it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8121. top1: 93.17. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.22it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8148. top1: 93.08. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.22it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8126. top1: 93.21. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.22it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8123. top1: 93.23. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.22it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8123. top1: 93.23. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8117. top1: 93.35. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8368. top1: 92.19. top5: 99.90. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8522. top1: 91.19. top5: 99.81. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8689. top1: 90.17. top5: 99.72. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8888. top1: 88.93. top5: 99.73. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9183. top1: 87.76. top5: 99.48. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9297. top1: 86.99. top5: 99.49. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9439. top1: 86.18. top5: 99.51. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9613. top1: 85.42. top5: 99.28. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9752. top1: 84.53. top5: 99.30. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9848. top1: 83.99. top5: 99.24. :  48%|████▊     | 30/63 [00:02<00:01, 26.57it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9848. top1: 83.99. top5: 99.24. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0033. top1: 83.11. top5: 99.26. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0161. top1: 82.63. top5: 99.20. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0241. top1: 82.32. top5: 99.15. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0298. top1: 81.94. top5: 99.17. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0406. top1: 81.18. top5: 99.18. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0495. top1: 80.65. top5: 99.14. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0570. top1: 80.27. top5: 99.15. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0661. top1: 79.97. top5: 99.04. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0735. top1: 79.50. top5: 99.00. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0900. top1: 78.62. top5: 99.02. :  65%|██████▌   | 41/63 [00:02<00:00, 38.35it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0900. top1: 78.62. top5: 99.02. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0959. top1: 78.31. top5: 98.98. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1064. top1: 77.77. top5: 98.94. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1178. top1: 77.26. top5: 98.90. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1224. top1: 76.76. top5: 98.92. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1281. top1: 76.34. top5: 98.94. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1392. top1: 75.77. top5: 98.90. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1499. top1: 75.22. top5: 98.81. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1574. top1: 74.79. top5: 98.78. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1585. top1: 74.74. top5: 98.80. :  81%|████████  | 51/63 [00:02<00:00, 47.30it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1585. top1: 74.74. top5: 98.80. :  95%|█████████▌| 60/63 [00:02<00:00, 53.81it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1676. top1: 74.33. top5: 98.77. :  95%|█████████▌| 60/63 [00:02<00:00, 53.81it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1789. top1: 73.69. top5: 98.79. :  95%|█████████▌| 60/63 [00:02<00:00, 53.81it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1806. top1: 73.50. top5: 98.80. :  95%|█████████▌| 60/63 [00:02<00:00, 53.81it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1806. top1: 73.50. top5: 98.80. : 100%|██████████| 63/63 [00:02<00:00, 24.17it/s]
total : 5000  current step :  4000
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4001/5000. LR: 0.0067. Data: 2.00s. Batch: 2.11s. S_Loss: 0.9473. T_Loss: 3.8715. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4001/5000. LR: 0.0067. Data: 2.00s. Batch: 2.11s. S_Loss: 0.9473. T_Loss: 3.8715. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:29,  2.12s/it]Train Iter: 4002/5000. LR: 0.0066. Data: 1.00s. Batch: 1.12s. S_Loss: 0.9023. T_Loss: 3.7048. Mask: 0.9531. :   1%|          | 1/100 [00:02<03:29,  2.12s/it]Train Iter: 4002/5000. LR: 0.0066. Data: 1.00s. Batch: 1.12s. S_Loss: 0.9023. T_Loss: 3.7048. Mask: 0.9531. :   2%|▏         | 2/100 [00:02<01:32,  1.06it/s]Train Iter: 4003/5000. LR: 0.0066. Data: 0.68s. Batch: 0.80s. S_Loss: 0.8880. T_Loss: 3.9572. Mask: 0.9479. :   2%|▏         | 2/100 [00:02<01:32,  1.06it/s]Train Iter: 4003/5000. LR: 0.0066. Data: 0.68s. Batch: 0.80s. S_Loss: 0.8880. T_Loss: 3.9572. Mask: 0.9479. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 4004/5000. LR: 0.0066. Data: 0.51s. Batch: 0.63s. S_Loss: 0.8916. T_Loss: 3.9363. Mask: 0.9219. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 4004/5000. LR: 0.0066. Data: 0.51s. Batch: 0.63s. S_Loss: 0.8916. T_Loss: 3.9363. Mask: 0.9219. :   4%|▍         | 4/100 [00:02<00:38,  2.48it/s]Train Iter: 4005/5000. LR: 0.0066. Data: 0.41s. Batch: 0.56s. S_Loss: 0.8964. T_Loss: 4.0223. Mask: 0.9187. :   4%|▍         | 4/100 [00:02<00:38,  2.48it/s]Train Iter: 4005/5000. LR: 0.0066. Data: 0.41s. Batch: 0.56s. S_Loss: 0.8964. T_Loss: 4.0223. Mask: 0.9187. :   5%|▌         | 5/100 [00:02<00:33,  2.81it/s]Train Iter: 4006/5000. LR: 0.0066. Data: 0.34s. Batch: 0.49s. S_Loss: 0.8912. T_Loss: 4.0829. Mask: 0.9167. :   5%|▌         | 5/100 [00:02<00:33,  2.81it/s]Train Iter: 4006/5000. LR: 0.0066. Data: 0.34s. Batch: 0.49s. S_Loss: 0.8912. T_Loss: 4.0829. Mask: 0.9167. :   6%|▌         | 6/100 [00:02<00:26,  3.61it/s]Train Iter: 4007/5000. LR: 0.0066. Data: 0.29s. Batch: 0.43s. S_Loss: 0.9007. T_Loss: 4.0785. Mask: 0.9152. :   6%|▌         | 6/100 [00:03<00:26,  3.61it/s]Train Iter: 4007/5000. LR: 0.0066. Data: 0.29s. Batch: 0.43s. S_Loss: 0.9007. T_Loss: 4.0785. Mask: 0.9152. :   7%|▋         | 7/100 [00:03<00:21,  4.41it/s]Train Iter: 4008/5000. LR: 0.0066. Data: 0.26s. Batch: 0.40s. S_Loss: 0.8934. T_Loss: 3.9832. Mask: 0.9219. :   7%|▋         | 7/100 [00:03<00:21,  4.41it/s]Train Iter: 4008/5000. LR: 0.0066. Data: 0.26s. Batch: 0.40s. S_Loss: 0.8934. T_Loss: 3.9832. Mask: 0.9219. :   8%|▊         | 8/100 [00:03<00:17,  5.13it/s]Train Iter: 4009/5000. LR: 0.0066. Data: 0.23s. Batch: 0.39s. S_Loss: 0.8997. T_Loss: 4.0381. Mask: 0.9271. :   8%|▊         | 8/100 [00:03<00:17,  5.13it/s]Train Iter: 4009/5000. LR: 0.0066. Data: 0.23s. Batch: 0.39s. S_Loss: 0.8997. T_Loss: 4.0381. Mask: 0.9271. :   9%|▉         | 9/100 [00:03<00:22,  4.10it/s]Train Iter: 4010/5000. LR: 0.0065. Data: 0.21s. Batch: 0.36s. S_Loss: 0.8983. T_Loss: 4.0488. Mask: 0.9313. :   9%|▉         | 9/100 [00:03<00:22,  4.10it/s]Train Iter: 4010/5000. LR: 0.0065. Data: 0.21s. Batch: 0.36s. S_Loss: 0.8983. T_Loss: 4.0488. Mask: 0.9313. :  10%|█         | 10/100 [00:03<00:19,  4.74it/s]Train Iter: 4011/5000. LR: 0.0065. Data: 0.19s. Batch: 0.34s. S_Loss: 0.8961. T_Loss: 4.0851. Mask: 0.9318. :  10%|█         | 10/100 [00:03<00:19,  4.74it/s]Train Iter: 4011/5000. LR: 0.0065. Data: 0.19s. Batch: 0.34s. S_Loss: 0.8961. T_Loss: 4.0851. Mask: 0.9318. :  11%|█         | 11/100 [00:03<00:16,  5.42it/s]Train Iter: 4012/5000. LR: 0.0065. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9066. T_Loss: 4.1136. Mask: 0.9271. :  11%|█         | 11/100 [00:03<00:16,  5.42it/s]Train Iter: 4012/5000. LR: 0.0065. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9066. T_Loss: 4.1136. Mask: 0.9271. :  12%|█▏        | 12/100 [00:03<00:14,  6.07it/s]Train Iter: 4013/5000. LR: 0.0065. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9004. T_Loss: 4.0487. Mask: 0.9255. :  12%|█▏        | 12/100 [00:04<00:14,  6.07it/s]Train Iter: 4013/5000. LR: 0.0065. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9004. T_Loss: 4.0487. Mask: 0.9255. :  13%|█▎        | 13/100 [00:04<00:13,  6.46it/s]Train Iter: 4014/5000. LR: 0.0065. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9082. T_Loss: 4.0841. Mask: 0.9174. :  13%|█▎        | 13/100 [00:04<00:13,  6.46it/s]Train Iter: 4014/5000. LR: 0.0065. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9082. T_Loss: 4.0841. Mask: 0.9174. :  14%|█▍        | 14/100 [00:04<00:12,  6.78it/s]Train Iter: 4015/5000. LR: 0.0065. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9065. T_Loss: 4.0792. Mask: 0.9208. :  14%|█▍        | 14/100 [00:04<00:12,  6.78it/s]Train Iter: 4015/5000. LR: 0.0065. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9065. T_Loss: 4.0792. Mask: 0.9208. :  15%|█▌        | 15/100 [00:04<00:15,  5.36it/s]Train Iter: 4016/5000. LR: 0.0065. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9159. T_Loss: 4.0729. Mask: 0.9180. :  15%|█▌        | 15/100 [00:04<00:15,  5.36it/s]Train Iter: 4016/5000. LR: 0.0065. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9159. T_Loss: 4.0729. Mask: 0.9180. :  16%|█▌        | 16/100 [00:04<00:14,  5.89it/s]Train Iter: 4017/5000. LR: 0.0065. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9197. T_Loss: 4.1004. Mask: 0.9173. :  16%|█▌        | 16/100 [00:04<00:14,  5.89it/s]Train Iter: 4017/5000. LR: 0.0065. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9197. T_Loss: 4.1004. Mask: 0.9173. :  17%|█▋        | 17/100 [00:04<00:12,  6.47it/s]Train Iter: 4018/5000. LR: 0.0064. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9166. T_Loss: 4.1072. Mask: 0.9201. :  17%|█▋        | 17/100 [00:04<00:12,  6.47it/s]Train Iter: 4018/5000. LR: 0.0064. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9166. T_Loss: 4.1072. Mask: 0.9201. :  18%|█▊        | 18/100 [00:04<00:11,  6.92it/s]Train Iter: 4019/5000. LR: 0.0064. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9122. T_Loss: 4.0483. Mask: 0.9194. :  18%|█▊        | 18/100 [00:05<00:11,  6.92it/s]Train Iter: 4019/5000. LR: 0.0064. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9122. T_Loss: 4.0483. Mask: 0.9194. :  19%|█▉        | 19/100 [00:05<00:15,  5.31it/s]Train Iter: 4020/5000. LR: 0.0064. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9171. T_Loss: 4.1484. Mask: 0.9203. :  19%|█▉        | 19/100 [00:05<00:15,  5.31it/s]Train Iter: 4020/5000. LR: 0.0064. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9171. T_Loss: 4.1484. Mask: 0.9203. :  20%|██        | 20/100 [00:05<00:13,  5.89it/s]Train Iter: 4021/5000. LR: 0.0064. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9163. T_Loss: 4.1261. Mask: 0.9211. :  20%|██        | 20/100 [00:05<00:13,  5.89it/s]Train Iter: 4021/5000. LR: 0.0064. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9163. T_Loss: 4.1261. Mask: 0.9211. :  21%|██        | 21/100 [00:05<00:12,  6.27it/s]Train Iter: 4022/5000. LR: 0.0064. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9128. T_Loss: 4.1166. Mask: 0.9233. :  21%|██        | 21/100 [00:05<00:12,  6.27it/s]Train Iter: 4022/5000. LR: 0.0064. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9128. T_Loss: 4.1166. Mask: 0.9233. :  22%|██▏       | 22/100 [00:05<00:11,  6.71it/s]Train Iter: 4023/5000. LR: 0.0064. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9197. T_Loss: 4.1351. Mask: 0.9226. :  22%|██▏       | 22/100 [00:05<00:11,  6.71it/s]Train Iter: 4023/5000. LR: 0.0064. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9197. T_Loss: 4.1351. Mask: 0.9226. :  23%|██▎       | 23/100 [00:05<00:10,  7.11it/s]Train Iter: 4024/5000. LR: 0.0064. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9221. T_Loss: 4.1409. Mask: 0.9206. :  23%|██▎       | 23/100 [00:05<00:10,  7.11it/s]Train Iter: 4024/5000. LR: 0.0064. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9221. T_Loss: 4.1409. Mask: 0.9206. :  24%|██▍       | 24/100 [00:05<00:10,  7.30it/s]Train Iter: 4025/5000. LR: 0.0064. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9221. T_Loss: 4.1596. Mask: 0.9225. :  24%|██▍       | 24/100 [00:05<00:10,  7.30it/s]Train Iter: 4025/5000. LR: 0.0064. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9221. T_Loss: 4.1596. Mask: 0.9225. :  25%|██▌       | 25/100 [00:05<00:09,  7.54it/s]total : 5000  current step :  4001
total : 5000  current step :  4002
total : 5000  current step :  4003
total : 5000  current step :  4004
total : 5000  current step :  4005
total : 5000  current step :  4006
total : 5000  current step :  4007
total : 5000  current step :  4008
total : 5000  current step :  4009
total : 5000  current step :  4010
total : 5000  current step :  4011
total : 5000  current step :  4012
total : 5000  current step :  4013
total : 5000  current step :  4014
total : 5000  current step :  4015
total : 5000  current step :  4016
total : 5000  current step :  4017
total : 5000  current step :  4018
total : 5000  current step :  4019
total : 5000  current step :  4020
total : 5000  current step :  4021
total : 5000  current step :  4022
total : 5000  current step :  4023
total : 5000  current step :  4024
total : 5000  current step :  4025
Train Iter: 4026/5000. LR: 0.0063. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9204. T_Loss: 4.1644. Mask: 0.9219. :  25%|██▌       | 25/100 [00:07<00:09,  7.54it/s]Train Iter: 4026/5000. LR: 0.0063. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9204. T_Loss: 4.1644. Mask: 0.9219. :  26%|██▌       | 26/100 [00:07<00:50,  1.46it/s]Train Iter: 4027/5000. LR: 0.0063. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9210. T_Loss: 4.1478. Mask: 0.9225. :  26%|██▌       | 26/100 [00:08<00:50,  1.46it/s]Train Iter: 4027/5000. LR: 0.0063. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9210. T_Loss: 4.1478. Mask: 0.9225. :  27%|██▋       | 27/100 [00:08<00:38,  1.89it/s]Train Iter: 4028/5000. LR: 0.0063. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9214. T_Loss: 4.1445. Mask: 0.9219. :  27%|██▋       | 27/100 [00:08<00:38,  1.89it/s]Train Iter: 4028/5000. LR: 0.0063. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9214. T_Loss: 4.1445. Mask: 0.9219. :  28%|██▊       | 28/100 [00:08<00:29,  2.46it/s]Train Iter: 4029/5000. LR: 0.0063. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9243. T_Loss: 4.1614. Mask: 0.9192. :  28%|██▊       | 28/100 [00:08<00:29,  2.46it/s]Train Iter: 4029/5000. LR: 0.0063. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9243. T_Loss: 4.1614. Mask: 0.9192. :  29%|██▉       | 29/100 [00:08<00:22,  3.12it/s]Train Iter: 4030/5000. LR: 0.0063. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9218. T_Loss: 4.1557. Mask: 0.9208. :  29%|██▉       | 29/100 [00:08<00:22,  3.12it/s]Train Iter: 4030/5000. LR: 0.0063. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9218. T_Loss: 4.1557. Mask: 0.9208. :  30%|███       | 30/100 [00:08<00:18,  3.82it/s]Train Iter: 4031/5000. LR: 0.0063. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9259. T_Loss: 4.1666. Mask: 0.9204. :  30%|███       | 30/100 [00:08<00:18,  3.82it/s]Train Iter: 4031/5000. LR: 0.0063. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9259. T_Loss: 4.1666. Mask: 0.9204. :  31%|███       | 31/100 [00:08<00:15,  4.55it/s]Train Iter: 4032/5000. LR: 0.0063. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9311. T_Loss: 4.1694. Mask: 0.9180. :  31%|███       | 31/100 [00:08<00:15,  4.55it/s]Train Iter: 4032/5000. LR: 0.0063. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9311. T_Loss: 4.1694. Mask: 0.9180. :  32%|███▏      | 32/100 [00:08<00:12,  5.27it/s]Train Iter: 4033/5000. LR: 0.0063. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9320. T_Loss: 4.1787. Mask: 0.9195. :  32%|███▏      | 32/100 [00:08<00:12,  5.27it/s]Train Iter: 4033/5000. LR: 0.0063. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9320. T_Loss: 4.1787. Mask: 0.9195. :  33%|███▎      | 33/100 [00:08<00:11,  5.99it/s]Train Iter: 4034/5000. LR: 0.0062. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9340. T_Loss: 4.1915. Mask: 0.9191. :  33%|███▎      | 33/100 [00:08<00:11,  5.99it/s]Train Iter: 4034/5000. LR: 0.0062. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9340. T_Loss: 4.1915. Mask: 0.9191. :  34%|███▍      | 34/100 [00:08<00:10,  6.51it/s]Train Iter: 4035/5000. LR: 0.0062. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9354. T_Loss: 4.1861. Mask: 0.9196. :  34%|███▍      | 34/100 [00:09<00:10,  6.51it/s]Train Iter: 4035/5000. LR: 0.0062. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9354. T_Loss: 4.1861. Mask: 0.9196. :  35%|███▌      | 35/100 [00:09<00:13,  4.85it/s]Train Iter: 4036/5000. LR: 0.0062. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9358. T_Loss: 4.1527. Mask: 0.9175. :  35%|███▌      | 35/100 [00:09<00:13,  4.85it/s]Train Iter: 4037/5000. LR: 0.0062. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9380. T_Loss: 4.1443. Mask: 0.9172. :  36%|███▌      | 36/100 [00:09<00:13,  4.85it/s]Train Iter: 4037/5000. LR: 0.0062. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9380. T_Loss: 4.1443. Mask: 0.9172. :  37%|███▋      | 37/100 [00:09<00:10,  6.28it/s]Train Iter: 4038/5000. LR: 0.0062. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9418. T_Loss: 4.1464. Mask: 0.9169. :  37%|███▋      | 37/100 [00:09<00:10,  6.28it/s]Train Iter: 4038/5000. LR: 0.0062. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9418. T_Loss: 4.1464. Mask: 0.9169. :  38%|███▊      | 38/100 [00:09<00:09,  6.65it/s]Train Iter: 4039/5000. LR: 0.0062. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9406. T_Loss: 4.1240. Mask: 0.9167. :  38%|███▊      | 38/100 [00:09<00:09,  6.65it/s]Train Iter: 4039/5000. LR: 0.0062. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9406. T_Loss: 4.1240. Mask: 0.9167. :  39%|███▉      | 39/100 [00:09<00:11,  5.26it/s]Train Iter: 4040/5000. LR: 0.0062. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9413. T_Loss: 4.1511. Mask: 0.9172. :  39%|███▉      | 39/100 [00:09<00:11,  5.26it/s]Train Iter: 4040/5000. LR: 0.0062. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9413. T_Loss: 4.1511. Mask: 0.9172. :  40%|████      | 40/100 [00:09<00:10,  5.90it/s]Train Iter: 4041/5000. LR: 0.0062. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9399. T_Loss: 4.1477. Mask: 0.9169. :  40%|████      | 40/100 [00:10<00:10,  5.90it/s]Train Iter: 4041/5000. LR: 0.0062. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9399. T_Loss: 4.1477. Mask: 0.9169. :  41%|████      | 41/100 [00:10<00:09,  6.36it/s]Train Iter: 4042/5000. LR: 0.0061. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9401. T_Loss: 4.1492. Mask: 0.9152. :  41%|████      | 41/100 [00:10<00:09,  6.36it/s]Train Iter: 4042/5000. LR: 0.0061. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9401. T_Loss: 4.1492. Mask: 0.9152. :  42%|████▏     | 42/100 [00:10<00:08,  6.97it/s]Train Iter: 4043/5000. LR: 0.0061. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9403. T_Loss: 4.1722. Mask: 0.9150. :  42%|████▏     | 42/100 [00:10<00:08,  6.97it/s]Train Iter: 4043/5000. LR: 0.0061. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9403. T_Loss: 4.1722. Mask: 0.9150. :  43%|████▎     | 43/100 [00:10<00:07,  7.30it/s]Train Iter: 4044/5000. LR: 0.0061. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.1778. Mask: 0.9134. :  43%|████▎     | 43/100 [00:10<00:07,  7.30it/s]Train Iter: 4044/5000. LR: 0.0061. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.1778. Mask: 0.9134. :  44%|████▍     | 44/100 [00:10<00:07,  7.41it/s]Train Iter: 4045/5000. LR: 0.0061. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9451. T_Loss: 4.1887. Mask: 0.9146. :  44%|████▍     | 44/100 [00:10<00:07,  7.41it/s]Train Iter: 4045/5000. LR: 0.0061. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9451. T_Loss: 4.1887. Mask: 0.9146. :  45%|████▌     | 45/100 [00:10<00:07,  7.49it/s]Train Iter: 4046/5000. LR: 0.0061. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9447. T_Loss: 4.2095. Mask: 0.9151. :  45%|████▌     | 45/100 [00:10<00:07,  7.49it/s]Train Iter: 4046/5000. LR: 0.0061. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9447. T_Loss: 4.2095. Mask: 0.9151. :  46%|████▌     | 46/100 [00:10<00:06,  7.77it/s]Train Iter: 4047/5000. LR: 0.0061. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9467. T_Loss: 4.2297. Mask: 0.9149. :  46%|████▌     | 46/100 [00:10<00:06,  7.77it/s]Train Iter: 4047/5000. LR: 0.0061. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9467. T_Loss: 4.2297. Mask: 0.9149. :  47%|████▋     | 47/100 [00:10<00:06,  8.02it/s]Train Iter: 4048/5000. LR: 0.0061. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9450. T_Loss: 4.2222. Mask: 0.9154. :  47%|████▋     | 47/100 [00:10<00:06,  8.02it/s]Train Iter: 4048/5000. LR: 0.0061. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9450. T_Loss: 4.2222. Mask: 0.9154. :  48%|████▊     | 48/100 [00:10<00:06,  8.40it/s]Train Iter: 4049/5000. LR: 0.0061. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9455. T_Loss: 4.2493. Mask: 0.9165. :  48%|████▊     | 48/100 [00:11<00:06,  8.40it/s]Train Iter: 4049/5000. LR: 0.0061. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9455. T_Loss: 4.2493. Mask: 0.9165. :  49%|████▉     | 49/100 [00:11<00:10,  4.99it/s]Train Iter: 4050/5000. LR: 0.0061. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9441. T_Loss: 4.2612. Mask: 0.9169. :  49%|████▉     | 49/100 [00:11<00:10,  4.99it/s]Train Iter: 4050/5000. LR: 0.0061. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9441. T_Loss: 4.2612. Mask: 0.9169. :  50%|█████     | 50/100 [00:11<00:08,  5.65it/s]total : 5000  current step :  4026
total : 5000  current step :  4027
total : 5000  current step :  4028
total : 5000  current step :  4029
total : 5000  current step :  4030
total : 5000  current step :  4031
total : 5000  current step :  4032
total : 5000  current step :  4033
total : 5000  current step :  4034
total : 5000  current step :  4035
total : 5000  current step :  4036
total : 5000  current step :  4037
total : 5000  current step :  4038
total : 5000  current step :  4039
total : 5000  current step :  4040
total : 5000  current step :  4041
total : 5000  current step :  4042
total : 5000  current step :  4043
total : 5000  current step :  4044
total : 5000  current step :  4045
total : 5000  current step :  4046
total : 5000  current step :  4047
total : 5000  current step :  4048
total : 5000  current step :  4049
total : 5000  current step :  4050
Train Iter: 4051/5000. LR: 0.0060. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.2747. Mask: 0.9167. :  50%|█████     | 50/100 [00:13<00:08,  5.65it/s]Train Iter: 4051/5000. LR: 0.0060. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.2747. Mask: 0.9167. :  51%|█████     | 51/100 [00:13<00:35,  1.39it/s]Train Iter: 4052/5000. LR: 0.0060. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9454. T_Loss: 4.2808. Mask: 0.9177. :  51%|█████     | 51/100 [00:13<00:35,  1.39it/s]Train Iter: 4052/5000. LR: 0.0060. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9454. T_Loss: 4.2808. Mask: 0.9177. :  52%|█████▏    | 52/100 [00:13<00:25,  1.86it/s]Train Iter: 4053/5000. LR: 0.0060. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9459. T_Loss: 4.2978. Mask: 0.9175. :  52%|█████▏    | 52/100 [00:13<00:25,  1.86it/s]Train Iter: 4053/5000. LR: 0.0060. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9459. T_Loss: 4.2978. Mask: 0.9175. :  53%|█████▎    | 53/100 [00:13<00:19,  2.45it/s]Train Iter: 4054/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.3261. Mask: 0.9184. :  53%|█████▎    | 53/100 [00:13<00:19,  2.45it/s]Train Iter: 4054/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.3261. Mask: 0.9184. :  54%|█████▍    | 54/100 [00:13<00:15,  3.06it/s]Train Iter: 4055/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9477. T_Loss: 4.3349. Mask: 0.9199. :  54%|█████▍    | 54/100 [00:14<00:15,  3.06it/s]Train Iter: 4055/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9477. T_Loss: 4.3349. Mask: 0.9199. :  55%|█████▌    | 55/100 [00:14<00:14,  3.20it/s]Train Iter: 4056/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9495. T_Loss: 4.3492. Mask: 0.9202. :  55%|█████▌    | 55/100 [00:14<00:14,  3.20it/s]Train Iter: 4056/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9495. T_Loss: 4.3492. Mask: 0.9202. :  56%|█████▌    | 56/100 [00:14<00:11,  3.96it/s]Train Iter: 4057/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9488. T_Loss: 4.3572. Mask: 0.9200. :  56%|█████▌    | 56/100 [00:14<00:11,  3.96it/s]Train Iter: 4057/5000. LR: 0.0060. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9488. T_Loss: 4.3572. Mask: 0.9200. :  57%|█████▋    | 57/100 [00:14<00:09,  4.78it/s]Train Iter: 4058/5000. LR: 0.0060. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.3604. Mask: 0.9203. :  57%|█████▋    | 57/100 [00:14<00:09,  4.78it/s]Train Iter: 4058/5000. LR: 0.0060. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.3604. Mask: 0.9203. :  58%|█████▊    | 58/100 [00:14<00:07,  5.46it/s]Train Iter: 4059/5000. LR: 0.0059. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9460. T_Loss: 4.3584. Mask: 0.9206. :  58%|█████▊    | 58/100 [00:14<00:07,  5.46it/s]Train Iter: 4059/5000. LR: 0.0059. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9460. T_Loss: 4.3584. Mask: 0.9206. :  59%|█████▉    | 59/100 [00:14<00:09,  4.36it/s]Train Iter: 4060/5000. LR: 0.0059. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9464. T_Loss: 4.3690. Mask: 0.9214. :  59%|█████▉    | 59/100 [00:14<00:09,  4.36it/s]Train Iter: 4060/5000. LR: 0.0059. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9464. T_Loss: 4.3690. Mask: 0.9214. :  60%|██████    | 60/100 [00:14<00:07,  5.01it/s]Train Iter: 4061/5000. LR: 0.0059. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9474. T_Loss: 4.3749. Mask: 0.9206. :  60%|██████    | 60/100 [00:14<00:07,  5.01it/s]Train Iter: 4061/5000. LR: 0.0059. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9474. T_Loss: 4.3749. Mask: 0.9206. :  61%|██████    | 61/100 [00:14<00:07,  5.55it/s]Train Iter: 4062/5000. LR: 0.0059. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9489. T_Loss: 4.3794. Mask: 0.9194. :  61%|██████    | 61/100 [00:15<00:07,  5.55it/s]Train Iter: 4062/5000. LR: 0.0059. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9489. T_Loss: 4.3794. Mask: 0.9194. :  62%|██████▏   | 62/100 [00:15<00:06,  6.08it/s]Train Iter: 4063/5000. LR: 0.0059. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9503. T_Loss: 4.3787. Mask: 0.9187. :  62%|██████▏   | 62/100 [00:15<00:06,  6.08it/s]Train Iter: 4063/5000. LR: 0.0059. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9503. T_Loss: 4.3787. Mask: 0.9187. :  63%|██████▎   | 63/100 [00:15<00:05,  6.35it/s]Train Iter: 4064/5000. LR: 0.0059. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9513. T_Loss: 4.3905. Mask: 0.9185. :  63%|██████▎   | 63/100 [00:15<00:05,  6.35it/s]Train Iter: 4064/5000. LR: 0.0059. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9513. T_Loss: 4.3905. Mask: 0.9185. :  64%|██████▍   | 64/100 [00:15<00:05,  6.76it/s]Train Iter: 4065/5000. LR: 0.0059. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9510. T_Loss: 4.3850. Mask: 0.9173. :  64%|██████▍   | 64/100 [00:15<00:05,  6.76it/s]Train Iter: 4065/5000. LR: 0.0059. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9510. T_Loss: 4.3850. Mask: 0.9173. :  65%|██████▌   | 65/100 [00:15<00:06,  5.15it/s]Train Iter: 4066/5000. LR: 0.0059. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9491. T_Loss: 4.3777. Mask: 0.9171. :  65%|██████▌   | 65/100 [00:15<00:06,  5.15it/s]Train Iter: 4066/5000. LR: 0.0059. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9491. T_Loss: 4.3777. Mask: 0.9171. :  66%|██████▌   | 66/100 [00:15<00:06,  5.51it/s]Train Iter: 4067/5000. LR: 0.0058. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9481. T_Loss: 4.3835. Mask: 0.9165. :  66%|██████▌   | 66/100 [00:15<00:06,  5.51it/s]Train Iter: 4067/5000. LR: 0.0058. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9481. T_Loss: 4.3835. Mask: 0.9165. :  67%|██████▋   | 67/100 [00:15<00:05,  6.10it/s]Train Iter: 4068/5000. LR: 0.0058. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9475. T_Loss: 4.3879. Mask: 0.9168. :  67%|██████▋   | 67/100 [00:16<00:05,  6.10it/s]Train Iter: 4068/5000. LR: 0.0058. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9475. T_Loss: 4.3879. Mask: 0.9168. :  68%|██████▊   | 68/100 [00:16<00:04,  6.42it/s]total : 5000  current step :  4051
total : 5000  current step :  4052
total : 5000  current step :  4053
total : 5000  current step :  4054
total : 5000  current step :  4055
total : 5000  current step :  4056
total : 5000  current step :  4057
total : 5000  current step :  4058
total : 5000  current step :  4059
total : 5000  current step :  4060
total : 5000  current step :  4061
total : 5000  current step :  4062
total : 5000  current step :  4063
total : 5000  current step :  4064
total : 5000  current step :  4065
total : 5000  current step :  4066
total : 5000  current step :  4067
total : 5000  current step :  4068
Train Iter: 4069/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9475. T_Loss: 4.3917. Mask: 0.9171. :  68%|██████▊   | 68/100 [00:18<00:04,  6.42it/s]Train Iter: 4069/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9475. T_Loss: 4.3917. Mask: 0.9171. :  69%|██████▉   | 69/100 [00:18<00:22,  1.36it/s]Train Iter: 4070/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9477. T_Loss: 4.4078. Mask: 0.9174. :  69%|██████▉   | 69/100 [00:18<00:22,  1.36it/s]Train Iter: 4070/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9477. T_Loss: 4.4078. Mask: 0.9174. :  70%|███████   | 70/100 [00:18<00:16,  1.79it/s]Train Iter: 4071/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9498. T_Loss: 4.4052. Mask: 0.9164. :  70%|███████   | 70/100 [00:18<00:16,  1.79it/s]Train Iter: 4071/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9498. T_Loss: 4.4052. Mask: 0.9164. :  71%|███████   | 71/100 [00:18<00:12,  2.35it/s]Train Iter: 4072/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9511. T_Loss: 4.4209. Mask: 0.9167. :  71%|███████   | 71/100 [00:18<00:12,  2.35it/s]Train Iter: 4072/5000. LR: 0.0058. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9511. T_Loss: 4.4209. Mask: 0.9167. :  72%|███████▏  | 72/100 [00:18<00:09,  2.99it/s]Train Iter: 4073/5000. LR: 0.0058. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9498. T_Loss: 4.4200. Mask: 0.9165. :  72%|███████▏  | 72/100 [00:18<00:09,  2.99it/s]Train Iter: 4073/5000. LR: 0.0058. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9498. T_Loss: 4.4200. Mask: 0.9165. :  73%|███████▎  | 73/100 [00:18<00:07,  3.76it/s]Train Iter: 4074/5000. LR: 0.0058. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.4242. Mask: 0.9172. :  73%|███████▎  | 73/100 [00:18<00:07,  3.76it/s]Train Iter: 4074/5000. LR: 0.0058. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.4242. Mask: 0.9172. :  74%|███████▍  | 74/100 [00:18<00:05,  4.51it/s]Train Iter: 4075/5000. LR: 0.0057. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.4114. Mask: 0.9167. :  74%|███████▍  | 74/100 [00:19<00:05,  4.51it/s]Train Iter: 4075/5000. LR: 0.0057. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.4114. Mask: 0.9167. :  75%|███████▌  | 75/100 [00:19<00:06,  4.12it/s]total : 5000  current step :  4069
total : 5000  current step :  4070
total : 5000  current step :  4071
total : 5000  current step :  4072
total : 5000  current step :  4073
total : 5000  current step :  4074
total : 5000  current step :  4075
Train Iter: 4076/5000. LR: 0.0057. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9483. T_Loss: 4.4263. Mask: 0.9169. :  75%|███████▌  | 75/100 [00:21<00:06,  4.12it/s]Train Iter: 4076/5000. LR: 0.0057. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9483. T_Loss: 4.4263. Mask: 0.9169. :  76%|███████▌  | 76/100 [00:21<00:18,  1.30it/s]Train Iter: 4077/5000. LR: 0.0057. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9480. T_Loss: 4.4283. Mask: 0.9180. :  76%|███████▌  | 76/100 [00:21<00:18,  1.30it/s]Train Iter: 4077/5000. LR: 0.0057. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9480. T_Loss: 4.4283. Mask: 0.9180. :  77%|███████▋  | 77/100 [00:21<00:13,  1.74it/s]Train Iter: 4078/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9469. T_Loss: 4.4283. Mask: 0.9171. :  77%|███████▋  | 77/100 [00:21<00:13,  1.74it/s]Train Iter: 4078/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9469. T_Loss: 4.4283. Mask: 0.9171. :  78%|███████▊  | 78/100 [00:21<00:09,  2.28it/s]Train Iter: 4079/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9479. T_Loss: 4.4289. Mask: 0.9165. :  78%|███████▊  | 78/100 [00:21<00:09,  2.28it/s]Train Iter: 4079/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9479. T_Loss: 4.4289. Mask: 0.9165. :  79%|███████▉  | 79/100 [00:21<00:08,  2.57it/s]Train Iter: 4080/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9482. T_Loss: 4.4397. Mask: 0.9168. :  79%|███████▉  | 79/100 [00:21<00:08,  2.57it/s]Train Iter: 4081/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9489. T_Loss: 4.4495. Mask: 0.9163. :  80%|████████  | 80/100 [00:21<00:07,  2.57it/s]Train Iter: 4081/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9489. T_Loss: 4.4495. Mask: 0.9163. :  81%|████████  | 81/100 [00:21<00:04,  3.90it/s]Train Iter: 4082/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9498. T_Loss: 4.4618. Mask: 0.9162. :  81%|████████  | 81/100 [00:21<00:04,  3.90it/s]Train Iter: 4082/5000. LR: 0.0057. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9498. T_Loss: 4.4618. Mask: 0.9162. :  82%|████████▏ | 82/100 [00:21<00:04,  4.49it/s]Train Iter: 4083/5000. LR: 0.0057. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9492. T_Loss: 4.4542. Mask: 0.9153. :  82%|████████▏ | 82/100 [00:22<00:04,  4.49it/s]Train Iter: 4083/5000. LR: 0.0057. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9492. T_Loss: 4.4542. Mask: 0.9153. :  83%|████████▎ | 83/100 [00:22<00:03,  5.10it/s]Train Iter: 4084/5000. LR: 0.0056. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9521. T_Loss: 4.4596. Mask: 0.9141. :  83%|████████▎ | 83/100 [00:22<00:03,  5.10it/s]Train Iter: 4084/5000. LR: 0.0056. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9521. T_Loss: 4.4596. Mask: 0.9141. :  84%|████████▍ | 84/100 [00:22<00:02,  5.66it/s]Train Iter: 4085/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9519. T_Loss: 4.4601. Mask: 0.9140. :  84%|████████▍ | 84/100 [00:22<00:02,  5.66it/s]Train Iter: 4085/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9519. T_Loss: 4.4601. Mask: 0.9140. :  85%|████████▌ | 85/100 [00:22<00:03,  4.56it/s]Train Iter: 4086/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9515. T_Loss: 4.4607. Mask: 0.9135. :  85%|████████▌ | 85/100 [00:22<00:03,  4.56it/s]Train Iter: 4086/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9515. T_Loss: 4.4607. Mask: 0.9135. :  86%|████████▌ | 86/100 [00:22<00:02,  5.27it/s]Train Iter: 4087/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9512. T_Loss: 4.4574. Mask: 0.9131. :  86%|████████▌ | 86/100 [00:22<00:02,  5.27it/s]Train Iter: 4087/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9512. T_Loss: 4.4574. Mask: 0.9131. :  87%|████████▋ | 87/100 [00:22<00:02,  5.73it/s]Train Iter: 4088/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9518. T_Loss: 4.4654. Mask: 0.9134. :  87%|████████▋ | 87/100 [00:22<00:02,  5.73it/s]Train Iter: 4088/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9518. T_Loss: 4.4654. Mask: 0.9134. :  88%|████████▊ | 88/100 [00:22<00:01,  6.32it/s]Train Iter: 4089/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9522. T_Loss: 4.4774. Mask: 0.9136. :  88%|████████▊ | 88/100 [00:23<00:01,  6.32it/s]Train Iter: 4089/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9522. T_Loss: 4.4774. Mask: 0.9136. :  89%|████████▉ | 89/100 [00:23<00:02,  4.72it/s]Train Iter: 4090/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9513. T_Loss: 4.4825. Mask: 0.9146. :  89%|████████▉ | 89/100 [00:23<00:02,  4.72it/s]Train Iter: 4090/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9513. T_Loss: 4.4825. Mask: 0.9146. :  90%|█████████ | 90/100 [00:23<00:01,  5.47it/s]Train Iter: 4091/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9521. T_Loss: 4.4950. Mask: 0.9141. :  90%|█████████ | 90/100 [00:23<00:01,  5.47it/s]Train Iter: 4091/5000. LR: 0.0056. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9521. T_Loss: 4.4950. Mask: 0.9141. :  91%|█████████ | 91/100 [00:23<00:01,  6.16it/s]Train Iter: 4092/5000. LR: 0.0055. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.4942. Mask: 0.9141. :  91%|█████████ | 91/100 [00:23<00:01,  6.16it/s]Train Iter: 4092/5000. LR: 0.0055. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.4942. Mask: 0.9141. :  92%|█████████▏| 92/100 [00:23<00:01,  6.67it/s]Train Iter: 4093/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9521. T_Loss: 4.4997. Mask: 0.9136. :  92%|█████████▏| 92/100 [00:23<00:01,  6.67it/s]Train Iter: 4093/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9521. T_Loss: 4.4997. Mask: 0.9136. :  93%|█████████▎| 93/100 [00:23<00:00,  7.20it/s]Train Iter: 4094/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9522. T_Loss: 4.5038. Mask: 0.9139. :  93%|█████████▎| 93/100 [00:23<00:00,  7.20it/s]Train Iter: 4094/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9522. T_Loss: 4.5038. Mask: 0.9139. :  94%|█████████▍| 94/100 [00:23<00:00,  7.51it/s]Train Iter: 4095/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9522. T_Loss: 4.5071. Mask: 0.9135. :  94%|█████████▍| 94/100 [00:24<00:00,  7.51it/s]Train Iter: 4095/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9522. T_Loss: 4.5071. Mask: 0.9135. :  95%|█████████▌| 95/100 [00:24<00:00,  5.79it/s]Train Iter: 4096/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.5124. Mask: 0.9141. :  95%|█████████▌| 95/100 [00:24<00:00,  5.79it/s]Train Iter: 4096/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9516. T_Loss: 4.5124. Mask: 0.9141. :  96%|█████████▌| 96/100 [00:24<00:00,  6.35it/s]Train Iter: 4097/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9517. T_Loss: 4.5104. Mask: 0.9137. :  96%|█████████▌| 96/100 [00:24<00:00,  6.35it/s]Train Iter: 4097/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9517. T_Loss: 4.5104. Mask: 0.9137. :  97%|█████████▋| 97/100 [00:24<00:00,  6.80it/s]Train Iter: 4098/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9507. T_Loss: 4.4979. Mask: 0.9123. :  97%|█████████▋| 97/100 [00:24<00:00,  6.80it/s]Train Iter: 4098/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9507. T_Loss: 4.4979. Mask: 0.9123. :  98%|█████████▊| 98/100 [00:24<00:00,  7.19it/s]Train Iter: 4099/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9522. T_Loss: 4.5068. Mask: 0.9126. :  98%|█████████▊| 98/100 [00:24<00:00,  7.19it/s]Train Iter: 4099/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9522. T_Loss: 4.5068. Mask: 0.9126. :  99%|█████████▉| 99/100 [00:24<00:00,  5.46it/s]Train Iter: 4100/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9533. T_Loss: 4.5077. Mask: 0.9119. :  99%|█████████▉| 99/100 [00:24<00:00,  5.46it/s]Train Iter: 4100/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9533. T_Loss: 4.5077. Mask: 0.9119. : 100%|██████████| 100/100 [00:24<00:00,  6.16it/s]Train Iter: 4100/5000. LR: 0.0055. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9533. T_Loss: 4.5077. Mask: 0.9119. : 100%|██████████| 100/100 [00:24<00:00,  4.03it/s]
total : 5000  current step :  4076
total : 5000  current step :  4077
total : 5000  current step :  4078
total : 5000  current step :  4079
total : 5000  current step :  4080
total : 5000  current step :  4081
total : 5000  current step :  4082
total : 5000  current step :  4083
total : 5000  current step :  4084
total : 5000  current step :  4085
total : 5000  current step :  4086
total : 5000  current step :  4087
total : 5000  current step :  4088
total : 5000  current step :  4089
total : 5000  current step :  4090
total : 5000  current step :  4091
total : 5000  current step :  4092
total : 5000  current step :  4093
total : 5000  current step :  4094
total : 5000  current step :  4095
total : 5000  current step :  4096
total : 5000  current step :  4097
total : 5000  current step :  4098
total : 5000  current step :  4099
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 0.8616. top1: 90.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 0.8616. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.86s. Loss: 0.8473. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.8267. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.8283. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8175. top1: 92.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8154. top1: 93.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.8302. top1: 92.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8291. top1: 91.80. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8291. top1: 91.80. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8279. top1: 91.67. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8331. top1: 91.56. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8244. top1: 92.33. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8258. top1: 92.19. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8211. top1: 92.31. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8172. top1: 92.63. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8163. top1: 92.71. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8175. top1: 92.58. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8175. top1: 92.58. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8156. top1: 92.65. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8162. top1: 92.71. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8154. top1: 92.60. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8149. top1: 92.66. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8176. top1: 92.56. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8160. top1: 92.76. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8128. top1: 93.07. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8102. top1: 93.23. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8080. top1: 93.25. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.22it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8118. top1: 92.91. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.22it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8120. top1: 92.94. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.22it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8120. top1: 92.94. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8146. top1: 92.86. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8123. top1: 93.00. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8120. top1: 93.02. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8113. top1: 93.15. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8357. top1: 91.99. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8509. top1: 91.00. top5: 99.81. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8672. top1: 89.98. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8867. top1: 88.75. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9150. top1: 87.67. top5: 99.48. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9257. top1: 86.91. top5: 99.49. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9393. top1: 86.02. top5: 99.51. :  43%|████▎     | 27/63 [00:02<00:01, 25.11it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9393. top1: 86.02. top5: 99.51. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9563. top1: 85.26. top5: 99.28. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9699. top1: 84.53. top5: 99.30. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9794. top1: 83.99. top5: 99.24. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9973. top1: 83.18. top5: 99.26. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0100. top1: 82.70. top5: 99.27. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0182. top1: 82.32. top5: 99.29. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0239. top1: 81.94. top5: 99.31. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0343. top1: 81.25. top5: 99.32. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0426. top1: 80.72. top5: 99.27. :  60%|██████    | 38/63 [00:02<00:00, 37.51it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0426. top1: 80.72. top5: 99.27. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0497. top1: 80.27. top5: 99.28. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0587. top1: 80.04. top5: 99.17. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0656. top1: 79.62. top5: 99.12. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0812. top1: 78.74. top5: 99.14. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0868. top1: 78.49. top5: 99.10. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0971. top1: 77.95. top5: 99.06. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1081. top1: 77.43. top5: 99.02. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1126. top1: 76.99. top5: 99.03. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1183. top1: 76.62. top5: 99.05. :  75%|███████▍  | 47/63 [00:02<00:00, 45.93it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1183. top1: 76.62. top5: 99.05. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1293. top1: 76.04. top5: 99.01. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1399. top1: 75.43. top5: 98.92. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1470. top1: 75.00. top5: 98.89. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1481. top1: 74.95. top5: 98.91. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1571. top1: 74.54. top5: 98.87. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1683. top1: 73.89. top5: 98.89. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1701. top1: 73.75. top5: 98.90. :  89%|████████▉ | 56/63 [00:02<00:00, 53.73it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1701. top1: 73.75. top5: 98.90. : 100%|██████████| 63/63 [00:02<00:00, 24.07it/s]
total : 5000  current step :  4100
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4101/5000. LR: 0.0054. Data: 1.98s. Batch: 2.12s. S_Loss: 1.0096. T_Loss: 4.5175. Mask: 0.8750. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4101/5000. LR: 0.0054. Data: 1.98s. Batch: 2.12s. S_Loss: 1.0096. T_Loss: 4.5175. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:29,  2.12s/it]Train Iter: 4102/5000. LR: 0.0054. Data: 1.00s. Batch: 1.13s. S_Loss: 0.9615. T_Loss: 4.7018. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:29,  2.12s/it]Train Iter: 4102/5000. LR: 0.0054. Data: 1.00s. Batch: 1.13s. S_Loss: 0.9615. T_Loss: 4.7018. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:34,  1.04it/s]Train Iter: 4103/5000. LR: 0.0054. Data: 0.67s. Batch: 0.80s. S_Loss: 0.9593. T_Loss: 4.6164. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:34,  1.04it/s]Train Iter: 4103/5000. LR: 0.0054. Data: 0.67s. Batch: 0.80s. S_Loss: 0.9593. T_Loss: 4.6164. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:57,  1.70it/s]Train Iter: 4104/5000. LR: 0.0054. Data: 0.50s. Batch: 0.63s. S_Loss: 0.9483. T_Loss: 4.7041. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:57,  1.70it/s]Train Iter: 4104/5000. LR: 0.0054. Data: 0.50s. Batch: 0.63s. S_Loss: 0.9483. T_Loss: 4.7041. Mask: 0.9062. :   4%|▍         | 4/100 [00:02<00:38,  2.49it/s]Train Iter: 4105/5000. LR: 0.0054. Data: 0.40s. Batch: 0.58s. S_Loss: 0.9559. T_Loss: 4.7583. Mask: 0.9062. :   4%|▍         | 4/100 [00:02<00:38,  2.49it/s]Train Iter: 4105/5000. LR: 0.0054. Data: 0.40s. Batch: 0.58s. S_Loss: 0.9559. T_Loss: 4.7583. Mask: 0.9062. :   5%|▌         | 5/100 [00:02<00:36,  2.59it/s]Train Iter: 4106/5000. LR: 0.0054. Data: 0.34s. Batch: 0.50s. S_Loss: 0.9373. T_Loss: 4.6652. Mask: 0.9167. :   5%|▌         | 5/100 [00:02<00:36,  2.59it/s]Train Iter: 4106/5000. LR: 0.0054. Data: 0.34s. Batch: 0.50s. S_Loss: 0.9373. T_Loss: 4.6652. Mask: 0.9167. :   6%|▌         | 6/100 [00:02<00:27,  3.45it/s]Train Iter: 4107/5000. LR: 0.0054. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9434. T_Loss: 4.6169. Mask: 0.9062. :   6%|▌         | 6/100 [00:03<00:27,  3.45it/s]Train Iter: 4107/5000. LR: 0.0054. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9434. T_Loss: 4.6169. Mask: 0.9062. :   7%|▋         | 7/100 [00:03<00:22,  4.22it/s]Train Iter: 4108/5000. LR: 0.0054. Data: 0.25s. Batch: 0.40s. S_Loss: 0.9498. T_Loss: 4.6295. Mask: 0.9062. :   7%|▋         | 7/100 [00:03<00:22,  4.22it/s]Train Iter: 4108/5000. LR: 0.0054. Data: 0.25s. Batch: 0.40s. S_Loss: 0.9498. T_Loss: 4.6295. Mask: 0.9062. :   8%|▊         | 8/100 [00:03<00:18,  5.01it/s]Train Iter: 4109/5000. LR: 0.0053. Data: 0.23s. Batch: 0.40s. S_Loss: 0.9448. T_Loss: 4.6496. Mask: 0.9167. :   8%|▊         | 8/100 [00:03<00:18,  5.01it/s]Train Iter: 4109/5000. LR: 0.0053. Data: 0.23s. Batch: 0.40s. S_Loss: 0.9448. T_Loss: 4.6496. Mask: 0.9167. :   9%|▉         | 9/100 [00:03<00:22,  4.05it/s]Train Iter: 4110/5000. LR: 0.0053. Data: 0.20s. Batch: 0.37s. S_Loss: 0.9440. T_Loss: 4.6045. Mask: 0.9156. :   9%|▉         | 9/100 [00:03<00:22,  4.05it/s]Train Iter: 4110/5000. LR: 0.0053. Data: 0.20s. Batch: 0.37s. S_Loss: 0.9440. T_Loss: 4.6045. Mask: 0.9156. :  10%|█         | 10/100 [00:03<00:18,  4.78it/s]Train Iter: 4111/5000. LR: 0.0053. Data: 0.18s. Batch: 0.35s. S_Loss: 0.9390. T_Loss: 4.6209. Mask: 0.9176. :  10%|█         | 10/100 [00:03<00:18,  4.78it/s]Train Iter: 4111/5000. LR: 0.0053. Data: 0.18s. Batch: 0.35s. S_Loss: 0.9390. T_Loss: 4.6209. Mask: 0.9176. :  11%|█         | 11/100 [00:03<00:16,  5.45it/s]Train Iter: 4112/5000. LR: 0.0053. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9368. T_Loss: 4.5242. Mask: 0.9115. :  11%|█         | 11/100 [00:03<00:16,  5.45it/s]Train Iter: 4112/5000. LR: 0.0053. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9368. T_Loss: 4.5242. Mask: 0.9115. :  12%|█▏        | 12/100 [00:03<00:14,  6.01it/s]Train Iter: 4113/5000. LR: 0.0053. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9356. T_Loss: 4.5370. Mask: 0.9159. :  12%|█▏        | 12/100 [00:04<00:14,  6.01it/s]Train Iter: 4113/5000. LR: 0.0053. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9356. T_Loss: 4.5370. Mask: 0.9159. :  13%|█▎        | 13/100 [00:04<00:13,  6.40it/s]Train Iter: 4114/5000. LR: 0.0053. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9362. T_Loss: 4.5802. Mask: 0.9196. :  13%|█▎        | 13/100 [00:04<00:13,  6.40it/s]Train Iter: 4114/5000. LR: 0.0053. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9362. T_Loss: 4.5802. Mask: 0.9196. :  14%|█▍        | 14/100 [00:04<00:12,  6.70it/s]Train Iter: 4115/5000. LR: 0.0053. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9406. T_Loss: 4.5511. Mask: 0.9125. :  14%|█▍        | 14/100 [00:04<00:12,  6.70it/s]Train Iter: 4115/5000. LR: 0.0053. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9406. T_Loss: 4.5511. Mask: 0.9125. :  15%|█▌        | 15/100 [00:04<00:14,  5.73it/s]Train Iter: 4116/5000. LR: 0.0053. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9427. T_Loss: 4.5165. Mask: 0.9082. :  15%|█▌        | 15/100 [00:04<00:14,  5.73it/s]Train Iter: 4116/5000. LR: 0.0053. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9427. T_Loss: 4.5165. Mask: 0.9082. :  16%|█▌        | 16/100 [00:04<00:13,  6.20it/s]Train Iter: 4117/5000. LR: 0.0053. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9451. T_Loss: 4.5396. Mask: 0.9062. :  16%|█▌        | 16/100 [00:04<00:13,  6.20it/s]Train Iter: 4117/5000. LR: 0.0053. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9451. T_Loss: 4.5396. Mask: 0.9062. :  17%|█▋        | 17/100 [00:04<00:12,  6.41it/s]Train Iter: 4118/5000. LR: 0.0052. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9524. T_Loss: 4.5339. Mask: 0.9045. :  17%|█▋        | 17/100 [00:04<00:12,  6.41it/s]Train Iter: 4118/5000. LR: 0.0052. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9524. T_Loss: 4.5339. Mask: 0.9045. :  18%|█▊        | 18/100 [00:04<00:11,  6.85it/s]Train Iter: 4119/5000. LR: 0.0052. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9584. T_Loss: 4.5371. Mask: 0.9013. :  18%|█▊        | 18/100 [00:05<00:11,  6.85it/s]Train Iter: 4119/5000. LR: 0.0052. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9584. T_Loss: 4.5371. Mask: 0.9013. :  19%|█▉        | 19/100 [00:05<00:15,  5.36it/s]Train Iter: 4120/5000. LR: 0.0052. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9583. T_Loss: 4.5565. Mask: 0.9062. :  19%|█▉        | 19/100 [00:05<00:15,  5.36it/s]Train Iter: 4120/5000. LR: 0.0052. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9583. T_Loss: 4.5565. Mask: 0.9062. :  20%|██        | 20/100 [00:05<00:13,  6.02it/s]Train Iter: 4121/5000. LR: 0.0052. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9560. T_Loss: 4.5336. Mask: 0.9048. :  20%|██        | 20/100 [00:05<00:13,  6.02it/s]Train Iter: 4121/5000. LR: 0.0052. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9560. T_Loss: 4.5336. Mask: 0.9048. :  21%|██        | 21/100 [00:05<00:11,  6.67it/s]Train Iter: 4122/5000. LR: 0.0052. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9513. T_Loss: 4.5122. Mask: 0.9062. :  21%|██        | 21/100 [00:05<00:11,  6.67it/s]Train Iter: 4122/5000. LR: 0.0052. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9513. T_Loss: 4.5122. Mask: 0.9062. :  22%|██▏       | 22/100 [00:05<00:11,  7.06it/s]Train Iter: 4123/5000. LR: 0.0052. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9586. T_Loss: 4.5054. Mask: 0.9062. :  22%|██▏       | 22/100 [00:05<00:11,  7.06it/s]Train Iter: 4123/5000. LR: 0.0052. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9586. T_Loss: 4.5054. Mask: 0.9062. :  23%|██▎       | 23/100 [00:05<00:10,  7.35it/s]Train Iter: 4124/5000. LR: 0.0052. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9610. T_Loss: 4.5246. Mask: 0.9062. :  23%|██▎       | 23/100 [00:05<00:10,  7.35it/s]Train Iter: 4124/5000. LR: 0.0052. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9610. T_Loss: 4.5246. Mask: 0.9062. :  24%|██▍       | 24/100 [00:05<00:09,  7.66it/s]Train Iter: 4125/5000. LR: 0.0052. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9598. T_Loss: 4.4957. Mask: 0.9062. :  24%|██▍       | 24/100 [00:05<00:09,  7.66it/s]Train Iter: 4125/5000. LR: 0.0052. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9598. T_Loss: 4.4957. Mask: 0.9062. :  25%|██▌       | 25/100 [00:05<00:09,  7.71it/s]total : 5000  current step :  4101
total : 5000  current step :  4102
total : 5000  current step :  4103
total : 5000  current step :  4104
total : 5000  current step :  4105
total : 5000  current step :  4106
total : 5000  current step :  4107
total : 5000  current step :  4108
total : 5000  current step :  4109
total : 5000  current step :  4110
total : 5000  current step :  4111
total : 5000  current step :  4112
total : 5000  current step :  4113
total : 5000  current step :  4114
total : 5000  current step :  4115
total : 5000  current step :  4116
total : 5000  current step :  4117
total : 5000  current step :  4118
total : 5000  current step :  4119
total : 5000  current step :  4120
total : 5000  current step :  4121
total : 5000  current step :  4122
total : 5000  current step :  4123
total : 5000  current step :  4124
total : 5000  current step :  4125
Train Iter: 4126/5000. LR: 0.0052. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9582. T_Loss: 4.5025. Mask: 0.9075. :  25%|██▌       | 25/100 [00:07<00:09,  7.71it/s]Train Iter: 4126/5000. LR: 0.0052. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9582. T_Loss: 4.5025. Mask: 0.9075. :  26%|██▌       | 26/100 [00:07<00:48,  1.51it/s]Train Iter: 4127/5000. LR: 0.0051. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9612. T_Loss: 4.5147. Mask: 0.9062. :  26%|██▌       | 26/100 [00:07<00:48,  1.51it/s]Train Iter: 4127/5000. LR: 0.0051. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9612. T_Loss: 4.5147. Mask: 0.9062. :  27%|██▋       | 27/100 [00:07<00:36,  2.00it/s]Train Iter: 4128/5000. LR: 0.0051. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9577. T_Loss: 4.4874. Mask: 0.9074. :  27%|██▋       | 27/100 [00:08<00:36,  2.00it/s]Train Iter: 4128/5000. LR: 0.0051. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9577. T_Loss: 4.4874. Mask: 0.9074. :  28%|██▊       | 28/100 [00:08<00:28,  2.56it/s]Train Iter: 4129/5000. LR: 0.0051. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9576. T_Loss: 4.4984. Mask: 0.9106. :  28%|██▊       | 28/100 [00:08<00:28,  2.56it/s]Train Iter: 4129/5000. LR: 0.0051. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9576. T_Loss: 4.4984. Mask: 0.9106. :  29%|██▉       | 29/100 [00:08<00:22,  3.21it/s]Train Iter: 4130/5000. LR: 0.0051. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9569. T_Loss: 4.4844. Mask: 0.9104. :  29%|██▉       | 29/100 [00:08<00:22,  3.21it/s]Train Iter: 4130/5000. LR: 0.0051. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9569. T_Loss: 4.4844. Mask: 0.9104. :  30%|███       | 30/100 [00:08<00:17,  3.93it/s]Train Iter: 4131/5000. LR: 0.0051. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9546. T_Loss: 4.4813. Mask: 0.9133. :  30%|███       | 30/100 [00:08<00:17,  3.93it/s]Train Iter: 4131/5000. LR: 0.0051. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9546. T_Loss: 4.4813. Mask: 0.9133. :  31%|███       | 31/100 [00:08<00:14,  4.65it/s]Train Iter: 4132/5000. LR: 0.0051. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9552. T_Loss: 4.5036. Mask: 0.9150. :  31%|███       | 31/100 [00:08<00:14,  4.65it/s]Train Iter: 4132/5000. LR: 0.0051. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9552. T_Loss: 4.5036. Mask: 0.9150. :  32%|███▏      | 32/100 [00:08<00:12,  5.31it/s]Train Iter: 4133/5000. LR: 0.0051. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9553. T_Loss: 4.5218. Mask: 0.9167. :  32%|███▏      | 32/100 [00:08<00:12,  5.31it/s]Train Iter: 4133/5000. LR: 0.0051. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9553. T_Loss: 4.5218. Mask: 0.9167. :  33%|███▎      | 33/100 [00:08<00:11,  5.98it/s]Train Iter: 4134/5000. LR: 0.0051. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9570. T_Loss: 4.5225. Mask: 0.9145. :  33%|███▎      | 33/100 [00:08<00:11,  5.98it/s]Train Iter: 4135/5000. LR: 0.0051. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9564. T_Loss: 4.4912. Mask: 0.9116. :  34%|███▍      | 34/100 [00:09<00:11,  5.98it/s]Train Iter: 4135/5000. LR: 0.0051. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9564. T_Loss: 4.4912. Mask: 0.9116. :  35%|███▌      | 35/100 [00:09<00:11,  5.78it/s]Train Iter: 4136/5000. LR: 0.0050. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9575. T_Loss: 4.5102. Mask: 0.9115. :  35%|███▌      | 35/100 [00:09<00:11,  5.78it/s]Train Iter: 4137/5000. LR: 0.0050. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9595. T_Loss: 4.5250. Mask: 0.9130. :  36%|███▌      | 36/100 [00:09<00:11,  5.78it/s]Train Iter: 4137/5000. LR: 0.0050. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9595. T_Loss: 4.5250. Mask: 0.9130. :  37%|███▋      | 37/100 [00:09<00:08,  7.47it/s]Train Iter: 4138/5000. LR: 0.0050. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9577. T_Loss: 4.5439. Mask: 0.9153. :  37%|███▋      | 37/100 [00:09<00:08,  7.47it/s]Train Iter: 4139/5000. LR: 0.0050. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9594. T_Loss: 4.5539. Mask: 0.9151. :  38%|███▊      | 38/100 [00:09<00:08,  7.47it/s]Train Iter: 4139/5000. LR: 0.0050. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9594. T_Loss: 4.5539. Mask: 0.9151. :  39%|███▉      | 39/100 [00:09<00:07,  8.25it/s]Train Iter: 4140/5000. LR: 0.0050. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9648. T_Loss: 4.5522. Mask: 0.9125. :  39%|███▉      | 39/100 [00:09<00:07,  8.25it/s]Train Iter: 4140/5000. LR: 0.0050. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9648. T_Loss: 4.5522. Mask: 0.9125. :  40%|████      | 40/100 [00:09<00:07,  8.22it/s]Train Iter: 4141/5000. LR: 0.0050. Data: 0.10s. Batch: 0.23s. S_Loss: 0.9672. T_Loss: 4.5849. Mask: 0.9101. :  40%|████      | 40/100 [00:09<00:07,  8.22it/s]Train Iter: 4141/5000. LR: 0.0050. Data: 0.10s. Batch: 0.23s. S_Loss: 0.9672. T_Loss: 4.5849. Mask: 0.9101. :  41%|████      | 41/100 [00:09<00:06,  8.52it/s]Train Iter: 4142/5000. LR: 0.0050. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9700. T_Loss: 4.5889. Mask: 0.9077. :  41%|████      | 41/100 [00:09<00:06,  8.52it/s]Train Iter: 4142/5000. LR: 0.0050. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9700. T_Loss: 4.5889. Mask: 0.9077. :  42%|████▏     | 42/100 [00:09<00:06,  8.51it/s]Train Iter: 4143/5000. LR: 0.0050. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9677. T_Loss: 4.5821. Mask: 0.9084. :  42%|████▏     | 42/100 [00:09<00:06,  8.51it/s]Train Iter: 4143/5000. LR: 0.0050. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9677. T_Loss: 4.5821. Mask: 0.9084. :  43%|████▎     | 43/100 [00:09<00:06,  8.63it/s]Train Iter: 4144/5000. LR: 0.0050. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9695. T_Loss: 4.5885. Mask: 0.9098. :  43%|████▎     | 43/100 [00:09<00:06,  8.63it/s]Train Iter: 4144/5000. LR: 0.0050. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9695. T_Loss: 4.5885. Mask: 0.9098. :  44%|████▍     | 44/100 [00:09<00:06,  8.70it/s]Train Iter: 4145/5000. LR: 0.0049. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9678. T_Loss: 4.5958. Mask: 0.9104. :  44%|████▍     | 44/100 [00:10<00:06,  8.70it/s]Train Iter: 4145/5000. LR: 0.0049. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9678. T_Loss: 4.5958. Mask: 0.9104. :  45%|████▌     | 45/100 [00:10<00:07,  6.88it/s]Train Iter: 4146/5000. LR: 0.0049. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9677. T_Loss: 4.6010. Mask: 0.9103. :  45%|████▌     | 45/100 [00:10<00:07,  6.88it/s]Train Iter: 4146/5000. LR: 0.0049. Data: 0.09s. Batch: 0.22s. S_Loss: 0.9677. T_Loss: 4.6010. Mask: 0.9103. :  46%|████▌     | 46/100 [00:10<00:07,  7.10it/s]Train Iter: 4147/5000. LR: 0.0049. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9672. T_Loss: 4.5953. Mask: 0.9102. :  46%|████▌     | 46/100 [00:10<00:07,  7.10it/s]Train Iter: 4148/5000. LR: 0.0049. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9674. T_Loss: 4.5965. Mask: 0.9102. :  47%|████▋     | 47/100 [00:10<00:07,  7.10it/s]Train Iter: 4148/5000. LR: 0.0049. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9674. T_Loss: 4.5965. Mask: 0.9102. :  48%|████▊     | 48/100 [00:10<00:06,  8.01it/s]Train Iter: 4149/5000. LR: 0.0049. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9655. T_Loss: 4.5789. Mask: 0.9082. :  48%|████▊     | 48/100 [00:10<00:06,  8.01it/s]Train Iter: 4149/5000. LR: 0.0049. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9655. T_Loss: 4.5789. Mask: 0.9082. :  49%|████▉     | 49/100 [00:10<00:08,  5.83it/s]Train Iter: 4150/5000. LR: 0.0049. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9650. T_Loss: 4.5595. Mask: 0.9081. :  49%|████▉     | 49/100 [00:10<00:08,  5.83it/s]Train Iter: 4150/5000. LR: 0.0049. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9650. T_Loss: 4.5595. Mask: 0.9081. :  50%|█████     | 50/100 [00:10<00:07,  6.37it/s]total : 5000  current step :  4126
total : 5000  current step :  4127
total : 5000  current step :  4128
total : 5000  current step :  4129
total : 5000  current step :  4130
total : 5000  current step :  4131
total : 5000  current step :  4132
total : 5000  current step :  4133
total : 5000  current step :  4134
total : 5000  current step :  4135
total : 5000  current step :  4136
total : 5000  current step :  4137
total : 5000  current step :  4138
total : 5000  current step :  4139
total : 5000  current step :  4140
total : 5000  current step :  4141
total : 5000  current step :  4142
total : 5000  current step :  4143
total : 5000  current step :  4144
total : 5000  current step :  4145
total : 5000  current step :  4146
total : 5000  current step :  4147
total : 5000  current step :  4148
total : 5000  current step :  4149
total : 5000  current step :  4150
Train Iter: 4151/5000. LR: 0.0049. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9651. T_Loss: 4.5627. Mask: 0.9075. :  50%|█████     | 50/100 [00:12<00:07,  6.37it/s]Train Iter: 4151/5000. LR: 0.0049. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9651. T_Loss: 4.5627. Mask: 0.9075. :  51%|█████     | 51/100 [00:12<00:32,  1.52it/s]Train Iter: 4152/5000. LR: 0.0049. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9656. T_Loss: 4.5754. Mask: 0.9087. :  51%|█████     | 51/100 [00:13<00:32,  1.52it/s]Train Iter: 4152/5000. LR: 0.0049. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9656. T_Loss: 4.5754. Mask: 0.9087. :  52%|█████▏    | 52/100 [00:13<00:24,  1.95it/s]Train Iter: 4153/5000. LR: 0.0049. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9619. T_Loss: 4.5556. Mask: 0.9092. :  52%|█████▏    | 52/100 [00:13<00:24,  1.95it/s]Train Iter: 4153/5000. LR: 0.0049. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9619. T_Loss: 4.5556. Mask: 0.9092. :  53%|█████▎    | 53/100 [00:13<00:18,  2.47it/s]Train Iter: 4154/5000. LR: 0.0048. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9641. T_Loss: 4.5643. Mask: 0.9091. :  53%|█████▎    | 53/100 [00:13<00:18,  2.47it/s]Train Iter: 4154/5000. LR: 0.0048. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9641. T_Loss: 4.5643. Mask: 0.9091. :  54%|█████▍    | 54/100 [00:13<00:14,  3.09it/s]Train Iter: 4155/5000. LR: 0.0048. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9639. T_Loss: 4.5595. Mask: 0.9074. :  54%|█████▍    | 54/100 [00:13<00:14,  3.09it/s]Train Iter: 4155/5000. LR: 0.0048. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9639. T_Loss: 4.5595. Mask: 0.9074. :  55%|█████▌    | 55/100 [00:13<00:13,  3.25it/s]Train Iter: 4156/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9616. T_Loss: 4.5520. Mask: 0.9079. :  55%|█████▌    | 55/100 [00:13<00:13,  3.25it/s]Train Iter: 4156/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9616. T_Loss: 4.5520. Mask: 0.9079. :  56%|█████▌    | 56/100 [00:13<00:11,  3.90it/s]Train Iter: 4157/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.5519. Mask: 0.9079. :  56%|█████▌    | 56/100 [00:13<00:11,  3.90it/s]Train Iter: 4157/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9619. T_Loss: 4.5519. Mask: 0.9079. :  57%|█████▋    | 57/100 [00:13<00:09,  4.60it/s]Train Iter: 4158/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9627. T_Loss: 4.5621. Mask: 0.9084. :  57%|█████▋    | 57/100 [00:13<00:09,  4.60it/s]Train Iter: 4158/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9627. T_Loss: 4.5621. Mask: 0.9084. :  58%|█████▊    | 58/100 [00:13<00:07,  5.45it/s]Train Iter: 4159/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9613. T_Loss: 4.5588. Mask: 0.9094. :  58%|█████▊    | 58/100 [00:14<00:07,  5.45it/s]Train Iter: 4159/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9613. T_Loss: 4.5588. Mask: 0.9094. :  59%|█████▉    | 59/100 [00:14<00:09,  4.34it/s]Train Iter: 4160/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9610. T_Loss: 4.5621. Mask: 0.9099. :  59%|█████▉    | 59/100 [00:14<00:09,  4.34it/s]Train Iter: 4160/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9610. T_Loss: 4.5621. Mask: 0.9099. :  60%|██████    | 60/100 [00:14<00:07,  5.06it/s]Train Iter: 4161/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9591. T_Loss: 4.5500. Mask: 0.9098. :  60%|██████    | 60/100 [00:14<00:07,  5.06it/s]Train Iter: 4161/5000. LR: 0.0048. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9591. T_Loss: 4.5500. Mask: 0.9098. :  61%|██████    | 61/100 [00:14<00:06,  5.75it/s]Train Iter: 4162/5000. LR: 0.0048. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9594. T_Loss: 4.5561. Mask: 0.9108. :  61%|██████    | 61/100 [00:14<00:06,  5.75it/s]Train Iter: 4162/5000. LR: 0.0048. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9594. T_Loss: 4.5561. Mask: 0.9108. :  62%|██████▏   | 62/100 [00:14<00:06,  6.29it/s]Train Iter: 4163/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9588. T_Loss: 4.5595. Mask: 0.9117. :  62%|██████▏   | 62/100 [00:14<00:06,  6.29it/s]Train Iter: 4163/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9588. T_Loss: 4.5595. Mask: 0.9117. :  63%|██████▎   | 63/100 [00:14<00:05,  6.57it/s]Train Iter: 4164/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9579. T_Loss: 4.5565. Mask: 0.9111. :  63%|██████▎   | 63/100 [00:14<00:05,  6.57it/s]Train Iter: 4164/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9579. T_Loss: 4.5565. Mask: 0.9111. :  64%|██████▍   | 64/100 [00:14<00:05,  6.89it/s]Train Iter: 4165/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9576. T_Loss: 4.5621. Mask: 0.9125. :  64%|██████▍   | 64/100 [00:15<00:05,  6.89it/s]Train Iter: 4165/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9576. T_Loss: 4.5621. Mask: 0.9125. :  65%|██████▌   | 65/100 [00:15<00:04,  7.07it/s]Train Iter: 4166/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9586. T_Loss: 4.5764. Mask: 0.9124. :  65%|██████▌   | 65/100 [00:15<00:04,  7.07it/s]Train Iter: 4166/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9586. T_Loss: 4.5764. Mask: 0.9124. :  66%|██████▌   | 66/100 [00:15<00:04,  7.03it/s]Train Iter: 4167/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9579. T_Loss: 4.5792. Mask: 0.9128. :  66%|██████▌   | 66/100 [00:15<00:04,  7.03it/s]Train Iter: 4167/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9579. T_Loss: 4.5792. Mask: 0.9128. :  67%|██████▋   | 67/100 [00:15<00:04,  7.37it/s]Train Iter: 4168/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9565. T_Loss: 4.5713. Mask: 0.9122. :  67%|██████▋   | 67/100 [00:15<00:04,  7.37it/s]Train Iter: 4168/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9565. T_Loss: 4.5713. Mask: 0.9122. :  68%|██████▊   | 68/100 [00:15<00:04,  7.65it/s]Train Iter: 4169/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9575. T_Loss: 4.5817. Mask: 0.9126. :  68%|██████▊   | 68/100 [00:15<00:04,  7.65it/s]Train Iter: 4169/5000. LR: 0.0047. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9575. T_Loss: 4.5817. Mask: 0.9126. :  69%|██████▉   | 69/100 [00:15<00:05,  5.22it/s]Train Iter: 4170/5000. LR: 0.0047. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9565. T_Loss: 4.5837. Mask: 0.9134. :  69%|██████▉   | 69/100 [00:15<00:05,  5.22it/s]Train Iter: 4170/5000. LR: 0.0047. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9565. T_Loss: 4.5837. Mask: 0.9134. :  70%|███████   | 70/100 [00:15<00:05,  5.79it/s]Train Iter: 4171/5000. LR: 0.0047. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9546. T_Loss: 4.5776. Mask: 0.9146. :  70%|███████   | 70/100 [00:16<00:05,  5.79it/s]Train Iter: 4171/5000. LR: 0.0047. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9546. T_Loss: 4.5776. Mask: 0.9146. :  71%|███████   | 71/100 [00:16<00:04,  6.44it/s]Train Iter: 4172/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9550. T_Loss: 4.5784. Mask: 0.9136. :  71%|███████   | 71/100 [00:16<00:04,  6.44it/s]Train Iter: 4172/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9550. T_Loss: 4.5784. Mask: 0.9136. :  72%|███████▏  | 72/100 [00:16<00:04,  6.94it/s]Train Iter: 4173/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9540. T_Loss: 4.5707. Mask: 0.9135. :  72%|███████▏  | 72/100 [00:16<00:04,  6.94it/s]Train Iter: 4173/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9540. T_Loss: 4.5707. Mask: 0.9135. :  73%|███████▎  | 73/100 [00:16<00:03,  7.30it/s]Train Iter: 4174/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9548. T_Loss: 4.5802. Mask: 0.9134. :  73%|███████▎  | 73/100 [00:16<00:03,  7.30it/s]Train Iter: 4174/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9548. T_Loss: 4.5802. Mask: 0.9134. :  74%|███████▍  | 74/100 [00:16<00:03,  7.50it/s]Train Iter: 4175/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9540. T_Loss: 4.5783. Mask: 0.9133. :  74%|███████▍  | 74/100 [00:16<00:03,  7.50it/s]Train Iter: 4175/5000. LR: 0.0046. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9540. T_Loss: 4.5783. Mask: 0.9133. :  75%|███████▌  | 75/100 [00:16<00:05,  4.60it/s]total : 5000  current step :  4151
total : 5000  current step :  4152
total : 5000  current step :  4153
total : 5000  current step :  4154
total : 5000  current step :  4155
total : 5000  current step :  4156
total : 5000  current step :  4157
total : 5000  current step :  4158
total : 5000  current step :  4159
total : 5000  current step :  4160
total : 5000  current step :  4161
total : 5000  current step :  4162
total : 5000  current step :  4163
total : 5000  current step :  4164
total : 5000  current step :  4165
total : 5000  current step :  4166
total : 5000  current step :  4167
total : 5000  current step :  4168
total : 5000  current step :  4169
total : 5000  current step :  4170
total : 5000  current step :  4171
total : 5000  current step :  4172
total : 5000  current step :  4173
total : 5000  current step :  4174
total : 5000  current step :  4175
Train Iter: 4176/5000. LR: 0.0046. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9540. T_Loss: 4.5878. Mask: 0.9141. :  75%|███████▌  | 75/100 [00:18<00:05,  4.60it/s]Train Iter: 4176/5000. LR: 0.0046. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9540. T_Loss: 4.5878. Mask: 0.9141. :  76%|███████▌  | 76/100 [00:18<00:18,  1.30it/s]Train Iter: 4177/5000. LR: 0.0046. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9550. T_Loss: 4.6002. Mask: 0.9144. :  76%|███████▌  | 76/100 [00:19<00:18,  1.30it/s]Train Iter: 4177/5000. LR: 0.0046. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9550. T_Loss: 4.6002. Mask: 0.9144. :  77%|███████▋  | 77/100 [00:19<00:13,  1.71it/s]Train Iter: 4178/5000. LR: 0.0046. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9554. T_Loss: 4.6032. Mask: 0.9147. :  77%|███████▋  | 77/100 [00:19<00:13,  1.71it/s]Train Iter: 4178/5000. LR: 0.0046. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9554. T_Loss: 4.6032. Mask: 0.9147. :  78%|███████▊  | 78/100 [00:19<00:09,  2.25it/s]Train Iter: 4179/5000. LR: 0.0046. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9564. T_Loss: 4.6068. Mask: 0.9138. :  78%|███████▊  | 78/100 [00:19<00:09,  2.25it/s]Train Iter: 4179/5000. LR: 0.0046. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9564. T_Loss: 4.6068. Mask: 0.9138. :  79%|███████▉  | 79/100 [00:19<00:08,  2.48it/s]Train Iter: 4180/5000. LR: 0.0046. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9563. T_Loss: 4.6077. Mask: 0.9137. :  79%|███████▉  | 79/100 [00:19<00:08,  2.48it/s]Train Iter: 4180/5000. LR: 0.0046. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9563. T_Loss: 4.6077. Mask: 0.9137. :  80%|████████  | 80/100 [00:19<00:06,  3.10it/s]Train Iter: 4181/5000. LR: 0.0045. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9578. T_Loss: 4.6036. Mask: 0.9117. :  80%|████████  | 80/100 [00:19<00:06,  3.10it/s]Train Iter: 4181/5000. LR: 0.0045. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9578. T_Loss: 4.6036. Mask: 0.9117. :  81%|████████  | 81/100 [00:19<00:04,  3.83it/s]Train Iter: 4182/5000. LR: 0.0045. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9566. T_Loss: 4.6029. Mask: 0.9123. :  81%|████████  | 81/100 [00:19<00:04,  3.83it/s]Train Iter: 4182/5000. LR: 0.0045. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9566. T_Loss: 4.6029. Mask: 0.9123. :  82%|████████▏ | 82/100 [00:19<00:03,  4.61it/s]Train Iter: 4183/5000. LR: 0.0045. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9553. T_Loss: 4.5996. Mask: 0.9127. :  82%|████████▏ | 82/100 [00:19<00:03,  4.61it/s]Train Iter: 4183/5000. LR: 0.0045. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9553. T_Loss: 4.5996. Mask: 0.9127. :  83%|████████▎ | 83/100 [00:19<00:03,  5.41it/s]Train Iter: 4184/5000. LR: 0.0045. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9562. T_Loss: 4.6074. Mask: 0.9129. :  83%|████████▎ | 83/100 [00:20<00:03,  5.41it/s]Train Iter: 4184/5000. LR: 0.0045. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9562. T_Loss: 4.6074. Mask: 0.9129. :  84%|████████▍ | 84/100 [00:20<00:02,  6.14it/s]Train Iter: 4185/5000. LR: 0.0045. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9553. T_Loss: 4.6082. Mask: 0.9132. :  84%|████████▍ | 84/100 [00:20<00:02,  6.14it/s]Train Iter: 4185/5000. LR: 0.0045. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9553. T_Loss: 4.6082. Mask: 0.9132. :  85%|████████▌ | 85/100 [00:20<00:03,  4.80it/s]Train Iter: 4186/5000. LR: 0.0045. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9549. T_Loss: 4.6087. Mask: 0.9135. :  85%|████████▌ | 85/100 [00:20<00:03,  4.80it/s]Train Iter: 4187/5000. LR: 0.0045. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9536. T_Loss: 4.6020. Mask: 0.9145. :  86%|████████▌ | 86/100 [00:20<00:02,  4.80it/s]Train Iter: 4187/5000. LR: 0.0045. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9536. T_Loss: 4.6020. Mask: 0.9145. :  87%|████████▋ | 87/100 [00:20<00:02,  6.19it/s]Train Iter: 4188/5000. LR: 0.0045. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9533. T_Loss: 4.6024. Mask: 0.9144. :  87%|████████▋ | 87/100 [00:20<00:02,  6.19it/s]Train Iter: 4188/5000. LR: 0.0045. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9533. T_Loss: 4.6024. Mask: 0.9144. :  88%|████████▊ | 88/100 [00:20<00:01,  6.72it/s]Train Iter: 4189/5000. LR: 0.0045. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9535. T_Loss: 4.6131. Mask: 0.9154. :  88%|████████▊ | 88/100 [00:21<00:01,  6.72it/s]Train Iter: 4189/5000. LR: 0.0045. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9535. T_Loss: 4.6131. Mask: 0.9154. :  89%|████████▉ | 89/100 [00:21<00:02,  4.88it/s]Train Iter: 4190/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9545. T_Loss: 4.6170. Mask: 0.9160. :  89%|████████▉ | 89/100 [00:21<00:02,  4.88it/s]Train Iter: 4190/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9545. T_Loss: 4.6170. Mask: 0.9160. :  90%|█████████ | 90/100 [00:21<00:01,  5.47it/s]Train Iter: 4191/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9528. T_Loss: 4.6123. Mask: 0.9166. :  90%|█████████ | 90/100 [00:21<00:01,  5.47it/s]Train Iter: 4191/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9528. T_Loss: 4.6123. Mask: 0.9166. :  91%|█████████ | 91/100 [00:21<00:01,  6.01it/s]Train Iter: 4192/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9527. T_Loss: 4.6063. Mask: 0.9164. :  91%|█████████ | 91/100 [00:21<00:01,  6.01it/s]Train Iter: 4192/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9527. T_Loss: 4.6063. Mask: 0.9164. :  92%|█████████▏| 92/100 [00:21<00:01,  6.48it/s]Train Iter: 4193/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9528. T_Loss: 4.6124. Mask: 0.9167. :  92%|█████████▏| 92/100 [00:21<00:01,  6.48it/s]Train Iter: 4193/5000. LR: 0.0044. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9528. T_Loss: 4.6124. Mask: 0.9167. :  93%|█████████▎| 93/100 [00:21<00:01,  6.71it/s]Train Iter: 4194/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9523. T_Loss: 4.6117. Mask: 0.9166. :  93%|█████████▎| 93/100 [00:21<00:01,  6.71it/s]Train Iter: 4194/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9523. T_Loss: 4.6117. Mask: 0.9166. :  94%|█████████▍| 94/100 [00:21<00:00,  7.04it/s]Train Iter: 4195/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9529. T_Loss: 4.6082. Mask: 0.9161. :  94%|█████████▍| 94/100 [00:21<00:00,  7.04it/s]Train Iter: 4195/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9529. T_Loss: 4.6082. Mask: 0.9161. :  95%|█████████▌| 95/100 [00:21<00:00,  7.03it/s]Train Iter: 4196/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9530. T_Loss: 4.6058. Mask: 0.9157. :  95%|█████████▌| 95/100 [00:21<00:00,  7.03it/s]Train Iter: 4196/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9530. T_Loss: 4.6058. Mask: 0.9157. :  96%|█████████▌| 96/100 [00:21<00:00,  7.20it/s]Train Iter: 4197/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9542. T_Loss: 4.6054. Mask: 0.9156. :  96%|█████████▌| 96/100 [00:22<00:00,  7.20it/s]Train Iter: 4197/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9542. T_Loss: 4.6054. Mask: 0.9156. :  97%|█████████▋| 97/100 [00:22<00:00,  7.33it/s]Train Iter: 4198/5000. LR: 0.0044. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9536. T_Loss: 4.5981. Mask: 0.9152. :  97%|█████████▋| 97/100 [00:22<00:00,  7.33it/s]Train Iter: 4199/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9526. T_Loss: 4.6014. Mask: 0.9154. :  98%|█████████▊| 98/100 [00:22<00:00,  7.33it/s]Train Iter: 4199/5000. LR: 0.0044. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9526. T_Loss: 4.6014. Mask: 0.9154. :  99%|█████████▉| 99/100 [00:22<00:00,  5.59it/s]Train Iter: 4200/5000. LR: 0.0043. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9520. T_Loss: 4.5979. Mask: 0.9153. :  99%|█████████▉| 99/100 [00:22<00:00,  5.59it/s]Train Iter: 4200/5000. LR: 0.0043. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9520. T_Loss: 4.5979. Mask: 0.9153. : 100%|██████████| 100/100 [00:22<00:00,  6.09it/s]Train Iter: 4200/5000. LR: 0.0043. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9520. T_Loss: 4.5979. Mask: 0.9153. : 100%|██████████| 100/100 [00:22<00:00,  4.42it/s]
total : 5000  current step :  4176
total : 5000  current step :  4177
total : 5000  current step :  4178
total : 5000  current step :  4179
total : 5000  current step :  4180
total : 5000  current step :  4181
total : 5000  current step :  4182
total : 5000  current step :  4183
total : 5000  current step :  4184
total : 5000  current step :  4185
total : 5000  current step :  4186
total : 5000  current step :  4187
total : 5000  current step :  4188
total : 5000  current step :  4189
total : 5000  current step :  4190
total : 5000  current step :  4191
total : 5000  current step :  4192
total : 5000  current step :  4193
total : 5000  current step :  4194
total : 5000  current step :  4195
total : 5000  current step :  4196
total : 5000  current step :  4197
total : 5000  current step :  4198
total : 5000  current step :  4199
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 0.8675. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 0.8675. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.90s. Loss: 0.8542. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.8318. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.8335. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.8219. top1: 91.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8201. top1: 92.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8346. top1: 91.07. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8335. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8335. top1: 90.62. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8324. top1: 90.62. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8369. top1: 90.62. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8278. top1: 91.48. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8296. top1: 91.41. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8249. top1: 91.59. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8210. top1: 91.96. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8210. top1: 91.96. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:04, 10.80it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8200. top1: 92.08. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.80it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8211. top1: 91.99. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.80it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8193. top1: 92.10. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.80it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8203. top1: 92.19. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.80it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8197. top1: 92.11. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.80it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8197. top1: 92.11. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8192. top1: 92.19. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8219. top1: 92.11. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8202. top1: 92.33. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8169. top1: 92.66. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8143. top1: 92.84. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8120. top1: 92.88. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8162. top1: 92.55. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8165. top1: 92.59. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8192. top1: 92.52. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8168. top1: 92.67. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.43it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8168. top1: 92.67. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8163. top1: 92.71. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8155. top1: 92.84. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8396. top1: 91.70. top5: 99.90. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8537. top1: 90.81. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8691. top1: 89.80. top5: 99.82. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8878. top1: 88.66. top5: 99.82. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9150. top1: 87.59. top5: 99.57. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9251. top1: 86.82. top5: 99.58. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9382. top1: 86.02. top5: 99.59. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9544. top1: 85.26. top5: 99.36. :  46%|████▌     | 29/63 [00:02<00:01, 27.61it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9544. top1: 85.26. top5: 99.36. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9674. top1: 84.53. top5: 99.38. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9763. top1: 83.99. top5: 99.31. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9935. top1: 83.18. top5: 99.33. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0060. top1: 82.70. top5: 99.27. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0139. top1: 82.32. top5: 99.29. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0191. top1: 81.94. top5: 99.31. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0290. top1: 81.32. top5: 99.32. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0366. top1: 80.78. top5: 99.34. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0435. top1: 80.40. top5: 99.35. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0520. top1: 80.17. top5: 99.23. :  62%|██████▏   | 39/63 [00:02<00:00, 39.98it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0520. top1: 80.17. top5: 99.23. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0584. top1: 79.75. top5: 99.19. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0732. top1: 78.92. top5: 99.20. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0786. top1: 78.67. top5: 99.16. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0881. top1: 78.18. top5: 99.12. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0986. top1: 77.66. top5: 99.07. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1026. top1: 77.22. top5: 99.09. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1078. top1: 76.90. top5: 99.11. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1183. top1: 76.43. top5: 99.07. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1284. top1: 75.86. top5: 98.98. :  78%|███████▊  | 49/63 [00:02<00:00, 50.79it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1284. top1: 75.86. top5: 98.98. :  92%|█████████▏| 58/63 [00:02<00:00, 59.11it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1352. top1: 75.42. top5: 98.94. :  92%|█████████▏| 58/63 [00:02<00:00, 59.11it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1362. top1: 75.52. top5: 98.96. :  92%|█████████▏| 58/63 [00:02<00:00, 59.11it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1448. top1: 75.10. top5: 98.92. :  92%|█████████▏| 58/63 [00:02<00:00, 59.11it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1557. top1: 74.50. top5: 98.94. :  92%|█████████▏| 58/63 [00:02<00:00, 59.11it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1574. top1: 74.40. top5: 98.95. :  92%|█████████▏| 58/63 [00:02<00:00, 59.11it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1574. top1: 74.40. top5: 98.95. : 100%|██████████| 63/63 [00:02<00:00, 22.73it/s]
total : 5000  current step :  4200
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4201/5000. LR: 0.0043. Data: 2.29s. Batch: 2.41s. S_Loss: 0.9509. T_Loss: 5.2576. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4201/5000. LR: 0.0043. Data: 2.29s. Batch: 2.41s. S_Loss: 0.9509. T_Loss: 5.2576. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:58,  2.41s/it]Train Iter: 4202/5000. LR: 0.0043. Data: 1.15s. Batch: 1.27s. S_Loss: 0.9283. T_Loss: 4.7171. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:58,  2.41s/it]Train Iter: 4202/5000. LR: 0.0043. Data: 1.15s. Batch: 1.27s. S_Loss: 0.9283. T_Loss: 4.7171. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:44,  1.07s/it]Train Iter: 4203/5000. LR: 0.0043. Data: 0.76s. Batch: 0.89s. S_Loss: 0.9705. T_Loss: 4.7304. Mask: 0.9271. :   2%|▏         | 2/100 [00:02<01:44,  1.07s/it]Train Iter: 4203/5000. LR: 0.0043. Data: 0.76s. Batch: 0.89s. S_Loss: 0.9705. T_Loss: 4.7304. Mask: 0.9271. :   3%|▎         | 3/100 [00:02<01:01,  1.57it/s]Train Iter: 4204/5000. LR: 0.0043. Data: 0.57s. Batch: 0.70s. S_Loss: 0.9770. T_Loss: 4.5869. Mask: 0.8984. :   3%|▎         | 3/100 [00:02<01:01,  1.57it/s]Train Iter: 4204/5000. LR: 0.0043. Data: 0.57s. Batch: 0.70s. S_Loss: 0.9770. T_Loss: 4.5869. Mask: 0.8984. :   4%|▍         | 4/100 [00:02<00:42,  2.27it/s]Train Iter: 4205/5000. LR: 0.0043. Data: 0.46s. Batch: 0.58s. S_Loss: 0.9650. T_Loss: 4.5055. Mask: 0.8938. :   4%|▍         | 4/100 [00:02<00:42,  2.27it/s]Train Iter: 4205/5000. LR: 0.0043. Data: 0.46s. Batch: 0.58s. S_Loss: 0.9650. T_Loss: 4.5055. Mask: 0.8938. :   5%|▌         | 5/100 [00:02<00:30,  3.10it/s]Train Iter: 4206/5000. LR: 0.0043. Data: 0.38s. Batch: 0.51s. S_Loss: 0.9576. T_Loss: 4.5770. Mask: 0.9062. :   5%|▌         | 5/100 [00:03<00:30,  3.10it/s]Train Iter: 4206/5000. LR: 0.0043. Data: 0.38s. Batch: 0.51s. S_Loss: 0.9576. T_Loss: 4.5770. Mask: 0.9062. :   6%|▌         | 6/100 [00:03<00:24,  3.89it/s]Train Iter: 4207/5000. LR: 0.0043. Data: 0.33s. Batch: 0.46s. S_Loss: 0.9543. T_Loss: 4.4997. Mask: 0.9062. :   6%|▌         | 6/100 [00:03<00:24,  3.89it/s]Train Iter: 4207/5000. LR: 0.0043. Data: 0.33s. Batch: 0.46s. S_Loss: 0.9543. T_Loss: 4.4997. Mask: 0.9062. :   7%|▋         | 7/100 [00:03<00:20,  4.48it/s]Train Iter: 4208/5000. LR: 0.0043. Data: 0.29s. Batch: 0.41s. S_Loss: 0.9532. T_Loss: 4.5975. Mask: 0.9180. :   7%|▋         | 7/100 [00:03<00:20,  4.48it/s]Train Iter: 4208/5000. LR: 0.0043. Data: 0.29s. Batch: 0.41s. S_Loss: 0.9532. T_Loss: 4.5975. Mask: 0.9180. :   8%|▊         | 8/100 [00:03<00:17,  5.17it/s]Train Iter: 4209/5000. LR: 0.0042. Data: 0.26s. Batch: 0.40s. S_Loss: 0.9574. T_Loss: 4.6819. Mask: 0.9236. :   8%|▊         | 8/100 [00:03<00:17,  5.17it/s]Train Iter: 4209/5000. LR: 0.0042. Data: 0.26s. Batch: 0.40s. S_Loss: 0.9574. T_Loss: 4.6819. Mask: 0.9236. :   9%|▉         | 9/100 [00:03<00:19,  4.58it/s]Train Iter: 4210/5000. LR: 0.0042. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9516. T_Loss: 4.6234. Mask: 0.9219. :   9%|▉         | 9/100 [00:03<00:19,  4.58it/s]Train Iter: 4210/5000. LR: 0.0042. Data: 0.23s. Batch: 0.37s. S_Loss: 0.9516. T_Loss: 4.6234. Mask: 0.9219. :  10%|█         | 10/100 [00:03<00:17,  5.07it/s]Train Iter: 4211/5000. LR: 0.0042. Data: 0.21s. Batch: 0.35s. S_Loss: 0.9422. T_Loss: 4.6067. Mask: 0.9261. :  10%|█         | 10/100 [00:03<00:17,  5.07it/s]Train Iter: 4211/5000. LR: 0.0042. Data: 0.21s. Batch: 0.35s. S_Loss: 0.9422. T_Loss: 4.6067. Mask: 0.9261. :  11%|█         | 11/100 [00:03<00:15,  5.63it/s]Train Iter: 4212/5000. LR: 0.0042. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9426. T_Loss: 4.5557. Mask: 0.9219. :  11%|█         | 11/100 [00:04<00:15,  5.63it/s]Train Iter: 4212/5000. LR: 0.0042. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9426. T_Loss: 4.5557. Mask: 0.9219. :  12%|█▏        | 12/100 [00:04<00:14,  6.20it/s]Train Iter: 4213/5000. LR: 0.0042. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9434. T_Loss: 4.5599. Mask: 0.9255. :  12%|█▏        | 12/100 [00:04<00:14,  6.20it/s]Train Iter: 4213/5000. LR: 0.0042. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9434. T_Loss: 4.5599. Mask: 0.9255. :  13%|█▎        | 13/100 [00:04<00:12,  6.74it/s]Train Iter: 4214/5000. LR: 0.0042. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9380. T_Loss: 4.5228. Mask: 0.9286. :  13%|█▎        | 13/100 [00:04<00:12,  6.74it/s]Train Iter: 4214/5000. LR: 0.0042. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9380. T_Loss: 4.5228. Mask: 0.9286. :  14%|█▍        | 14/100 [00:04<00:12,  6.96it/s]Train Iter: 4215/5000. LR: 0.0042. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9324. T_Loss: 4.5283. Mask: 0.9333. :  14%|█▍        | 14/100 [00:04<00:12,  6.96it/s]Train Iter: 4215/5000. LR: 0.0042. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9324. T_Loss: 4.5283. Mask: 0.9333. :  15%|█▌        | 15/100 [00:04<00:16,  5.06it/s]Train Iter: 4216/5000. LR: 0.0042. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9319. T_Loss: 4.5093. Mask: 0.9355. :  15%|█▌        | 15/100 [00:04<00:16,  5.06it/s]Train Iter: 4216/5000. LR: 0.0042. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9319. T_Loss: 4.5093. Mask: 0.9355. :  16%|█▌        | 16/100 [00:04<00:14,  5.63it/s]Train Iter: 4217/5000. LR: 0.0042. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9342. T_Loss: 4.5093. Mask: 0.9357. :  16%|█▌        | 16/100 [00:04<00:14,  5.63it/s]Train Iter: 4217/5000. LR: 0.0042. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9342. T_Loss: 4.5093. Mask: 0.9357. :  17%|█▋        | 17/100 [00:04<00:13,  6.20it/s]Train Iter: 4218/5000. LR: 0.0042. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9347. T_Loss: 4.5147. Mask: 0.9375. :  17%|█▋        | 17/100 [00:04<00:13,  6.20it/s]Train Iter: 4218/5000. LR: 0.0042. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9347. T_Loss: 4.5147. Mask: 0.9375. :  18%|█▊        | 18/100 [00:04<00:12,  6.54it/s]Train Iter: 4219/5000. LR: 0.0041. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9376. T_Loss: 4.5585. Mask: 0.9359. :  18%|█▊        | 18/100 [00:05<00:12,  6.54it/s]Train Iter: 4219/5000. LR: 0.0041. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9376. T_Loss: 4.5585. Mask: 0.9359. :  19%|█▉        | 19/100 [00:05<00:11,  6.82it/s]Train Iter: 4220/5000. LR: 0.0041. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9430. T_Loss: 4.5993. Mask: 0.9359. :  19%|█▉        | 19/100 [00:05<00:11,  6.82it/s]Train Iter: 4220/5000. LR: 0.0041. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9430. T_Loss: 4.5993. Mask: 0.9359. :  20%|██        | 20/100 [00:05<00:11,  7.06it/s]Train Iter: 4221/5000. LR: 0.0041. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9418. T_Loss: 4.6153. Mask: 0.9345. :  20%|██        | 20/100 [00:05<00:11,  7.06it/s]Train Iter: 4221/5000. LR: 0.0041. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9418. T_Loss: 4.6153. Mask: 0.9345. :  21%|██        | 21/100 [00:05<00:10,  7.20it/s]Train Iter: 4222/5000. LR: 0.0041. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9410. T_Loss: 4.5973. Mask: 0.9332. :  21%|██        | 21/100 [00:05<00:10,  7.20it/s]Train Iter: 4222/5000. LR: 0.0041. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9410. T_Loss: 4.5973. Mask: 0.9332. :  22%|██▏       | 22/100 [00:05<00:10,  7.32it/s]Train Iter: 4223/5000. LR: 0.0041. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9455. T_Loss: 4.6510. Mask: 0.9348. :  22%|██▏       | 22/100 [00:05<00:10,  7.32it/s]Train Iter: 4223/5000. LR: 0.0041. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9455. T_Loss: 4.6510. Mask: 0.9348. :  23%|██▎       | 23/100 [00:05<00:10,  7.37it/s]Train Iter: 4224/5000. LR: 0.0041. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9464. T_Loss: 4.6577. Mask: 0.9349. :  23%|██▎       | 23/100 [00:05<00:10,  7.37it/s]Train Iter: 4224/5000. LR: 0.0041. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9464. T_Loss: 4.6577. Mask: 0.9349. :  24%|██▍       | 24/100 [00:05<00:10,  7.41it/s]Train Iter: 4225/5000. LR: 0.0041. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9460. T_Loss: 4.6398. Mask: 0.9337. :  24%|██▍       | 24/100 [00:06<00:10,  7.41it/s]Train Iter: 4225/5000. LR: 0.0041. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9460. T_Loss: 4.6398. Mask: 0.9337. :  25%|██▌       | 25/100 [00:06<00:14,  5.22it/s]total : 5000  current step :  4201
total : 5000  current step :  4202
total : 5000  current step :  4203
total : 5000  current step :  4204
total : 5000  current step :  4205
total : 5000  current step :  4206
total : 5000  current step :  4207
total : 5000  current step :  4208
total : 5000  current step :  4209
total : 5000  current step :  4210
total : 5000  current step :  4211
total : 5000  current step :  4212
total : 5000  current step :  4213
total : 5000  current step :  4214
total : 5000  current step :  4215
total : 5000  current step :  4216
total : 5000  current step :  4217
total : 5000  current step :  4218
total : 5000  current step :  4219
total : 5000  current step :  4220
total : 5000  current step :  4221
total : 5000  current step :  4222
total : 5000  current step :  4223
total : 5000  current step :  4224
total : 5000  current step :  4225
Train Iter: 4226/5000. LR: 0.0041. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9484. T_Loss: 4.6400. Mask: 0.9339. :  25%|██▌       | 25/100 [00:08<00:14,  5.22it/s]Train Iter: 4226/5000. LR: 0.0041. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9484. T_Loss: 4.6400. Mask: 0.9339. :  26%|██▌       | 26/100 [00:08<01:00,  1.22it/s]Train Iter: 4227/5000. LR: 0.0041. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9452. T_Loss: 4.6195. Mask: 0.9340. :  26%|██▌       | 26/100 [00:08<01:00,  1.22it/s]Train Iter: 4227/5000. LR: 0.0041. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9452. T_Loss: 4.6195. Mask: 0.9340. :  27%|██▋       | 27/100 [00:08<00:44,  1.63it/s]Train Iter: 4228/5000. LR: 0.0041. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9499. T_Loss: 4.6501. Mask: 0.9330. :  27%|██▋       | 27/100 [00:08<00:44,  1.63it/s]Train Iter: 4228/5000. LR: 0.0041. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9499. T_Loss: 4.6501. Mask: 0.9330. :  28%|██▊       | 28/100 [00:08<00:33,  2.17it/s]Train Iter: 4229/5000. LR: 0.0040. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9477. T_Loss: 4.6287. Mask: 0.9332. :  28%|██▊       | 28/100 [00:08<00:33,  2.17it/s]Train Iter: 4229/5000. LR: 0.0040. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9477. T_Loss: 4.6287. Mask: 0.9332. :  29%|██▉       | 29/100 [00:08<00:28,  2.48it/s]Train Iter: 4230/5000. LR: 0.0040. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9505. T_Loss: 4.6523. Mask: 0.9344. :  29%|██▉       | 29/100 [00:08<00:28,  2.48it/s]Train Iter: 4230/5000. LR: 0.0040. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9505. T_Loss: 4.6523. Mask: 0.9344. :  30%|███       | 30/100 [00:08<00:22,  3.17it/s]Train Iter: 4231/5000. LR: 0.0040. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9509. T_Loss: 4.6716. Mask: 0.9365. :  30%|███       | 30/100 [00:09<00:22,  3.17it/s]Train Iter: 4231/5000. LR: 0.0040. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9509. T_Loss: 4.6716. Mask: 0.9365. :  31%|███       | 31/100 [00:09<00:17,  3.86it/s]Train Iter: 4232/5000. LR: 0.0040. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9526. T_Loss: 4.6844. Mask: 0.9355. :  31%|███       | 31/100 [00:09<00:17,  3.86it/s]Train Iter: 4232/5000. LR: 0.0040. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9526. T_Loss: 4.6844. Mask: 0.9355. :  32%|███▏      | 32/100 [00:09<00:14,  4.71it/s]Train Iter: 4233/5000. LR: 0.0040. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9506. T_Loss: 4.6770. Mask: 0.9337. :  32%|███▏      | 32/100 [00:09<00:14,  4.71it/s]Train Iter: 4233/5000. LR: 0.0040. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9506. T_Loss: 4.6770. Mask: 0.9337. :  33%|███▎      | 33/100 [00:09<00:12,  5.33it/s]Train Iter: 4234/5000. LR: 0.0040. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9496. T_Loss: 4.6942. Mask: 0.9347. :  33%|███▎      | 33/100 [00:09<00:12,  5.33it/s]Train Iter: 4234/5000. LR: 0.0040. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9496. T_Loss: 4.6942. Mask: 0.9347. :  34%|███▍      | 34/100 [00:09<00:11,  5.86it/s]Train Iter: 4235/5000. LR: 0.0040. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9483. T_Loss: 4.6893. Mask: 0.9348. :  34%|███▍      | 34/100 [00:09<00:11,  5.86it/s]Train Iter: 4235/5000. LR: 0.0040. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9483. T_Loss: 4.6893. Mask: 0.9348. :  35%|███▌      | 35/100 [00:09<00:15,  4.22it/s]Train Iter: 4236/5000. LR: 0.0040. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9504. T_Loss: 4.6875. Mask: 0.9332. :  35%|███▌      | 35/100 [00:10<00:15,  4.22it/s]Train Iter: 4236/5000. LR: 0.0040. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9504. T_Loss: 4.6875. Mask: 0.9332. :  36%|███▌      | 36/100 [00:10<00:13,  4.87it/s]Train Iter: 4237/5000. LR: 0.0040. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9512. T_Loss: 4.6874. Mask: 0.9341. :  36%|███▌      | 36/100 [00:10<00:13,  4.87it/s]Train Iter: 4237/5000. LR: 0.0040. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9512. T_Loss: 4.6874. Mask: 0.9341. :  37%|███▋      | 37/100 [00:10<00:11,  5.44it/s]Train Iter: 4238/5000. LR: 0.0040. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9499. T_Loss: 4.6735. Mask: 0.9350. :  37%|███▋      | 37/100 [00:10<00:11,  5.44it/s]Train Iter: 4238/5000. LR: 0.0040. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9499. T_Loss: 4.6735. Mask: 0.9350. :  38%|███▊      | 38/100 [00:10<00:10,  6.12it/s]Train Iter: 4239/5000. LR: 0.0039. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9497. T_Loss: 4.6807. Mask: 0.9343. :  38%|███▊      | 38/100 [00:10<00:10,  6.12it/s]Train Iter: 4239/5000. LR: 0.0039. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9497. T_Loss: 4.6807. Mask: 0.9343. :  39%|███▉      | 39/100 [00:10<00:09,  6.59it/s]Train Iter: 4240/5000. LR: 0.0039. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9514. T_Loss: 4.6822. Mask: 0.9328. :  39%|███▉      | 39/100 [00:10<00:09,  6.59it/s]Train Iter: 4240/5000. LR: 0.0039. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9514. T_Loss: 4.6822. Mask: 0.9328. :  40%|████      | 40/100 [00:10<00:08,  6.87it/s]Train Iter: 4241/5000. LR: 0.0039. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9484. T_Loss: 4.6716. Mask: 0.9337. :  40%|████      | 40/100 [00:10<00:08,  6.87it/s]Train Iter: 4241/5000. LR: 0.0039. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9484. T_Loss: 4.6716. Mask: 0.9337. :  41%|████      | 41/100 [00:10<00:08,  7.24it/s]Train Iter: 4242/5000. LR: 0.0039. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9486. T_Loss: 4.6800. Mask: 0.9338. :  41%|████      | 41/100 [00:10<00:08,  7.24it/s]Train Iter: 4242/5000. LR: 0.0039. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9486. T_Loss: 4.6800. Mask: 0.9338. :  42%|████▏     | 42/100 [00:10<00:07,  7.39it/s]Train Iter: 4243/5000. LR: 0.0039. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9523. T_Loss: 4.6768. Mask: 0.9324. :  42%|████▏     | 42/100 [00:10<00:07,  7.39it/s]Train Iter: 4243/5000. LR: 0.0039. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9523. T_Loss: 4.6768. Mask: 0.9324. :  43%|████▎     | 43/100 [00:10<00:07,  7.90it/s]Train Iter: 4244/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9506. T_Loss: 4.6831. Mask: 0.9332. :  43%|████▎     | 43/100 [00:10<00:07,  7.90it/s]Train Iter: 4244/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9506. T_Loss: 4.6831. Mask: 0.9332. :  44%|████▍     | 44/100 [00:10<00:07,  7.88it/s]Train Iter: 4245/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9489. T_Loss: 4.6755. Mask: 0.9326. :  44%|████▍     | 44/100 [00:11<00:07,  7.88it/s]Train Iter: 4245/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9489. T_Loss: 4.6755. Mask: 0.9326. :  45%|████▌     | 45/100 [00:11<00:10,  5.15it/s]Train Iter: 4246/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9529. T_Loss: 4.6836. Mask: 0.9314. :  45%|████▌     | 45/100 [00:11<00:10,  5.15it/s]Train Iter: 4246/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9529. T_Loss: 4.6836. Mask: 0.9314. :  46%|████▌     | 46/100 [00:11<00:09,  5.55it/s]Train Iter: 4247/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9535. T_Loss: 4.6850. Mask: 0.9322. :  46%|████▌     | 46/100 [00:11<00:09,  5.55it/s]Train Iter: 4247/5000. LR: 0.0039. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9535. T_Loss: 4.6850. Mask: 0.9322. :  47%|████▋     | 47/100 [00:11<00:08,  6.27it/s]Train Iter: 4248/5000. LR: 0.0039. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9556. T_Loss: 4.6813. Mask: 0.9303. :  47%|████▋     | 47/100 [00:11<00:08,  6.27it/s]Train Iter: 4248/5000. LR: 0.0039. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9556. T_Loss: 4.6813. Mask: 0.9303. :  48%|████▊     | 48/100 [00:11<00:07,  6.56it/s]Train Iter: 4249/5000. LR: 0.0038. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9544. T_Loss: 4.6672. Mask: 0.9292. :  48%|████▊     | 48/100 [00:12<00:07,  6.56it/s]Train Iter: 4249/5000. LR: 0.0038. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9544. T_Loss: 4.6672. Mask: 0.9292. :  49%|████▉     | 49/100 [00:12<00:10,  5.07it/s]Train Iter: 4250/5000. LR: 0.0038. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9544. T_Loss: 4.6798. Mask: 0.9294. :  49%|████▉     | 49/100 [00:12<00:10,  5.07it/s]Train Iter: 4250/5000. LR: 0.0038. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9544. T_Loss: 4.6798. Mask: 0.9294. :  50%|█████     | 50/100 [00:12<00:08,  5.84it/s]total : 5000  current step :  4226
total : 5000  current step :  4227
total : 5000  current step :  4228
total : 5000  current step :  4229
total : 5000  current step :  4230
total : 5000  current step :  4231
total : 5000  current step :  4232
total : 5000  current step :  4233
total : 5000  current step :  4234
total : 5000  current step :  4235
total : 5000  current step :  4236
total : 5000  current step :  4237
total : 5000  current step :  4238
total : 5000  current step :  4239
total : 5000  current step :  4240
total : 5000  current step :  4241
total : 5000  current step :  4242
total : 5000  current step :  4243
total : 5000  current step :  4244
total : 5000  current step :  4245
total : 5000  current step :  4246
total : 5000  current step :  4247
total : 5000  current step :  4248
total : 5000  current step :  4249
total : 5000  current step :  4250
Train Iter: 4251/5000. LR: 0.0038. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9535. T_Loss: 4.6703. Mask: 0.9301. :  50%|█████     | 50/100 [00:14<00:08,  5.84it/s]Train Iter: 4251/5000. LR: 0.0038. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9535. T_Loss: 4.6703. Mask: 0.9301. :  51%|█████     | 51/100 [00:14<00:35,  1.36it/s]Train Iter: 4252/5000. LR: 0.0038. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9518. T_Loss: 4.6545. Mask: 0.9297. :  51%|█████     | 51/100 [00:14<00:35,  1.36it/s]Train Iter: 4252/5000. LR: 0.0038. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9518. T_Loss: 4.6545. Mask: 0.9297. :  52%|█████▏    | 52/100 [00:14<00:26,  1.81it/s]Train Iter: 4253/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9521. T_Loss: 4.6567. Mask: 0.9287. :  52%|█████▏    | 52/100 [00:14<00:26,  1.81it/s]Train Iter: 4253/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9521. T_Loss: 4.6567. Mask: 0.9287. :  53%|█████▎    | 53/100 [00:14<00:20,  2.35it/s]Train Iter: 4254/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9511. T_Loss: 4.6543. Mask: 0.9277. :  53%|█████▎    | 53/100 [00:14<00:20,  2.35it/s]Train Iter: 4254/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9511. T_Loss: 4.6543. Mask: 0.9277. :  54%|█████▍    | 54/100 [00:14<00:15,  2.91it/s]Train Iter: 4255/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9525. T_Loss: 4.6568. Mask: 0.9267. :  54%|█████▍    | 54/100 [00:14<00:15,  2.91it/s]Train Iter: 4255/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9525. T_Loss: 4.6568. Mask: 0.9267. :  55%|█████▌    | 55/100 [00:14<00:14,  3.09it/s]Train Iter: 4256/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9523. T_Loss: 4.6495. Mask: 0.9263. :  55%|█████▌    | 55/100 [00:15<00:14,  3.09it/s]Train Iter: 4256/5000. LR: 0.0038. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9523. T_Loss: 4.6495. Mask: 0.9263. :  56%|█████▌    | 56/100 [00:15<00:11,  3.80it/s]Train Iter: 4257/5000. LR: 0.0038. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9523. T_Loss: 4.6462. Mask: 0.9260. :  56%|█████▌    | 56/100 [00:15<00:11,  3.80it/s]Train Iter: 4257/5000. LR: 0.0038. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9523. T_Loss: 4.6462. Mask: 0.9260. :  57%|█████▋    | 57/100 [00:15<00:09,  4.53it/s]Train Iter: 4258/5000. LR: 0.0038. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9507. T_Loss: 4.6527. Mask: 0.9267. :  57%|█████▋    | 57/100 [00:15<00:09,  4.53it/s]Train Iter: 4258/5000. LR: 0.0038. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9507. T_Loss: 4.6527. Mask: 0.9267. :  58%|█████▊    | 58/100 [00:15<00:08,  5.23it/s]Train Iter: 4259/5000. LR: 0.0037. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9509. T_Loss: 4.6512. Mask: 0.9269. :  58%|█████▊    | 58/100 [00:15<00:08,  5.23it/s]Train Iter: 4259/5000. LR: 0.0037. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9509. T_Loss: 4.6512. Mask: 0.9269. :  59%|█████▉    | 59/100 [00:15<00:08,  4.63it/s]Train Iter: 4260/5000. LR: 0.0037. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9498. T_Loss: 4.6365. Mask: 0.9255. :  59%|█████▉    | 59/100 [00:15<00:08,  4.63it/s]Train Iter: 4260/5000. LR: 0.0037. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9498. T_Loss: 4.6365. Mask: 0.9255. :  60%|██████    | 60/100 [00:15<00:07,  5.30it/s]Train Iter: 4261/5000. LR: 0.0037. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9514. T_Loss: 4.6396. Mask: 0.9257. :  60%|██████    | 60/100 [00:15<00:07,  5.30it/s]Train Iter: 4261/5000. LR: 0.0037. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9514. T_Loss: 4.6396. Mask: 0.9257. :  61%|██████    | 61/100 [00:15<00:06,  5.97it/s]Train Iter: 4262/5000. LR: 0.0037. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.6225. Mask: 0.9244. :  61%|██████    | 61/100 [00:15<00:06,  5.97it/s]Train Iter: 4263/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9486. T_Loss: 4.6108. Mask: 0.9241. :  62%|██████▏   | 62/100 [00:15<00:06,  5.97it/s]Train Iter: 4263/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9486. T_Loss: 4.6108. Mask: 0.9241. :  63%|██████▎   | 63/100 [00:15<00:05,  7.03it/s]Train Iter: 4264/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9467. T_Loss: 4.6067. Mask: 0.9253. :  63%|██████▎   | 63/100 [00:16<00:05,  7.03it/s]Train Iter: 4264/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9467. T_Loss: 4.6067. Mask: 0.9253. :  64%|██████▍   | 64/100 [00:16<00:04,  7.30it/s]Train Iter: 4265/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9481. T_Loss: 4.6209. Mask: 0.9260. :  64%|██████▍   | 64/100 [00:16<00:04,  7.30it/s]Train Iter: 4265/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9481. T_Loss: 4.6209. Mask: 0.9260. :  65%|██████▌   | 65/100 [00:16<00:06,  5.46it/s]Train Iter: 4266/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9485. T_Loss: 4.6162. Mask: 0.9257. :  65%|██████▌   | 65/100 [00:16<00:06,  5.46it/s]Train Iter: 4266/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9485. T_Loss: 4.6162. Mask: 0.9257. :  66%|██████▌   | 66/100 [00:16<00:05,  6.14it/s]Train Iter: 4267/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9482. T_Loss: 4.6110. Mask: 0.9254. :  66%|██████▌   | 66/100 [00:16<00:05,  6.14it/s]Train Iter: 4267/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9482. T_Loss: 4.6110. Mask: 0.9254. :  67%|██████▋   | 67/100 [00:16<00:05,  6.58it/s]Train Iter: 4268/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9485. T_Loss: 4.6030. Mask: 0.9251. :  67%|██████▋   | 67/100 [00:16<00:05,  6.58it/s]Train Iter: 4268/5000. LR: 0.0037. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9485. T_Loss: 4.6030. Mask: 0.9251. :  68%|██████▊   | 68/100 [00:16<00:04,  6.95it/s]Train Iter: 4269/5000. LR: 0.0036. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9472. T_Loss: 4.5979. Mask: 0.9235. :  68%|██████▊   | 68/100 [00:17<00:04,  6.95it/s]Train Iter: 4269/5000. LR: 0.0036. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9472. T_Loss: 4.5979. Mask: 0.9235. :  69%|██████▉   | 69/100 [00:17<00:05,  6.11it/s]Train Iter: 4270/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9484. T_Loss: 4.5973. Mask: 0.9241. :  69%|██████▉   | 69/100 [00:17<00:05,  6.11it/s]Train Iter: 4270/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9484. T_Loss: 4.5973. Mask: 0.9241. :  70%|███████   | 70/100 [00:17<00:04,  6.49it/s]Train Iter: 4271/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9477. T_Loss: 4.5962. Mask: 0.9247. :  70%|███████   | 70/100 [00:17<00:04,  6.49it/s]Train Iter: 4271/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9477. T_Loss: 4.5962. Mask: 0.9247. :  71%|███████   | 71/100 [00:17<00:04,  6.89it/s]Train Iter: 4272/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9479. T_Loss: 4.6044. Mask: 0.9253. :  71%|███████   | 71/100 [00:17<00:04,  6.89it/s]Train Iter: 4272/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9479. T_Loss: 4.6044. Mask: 0.9253. :  72%|███████▏  | 72/100 [00:17<00:03,  7.09it/s]Train Iter: 4273/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9464. T_Loss: 4.5884. Mask: 0.9255. :  72%|███████▏  | 72/100 [00:17<00:03,  7.09it/s]Train Iter: 4273/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9464. T_Loss: 4.5884. Mask: 0.9255. :  73%|███████▎  | 73/100 [00:17<00:03,  7.37it/s]Train Iter: 4274/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9487. T_Loss: 4.5975. Mask: 0.9253. :  73%|███████▎  | 73/100 [00:17<00:03,  7.37it/s]Train Iter: 4274/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9487. T_Loss: 4.5975. Mask: 0.9253. :  74%|███████▍  | 74/100 [00:17<00:03,  7.60it/s]Train Iter: 4275/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9482. T_Loss: 4.5991. Mask: 0.9250. :  74%|███████▍  | 74/100 [00:17<00:03,  7.60it/s]Train Iter: 4275/5000. LR: 0.0036. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9482. T_Loss: 4.5991. Mask: 0.9250. :  75%|███████▌  | 75/100 [00:17<00:04,  5.88it/s]total : 5000  current step :  4251
total : 5000  current step :  4252
total : 5000  current step :  4253
total : 5000  current step :  4254
total : 5000  current step :  4255
total : 5000  current step :  4256
total : 5000  current step :  4257
total : 5000  current step :  4258
total : 5000  current step :  4259
total : 5000  current step :  4260
total : 5000  current step :  4261
total : 5000  current step :  4262
total : 5000  current step :  4263
total : 5000  current step :  4264
total : 5000  current step :  4265
total : 5000  current step :  4266
total : 5000  current step :  4267
total : 5000  current step :  4268
total : 5000  current step :  4269
total : 5000  current step :  4270
total : 5000  current step :  4271
total : 5000  current step :  4272
total : 5000  current step :  4273
total : 5000  current step :  4274
total : 5000  current step :  4275
Train Iter: 4276/5000. LR: 0.0036. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9474. T_Loss: 4.5968. Mask: 0.9256. :  75%|███████▌  | 75/100 [00:19<00:04,  5.88it/s]Train Iter: 4276/5000. LR: 0.0036. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9474. T_Loss: 4.5968. Mask: 0.9256. :  76%|███████▌  | 76/100 [00:19<00:17,  1.35it/s]Train Iter: 4277/5000. LR: 0.0036. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9460. T_Loss: 4.5865. Mask: 0.9245. :  76%|███████▌  | 76/100 [00:20<00:17,  1.35it/s]Train Iter: 4277/5000. LR: 0.0036. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9460. T_Loss: 4.5865. Mask: 0.9245. :  77%|███████▋  | 77/100 [00:20<00:13,  1.76it/s]Train Iter: 4278/5000. LR: 0.0036. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5817. Mask: 0.9251. :  77%|███████▋  | 77/100 [00:20<00:13,  1.76it/s]Train Iter: 4278/5000. LR: 0.0036. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5817. Mask: 0.9251. :  78%|███████▊  | 78/100 [00:20<00:09,  2.31it/s]Train Iter: 4279/5000. LR: 0.0035. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9455. T_Loss: 4.5754. Mask: 0.9244. :  78%|███████▊  | 78/100 [00:20<00:09,  2.31it/s]Train Iter: 4279/5000. LR: 0.0035. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9455. T_Loss: 4.5754. Mask: 0.9244. :  79%|███████▉  | 79/100 [00:20<00:07,  2.91it/s]Train Iter: 4280/5000. LR: 0.0035. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9464. T_Loss: 4.5891. Mask: 0.9250. :  79%|███████▉  | 79/100 [00:20<00:07,  2.91it/s]Train Iter: 4281/5000. LR: 0.0035. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9475. T_Loss: 4.6006. Mask: 0.9255. :  80%|████████  | 80/100 [00:20<00:06,  2.91it/s]Train Iter: 4281/5000. LR: 0.0035. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9475. T_Loss: 4.6006. Mask: 0.9255. :  81%|████████  | 81/100 [00:20<00:04,  4.27it/s]Train Iter: 4282/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9480. T_Loss: 4.5894. Mask: 0.9234. :  81%|████████  | 81/100 [00:20<00:04,  4.27it/s]Train Iter: 4282/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9480. T_Loss: 4.5894. Mask: 0.9234. :  82%|████████▏ | 82/100 [00:20<00:03,  4.76it/s]Train Iter: 4283/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9480. T_Loss: 4.5978. Mask: 0.9239. :  82%|████████▏ | 82/100 [00:20<00:03,  4.76it/s]Train Iter: 4283/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9480. T_Loss: 4.5978. Mask: 0.9239. :  83%|████████▎ | 83/100 [00:20<00:03,  5.32it/s]Train Iter: 4284/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5972. Mask: 0.9241. :  83%|████████▎ | 83/100 [00:20<00:03,  5.32it/s]Train Iter: 4284/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5972. Mask: 0.9241. :  84%|████████▍ | 84/100 [00:20<00:02,  5.84it/s]Train Iter: 4285/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5860. Mask: 0.9232. :  84%|████████▍ | 84/100 [00:21<00:02,  5.84it/s]Train Iter: 4285/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5860. Mask: 0.9232. :  85%|████████▌ | 85/100 [00:21<00:03,  4.87it/s]Train Iter: 4286/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.5836. Mask: 0.9233. :  85%|████████▌ | 85/100 [00:21<00:03,  4.87it/s]Train Iter: 4286/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9474. T_Loss: 4.5836. Mask: 0.9233. :  86%|████████▌ | 86/100 [00:21<00:02,  5.35it/s]Train Iter: 4287/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9484. T_Loss: 4.5957. Mask: 0.9231. :  86%|████████▌ | 86/100 [00:21<00:02,  5.35it/s]Train Iter: 4287/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9484. T_Loss: 4.5957. Mask: 0.9231. :  87%|████████▋ | 87/100 [00:21<00:02,  5.77it/s]Train Iter: 4288/5000. LR: 0.0035. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9475. T_Loss: 4.5867. Mask: 0.9233. :  87%|████████▋ | 87/100 [00:21<00:02,  5.77it/s]Train Iter: 4288/5000. LR: 0.0035. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9475. T_Loss: 4.5867. Mask: 0.9233. :  88%|████████▊ | 88/100 [00:21<00:01,  6.16it/s]Train Iter: 4289/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5861. Mask: 0.9242. :  88%|████████▊ | 88/100 [00:22<00:01,  6.16it/s]Train Iter: 4289/5000. LR: 0.0035. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9470. T_Loss: 4.5861. Mask: 0.9242. :  89%|████████▉ | 89/100 [00:22<00:02,  4.42it/s]Train Iter: 4290/5000. LR: 0.0034. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9468. T_Loss: 4.5870. Mask: 0.9243. :  89%|████████▉ | 89/100 [00:22<00:02,  4.42it/s]Train Iter: 4290/5000. LR: 0.0034. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9468. T_Loss: 4.5870. Mask: 0.9243. :  90%|█████████ | 90/100 [00:22<00:01,  5.01it/s]Train Iter: 4291/5000. LR: 0.0034. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.5839. Mask: 0.9248. :  90%|█████████ | 90/100 [00:22<00:01,  5.01it/s]Train Iter: 4291/5000. LR: 0.0034. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.5839. Mask: 0.9248. :  91%|█████████ | 91/100 [00:22<00:01,  5.76it/s]Train Iter: 4292/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9459. T_Loss: 4.5845. Mask: 0.9249. :  91%|█████████ | 91/100 [00:22<00:01,  5.76it/s]Train Iter: 4293/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.5850. Mask: 0.9247. :  92%|█████████▏| 92/100 [00:22<00:01,  5.76it/s]Train Iter: 4293/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.5850. Mask: 0.9247. :  93%|█████████▎| 93/100 [00:22<00:00,  7.54it/s]Train Iter: 4294/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9448. T_Loss: 4.5728. Mask: 0.9249. :  93%|█████████▎| 93/100 [00:22<00:00,  7.54it/s]Train Iter: 4295/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9452. T_Loss: 4.5680. Mask: 0.9247. :  94%|█████████▍| 94/100 [00:22<00:00,  7.54it/s]Train Iter: 4295/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9452. T_Loss: 4.5680. Mask: 0.9247. :  95%|█████████▌| 95/100 [00:22<00:00,  6.26it/s]Train Iter: 4296/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.5741. Mask: 0.9251. :  95%|█████████▌| 95/100 [00:23<00:00,  6.26it/s]Train Iter: 4296/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.5741. Mask: 0.9251. :  96%|█████████▌| 96/100 [00:23<00:00,  6.16it/s]Train Iter: 4297/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9461. T_Loss: 4.5609. Mask: 0.9240. :  96%|█████████▌| 96/100 [00:23<00:00,  6.16it/s]Train Iter: 4297/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9461. T_Loss: 4.5609. Mask: 0.9240. :  97%|█████████▋| 97/100 [00:23<00:00,  6.53it/s]Train Iter: 4298/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9468. T_Loss: 4.5613. Mask: 0.9232. :  97%|█████████▋| 97/100 [00:23<00:00,  6.53it/s]Train Iter: 4298/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9468. T_Loss: 4.5613. Mask: 0.9232. :  98%|█████████▊| 98/100 [00:23<00:00,  6.62it/s]Train Iter: 4299/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9468. T_Loss: 4.5483. Mask: 0.9211. :  98%|█████████▊| 98/100 [00:23<00:00,  6.62it/s]Train Iter: 4299/5000. LR: 0.0034. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9468. T_Loss: 4.5483. Mask: 0.9211. :  99%|█████████▉| 99/100 [00:23<00:00,  6.93it/s]Train Iter: 4300/5000. LR: 0.0033. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9466. T_Loss: 4.5473. Mask: 0.9216. :  99%|█████████▉| 99/100 [00:23<00:00,  6.93it/s]Train Iter: 4300/5000. LR: 0.0033. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9466. T_Loss: 4.5473. Mask: 0.9216. : 100%|██████████| 100/100 [00:23<00:00,  7.06it/s]Train Iter: 4300/5000. LR: 0.0033. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9466. T_Loss: 4.5473. Mask: 0.9216. : 100%|██████████| 100/100 [00:23<00:00,  4.24it/s]
total : 5000  current step :  4276
total : 5000  current step :  4277
total : 5000  current step :  4278
total : 5000  current step :  4279
total : 5000  current step :  4280
total : 5000  current step :  4281
total : 5000  current step :  4282
total : 5000  current step :  4283
total : 5000  current step :  4284
total : 5000  current step :  4285
total : 5000  current step :  4286
total : 5000  current step :  4287
total : 5000  current step :  4288
total : 5000  current step :  4289
total : 5000  current step :  4290
total : 5000  current step :  4291
total : 5000  current step :  4292
total : 5000  current step :  4293
total : 5000  current step :  4294
total : 5000  current step :  4295
total : 5000  current step :  4296
total : 5000  current step :  4297
total : 5000  current step :  4298
total : 5000  current step :  4299
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 0.8606. top1: 90.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 0.8606. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.95s. Loss: 0.8481. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 0.8261. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.8266. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 0.8155. top1: 92.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8134. top1: 93.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8278. top1: 92.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8278. top1: 92.41. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.77it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8262. top1: 91.80. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.77it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8254. top1: 91.67. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.77it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8297. top1: 91.56. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.77it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8207. top1: 92.33. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.77it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8230. top1: 92.19. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.77it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8185. top1: 92.31. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.77it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8147. top1: 92.63. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.77it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8139. top1: 92.71. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.77it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8152. top1: 92.58. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.77it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8152. top1: 92.58. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8133. top1: 92.65. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8145. top1: 92.71. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8141. top1: 92.60. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8136. top1: 92.66. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8164. top1: 92.71. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8147. top1: 92.90. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8114. top1: 93.21. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8089. top1: 93.36. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8066. top1: 93.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8108. top1: 93.15. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.16it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8108. top1: 93.15. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8112. top1: 93.17. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8139. top1: 93.08. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8114. top1: 93.21. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8109. top1: 93.23. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8101. top1: 93.35. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8355. top1: 92.19. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8506. top1: 91.19. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8666. top1: 90.17. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 21.90it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8666. top1: 90.17. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8864. top1: 89.02. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9142. top1: 87.93. top5: 99.57. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9250. top1: 87.08. top5: 99.58. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9391. top1: 86.27. top5: 99.59. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9558. top1: 85.50. top5: 99.36. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9695. top1: 84.77. top5: 99.38. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9789. top1: 84.22. top5: 99.31. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9967. top1: 83.41. top5: 99.33. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0097. top1: 82.92. top5: 99.20. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0182. top1: 82.53. top5: 99.22. :  54%|█████▍    | 34/63 [00:02<00:00, 29.72it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0182. top1: 82.53. top5: 99.22. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0239. top1: 82.15. top5: 99.24. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0347. top1: 81.39. top5: 99.25. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0424. top1: 80.85. top5: 99.27. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0497. top1: 80.40. top5: 99.28. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0587. top1: 80.17. top5: 99.17. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0653. top1: 79.75. top5: 99.12. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0806. top1: 78.92. top5: 99.14. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0862. top1: 78.67. top5: 99.10. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0961. top1: 78.12. top5: 99.06. :  70%|██████▉   | 44/63 [00:02<00:00, 40.70it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0961. top1: 78.12. top5: 99.06. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1070. top1: 77.60. top5: 99.02. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1110. top1: 77.22. top5: 99.03. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1162. top1: 76.95. top5: 99.05. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1270. top1: 76.43. top5: 99.01. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1377. top1: 75.92. top5: 98.92. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1448. top1: 75.48. top5: 98.83. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1460. top1: 75.47. top5: 98.85. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1547. top1: 75.05. top5: 98.82. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1660. top1: 74.40. top5: 98.84. :  84%|████████▍ | 53/63 [00:02<00:00, 49.55it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1660. top1: 74.40. top5: 98.84. :  98%|█████████▊| 62/63 [00:02<00:00, 56.71it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1678. top1: 74.25. top5: 98.85. :  98%|█████████▊| 62/63 [00:02<00:00, 56.71it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1678. top1: 74.25. top5: 98.85. : 100%|██████████| 63/63 [00:02<00:00, 22.04it/s]
total : 5000  current step :  4300
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4301/5000. LR: 0.0033. Data: 2.54s. Batch: 2.69s. S_Loss: 1.0103. T_Loss: 4.6966. Mask: 0.8438. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4301/5000. LR: 0.0033. Data: 2.54s. Batch: 2.69s. S_Loss: 1.0103. T_Loss: 4.6966. Mask: 0.8438. :   1%|          | 1/100 [00:02<04:26,  2.69s/it]Train Iter: 4302/5000. LR: 0.0033. Data: 1.28s. Batch: 1.43s. S_Loss: 0.9070. T_Loss: 4.4659. Mask: 0.8750. :   1%|          | 1/100 [00:02<04:26,  2.69s/it]Train Iter: 4302/5000. LR: 0.0033. Data: 1.28s. Batch: 1.43s. S_Loss: 0.9070. T_Loss: 4.4659. Mask: 0.8750. :   2%|▏         | 2/100 [00:02<01:58,  1.21s/it]Train Iter: 4303/5000. LR: 0.0033. Data: 0.86s. Batch: 0.99s. S_Loss: 0.9274. T_Loss: 4.3425. Mask: 0.8958. :   2%|▏         | 2/100 [00:02<01:58,  1.21s/it]Train Iter: 4303/5000. LR: 0.0033. Data: 0.86s. Batch: 0.99s. S_Loss: 0.9274. T_Loss: 4.3425. Mask: 0.8958. :   3%|▎         | 3/100 [00:02<01:08,  1.41it/s]Train Iter: 4304/5000. LR: 0.0033. Data: 0.64s. Batch: 0.77s. S_Loss: 0.9383. T_Loss: 4.3589. Mask: 0.8906. :   3%|▎         | 3/100 [00:03<01:08,  1.41it/s]Train Iter: 4304/5000. LR: 0.0033. Data: 0.64s. Batch: 0.77s. S_Loss: 0.9383. T_Loss: 4.3589. Mask: 0.8906. :   4%|▍         | 4/100 [00:03<00:45,  2.09it/s]Train Iter: 4305/5000. LR: 0.0033. Data: 0.52s. Batch: 0.64s. S_Loss: 0.9327. T_Loss: 4.3332. Mask: 0.8875. :   4%|▍         | 4/100 [00:03<00:45,  2.09it/s]Train Iter: 4305/5000. LR: 0.0033. Data: 0.52s. Batch: 0.64s. S_Loss: 0.9327. T_Loss: 4.3332. Mask: 0.8875. :   5%|▌         | 5/100 [00:03<00:33,  2.86it/s]Train Iter: 4306/5000. LR: 0.0033. Data: 0.43s. Batch: 0.56s. S_Loss: 0.9666. T_Loss: 4.4195. Mask: 0.8854. :   5%|▌         | 5/100 [00:03<00:33,  2.86it/s]Train Iter: 4306/5000. LR: 0.0033. Data: 0.43s. Batch: 0.56s. S_Loss: 0.9666. T_Loss: 4.4195. Mask: 0.8854. :   6%|▌         | 6/100 [00:03<00:25,  3.65it/s]Train Iter: 4307/5000. LR: 0.0033. Data: 0.37s. Batch: 0.50s. S_Loss: 0.9566. T_Loss: 4.3748. Mask: 0.8839. :   6%|▌         | 6/100 [00:03<00:25,  3.65it/s]Train Iter: 4307/5000. LR: 0.0033. Data: 0.37s. Batch: 0.50s. S_Loss: 0.9566. T_Loss: 4.3748. Mask: 0.8839. :   7%|▋         | 7/100 [00:03<00:21,  4.40it/s]Train Iter: 4308/5000. LR: 0.0033. Data: 0.32s. Batch: 0.45s. S_Loss: 0.9698. T_Loss: 4.5245. Mask: 0.8945. :   7%|▋         | 7/100 [00:03<00:21,  4.40it/s]Train Iter: 4308/5000. LR: 0.0033. Data: 0.32s. Batch: 0.45s. S_Loss: 0.9698. T_Loss: 4.5245. Mask: 0.8945. :   8%|▊         | 8/100 [00:03<00:18,  5.07it/s]Train Iter: 4309/5000. LR: 0.0033. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9721. T_Loss: 4.5218. Mask: 0.8889. :   8%|▊         | 8/100 [00:03<00:18,  5.07it/s]Train Iter: 4309/5000. LR: 0.0033. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9721. T_Loss: 4.5218. Mask: 0.8889. :   9%|▉         | 9/100 [00:03<00:22,  4.11it/s]Train Iter: 4310/5000. LR: 0.0033. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9770. T_Loss: 4.5364. Mask: 0.8906. :   9%|▉         | 9/100 [00:04<00:22,  4.11it/s]Train Iter: 4310/5000. LR: 0.0033. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9770. T_Loss: 4.5364. Mask: 0.8906. :  10%|█         | 10/100 [00:04<00:19,  4.72it/s]Train Iter: 4311/5000. LR: 0.0032. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9713. T_Loss: 4.4709. Mask: 0.8892. :  10%|█         | 10/100 [00:04<00:19,  4.72it/s]Train Iter: 4311/5000. LR: 0.0032. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9713. T_Loss: 4.4709. Mask: 0.8892. :  11%|█         | 11/100 [00:04<00:16,  5.33it/s]Train Iter: 4312/5000. LR: 0.0032. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9666. T_Loss: 4.4785. Mask: 0.8958. :  11%|█         | 11/100 [00:04<00:16,  5.33it/s]Train Iter: 4312/5000. LR: 0.0032. Data: 0.22s. Batch: 0.36s. S_Loss: 0.9666. T_Loss: 4.4785. Mask: 0.8958. :  12%|█▏        | 12/100 [00:04<00:15,  5.81it/s]Train Iter: 4313/5000. LR: 0.0032. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9579. T_Loss: 4.4622. Mask: 0.8966. :  12%|█▏        | 12/100 [00:04<00:15,  5.81it/s]Train Iter: 4313/5000. LR: 0.0032. Data: 0.20s. Batch: 0.35s. S_Loss: 0.9579. T_Loss: 4.4622. Mask: 0.8966. :  13%|█▎        | 13/100 [00:04<00:14,  6.09it/s]Train Iter: 4314/5000. LR: 0.0032. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9607. T_Loss: 4.4585. Mask: 0.8951. :  13%|█▎        | 13/100 [00:04<00:14,  6.09it/s]Train Iter: 4314/5000. LR: 0.0032. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9607. T_Loss: 4.4585. Mask: 0.8951. :  14%|█▍        | 14/100 [00:04<00:13,  6.27it/s]Train Iter: 4315/5000. LR: 0.0032. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9546. T_Loss: 4.4290. Mask: 0.9000. :  14%|█▍        | 14/100 [00:04<00:13,  6.27it/s]Train Iter: 4315/5000. LR: 0.0032. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9546. T_Loss: 4.4290. Mask: 0.9000. :  15%|█▌        | 15/100 [00:04<00:16,  5.23it/s]Train Iter: 4316/5000. LR: 0.0032. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9528. T_Loss: 4.4507. Mask: 0.9023. :  15%|█▌        | 15/100 [00:05<00:16,  5.23it/s]Train Iter: 4316/5000. LR: 0.0032. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9528. T_Loss: 4.4507. Mask: 0.9023. :  16%|█▌        | 16/100 [00:05<00:14,  5.90it/s]Train Iter: 4317/5000. LR: 0.0032. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9524. T_Loss: 4.5101. Mask: 0.9044. :  16%|█▌        | 16/100 [00:05<00:14,  5.90it/s]Train Iter: 4317/5000. LR: 0.0032. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9524. T_Loss: 4.5101. Mask: 0.9044. :  17%|█▋        | 17/100 [00:05<00:13,  6.36it/s]Train Iter: 4318/5000. LR: 0.0032. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9432. T_Loss: 4.4879. Mask: 0.9045. :  17%|█▋        | 17/100 [00:05<00:13,  6.36it/s]Train Iter: 4318/5000. LR: 0.0032. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9432. T_Loss: 4.4879. Mask: 0.9045. :  18%|█▊        | 18/100 [00:05<00:12,  6.47it/s]Train Iter: 4319/5000. LR: 0.0032. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9421. T_Loss: 4.4927. Mask: 0.9079. :  18%|█▊        | 18/100 [00:05<00:12,  6.47it/s]Train Iter: 4319/5000. LR: 0.0032. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9421. T_Loss: 4.4927. Mask: 0.9079. :  19%|█▉        | 19/100 [00:05<00:13,  6.06it/s]Train Iter: 4320/5000. LR: 0.0032. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9443. T_Loss: 4.4558. Mask: 0.9047. :  19%|█▉        | 19/100 [00:05<00:13,  6.06it/s]Train Iter: 4320/5000. LR: 0.0032. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9443. T_Loss: 4.4558. Mask: 0.9047. :  20%|██        | 20/100 [00:05<00:12,  6.47it/s]Train Iter: 4321/5000. LR: 0.0032. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9432. T_Loss: 4.4687. Mask: 0.9048. :  20%|██        | 20/100 [00:05<00:12,  6.47it/s]Train Iter: 4321/5000. LR: 0.0032. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9432. T_Loss: 4.4687. Mask: 0.9048. :  21%|██        | 21/100 [00:05<00:11,  6.68it/s]Train Iter: 4322/5000. LR: 0.0031. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9385. T_Loss: 4.4418. Mask: 0.9077. :  21%|██        | 21/100 [00:05<00:11,  6.68it/s]Train Iter: 4322/5000. LR: 0.0031. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9385. T_Loss: 4.4418. Mask: 0.9077. :  22%|██▏       | 22/100 [00:05<00:11,  6.77it/s]Train Iter: 4323/5000. LR: 0.0031. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9360. T_Loss: 4.4350. Mask: 0.9103. :  22%|██▏       | 22/100 [00:06<00:11,  6.77it/s]Train Iter: 4323/5000. LR: 0.0031. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9360. T_Loss: 4.4350. Mask: 0.9103. :  23%|██▎       | 23/100 [00:06<00:11,  6.83it/s]Train Iter: 4324/5000. LR: 0.0031. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9353. T_Loss: 4.4179. Mask: 0.9089. :  23%|██▎       | 23/100 [00:06<00:11,  6.83it/s]Train Iter: 4324/5000. LR: 0.0031. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9353. T_Loss: 4.4179. Mask: 0.9089. :  24%|██▍       | 24/100 [00:06<00:10,  7.09it/s]Train Iter: 4325/5000. LR: 0.0031. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9339. T_Loss: 4.4096. Mask: 0.9100. :  24%|██▍       | 24/100 [00:06<00:10,  7.09it/s]Train Iter: 4325/5000. LR: 0.0031. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9339. T_Loss: 4.4096. Mask: 0.9100. :  25%|██▌       | 25/100 [00:06<00:12,  5.87it/s]total : 5000  current step :  4301
total : 5000  current step :  4302
total : 5000  current step :  4303
total : 5000  current step :  4304
total : 5000  current step :  4305
total : 5000  current step :  4306
total : 5000  current step :  4307
total : 5000  current step :  4308
total : 5000  current step :  4309
total : 5000  current step :  4310
total : 5000  current step :  4311
total : 5000  current step :  4312
total : 5000  current step :  4313
total : 5000  current step :  4314
total : 5000  current step :  4315
total : 5000  current step :  4316
total : 5000  current step :  4317
total : 5000  current step :  4318
total : 5000  current step :  4319
total : 5000  current step :  4320
total : 5000  current step :  4321
total : 5000  current step :  4322
total : 5000  current step :  4323
total : 5000  current step :  4324
total : 5000  current step :  4325
Train Iter: 4326/5000. LR: 0.0031. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9305. T_Loss: 4.4012. Mask: 0.9111. :  25%|██▌       | 25/100 [00:08<00:12,  5.87it/s]Train Iter: 4326/5000. LR: 0.0031. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9305. T_Loss: 4.4012. Mask: 0.9111. :  26%|██▌       | 26/100 [00:08<00:55,  1.34it/s]Train Iter: 4327/5000. LR: 0.0031. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9327. T_Loss: 4.4433. Mask: 0.9120. :  26%|██▌       | 26/100 [00:08<00:55,  1.34it/s]Train Iter: 4327/5000. LR: 0.0031. Data: 0.17s. Batch: 0.32s. S_Loss: 0.9327. T_Loss: 4.4433. Mask: 0.9120. :  27%|██▋       | 27/100 [00:08<00:42,  1.73it/s]Train Iter: 4328/5000. LR: 0.0031. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9354. T_Loss: 4.4977. Mask: 0.9141. :  27%|██▋       | 27/100 [00:08<00:42,  1.73it/s]Train Iter: 4328/5000. LR: 0.0031. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9354. T_Loss: 4.4977. Mask: 0.9141. :  28%|██▊       | 28/100 [00:08<00:32,  2.23it/s]Train Iter: 4329/5000. LR: 0.0031. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9358. T_Loss: 4.5028. Mask: 0.9149. :  28%|██▊       | 28/100 [00:09<00:32,  2.23it/s]Train Iter: 4329/5000. LR: 0.0031. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9358. T_Loss: 4.5028. Mask: 0.9149. :  29%|██▉       | 29/100 [00:09<00:25,  2.74it/s]Train Iter: 4330/5000. LR: 0.0031. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9422. T_Loss: 4.5097. Mask: 0.9125. :  29%|██▉       | 29/100 [00:09<00:25,  2.74it/s]Train Iter: 4330/5000. LR: 0.0031. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9422. T_Loss: 4.5097. Mask: 0.9125. :  30%|███       | 30/100 [00:09<00:20,  3.41it/s]Train Iter: 4331/5000. LR: 0.0031. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9428. T_Loss: 4.5138. Mask: 0.9153. :  30%|███       | 30/100 [00:09<00:20,  3.41it/s]Train Iter: 4331/5000. LR: 0.0031. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9428. T_Loss: 4.5138. Mask: 0.9153. :  31%|███       | 31/100 [00:09<00:16,  4.21it/s]Train Iter: 4332/5000. LR: 0.0031. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9423. T_Loss: 4.5174. Mask: 0.9141. :  31%|███       | 31/100 [00:09<00:16,  4.21it/s]Train Iter: 4332/5000. LR: 0.0031. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9423. T_Loss: 4.5174. Mask: 0.9141. :  32%|███▏      | 32/100 [00:09<00:14,  4.81it/s]Train Iter: 4333/5000. LR: 0.0030. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9456. T_Loss: 4.5050. Mask: 0.9129. :  32%|███▏      | 32/100 [00:09<00:14,  4.81it/s]Train Iter: 4333/5000. LR: 0.0030. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9456. T_Loss: 4.5050. Mask: 0.9129. :  33%|███▎      | 33/100 [00:09<00:12,  5.31it/s]Train Iter: 4334/5000. LR: 0.0030. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9488. T_Loss: 4.5218. Mask: 0.9118. :  33%|███▎      | 33/100 [00:09<00:12,  5.31it/s]Train Iter: 4334/5000. LR: 0.0030. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9488. T_Loss: 4.5218. Mask: 0.9118. :  34%|███▍      | 34/100 [00:09<00:11,  5.81it/s]Train Iter: 4335/5000. LR: 0.0030. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9480. T_Loss: 4.5166. Mask: 0.9125. :  34%|███▍      | 34/100 [00:09<00:11,  5.81it/s]Train Iter: 4335/5000. LR: 0.0030. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9480. T_Loss: 4.5166. Mask: 0.9125. :  35%|███▌      | 35/100 [00:09<00:13,  4.95it/s]Train Iter: 4336/5000. LR: 0.0030. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9486. T_Loss: 4.5276. Mask: 0.9132. :  35%|███▌      | 35/100 [00:10<00:13,  4.95it/s]Train Iter: 4336/5000. LR: 0.0030. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9486. T_Loss: 4.5276. Mask: 0.9132. :  36%|███▌      | 36/100 [00:10<00:11,  5.55it/s]Train Iter: 4337/5000. LR: 0.0030. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9462. T_Loss: 4.5125. Mask: 0.9113. :  36%|███▌      | 36/100 [00:10<00:11,  5.55it/s]Train Iter: 4337/5000. LR: 0.0030. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9462. T_Loss: 4.5125. Mask: 0.9113. :  37%|███▋      | 37/100 [00:10<00:10,  6.06it/s]Train Iter: 4338/5000. LR: 0.0030. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9448. T_Loss: 4.5208. Mask: 0.9120. :  37%|███▋      | 37/100 [00:10<00:10,  6.06it/s]Train Iter: 4338/5000. LR: 0.0030. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9448. T_Loss: 4.5208. Mask: 0.9120. :  38%|███▊      | 38/100 [00:10<00:09,  6.49it/s]Train Iter: 4339/5000. LR: 0.0030. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9453. T_Loss: 4.5411. Mask: 0.9119. :  38%|███▊      | 38/100 [00:10<00:09,  6.49it/s]Train Iter: 4339/5000. LR: 0.0030. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9453. T_Loss: 4.5411. Mask: 0.9119. :  39%|███▉      | 39/100 [00:10<00:14,  4.35it/s]Train Iter: 4340/5000. LR: 0.0030. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9444. T_Loss: 4.5355. Mask: 0.9133. :  39%|███▉      | 39/100 [00:10<00:14,  4.35it/s]Train Iter: 4340/5000. LR: 0.0030. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9444. T_Loss: 4.5355. Mask: 0.9133. :  40%|████      | 40/100 [00:10<00:11,  5.19it/s]Train Iter: 4341/5000. LR: 0.0030. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9461. T_Loss: 4.5212. Mask: 0.9108. :  40%|████      | 40/100 [00:10<00:11,  5.19it/s]Train Iter: 4341/5000. LR: 0.0030. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9461. T_Loss: 4.5212. Mask: 0.9108. :  41%|████      | 41/100 [00:10<00:10,  5.60it/s]Train Iter: 4342/5000. LR: 0.0030. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9460. T_Loss: 4.5130. Mask: 0.9100. :  41%|████      | 41/100 [00:11<00:10,  5.60it/s]Train Iter: 4342/5000. LR: 0.0030. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9460. T_Loss: 4.5130. Mask: 0.9100. :  42%|████▏     | 42/100 [00:11<00:09,  6.12it/s]Train Iter: 4343/5000. LR: 0.0030. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9486. T_Loss: 4.5051. Mask: 0.9099. :  42%|████▏     | 42/100 [00:11<00:09,  6.12it/s]Train Iter: 4343/5000. LR: 0.0030. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9486. T_Loss: 4.5051. Mask: 0.9099. :  43%|████▎     | 43/100 [00:11<00:09,  6.27it/s]Train Iter: 4344/5000. LR: 0.0029. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9500. T_Loss: 4.5122. Mask: 0.9098. :  43%|████▎     | 43/100 [00:11<00:09,  6.27it/s]Train Iter: 4344/5000. LR: 0.0029. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9500. T_Loss: 4.5122. Mask: 0.9098. :  44%|████▍     | 44/100 [00:11<00:08,  6.52it/s]Train Iter: 4345/5000. LR: 0.0029. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9502. T_Loss: 4.5208. Mask: 0.9104. :  44%|████▍     | 44/100 [00:11<00:08,  6.52it/s]Train Iter: 4345/5000. LR: 0.0029. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9502. T_Loss: 4.5208. Mask: 0.9104. :  45%|████▌     | 45/100 [00:11<00:11,  4.98it/s]Train Iter: 4346/5000. LR: 0.0029. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9498. T_Loss: 4.5177. Mask: 0.9103. :  45%|████▌     | 45/100 [00:11<00:11,  4.98it/s]Train Iter: 4346/5000. LR: 0.0029. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9498. T_Loss: 4.5177. Mask: 0.9103. :  46%|████▌     | 46/100 [00:11<00:09,  5.64it/s]Train Iter: 4347/5000. LR: 0.0029. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9494. T_Loss: 4.5169. Mask: 0.9102. :  46%|████▌     | 46/100 [00:11<00:09,  5.64it/s]Train Iter: 4347/5000. LR: 0.0029. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9494. T_Loss: 4.5169. Mask: 0.9102. :  47%|████▋     | 47/100 [00:11<00:08,  6.13it/s]Train Iter: 4348/5000. LR: 0.0029. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9495. T_Loss: 4.5262. Mask: 0.9108. :  47%|████▋     | 47/100 [00:12<00:08,  6.13it/s]Train Iter: 4348/5000. LR: 0.0029. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9495. T_Loss: 4.5262. Mask: 0.9108. :  48%|████▊     | 48/100 [00:12<00:08,  6.50it/s]Train Iter: 4349/5000. LR: 0.0029. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9504. T_Loss: 4.5488. Mask: 0.9114. :  48%|████▊     | 48/100 [00:12<00:08,  6.50it/s]Train Iter: 4349/5000. LR: 0.0029. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9504. T_Loss: 4.5488. Mask: 0.9114. :  49%|████▉     | 49/100 [00:12<00:10,  4.92it/s]Train Iter: 4350/5000. LR: 0.0029. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9489. T_Loss: 4.5359. Mask: 0.9113. :  49%|████▉     | 49/100 [00:12<00:10,  4.92it/s]Train Iter: 4350/5000. LR: 0.0029. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9489. T_Loss: 4.5359. Mask: 0.9113. :  50%|█████     | 50/100 [00:12<00:09,  5.41it/s]total : 5000  current step :  4326
total : 5000  current step :  4327
total : 5000  current step :  4328
total : 5000  current step :  4329
total : 5000  current step :  4330
total : 5000  current step :  4331
total : 5000  current step :  4332
total : 5000  current step :  4333
total : 5000  current step :  4334
total : 5000  current step :  4335
total : 5000  current step :  4336
total : 5000  current step :  4337
total : 5000  current step :  4338
total : 5000  current step :  4339
total : 5000  current step :  4340
total : 5000  current step :  4341
total : 5000  current step :  4342
total : 5000  current step :  4343
total : 5000  current step :  4344
total : 5000  current step :  4345
total : 5000  current step :  4346
total : 5000  current step :  4347
total : 5000  current step :  4348
total : 5000  current step :  4349
total : 5000  current step :  4350
Train Iter: 4351/5000. LR: 0.0029. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9495. T_Loss: 4.5395. Mask: 0.9118. :  50%|█████     | 50/100 [00:14<00:09,  5.41it/s]Train Iter: 4351/5000. LR: 0.0029. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9495. T_Loss: 4.5395. Mask: 0.9118. :  51%|█████     | 51/100 [00:14<00:36,  1.33it/s]Train Iter: 4352/5000. LR: 0.0029. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9488. T_Loss: 4.5290. Mask: 0.9105. :  51%|█████     | 51/100 [00:14<00:36,  1.33it/s]Train Iter: 4352/5000. LR: 0.0029. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9488. T_Loss: 4.5290. Mask: 0.9105. :  52%|█████▏    | 52/100 [00:14<00:27,  1.77it/s]Train Iter: 4353/5000. LR: 0.0029. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9491. T_Loss: 4.5374. Mask: 0.9104. :  52%|█████▏    | 52/100 [00:14<00:27,  1.77it/s]Train Iter: 4353/5000. LR: 0.0029. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9491. T_Loss: 4.5374. Mask: 0.9104. :  53%|█████▎    | 53/100 [00:14<00:20,  2.28it/s]Train Iter: 4354/5000. LR: 0.0029. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9506. T_Loss: 4.5614. Mask: 0.9115. :  53%|█████▎    | 53/100 [00:15<00:20,  2.28it/s]Train Iter: 4354/5000. LR: 0.0029. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9506. T_Loss: 4.5614. Mask: 0.9115. :  54%|█████▍    | 54/100 [00:15<00:16,  2.87it/s]Train Iter: 4355/5000. LR: 0.0029. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9504. T_Loss: 4.5511. Mask: 0.9119. :  54%|█████▍    | 54/100 [00:15<00:16,  2.87it/s]Train Iter: 4355/5000. LR: 0.0029. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9504. T_Loss: 4.5511. Mask: 0.9119. :  55%|█████▌    | 55/100 [00:15<00:15,  2.91it/s]Train Iter: 4356/5000. LR: 0.0028. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9488. T_Loss: 4.5318. Mask: 0.9124. :  55%|█████▌    | 55/100 [00:15<00:15,  2.91it/s]Train Iter: 4356/5000. LR: 0.0028. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9488. T_Loss: 4.5318. Mask: 0.9124. :  56%|█████▌    | 56/100 [00:15<00:12,  3.60it/s]Train Iter: 4357/5000. LR: 0.0028. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9492. T_Loss: 4.5245. Mask: 0.9112. :  56%|█████▌    | 56/100 [00:15<00:12,  3.60it/s]Train Iter: 4357/5000. LR: 0.0028. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9492. T_Loss: 4.5245. Mask: 0.9112. :  57%|█████▋    | 57/100 [00:15<00:09,  4.31it/s]Train Iter: 4358/5000. LR: 0.0028. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9486. T_Loss: 4.5214. Mask: 0.9111. :  57%|█████▋    | 57/100 [00:15<00:09,  4.31it/s]Train Iter: 4358/5000. LR: 0.0028. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9486. T_Loss: 4.5214. Mask: 0.9111. :  58%|█████▊    | 58/100 [00:15<00:08,  5.06it/s]Train Iter: 4359/5000. LR: 0.0028. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9496. T_Loss: 4.5238. Mask: 0.9110. :  58%|█████▊    | 58/100 [00:15<00:08,  5.06it/s]Train Iter: 4359/5000. LR: 0.0028. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9496. T_Loss: 4.5238. Mask: 0.9110. :  59%|█████▉    | 59/100 [00:15<00:08,  5.08it/s]Train Iter: 4360/5000. LR: 0.0028. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9513. T_Loss: 4.5239. Mask: 0.9104. :  59%|█████▉    | 59/100 [00:16<00:08,  5.08it/s]Train Iter: 4360/5000. LR: 0.0028. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9513. T_Loss: 4.5239. Mask: 0.9104. :  60%|██████    | 60/100 [00:16<00:07,  5.55it/s]Train Iter: 4361/5000. LR: 0.0028. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9530. T_Loss: 4.5309. Mask: 0.9098. :  60%|██████    | 60/100 [00:16<00:07,  5.55it/s]Train Iter: 4361/5000. LR: 0.0028. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9530. T_Loss: 4.5309. Mask: 0.9098. :  61%|██████    | 61/100 [00:16<00:06,  6.16it/s]Train Iter: 4362/5000. LR: 0.0028. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9523. T_Loss: 4.5322. Mask: 0.9098. :  61%|██████    | 61/100 [00:16<00:06,  6.16it/s]Train Iter: 4362/5000. LR: 0.0028. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9523. T_Loss: 4.5322. Mask: 0.9098. :  62%|██████▏   | 62/100 [00:16<00:05,  6.43it/s]Train Iter: 4363/5000. LR: 0.0028. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9537. T_Loss: 4.5456. Mask: 0.9097. :  62%|██████▏   | 62/100 [00:16<00:05,  6.43it/s]Train Iter: 4363/5000. LR: 0.0028. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9537. T_Loss: 4.5456. Mask: 0.9097. :  63%|██████▎   | 63/100 [00:16<00:05,  6.70it/s]Train Iter: 4364/5000. LR: 0.0028. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9547. T_Loss: 4.5450. Mask: 0.9102. :  63%|██████▎   | 63/100 [00:16<00:05,  6.70it/s]Train Iter: 4364/5000. LR: 0.0028. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9547. T_Loss: 4.5450. Mask: 0.9102. :  64%|██████▍   | 64/100 [00:16<00:05,  6.69it/s]Train Iter: 4365/5000. LR: 0.0028. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9547. T_Loss: 4.5465. Mask: 0.9096. :  64%|██████▍   | 64/100 [00:16<00:05,  6.69it/s]Train Iter: 4365/5000. LR: 0.0028. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9547. T_Loss: 4.5465. Mask: 0.9096. :  65%|██████▌   | 65/100 [00:16<00:05,  5.95it/s]Train Iter: 4366/5000. LR: 0.0028. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9530. T_Loss: 4.5360. Mask: 0.9091. :  65%|██████▌   | 65/100 [00:17<00:05,  5.95it/s]Train Iter: 4366/5000. LR: 0.0028. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9530. T_Loss: 4.5360. Mask: 0.9091. :  66%|██████▌   | 66/100 [00:17<00:05,  6.07it/s]Train Iter: 4367/5000. LR: 0.0028. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9525. T_Loss: 4.5357. Mask: 0.9095. :  66%|██████▌   | 66/100 [00:17<00:05,  6.07it/s]Train Iter: 4367/5000. LR: 0.0028. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9525. T_Loss: 4.5357. Mask: 0.9095. :  67%|██████▋   | 67/100 [00:17<00:05,  6.46it/s]Train Iter: 4368/5000. LR: 0.0027. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9534. T_Loss: 4.5394. Mask: 0.9104. :  67%|██████▋   | 67/100 [00:17<00:05,  6.46it/s]Train Iter: 4369/5000. LR: 0.0027. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9536. T_Loss: 4.5391. Mask: 0.9103. :  68%|██████▊   | 68/100 [00:17<00:04,  6.46it/s]Train Iter: 4369/5000. LR: 0.0027. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9536. T_Loss: 4.5391. Mask: 0.9103. :  69%|██████▉   | 69/100 [00:17<00:05,  6.18it/s]Train Iter: 4370/5000. LR: 0.0027. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9538. T_Loss: 4.5461. Mask: 0.9112. :  69%|██████▉   | 69/100 [00:17<00:05,  6.18it/s]Train Iter: 4371/5000. LR: 0.0027. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9551. T_Loss: 4.5559. Mask: 0.9111. :  70%|███████   | 70/100 [00:17<00:04,  6.18it/s]Train Iter: 4371/5000. LR: 0.0027. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9551. T_Loss: 4.5559. Mask: 0.9111. :  71%|███████   | 71/100 [00:17<00:03,  7.37it/s]Train Iter: 4372/5000. LR: 0.0027. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9566. T_Loss: 4.5574. Mask: 0.9102. :  71%|███████   | 71/100 [00:17<00:03,  7.37it/s]Train Iter: 4373/5000. LR: 0.0027. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9588. T_Loss: 4.5783. Mask: 0.9110. :  72%|███████▏  | 72/100 [00:17<00:03,  7.37it/s]Train Iter: 4373/5000. LR: 0.0027. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9588. T_Loss: 4.5783. Mask: 0.9110. :  73%|███████▎  | 73/100 [00:17<00:03,  7.92it/s]Train Iter: 4374/5000. LR: 0.0027. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9603. T_Loss: 4.5826. Mask: 0.9096. :  73%|███████▎  | 73/100 [00:18<00:03,  7.92it/s]Train Iter: 4374/5000. LR: 0.0027. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9603. T_Loss: 4.5826. Mask: 0.9096. :  74%|███████▍  | 74/100 [00:18<00:03,  7.91it/s]Train Iter: 4375/5000. LR: 0.0027. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9610. T_Loss: 4.5858. Mask: 0.9092. :  74%|███████▍  | 74/100 [00:18<00:03,  7.91it/s]Train Iter: 4375/5000. LR: 0.0027. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9610. T_Loss: 4.5858. Mask: 0.9092. :  75%|███████▌  | 75/100 [00:18<00:03,  7.40it/s]total : 5000  current step :  4351
total : 5000  current step :  4352
total : 5000  current step :  4353
total : 5000  current step :  4354
total : 5000  current step :  4355
total : 5000  current step :  4356
total : 5000  current step :  4357
total : 5000  current step :  4358
total : 5000  current step :  4359
total : 5000  current step :  4360
total : 5000  current step :  4361
total : 5000  current step :  4362
total : 5000  current step :  4363
total : 5000  current step :  4364
total : 5000  current step :  4365
total : 5000  current step :  4366
total : 5000  current step :  4367
total : 5000  current step :  4368
total : 5000  current step :  4369
total : 5000  current step :  4370
total : 5000  current step :  4371
total : 5000  current step :  4372
total : 5000  current step :  4373
total : 5000  current step :  4374
total : 5000  current step :  4375
Train Iter: 4376/5000. LR: 0.0027. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9609. T_Loss: 4.5827. Mask: 0.9095. :  75%|███████▌  | 75/100 [00:20<00:03,  7.40it/s]Train Iter: 4376/5000. LR: 0.0027. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9609. T_Loss: 4.5827. Mask: 0.9095. :  76%|███████▌  | 76/100 [00:20<00:15,  1.60it/s]Train Iter: 4377/5000. LR: 0.0027. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9619. T_Loss: 4.5885. Mask: 0.9099. :  76%|███████▌  | 76/100 [00:20<00:15,  1.60it/s]Train Iter: 4377/5000. LR: 0.0027. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9619. T_Loss: 4.5885. Mask: 0.9099. :  77%|███████▋  | 77/100 [00:20<00:11,  2.00it/s]Train Iter: 4378/5000. LR: 0.0027. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9624. T_Loss: 4.5893. Mask: 0.9099. :  77%|███████▋  | 77/100 [00:20<00:11,  2.00it/s]Train Iter: 4378/5000. LR: 0.0027. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9624. T_Loss: 4.5893. Mask: 0.9099. :  78%|███████▊  | 78/100 [00:20<00:08,  2.48it/s]Train Iter: 4379/5000. LR: 0.0026. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9612. T_Loss: 4.5900. Mask: 0.9106. :  78%|███████▊  | 78/100 [00:20<00:08,  2.48it/s]Train Iter: 4379/5000. LR: 0.0026. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9612. T_Loss: 4.5900. Mask: 0.9106. :  79%|███████▉  | 79/100 [00:20<00:08,  2.60it/s]Train Iter: 4380/5000. LR: 0.0026. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9612. T_Loss: 4.5739. Mask: 0.9086. :  79%|███████▉  | 79/100 [00:21<00:08,  2.60it/s]Train Iter: 4380/5000. LR: 0.0026. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9612. T_Loss: 4.5739. Mask: 0.9086. :  80%|████████  | 80/100 [00:21<00:06,  3.24it/s]Train Iter: 4381/5000. LR: 0.0026. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9606. T_Loss: 4.5746. Mask: 0.9086. :  80%|████████  | 80/100 [00:21<00:06,  3.24it/s]Train Iter: 4381/5000. LR: 0.0026. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9606. T_Loss: 4.5746. Mask: 0.9086. :  81%|████████  | 81/100 [00:21<00:04,  3.97it/s]total : 5000  current step :  4376
total : 5000  current step :  4377
total : 5000  current step :  4378
total : 5000  current step :  4379
total : 5000  current step :  4380
total : 5000  current step :  4381
Train Iter: 4382/5000. LR: 0.0026. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9599. T_Loss: 4.5754. Mask: 0.9085. :  81%|████████  | 81/100 [00:23<00:04,  3.97it/s]Train Iter: 4382/5000. LR: 0.0026. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9599. T_Loss: 4.5754. Mask: 0.9085. :  82%|████████▏ | 82/100 [00:23<00:13,  1.34it/s]Train Iter: 4383/5000. LR: 0.0026. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9595. T_Loss: 4.5670. Mask: 0.9078. :  82%|████████▏ | 82/100 [00:23<00:13,  1.34it/s]Train Iter: 4383/5000. LR: 0.0026. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9595. T_Loss: 4.5670. Mask: 0.9078. :  83%|████████▎ | 83/100 [00:23<00:09,  1.76it/s]Train Iter: 4384/5000. LR: 0.0026. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9619. T_Loss: 4.5762. Mask: 0.9066. :  83%|████████▎ | 83/100 [00:23<00:09,  1.76it/s]Train Iter: 4384/5000. LR: 0.0026. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9619. T_Loss: 4.5762. Mask: 0.9066. :  84%|████████▍ | 84/100 [00:23<00:06,  2.30it/s]Train Iter: 4385/5000. LR: 0.0026. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9645. T_Loss: 4.5810. Mask: 0.9066. :  84%|████████▍ | 84/100 [00:23<00:06,  2.30it/s]Train Iter: 4385/5000. LR: 0.0026. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9645. T_Loss: 4.5810. Mask: 0.9066. :  85%|████████▌ | 85/100 [00:23<00:05,  2.55it/s]Train Iter: 4386/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9643. T_Loss: 4.5812. Mask: 0.9070. :  85%|████████▌ | 85/100 [00:23<00:05,  2.55it/s]Train Iter: 4386/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9643. T_Loss: 4.5812. Mask: 0.9070. :  86%|████████▌ | 86/100 [00:23<00:04,  3.21it/s]Train Iter: 4387/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9653. T_Loss: 4.5875. Mask: 0.9077. :  86%|████████▌ | 86/100 [00:23<00:04,  3.21it/s]Train Iter: 4387/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9653. T_Loss: 4.5875. Mask: 0.9077. :  87%|████████▋ | 87/100 [00:23<00:03,  3.91it/s]Train Iter: 4388/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9651. T_Loss: 4.5875. Mask: 0.9080. :  87%|████████▋ | 87/100 [00:24<00:03,  3.91it/s]Train Iter: 4388/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9651. T_Loss: 4.5875. Mask: 0.9080. :  88%|████████▊ | 88/100 [00:24<00:02,  4.58it/s]Train Iter: 4389/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9656. T_Loss: 4.5943. Mask: 0.9084. :  88%|████████▊ | 88/100 [00:24<00:02,  4.58it/s]Train Iter: 4389/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9656. T_Loss: 4.5943. Mask: 0.9084. :  89%|████████▉ | 89/100 [00:24<00:02,  3.82it/s]Train Iter: 4390/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9659. T_Loss: 4.6019. Mask: 0.9087. :  89%|████████▉ | 89/100 [00:24<00:02,  3.82it/s]Train Iter: 4390/5000. LR: 0.0026. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9659. T_Loss: 4.6019. Mask: 0.9087. :  90%|█████████ | 90/100 [00:24<00:02,  4.53it/s]Train Iter: 4391/5000. LR: 0.0025. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9660. T_Loss: 4.6083. Mask: 0.9087. :  90%|█████████ | 90/100 [00:24<00:02,  4.53it/s]Train Iter: 4391/5000. LR: 0.0025. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9660. T_Loss: 4.6083. Mask: 0.9087. :  91%|█████████ | 91/100 [00:24<00:01,  5.01it/s]Train Iter: 4392/5000. LR: 0.0025. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9667. T_Loss: 4.6142. Mask: 0.9079. :  91%|█████████ | 91/100 [00:24<00:01,  5.01it/s]Train Iter: 4393/5000. LR: 0.0025. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9653. T_Loss: 4.6117. Mask: 0.9086. :  92%|█████████▏| 92/100 [00:24<00:01,  5.01it/s]Train Iter: 4393/5000. LR: 0.0025. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9653. T_Loss: 4.6117. Mask: 0.9086. :  93%|█████████▎| 93/100 [00:24<00:01,  6.53it/s]Train Iter: 4394/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9674. T_Loss: 4.6115. Mask: 0.9082. :  93%|█████████▎| 93/100 [00:24<00:01,  6.53it/s]Train Iter: 4395/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9674. T_Loss: 4.6103. Mask: 0.9082. :  94%|█████████▍| 94/100 [00:25<00:00,  6.53it/s]Train Iter: 4395/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9674. T_Loss: 4.6103. Mask: 0.9082. :  95%|█████████▌| 95/100 [00:25<00:00,  7.37it/s]Train Iter: 4396/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9685. T_Loss: 4.6195. Mask: 0.9092. :  95%|█████████▌| 95/100 [00:25<00:00,  7.37it/s]Train Iter: 4397/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9692. T_Loss: 4.6181. Mask: 0.9085. :  96%|█████████▌| 96/100 [00:25<00:00,  7.37it/s]Train Iter: 4397/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9692. T_Loss: 4.6181. Mask: 0.9085. :  97%|█████████▋| 97/100 [00:25<00:00,  8.39it/s]Train Iter: 4398/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9700. T_Loss: 4.6257. Mask: 0.9091. :  97%|█████████▋| 97/100 [00:25<00:00,  8.39it/s]Train Iter: 4398/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9700. T_Loss: 4.6257. Mask: 0.9091. :  98%|█████████▊| 98/100 [00:25<00:00,  8.24it/s]Train Iter: 4399/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9719. T_Loss: 4.6289. Mask: 0.9088. :  98%|█████████▊| 98/100 [00:25<00:00,  8.24it/s]Train Iter: 4399/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9719. T_Loss: 4.6289. Mask: 0.9088. :  99%|█████████▉| 99/100 [00:25<00:00,  5.85it/s]Train Iter: 4400/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9716. T_Loss: 4.6365. Mask: 0.9087. :  99%|█████████▉| 99/100 [00:25<00:00,  5.85it/s]Train Iter: 4400/5000. LR: 0.0025. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9716. T_Loss: 4.6365. Mask: 0.9087. : 100%|██████████| 100/100 [00:25<00:00,  3.87it/s]
total : 5000  current step :  4382
total : 5000  current step :  4383
total : 5000  current step :  4384
total : 5000  current step :  4385
total : 5000  current step :  4386
total : 5000  current step :  4387
total : 5000  current step :  4388
total : 5000  current step :  4389
total : 5000  current step :  4390
total : 5000  current step :  4391
total : 5000  current step :  4392
total : 5000  current step :  4393
total : 5000  current step :  4394
total : 5000  current step :  4395
total : 5000  current step :  4396
total : 5000  current step :  4397
total : 5000  current step :  4398
total : 5000  current step :  4399
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 0.8577. top1: 90.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 0.8577. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.93s. Loss: 0.8476. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.8243. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.8230. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8125. top1: 92.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8095. top1: 93.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8229. top1: 92.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8206. top1: 92.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8212. top1: 92.36. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8255. top1: 92.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8165. top1: 92.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8165. top1: 92.90. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.64it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8193. top1: 92.45. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.64it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8146. top1: 92.79. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.64it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8108. top1: 93.08. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.64it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8100. top1: 93.12. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.64it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8115. top1: 92.97. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.64it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8099. top1: 93.01. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.64it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8099. top1: 93.01. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8112. top1: 93.06. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8106. top1: 93.09. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8098. top1: 93.12. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8122. top1: 93.30. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8104. top1: 93.47. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8070. top1: 93.75. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8046. top1: 93.88. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8022. top1: 93.88. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8067. top1: 93.63. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.36it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8067. top1: 93.63. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8069. top1: 93.63. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8099. top1: 93.53. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8074. top1: 93.64. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8070. top1: 93.65. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8061. top1: 93.75. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8323. top1: 92.58. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8477. top1: 91.67. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8641. top1: 90.62. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8850. top1: 89.46. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9130. top1: 88.37. top5: 99.57. :  41%|████▏     | 26/63 [00:02<00:01, 21.17it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9130. top1: 88.37. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9240. top1: 87.67. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9384. top1: 87.01. top5: 99.59. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9552. top1: 86.22. top5: 99.36. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9689. top1: 85.47. top5: 99.38. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9782. top1: 84.91. top5: 99.31. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9960. top1: 84.15. top5: 99.33. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0092. top1: 83.58. top5: 99.20. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0179. top1: 83.10. top5: 99.15. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0237. top1: 82.64. top5: 99.17. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0343. top1: 81.93. top5: 99.18. :  57%|█████▋    | 36/63 [00:02<00:00, 32.17it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0343. top1: 81.93. top5: 99.18. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0422. top1: 81.38. top5: 99.20. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0496. top1: 80.99. top5: 99.22. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0582. top1: 80.68. top5: 99.11. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0653. top1: 80.19. top5: 99.06. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0805. top1: 79.35. top5: 99.08. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0862. top1: 79.09. top5: 99.04. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0959. top1: 78.60. top5: 99.06. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1068. top1: 78.07. top5: 99.02. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1111. top1: 77.61. top5: 99.03. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1164. top1: 77.23. top5: 99.05. :  73%|███████▎  | 46/63 [00:02<00:00, 42.85it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1164. top1: 77.23. top5: 99.05. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1279. top1: 76.75. top5: 99.01. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1387. top1: 76.24. top5: 98.92. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1459. top1: 75.79. top5: 98.83. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1475. top1: 75.68. top5: 98.80. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1564. top1: 75.31. top5: 98.77. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1684. top1: 74.70. top5: 98.79. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1704. top1: 74.60. top5: 98.80. :  89%|████████▉ | 56/63 [00:02<00:00, 53.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1704. top1: 74.60. top5: 98.80. : 100%|██████████| 63/63 [00:02<00:00, 22.70it/s]
total : 5000  current step :  4400
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4401/5000. LR: 0.0025. Data: 1.92s. Batch: 2.03s. S_Loss: 0.9672. T_Loss: 4.2356. Mask: 0.9375. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4401/5000. LR: 0.0025. Data: 1.92s. Batch: 2.03s. S_Loss: 0.9672. T_Loss: 4.2356. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:21,  2.04s/it]Train Iter: 4402/5000. LR: 0.0025. Data: 0.96s. Batch: 1.07s. S_Loss: 1.0433. T_Loss: 5.0153. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:21,  2.04s/it]Train Iter: 4402/5000. LR: 0.0025. Data: 0.96s. Batch: 1.07s. S_Loss: 1.0433. T_Loss: 5.0153. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 4403/5000. LR: 0.0025. Data: 0.64s. Batch: 0.75s. S_Loss: 0.9927. T_Loss: 4.6544. Mask: 0.8958. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 4403/5000. LR: 0.0025. Data: 0.64s. Batch: 0.75s. S_Loss: 0.9927. T_Loss: 4.6544. Mask: 0.8958. :   3%|▎         | 3/100 [00:02<00:53,  1.83it/s]Train Iter: 4404/5000. LR: 0.0024. Data: 0.48s. Batch: 0.60s. S_Loss: 0.9729. T_Loss: 4.7338. Mask: 0.8906. :   3%|▎         | 3/100 [00:02<00:53,  1.83it/s]Train Iter: 4404/5000. LR: 0.0024. Data: 0.48s. Batch: 0.60s. S_Loss: 0.9729. T_Loss: 4.7338. Mask: 0.8906. :   4%|▍         | 4/100 [00:02<00:36,  2.64it/s]Train Iter: 4405/5000. LR: 0.0024. Data: 0.39s. Batch: 0.55s. S_Loss: 0.9410. T_Loss: 4.5766. Mask: 0.8938. :   4%|▍         | 4/100 [00:02<00:36,  2.64it/s]Train Iter: 4405/5000. LR: 0.0024. Data: 0.39s. Batch: 0.55s. S_Loss: 0.9410. T_Loss: 4.5766. Mask: 0.8938. :   5%|▌         | 5/100 [00:02<00:35,  2.68it/s]Train Iter: 4406/5000. LR: 0.0024. Data: 0.32s. Batch: 0.48s. S_Loss: 0.9675. T_Loss: 4.6809. Mask: 0.9010. :   5%|▌         | 5/100 [00:02<00:35,  2.68it/s]Train Iter: 4406/5000. LR: 0.0024. Data: 0.32s. Batch: 0.48s. S_Loss: 0.9675. T_Loss: 4.6809. Mask: 0.9010. :   6%|▌         | 6/100 [00:02<00:26,  3.53it/s]Train Iter: 4407/5000. LR: 0.0024. Data: 0.28s. Batch: 0.42s. S_Loss: 0.9694. T_Loss: 4.5688. Mask: 0.8929. :   6%|▌         | 6/100 [00:02<00:26,  3.53it/s]Train Iter: 4407/5000. LR: 0.0024. Data: 0.28s. Batch: 0.42s. S_Loss: 0.9694. T_Loss: 4.5688. Mask: 0.8929. :   7%|▋         | 7/100 [00:02<00:21,  4.37it/s]Train Iter: 4408/5000. LR: 0.0024. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9566. T_Loss: 4.5229. Mask: 0.8906. :   7%|▋         | 7/100 [00:03<00:21,  4.37it/s]Train Iter: 4408/5000. LR: 0.0024. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9566. T_Loss: 4.5229. Mask: 0.8906. :   8%|▊         | 8/100 [00:03<00:18,  5.08it/s]Train Iter: 4409/5000. LR: 0.0024. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9551. T_Loss: 4.4443. Mask: 0.8854. :   8%|▊         | 8/100 [00:03<00:18,  5.08it/s]Train Iter: 4409/5000. LR: 0.0024. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9551. T_Loss: 4.4443. Mask: 0.8854. :   9%|▉         | 9/100 [00:03<00:15,  5.73it/s]Train Iter: 4410/5000. LR: 0.0024. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9531. T_Loss: 4.4079. Mask: 0.8844. :   9%|▉         | 9/100 [00:03<00:15,  5.73it/s]Train Iter: 4410/5000. LR: 0.0024. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9531. T_Loss: 4.4079. Mask: 0.8844. :  10%|█         | 10/100 [00:03<00:14,  6.32it/s]Train Iter: 4411/5000. LR: 0.0024. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9614. T_Loss: 4.4271. Mask: 0.8778. :  10%|█         | 10/100 [00:03<00:14,  6.32it/s]Train Iter: 4411/5000. LR: 0.0024. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9614. T_Loss: 4.4271. Mask: 0.8778. :  11%|█         | 11/100 [00:03<00:13,  6.70it/s]Train Iter: 4412/5000. LR: 0.0024. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9725. T_Loss: 4.4486. Mask: 0.8802. :  11%|█         | 11/100 [00:03<00:13,  6.70it/s]Train Iter: 4412/5000. LR: 0.0024. Data: 0.16s. Batch: 0.30s. S_Loss: 0.9725. T_Loss: 4.4486. Mask: 0.8802. :  12%|█▏        | 12/100 [00:03<00:12,  7.24it/s]Train Iter: 4413/5000. LR: 0.0024. Data: 0.15s. Batch: 0.28s. S_Loss: 0.9823. T_Loss: 4.5679. Mask: 0.8894. :  12%|█▏        | 12/100 [00:03<00:12,  7.24it/s]Train Iter: 4413/5000. LR: 0.0024. Data: 0.15s. Batch: 0.28s. S_Loss: 0.9823. T_Loss: 4.5679. Mask: 0.8894. :  13%|█▎        | 13/100 [00:03<00:11,  7.52it/s]Train Iter: 4414/5000. LR: 0.0024. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9939. T_Loss: 4.6232. Mask: 0.8884. :  13%|█▎        | 13/100 [00:03<00:11,  7.52it/s]Train Iter: 4414/5000. LR: 0.0024. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9939. T_Loss: 4.6232. Mask: 0.8884. :  14%|█▍        | 14/100 [00:03<00:11,  7.56it/s]Train Iter: 4415/5000. LR: 0.0024. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9958. T_Loss: 4.6434. Mask: 0.8896. :  14%|█▍        | 14/100 [00:04<00:11,  7.56it/s]Train Iter: 4415/5000. LR: 0.0024. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9958. T_Loss: 4.6434. Mask: 0.8896. :  15%|█▌        | 15/100 [00:04<00:14,  5.83it/s]Train Iter: 4416/5000. LR: 0.0023. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9991. T_Loss: 4.7253. Mask: 0.8965. :  15%|█▌        | 15/100 [00:04<00:14,  5.83it/s]Train Iter: 4416/5000. LR: 0.0023. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9991. T_Loss: 4.7253. Mask: 0.8965. :  16%|█▌        | 16/100 [00:04<00:13,  6.27it/s]Train Iter: 4417/5000. LR: 0.0023. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9965. T_Loss: 4.6980. Mask: 0.8989. :  16%|█▌        | 16/100 [00:04<00:13,  6.27it/s]Train Iter: 4417/5000. LR: 0.0023. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9965. T_Loss: 4.6980. Mask: 0.8989. :  17%|█▋        | 17/100 [00:04<00:12,  6.67it/s]Train Iter: 4418/5000. LR: 0.0023. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0008. T_Loss: 4.7274. Mask: 0.9028. :  17%|█▋        | 17/100 [00:04<00:12,  6.67it/s]Train Iter: 4418/5000. LR: 0.0023. Data: 0.11s. Batch: 0.25s. S_Loss: 1.0008. T_Loss: 4.7274. Mask: 0.9028. :  18%|█▊        | 18/100 [00:04<00:12,  6.70it/s]Train Iter: 4419/5000. LR: 0.0023. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9911. T_Loss: 4.7018. Mask: 0.9030. :  18%|█▊        | 18/100 [00:04<00:12,  6.70it/s]Train Iter: 4419/5000. LR: 0.0023. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9911. T_Loss: 4.7018. Mask: 0.9030. :  19%|█▉        | 19/100 [00:04<00:18,  4.45it/s]Train Iter: 4420/5000. LR: 0.0023. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9907. T_Loss: 4.7398. Mask: 0.9062. :  19%|█▉        | 19/100 [00:05<00:18,  4.45it/s]Train Iter: 4420/5000. LR: 0.0023. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9907. T_Loss: 4.7398. Mask: 0.9062. :  20%|██        | 20/100 [00:05<00:15,  5.12it/s]Train Iter: 4421/5000. LR: 0.0023. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9872. T_Loss: 4.7070. Mask: 0.9033. :  20%|██        | 20/100 [00:05<00:15,  5.12it/s]Train Iter: 4421/5000. LR: 0.0023. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9872. T_Loss: 4.7070. Mask: 0.9033. :  21%|██        | 21/100 [00:05<00:13,  5.74it/s]Train Iter: 4422/5000. LR: 0.0023. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9986. T_Loss: 4.7295. Mask: 0.9006. :  21%|██        | 21/100 [00:05<00:13,  5.74it/s]Train Iter: 4422/5000. LR: 0.0023. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9986. T_Loss: 4.7295. Mask: 0.9006. :  22%|██▏       | 22/100 [00:05<00:12,  6.28it/s]Train Iter: 4423/5000. LR: 0.0023. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0004. T_Loss: 4.7175. Mask: 0.8981. :  22%|██▏       | 22/100 [00:05<00:12,  6.28it/s]Train Iter: 4423/5000. LR: 0.0023. Data: 0.09s. Batch: 0.23s. S_Loss: 1.0004. T_Loss: 4.7175. Mask: 0.8981. :  23%|██▎       | 23/100 [00:05<00:11,  6.73it/s]Train Iter: 4424/5000. LR: 0.0023. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0019. T_Loss: 4.7383. Mask: 0.8997. :  23%|██▎       | 23/100 [00:05<00:11,  6.73it/s]Train Iter: 4424/5000. LR: 0.0023. Data: 0.08s. Batch: 0.23s. S_Loss: 1.0019. T_Loss: 4.7383. Mask: 0.8997. :  24%|██▍       | 24/100 [00:05<00:10,  6.93it/s]Train Iter: 4425/5000. LR: 0.0023. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9985. T_Loss: 4.7582. Mask: 0.9025. :  24%|██▍       | 24/100 [00:05<00:10,  6.93it/s]Train Iter: 4425/5000. LR: 0.0023. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9985. T_Loss: 4.7582. Mask: 0.9025. :  25%|██▌       | 25/100 [00:05<00:14,  5.26it/s]total : 5000  current step :  4401
total : 5000  current step :  4402
total : 5000  current step :  4403
total : 5000  current step :  4404
total : 5000  current step :  4405
total : 5000  current step :  4406
total : 5000  current step :  4407
total : 5000  current step :  4408
total : 5000  current step :  4409
total : 5000  current step :  4410
total : 5000  current step :  4411
total : 5000  current step :  4412
total : 5000  current step :  4413
total : 5000  current step :  4414
total : 5000  current step :  4415
total : 5000  current step :  4416
total : 5000  current step :  4417
total : 5000  current step :  4418
total : 5000  current step :  4419
total : 5000  current step :  4420
total : 5000  current step :  4421
total : 5000  current step :  4422
total : 5000  current step :  4423
total : 5000  current step :  4424
total : 5000  current step :  4425
Train Iter: 4426/5000. LR: 0.0023. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9944. T_Loss: 4.7397. Mask: 0.9014. :  25%|██▌       | 25/100 [00:07<00:14,  5.26it/s]Train Iter: 4426/5000. LR: 0.0023. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9944. T_Loss: 4.7397. Mask: 0.9014. :  26%|██▌       | 26/100 [00:07<00:52,  1.40it/s]Train Iter: 4427/5000. LR: 0.0023. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9955. T_Loss: 4.7013. Mask: 0.8958. :  26%|██▌       | 26/100 [00:07<00:52,  1.40it/s]Train Iter: 4427/5000. LR: 0.0023. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9955. T_Loss: 4.7013. Mask: 0.8958. :  27%|██▋       | 27/100 [00:07<00:39,  1.86it/s]Train Iter: 4428/5000. LR: 0.0023. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9932. T_Loss: 4.6981. Mask: 0.8984. :  27%|██▋       | 27/100 [00:08<00:39,  1.86it/s]Train Iter: 4428/5000. LR: 0.0023. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9932. T_Loss: 4.6981. Mask: 0.8984. :  28%|██▊       | 28/100 [00:08<00:29,  2.45it/s]Train Iter: 4429/5000. LR: 0.0022. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9930. T_Loss: 4.6748. Mask: 0.8955. :  28%|██▊       | 28/100 [00:08<00:29,  2.45it/s]Train Iter: 4429/5000. LR: 0.0022. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9930. T_Loss: 4.6748. Mask: 0.8955. :  29%|██▉       | 29/100 [00:08<00:26,  2.73it/s]Train Iter: 4430/5000. LR: 0.0022. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9945. T_Loss: 4.6948. Mask: 0.8969. :  29%|██▉       | 29/100 [00:08<00:26,  2.73it/s]Train Iter: 4430/5000. LR: 0.0022. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9945. T_Loss: 4.6948. Mask: 0.8969. :  30%|███       | 30/100 [00:08<00:20,  3.44it/s]Train Iter: 4431/5000. LR: 0.0022. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9912. T_Loss: 4.6578. Mask: 0.8962. :  30%|███       | 30/100 [00:08<00:20,  3.44it/s]Train Iter: 4431/5000. LR: 0.0022. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9912. T_Loss: 4.6578. Mask: 0.8962. :  31%|███       | 31/100 [00:08<00:16,  4.26it/s]Train Iter: 4432/5000. LR: 0.0022. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9913. T_Loss: 4.6753. Mask: 0.8965. :  31%|███       | 31/100 [00:08<00:16,  4.26it/s]Train Iter: 4432/5000. LR: 0.0022. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9913. T_Loss: 4.6753. Mask: 0.8965. :  32%|███▏      | 32/100 [00:08<00:13,  4.92it/s]Train Iter: 4433/5000. LR: 0.0022. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9926. T_Loss: 4.6803. Mask: 0.8968. :  32%|███▏      | 32/100 [00:08<00:13,  4.92it/s]Train Iter: 4433/5000. LR: 0.0022. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9926. T_Loss: 4.6803. Mask: 0.8968. :  33%|███▎      | 33/100 [00:08<00:11,  5.63it/s]Train Iter: 4434/5000. LR: 0.0022. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9925. T_Loss: 4.6739. Mask: 0.8952. :  33%|███▎      | 33/100 [00:08<00:11,  5.63it/s]Train Iter: 4434/5000. LR: 0.0022. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9925. T_Loss: 4.6739. Mask: 0.8952. :  34%|███▍      | 34/100 [00:08<00:10,  6.23it/s]Train Iter: 4435/5000. LR: 0.0022. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9947. T_Loss: 4.6695. Mask: 0.8929. :  34%|███▍      | 34/100 [00:09<00:10,  6.23it/s]Train Iter: 4435/5000. LR: 0.0022. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9947. T_Loss: 4.6695. Mask: 0.8929. :  35%|███▌      | 35/100 [00:09<00:09,  6.60it/s]Train Iter: 4436/5000. LR: 0.0022. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9930. T_Loss: 4.6561. Mask: 0.8924. :  35%|███▌      | 35/100 [00:09<00:09,  6.60it/s]Train Iter: 4436/5000. LR: 0.0022. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9930. T_Loss: 4.6561. Mask: 0.8924. :  36%|███▌      | 36/100 [00:09<00:09,  6.88it/s]Train Iter: 4437/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9894. T_Loss: 4.6406. Mask: 0.8936. :  36%|███▌      | 36/100 [00:09<00:09,  6.88it/s]Train Iter: 4437/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9894. T_Loss: 4.6406. Mask: 0.8936. :  37%|███▋      | 37/100 [00:09<00:08,  7.01it/s]Train Iter: 4438/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9878. T_Loss: 4.6410. Mask: 0.8947. :  37%|███▋      | 37/100 [00:09<00:08,  7.01it/s]Train Iter: 4438/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9878. T_Loss: 4.6410. Mask: 0.8947. :  38%|███▊      | 38/100 [00:09<00:08,  7.21it/s]Train Iter: 4439/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9874. T_Loss: 4.6557. Mask: 0.8958. :  38%|███▊      | 38/100 [00:09<00:08,  7.21it/s]Train Iter: 4439/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9874. T_Loss: 4.6557. Mask: 0.8958. :  39%|███▉      | 39/100 [00:09<00:11,  5.22it/s]Train Iter: 4440/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9855. T_Loss: 4.6464. Mask: 0.8953. :  39%|███▉      | 39/100 [00:09<00:11,  5.22it/s]Train Iter: 4440/5000. LR: 0.0022. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9855. T_Loss: 4.6464. Mask: 0.8953. :  40%|████      | 40/100 [00:09<00:10,  5.57it/s]Train Iter: 4441/5000. LR: 0.0022. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9874. T_Loss: 4.6579. Mask: 0.8956. :  40%|████      | 40/100 [00:09<00:10,  5.57it/s]Train Iter: 4441/5000. LR: 0.0022. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9874. T_Loss: 4.6579. Mask: 0.8956. :  41%|████      | 41/100 [00:09<00:09,  6.06it/s]Train Iter: 4442/5000. LR: 0.0021. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9873. T_Loss: 4.6428. Mask: 0.8958. :  41%|████      | 41/100 [00:10<00:09,  6.06it/s]Train Iter: 4442/5000. LR: 0.0021. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9873. T_Loss: 4.6428. Mask: 0.8958. :  42%|████▏     | 42/100 [00:10<00:08,  6.56it/s]Train Iter: 4443/5000. LR: 0.0021. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9871. T_Loss: 4.6337. Mask: 0.8946. :  42%|████▏     | 42/100 [00:10<00:08,  6.56it/s]Train Iter: 4443/5000. LR: 0.0021. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9871. T_Loss: 4.6337. Mask: 0.8946. :  43%|████▎     | 43/100 [00:10<00:08,  6.96it/s]Train Iter: 4444/5000. LR: 0.0021. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9878. T_Loss: 4.6426. Mask: 0.8963. :  43%|████▎     | 43/100 [00:10<00:08,  6.96it/s]Train Iter: 4444/5000. LR: 0.0021. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9878. T_Loss: 4.6426. Mask: 0.8963. :  44%|████▍     | 44/100 [00:10<00:07,  7.13it/s]Train Iter: 4445/5000. LR: 0.0021. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9879. T_Loss: 4.6445. Mask: 0.8979. :  44%|████▍     | 44/100 [00:10<00:07,  7.13it/s]Train Iter: 4445/5000. LR: 0.0021. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9879. T_Loss: 4.6445. Mask: 0.8979. :  45%|████▌     | 45/100 [00:10<00:10,  5.22it/s]Train Iter: 4446/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9877. T_Loss: 4.6278. Mask: 0.8961. :  45%|████▌     | 45/100 [00:10<00:10,  5.22it/s]Train Iter: 4446/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9877. T_Loss: 4.6278. Mask: 0.8961. :  46%|████▌     | 46/100 [00:10<00:09,  5.68it/s]Train Iter: 4447/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9867. T_Loss: 4.6216. Mask: 0.8969. :  46%|████▌     | 46/100 [00:10<00:09,  5.68it/s]Train Iter: 4447/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9867. T_Loss: 4.6216. Mask: 0.8969. :  47%|████▋     | 47/100 [00:10<00:08,  6.19it/s]Train Iter: 4448/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9855. T_Loss: 4.6258. Mask: 0.8965. :  47%|████▋     | 47/100 [00:11<00:08,  6.19it/s]Train Iter: 4448/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9855. T_Loss: 4.6258. Mask: 0.8965. :  48%|████▊     | 48/100 [00:11<00:07,  6.75it/s]Train Iter: 4449/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9847. T_Loss: 4.6157. Mask: 0.8954. :  48%|████▊     | 48/100 [00:11<00:07,  6.75it/s]Train Iter: 4449/5000. LR: 0.0021. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9847. T_Loss: 4.6157. Mask: 0.8954. :  49%|████▉     | 49/100 [00:11<00:07,  7.27it/s]Train Iter: 4450/5000. LR: 0.0021. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9845. T_Loss: 4.6168. Mask: 0.8962. :  49%|████▉     | 49/100 [00:11<00:07,  7.27it/s]Train Iter: 4450/5000. LR: 0.0021. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9845. T_Loss: 4.6168. Mask: 0.8962. :  50%|█████     | 50/100 [00:11<00:06,  7.82it/s]total : 5000  current step :  4426
total : 5000  current step :  4427
total : 5000  current step :  4428
total : 5000  current step :  4429
total : 5000  current step :  4430
total : 5000  current step :  4431
total : 5000  current step :  4432
total : 5000  current step :  4433
total : 5000  current step :  4434
total : 5000  current step :  4435
total : 5000  current step :  4436
total : 5000  current step :  4437
total : 5000  current step :  4438
total : 5000  current step :  4439
total : 5000  current step :  4440
total : 5000  current step :  4441
total : 5000  current step :  4442
total : 5000  current step :  4443
total : 5000  current step :  4444
total : 5000  current step :  4445
total : 5000  current step :  4446
total : 5000  current step :  4447
total : 5000  current step :  4448
total : 5000  current step :  4449
total : 5000  current step :  4450
Train Iter: 4451/5000. LR: 0.0021. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9817. T_Loss: 4.6091. Mask: 0.8977. :  50%|█████     | 50/100 [00:13<00:06,  7.82it/s]Train Iter: 4451/5000. LR: 0.0021. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9817. T_Loss: 4.6091. Mask: 0.8977. :  51%|█████     | 51/100 [00:13<00:36,  1.35it/s]Train Iter: 4452/5000. LR: 0.0021. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9817. T_Loss: 4.6162. Mask: 0.8966. :  51%|█████     | 51/100 [00:13<00:36,  1.35it/s]Train Iter: 4452/5000. LR: 0.0021. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9817. T_Loss: 4.6162. Mask: 0.8966. :  52%|█████▏    | 52/100 [00:13<00:26,  1.79it/s]Train Iter: 4453/5000. LR: 0.0021. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9814. T_Loss: 4.6085. Mask: 0.8968. :  52%|█████▏    | 52/100 [00:13<00:26,  1.79it/s]Train Iter: 4453/5000. LR: 0.0021. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9814. T_Loss: 4.6085. Mask: 0.8968. :  53%|█████▎    | 53/100 [00:13<00:20,  2.33it/s]Train Iter: 4454/5000. LR: 0.0021. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9828. T_Loss: 4.6105. Mask: 0.8970. :  53%|█████▎    | 53/100 [00:13<00:20,  2.33it/s]Train Iter: 4454/5000. LR: 0.0021. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9828. T_Loss: 4.6105. Mask: 0.8970. :  54%|█████▍    | 54/100 [00:13<00:15,  2.95it/s]Train Iter: 4455/5000. LR: 0.0020. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9830. T_Loss: 4.6312. Mask: 0.8989. :  54%|█████▍    | 54/100 [00:14<00:15,  2.95it/s]Train Iter: 4455/5000. LR: 0.0020. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9830. T_Loss: 4.6312. Mask: 0.8989. :  55%|█████▌    | 55/100 [00:14<00:15,  2.97it/s]Train Iter: 4456/5000. LR: 0.0020. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9825. T_Loss: 4.6263. Mask: 0.9001. :  55%|█████▌    | 55/100 [00:14<00:15,  2.97it/s]Train Iter: 4456/5000. LR: 0.0020. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9825. T_Loss: 4.6263. Mask: 0.9001. :  56%|█████▌    | 56/100 [00:14<00:11,  3.69it/s]Train Iter: 4457/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.6232. Mask: 0.9002. :  56%|█████▌    | 56/100 [00:14<00:11,  3.69it/s]Train Iter: 4457/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9809. T_Loss: 4.6232. Mask: 0.9002. :  57%|█████▋    | 57/100 [00:14<00:09,  4.45it/s]Train Iter: 4458/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9804. T_Loss: 4.6391. Mask: 0.9019. :  57%|█████▋    | 57/100 [00:14<00:09,  4.45it/s]Train Iter: 4458/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9804. T_Loss: 4.6391. Mask: 0.9019. :  58%|█████▊    | 58/100 [00:14<00:08,  5.22it/s]Train Iter: 4459/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.6502. Mask: 0.9020. :  58%|█████▊    | 58/100 [00:14<00:08,  5.22it/s]Train Iter: 4459/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9811. T_Loss: 4.6502. Mask: 0.9020. :  59%|█████▉    | 59/100 [00:14<00:08,  4.72it/s]Train Iter: 4460/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.6533. Mask: 0.9031. :  59%|█████▉    | 59/100 [00:14<00:08,  4.72it/s]Train Iter: 4460/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9788. T_Loss: 4.6533. Mask: 0.9031. :  60%|██████    | 60/100 [00:14<00:07,  5.37it/s]Train Iter: 4461/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9801. T_Loss: 4.6614. Mask: 0.9022. :  60%|██████    | 60/100 [00:15<00:07,  5.37it/s]Train Iter: 4461/5000. LR: 0.0020. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9801. T_Loss: 4.6614. Mask: 0.9022. :  61%|██████    | 61/100 [00:15<00:06,  5.91it/s]Train Iter: 4462/5000. LR: 0.0020. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9811. T_Loss: 4.6683. Mask: 0.9027. :  61%|██████    | 61/100 [00:15<00:06,  5.91it/s]Train Iter: 4462/5000. LR: 0.0020. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9811. T_Loss: 4.6683. Mask: 0.9027. :  62%|██████▏   | 62/100 [00:15<00:05,  6.40it/s]Train Iter: 4463/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9811. T_Loss: 4.6717. Mask: 0.9033. :  62%|██████▏   | 62/100 [00:15<00:05,  6.40it/s]Train Iter: 4463/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9811. T_Loss: 4.6717. Mask: 0.9033. :  63%|██████▎   | 63/100 [00:15<00:05,  6.86it/s]Train Iter: 4464/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9796. T_Loss: 4.6633. Mask: 0.9043. :  63%|██████▎   | 63/100 [00:15<00:05,  6.86it/s]Train Iter: 4464/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9796. T_Loss: 4.6633. Mask: 0.9043. :  64%|██████▍   | 64/100 [00:15<00:04,  7.22it/s]Train Iter: 4465/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9805. T_Loss: 4.6706. Mask: 0.9048. :  64%|██████▍   | 64/100 [00:15<00:04,  7.22it/s]Train Iter: 4465/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9805. T_Loss: 4.6706. Mask: 0.9048. :  65%|██████▌   | 65/100 [00:15<00:06,  5.24it/s]Train Iter: 4466/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9818. T_Loss: 4.6744. Mask: 0.9048. :  65%|██████▌   | 65/100 [00:15<00:06,  5.24it/s]Train Iter: 4466/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9818. T_Loss: 4.6744. Mask: 0.9048. :  66%|██████▌   | 66/100 [00:15<00:06,  5.46it/s]Train Iter: 4467/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9800. T_Loss: 4.6661. Mask: 0.9058. :  66%|██████▌   | 66/100 [00:16<00:06,  5.46it/s]Train Iter: 4467/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9800. T_Loss: 4.6661. Mask: 0.9058. :  67%|██████▋   | 67/100 [00:16<00:05,  5.78it/s]Train Iter: 4468/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9790. T_Loss: 4.6608. Mask: 0.9058. :  67%|██████▋   | 67/100 [00:16<00:05,  5.78it/s]Train Iter: 4468/5000. LR: 0.0020. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9790. T_Loss: 4.6608. Mask: 0.9058. :  68%|██████▊   | 68/100 [00:16<00:05,  6.31it/s]Train Iter: 4469/5000. LR: 0.0019. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9774. T_Loss: 4.6556. Mask: 0.9053. :  68%|██████▊   | 68/100 [00:16<00:05,  6.31it/s]Train Iter: 4469/5000. LR: 0.0019. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9774. T_Loss: 4.6556. Mask: 0.9053. :  69%|██████▉   | 69/100 [00:16<00:06,  4.59it/s]Train Iter: 4470/5000. LR: 0.0019. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9772. T_Loss: 4.6513. Mask: 0.9054. :  69%|██████▉   | 69/100 [00:16<00:06,  4.59it/s]Train Iter: 4470/5000. LR: 0.0019. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9772. T_Loss: 4.6513. Mask: 0.9054. :  70%|███████   | 70/100 [00:16<00:05,  5.28it/s]Train Iter: 4471/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9763. T_Loss: 4.6362. Mask: 0.9040. :  70%|███████   | 70/100 [00:16<00:05,  5.28it/s]Train Iter: 4471/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9763. T_Loss: 4.6362. Mask: 0.9040. :  71%|███████   | 71/100 [00:16<00:04,  5.88it/s]Train Iter: 4472/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9759. T_Loss: 4.6321. Mask: 0.9036. :  71%|███████   | 71/100 [00:16<00:04,  5.88it/s]Train Iter: 4472/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9759. T_Loss: 4.6321. Mask: 0.9036. :  72%|███████▏  | 72/100 [00:16<00:04,  6.48it/s]Train Iter: 4473/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9770. T_Loss: 4.6368. Mask: 0.9037. :  72%|███████▏  | 72/100 [00:17<00:04,  6.48it/s]Train Iter: 4473/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9770. T_Loss: 4.6368. Mask: 0.9037. :  73%|███████▎  | 73/100 [00:17<00:03,  6.97it/s]Train Iter: 4474/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9760. T_Loss: 4.6376. Mask: 0.9046. :  73%|███████▎  | 73/100 [00:17<00:03,  6.97it/s]Train Iter: 4474/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9760. T_Loss: 4.6376. Mask: 0.9046. :  74%|███████▍  | 74/100 [00:17<00:03,  7.37it/s]Train Iter: 4475/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9750. T_Loss: 4.6379. Mask: 0.9054. :  74%|███████▍  | 74/100 [00:17<00:03,  7.37it/s]Train Iter: 4475/5000. LR: 0.0019. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9750. T_Loss: 4.6379. Mask: 0.9054. :  75%|███████▌  | 75/100 [00:17<00:05,  4.86it/s]total : 5000  current step :  4451
total : 5000  current step :  4452
total : 5000  current step :  4453
total : 5000  current step :  4454
total : 5000  current step :  4455
total : 5000  current step :  4456
total : 5000  current step :  4457
total : 5000  current step :  4458
total : 5000  current step :  4459
total : 5000  current step :  4460
total : 5000  current step :  4461
total : 5000  current step :  4462
total : 5000  current step :  4463
total : 5000  current step :  4464
total : 5000  current step :  4465
total : 5000  current step :  4466
total : 5000  current step :  4467
total : 5000  current step :  4468
total : 5000  current step :  4469
total : 5000  current step :  4470
total : 5000  current step :  4471
total : 5000  current step :  4472
total : 5000  current step :  4473
total : 5000  current step :  4474
total : 5000  current step :  4475
Train Iter: 4476/5000. LR: 0.0019. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9740. T_Loss: 4.6220. Mask: 0.9038. :  75%|███████▌  | 75/100 [00:19<00:05,  4.86it/s]Train Iter: 4476/5000. LR: 0.0019. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9740. T_Loss: 4.6220. Mask: 0.9038. :  76%|███████▌  | 76/100 [00:19<00:18,  1.32it/s]Train Iter: 4477/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9732. T_Loss: 4.6210. Mask: 0.9042. :  76%|███████▌  | 76/100 [00:19<00:18,  1.32it/s]Train Iter: 4477/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9732. T_Loss: 4.6210. Mask: 0.9042. :  77%|███████▋  | 77/100 [00:19<00:13,  1.75it/s]Train Iter: 4478/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9724. T_Loss: 4.6206. Mask: 0.9050. :  77%|███████▋  | 77/100 [00:19<00:13,  1.75it/s]Train Iter: 4478/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9724. T_Loss: 4.6206. Mask: 0.9050. :  78%|███████▊  | 78/100 [00:19<00:09,  2.26it/s]Train Iter: 4479/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9729. T_Loss: 4.6202. Mask: 0.9051. :  78%|███████▊  | 78/100 [00:20<00:09,  2.26it/s]Train Iter: 4479/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9729. T_Loss: 4.6202. Mask: 0.9051. :  79%|███████▉  | 79/100 [00:20<00:08,  2.52it/s]Train Iter: 4480/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9709. T_Loss: 4.6086. Mask: 0.9062. :  79%|███████▉  | 79/100 [00:20<00:08,  2.52it/s]Train Iter: 4480/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9709. T_Loss: 4.6086. Mask: 0.9062. :  80%|████████  | 80/100 [00:20<00:06,  3.15it/s]Train Iter: 4481/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9696. T_Loss: 4.6043. Mask: 0.9070. :  80%|████████  | 80/100 [00:20<00:06,  3.15it/s]Train Iter: 4481/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9696. T_Loss: 4.6043. Mask: 0.9070. :  81%|████████  | 81/100 [00:20<00:04,  3.94it/s]Train Iter: 4482/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9693. T_Loss: 4.6098. Mask: 0.9070. :  81%|████████  | 81/100 [00:20<00:04,  3.94it/s]Train Iter: 4482/5000. LR: 0.0019. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9693. T_Loss: 4.6098. Mask: 0.9070. :  82%|████████▏ | 82/100 [00:20<00:03,  4.68it/s]Train Iter: 4483/5000. LR: 0.0018. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9686. T_Loss: 4.6081. Mask: 0.9066. :  82%|████████▏ | 82/100 [00:20<00:03,  4.68it/s]Train Iter: 4483/5000. LR: 0.0018. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9686. T_Loss: 4.6081. Mask: 0.9066. :  83%|████████▎ | 83/100 [00:20<00:03,  5.31it/s]Train Iter: 4484/5000. LR: 0.0018. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9689. T_Loss: 4.6206. Mask: 0.9074. :  83%|████████▎ | 83/100 [00:20<00:03,  5.31it/s]Train Iter: 4484/5000. LR: 0.0018. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9689. T_Loss: 4.6206. Mask: 0.9074. :  84%|████████▍ | 84/100 [00:20<00:02,  5.90it/s]Train Iter: 4485/5000. LR: 0.0018. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9693. T_Loss: 4.6086. Mask: 0.9062. :  84%|████████▍ | 84/100 [00:21<00:02,  5.90it/s]Train Iter: 4485/5000. LR: 0.0018. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9693. T_Loss: 4.6086. Mask: 0.9062. :  85%|████████▌ | 85/100 [00:21<00:03,  4.23it/s]Train Iter: 4486/5000. LR: 0.0018. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9690. T_Loss: 4.6013. Mask: 0.9044. :  85%|████████▌ | 85/100 [00:21<00:03,  4.23it/s]Train Iter: 4486/5000. LR: 0.0018. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9690. T_Loss: 4.6013. Mask: 0.9044. :  86%|████████▌ | 86/100 [00:21<00:02,  4.84it/s]Train Iter: 4487/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9675. T_Loss: 4.5927. Mask: 0.9041. :  86%|████████▌ | 86/100 [00:21<00:02,  4.84it/s]Train Iter: 4487/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9675. T_Loss: 4.5927. Mask: 0.9041. :  87%|████████▋ | 87/100 [00:21<00:02,  5.35it/s]Train Iter: 4488/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9669. T_Loss: 4.5815. Mask: 0.9038. :  87%|████████▋ | 87/100 [00:21<00:02,  5.35it/s]Train Iter: 4488/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9669. T_Loss: 4.5815. Mask: 0.9038. :  88%|████████▊ | 88/100 [00:21<00:02,  5.90it/s]Train Iter: 4489/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9660. T_Loss: 4.5809. Mask: 0.9041. :  88%|████████▊ | 88/100 [00:21<00:02,  5.90it/s]Train Iter: 4489/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9660. T_Loss: 4.5809. Mask: 0.9041. :  89%|████████▉ | 89/100 [00:21<00:01,  6.31it/s]Train Iter: 4490/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9653. T_Loss: 4.5800. Mask: 0.9045. :  89%|████████▉ | 89/100 [00:21<00:01,  6.31it/s]Train Iter: 4490/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9653. T_Loss: 4.5800. Mask: 0.9045. :  90%|█████████ | 90/100 [00:21<00:01,  6.65it/s]Train Iter: 4491/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9647. T_Loss: 4.5841. Mask: 0.9049. :  90%|█████████ | 90/100 [00:21<00:01,  6.65it/s]Train Iter: 4491/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9647. T_Loss: 4.5841. Mask: 0.9049. :  91%|█████████ | 91/100 [00:21<00:01,  7.08it/s]Train Iter: 4492/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9647. T_Loss: 4.5785. Mask: 0.9052. :  91%|█████████ | 91/100 [00:22<00:01,  7.08it/s]Train Iter: 4493/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9642. T_Loss: 4.5665. Mask: 0.9046. :  92%|█████████▏| 92/100 [00:22<00:01,  7.08it/s]Train Iter: 4493/5000. LR: 0.0018. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9642. T_Loss: 4.5665. Mask: 0.9046. :  93%|█████████▎| 93/100 [00:22<00:00,  8.43it/s]Train Iter: 4494/5000. LR: 0.0018. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9640. T_Loss: 4.5715. Mask: 0.9056. :  93%|█████████▎| 93/100 [00:22<00:00,  8.43it/s]Train Iter: 4494/5000. LR: 0.0018. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9640. T_Loss: 4.5715. Mask: 0.9056. :  94%|█████████▍| 94/100 [00:22<00:00,  8.68it/s]Train Iter: 4495/5000. LR: 0.0018. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9650. T_Loss: 4.5757. Mask: 0.9053. :  94%|█████████▍| 94/100 [00:22<00:00,  8.68it/s]Train Iter: 4495/5000. LR: 0.0018. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9650. T_Loss: 4.5757. Mask: 0.9053. :  95%|█████████▌| 95/100 [00:22<00:00,  6.33it/s]Train Iter: 4496/5000. LR: 0.0018. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9647. T_Loss: 4.5729. Mask: 0.9056. :  95%|█████████▌| 95/100 [00:22<00:00,  6.33it/s]Train Iter: 4497/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9638. T_Loss: 4.5724. Mask: 0.9062. :  96%|█████████▌| 96/100 [00:22<00:00,  6.33it/s]Train Iter: 4497/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9638. T_Loss: 4.5724. Mask: 0.9062. :  97%|█████████▋| 97/100 [00:22<00:00,  7.40it/s]Train Iter: 4498/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9630. T_Loss: 4.5661. Mask: 0.9066. :  97%|█████████▋| 97/100 [00:22<00:00,  7.40it/s]Train Iter: 4498/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9630. T_Loss: 4.5661. Mask: 0.9066. :  98%|█████████▊| 98/100 [00:22<00:00,  7.54it/s]Train Iter: 4499/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9624. T_Loss: 4.5639. Mask: 0.9066. :  98%|█████████▊| 98/100 [00:23<00:00,  7.54it/s]Train Iter: 4499/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9624. T_Loss: 4.5639. Mask: 0.9066. :  99%|█████████▉| 99/100 [00:23<00:00,  5.33it/s]Train Iter: 4500/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9616. T_Loss: 4.5726. Mask: 0.9075. :  99%|█████████▉| 99/100 [00:23<00:00,  5.33it/s]Train Iter: 4500/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9616. T_Loss: 4.5726. Mask: 0.9075. : 100%|██████████| 100/100 [00:23<00:00,  6.03it/s]Train Iter: 4500/5000. LR: 0.0017. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9616. T_Loss: 4.5726. Mask: 0.9075. : 100%|██████████| 100/100 [00:23<00:00,  4.30it/s]
total : 5000  current step :  4476
total : 5000  current step :  4477
total : 5000  current step :  4478
total : 5000  current step :  4479
total : 5000  current step :  4480
total : 5000  current step :  4481
total : 5000  current step :  4482
total : 5000  current step :  4483
total : 5000  current step :  4484
total : 5000  current step :  4485
total : 5000  current step :  4486
total : 5000  current step :  4487
total : 5000  current step :  4488
total : 5000  current step :  4489
total : 5000  current step :  4490
total : 5000  current step :  4491
total : 5000  current step :  4492
total : 5000  current step :  4493
total : 5000  current step :  4494
total : 5000  current step :  4495
total : 5000  current step :  4496
total : 5000  current step :  4497
total : 5000  current step :  4498
total : 5000  current step :  4499
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 0.8553. top1: 90.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 0.8553. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 0.8467. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.8229. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.8221. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 0.8116. top1: 92.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8081. top1: 93.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.8211. top1: 92.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8186. top1: 92.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8203. top1: 92.36. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8241. top1: 92.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8153. top1: 92.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8153. top1: 92.90. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8183. top1: 92.45. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8135. top1: 93.03. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8096. top1: 93.30. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8088. top1: 93.33. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8103. top1: 93.16. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8088. top1: 93.20. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8102. top1: 93.23. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8095. top1: 93.26. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.13it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8095. top1: 93.26. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.08it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8088. top1: 93.28. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.08it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8109. top1: 93.45. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.08it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8090. top1: 93.61. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.08it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8059. top1: 93.89. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.08it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8034. top1: 94.01. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.08it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8010. top1: 94.00. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.08it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8054. top1: 93.63. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.08it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8055. top1: 93.63. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.08it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8086. top1: 93.53. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.08it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8061. top1: 93.64. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.08it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8061. top1: 93.64. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8056. top1: 93.65. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8047. top1: 93.75. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8302. top1: 92.58. top5: 99.90. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8456. top1: 91.67. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8614. top1: 90.81. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8822. top1: 89.64. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9090. top1: 88.54. top5: 99.65. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9197. top1: 87.84. top5: 99.66. :  46%|████▌     | 29/63 [00:02<00:01, 25.31it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9197. top1: 87.84. top5: 99.66. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9339. top1: 87.17. top5: 99.67. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9501. top1: 86.38. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9638. top1: 85.62. top5: 99.61. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9731. top1: 85.14. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9907. top1: 84.45. top5: 99.55. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0036. top1: 83.87. top5: 99.49. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0125. top1: 83.38. top5: 99.50. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0183. top1: 82.99. top5: 99.51. :  59%|█████▊    | 37/63 [00:02<00:00, 33.14it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0183. top1: 82.99. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0289. top1: 82.34. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0365. top1: 81.78. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0440. top1: 81.32. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0522. top1: 80.99. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0593. top1: 80.56. top5: 99.44. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0738. top1: 79.72. top5: 99.45. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0793. top1: 79.39. top5: 99.40. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0884. top1: 78.89. top5: 99.41. :  71%|███████▏  | 45/63 [00:02<00:00, 38.26it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0884. top1: 78.89. top5: 99.41. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0993. top1: 78.36. top5: 99.36. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1035. top1: 77.90. top5: 99.38. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1086. top1: 77.57. top5: 99.39. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1202. top1: 77.08. top5: 99.34. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1308. top1: 76.56. top5: 99.30. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1379. top1: 76.11. top5: 99.21. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1397. top1: 75.99. top5: 99.17. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1482. top1: 75.61. top5: 99.13. :  84%|████████▍ | 53/63 [00:02<00:00, 45.15it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1482. top1: 75.61. top5: 99.13. :  97%|█████████▋| 61/63 [00:02<00:00, 51.91it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1598. top1: 75.00. top5: 99.14. :  97%|█████████▋| 61/63 [00:02<00:00, 51.91it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1619. top1: 74.90. top5: 99.15. :  97%|█████████▋| 61/63 [00:02<00:00, 51.91it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1619. top1: 74.90. top5: 99.15. : 100%|██████████| 63/63 [00:02<00:00, 23.02it/s]
total : 5000  current step :  4500
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4501/5000. LR: 0.0017. Data: 1.85s. Batch: 1.99s. S_Loss: 0.9006. T_Loss: 4.5529. Mask: 0.9375. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 4501/5000. LR: 0.0017. Data: 1.85s. Batch: 1.99s. S_Loss: 0.9006. T_Loss: 4.5529. Mask: 0.9375. :   1%|          | 1/100 [00:01<03:17,  2.00s/it]Train Iter: 4502/5000. LR: 0.0017. Data: 0.93s. Batch: 1.06s. S_Loss: 0.9388. T_Loss: 4.7767. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:17,  2.00s/it]Train Iter: 4502/5000. LR: 0.0017. Data: 0.93s. Batch: 1.06s. S_Loss: 0.9388. T_Loss: 4.7767. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 4503/5000. LR: 0.0017. Data: 0.62s. Batch: 0.75s. S_Loss: 0.9484. T_Loss: 5.0542. Mask: 0.9479. :   2%|▏         | 2/100 [00:02<01:28,  1.11it/s]Train Iter: 4503/5000. LR: 0.0017. Data: 0.62s. Batch: 0.75s. S_Loss: 0.9484. T_Loss: 5.0542. Mask: 0.9479. :   3%|▎         | 3/100 [00:02<00:53,  1.82it/s]Train Iter: 4504/5000. LR: 0.0017. Data: 0.47s. Batch: 0.60s. S_Loss: 0.9227. T_Loss: 4.8680. Mask: 0.9531. :   3%|▎         | 3/100 [00:02<00:53,  1.82it/s]Train Iter: 4504/5000. LR: 0.0017. Data: 0.47s. Batch: 0.60s. S_Loss: 0.9227. T_Loss: 4.8680. Mask: 0.9531. :   4%|▍         | 4/100 [00:02<00:37,  2.55it/s]Train Iter: 4505/5000. LR: 0.0017. Data: 0.38s. Batch: 0.56s. S_Loss: 0.9301. T_Loss: 4.7275. Mask: 0.9313. :   4%|▍         | 4/100 [00:02<00:37,  2.55it/s]Train Iter: 4505/5000. LR: 0.0017. Data: 0.38s. Batch: 0.56s. S_Loss: 0.9301. T_Loss: 4.7275. Mask: 0.9313. :   5%|▌         | 5/100 [00:02<00:37,  2.52it/s]Train Iter: 4506/5000. LR: 0.0017. Data: 0.31s. Batch: 0.49s. S_Loss: 0.9304. T_Loss: 4.6364. Mask: 0.9219. :   5%|▌         | 5/100 [00:02<00:37,  2.52it/s]Train Iter: 4506/5000. LR: 0.0017. Data: 0.31s. Batch: 0.49s. S_Loss: 0.9304. T_Loss: 4.6364. Mask: 0.9219. :   6%|▌         | 6/100 [00:02<00:28,  3.29it/s]Train Iter: 4507/5000. LR: 0.0017. Data: 0.27s. Batch: 0.44s. S_Loss: 0.9376. T_Loss: 4.6319. Mask: 0.9196. :   6%|▌         | 6/100 [00:03<00:28,  3.29it/s]Train Iter: 4507/5000. LR: 0.0017. Data: 0.27s. Batch: 0.44s. S_Loss: 0.9376. T_Loss: 4.6319. Mask: 0.9196. :   7%|▋         | 7/100 [00:03<00:22,  4.09it/s]Train Iter: 4508/5000. LR: 0.0017. Data: 0.24s. Batch: 0.40s. S_Loss: 0.9344. T_Loss: 4.6217. Mask: 0.9180. :   7%|▋         | 7/100 [00:03<00:22,  4.09it/s]Train Iter: 4508/5000. LR: 0.0017. Data: 0.24s. Batch: 0.40s. S_Loss: 0.9344. T_Loss: 4.6217. Mask: 0.9180. :   8%|▊         | 8/100 [00:03<00:19,  4.71it/s]Train Iter: 4509/5000. LR: 0.0017. Data: 0.21s. Batch: 0.39s. S_Loss: 0.9263. T_Loss: 4.5283. Mask: 0.9167. :   8%|▊         | 8/100 [00:03<00:19,  4.71it/s]Train Iter: 4509/5000. LR: 0.0017. Data: 0.21s. Batch: 0.39s. S_Loss: 0.9263. T_Loss: 4.5283. Mask: 0.9167. :   9%|▉         | 9/100 [00:03<00:22,  4.02it/s]Train Iter: 4510/5000. LR: 0.0017. Data: 0.19s. Batch: 0.36s. S_Loss: 0.9385. T_Loss: 4.6088. Mask: 0.9156. :   9%|▉         | 9/100 [00:03<00:22,  4.02it/s]Train Iter: 4510/5000. LR: 0.0017. Data: 0.19s. Batch: 0.36s. S_Loss: 0.9385. T_Loss: 4.6088. Mask: 0.9156. :  10%|█         | 10/100 [00:03<00:18,  4.84it/s]Train Iter: 4511/5000. LR: 0.0017. Data: 0.17s. Batch: 0.34s. S_Loss: 0.9417. T_Loss: 4.5542. Mask: 0.9119. :  10%|█         | 10/100 [00:03<00:18,  4.84it/s]Train Iter: 4511/5000. LR: 0.0017. Data: 0.17s. Batch: 0.34s. S_Loss: 0.9417. T_Loss: 4.5542. Mask: 0.9119. :  11%|█         | 11/100 [00:03<00:16,  5.54it/s]Train Iter: 4512/5000. LR: 0.0016. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9326. T_Loss: 4.5053. Mask: 0.9167. :  11%|█         | 11/100 [00:03<00:16,  5.54it/s]Train Iter: 4512/5000. LR: 0.0016. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9326. T_Loss: 4.5053. Mask: 0.9167. :  12%|█▏        | 12/100 [00:03<00:14,  6.22it/s]Train Iter: 4513/5000. LR: 0.0016. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9240. T_Loss: 4.4652. Mask: 0.9207. :  12%|█▏        | 12/100 [00:04<00:14,  6.22it/s]Train Iter: 4513/5000. LR: 0.0016. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9240. T_Loss: 4.4652. Mask: 0.9207. :  13%|█▎        | 13/100 [00:04<00:13,  6.61it/s]Train Iter: 4514/5000. LR: 0.0016. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9138. T_Loss: 4.4218. Mask: 0.9241. :  13%|█▎        | 13/100 [00:04<00:13,  6.61it/s]Train Iter: 4514/5000. LR: 0.0016. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9138. T_Loss: 4.4218. Mask: 0.9241. :  14%|█▍        | 14/100 [00:04<00:12,  6.87it/s]Train Iter: 4515/5000. LR: 0.0016. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9130. T_Loss: 4.4021. Mask: 0.9208. :  14%|█▍        | 14/100 [00:04<00:12,  6.87it/s]Train Iter: 4515/5000. LR: 0.0016. Data: 0.13s. Batch: 0.30s. S_Loss: 0.9130. T_Loss: 4.4021. Mask: 0.9208. :  15%|█▌        | 15/100 [00:04<00:17,  4.97it/s]Train Iter: 4516/5000. LR: 0.0016. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9158. T_Loss: 4.3729. Mask: 0.9219. :  15%|█▌        | 15/100 [00:04<00:17,  4.97it/s]Train Iter: 4516/5000. LR: 0.0016. Data: 0.12s. Batch: 0.29s. S_Loss: 0.9158. T_Loss: 4.3729. Mask: 0.9219. :  16%|█▌        | 16/100 [00:04<00:15,  5.52it/s]Train Iter: 4517/5000. LR: 0.0016. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9192. T_Loss: 4.4233. Mask: 0.9210. :  16%|█▌        | 16/100 [00:04<00:15,  5.52it/s]Train Iter: 4517/5000. LR: 0.0016. Data: 0.11s. Batch: 0.28s. S_Loss: 0.9192. T_Loss: 4.4233. Mask: 0.9210. :  17%|█▋        | 17/100 [00:04<00:13,  5.98it/s]Train Iter: 4518/5000. LR: 0.0016. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9174. T_Loss: 4.4161. Mask: 0.9236. :  17%|█▋        | 17/100 [00:04<00:13,  5.98it/s]Train Iter: 4518/5000. LR: 0.0016. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9174. T_Loss: 4.4161. Mask: 0.9236. :  18%|█▊        | 18/100 [00:04<00:12,  6.48it/s]Train Iter: 4519/5000. LR: 0.0016. Data: 0.10s. Batch: 0.28s. S_Loss: 0.9221. T_Loss: 4.4036. Mask: 0.9211. :  18%|█▊        | 18/100 [00:05<00:12,  6.48it/s]Train Iter: 4519/5000. LR: 0.0016. Data: 0.10s. Batch: 0.28s. S_Loss: 0.9221. T_Loss: 4.4036. Mask: 0.9211. :  19%|█▉        | 19/100 [00:05<00:18,  4.31it/s]Train Iter: 4520/5000. LR: 0.0016. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9229. T_Loss: 4.4079. Mask: 0.9219. :  19%|█▉        | 19/100 [00:05<00:18,  4.31it/s]Train Iter: 4520/5000. LR: 0.0016. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9229. T_Loss: 4.4079. Mask: 0.9219. :  20%|██        | 20/100 [00:05<00:15,  5.00it/s]Train Iter: 4521/5000. LR: 0.0016. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9228. T_Loss: 4.3988. Mask: 0.9226. :  20%|██        | 20/100 [00:05<00:15,  5.00it/s]Train Iter: 4521/5000. LR: 0.0016. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9228. T_Loss: 4.3988. Mask: 0.9226. :  21%|██        | 21/100 [00:05<00:13,  5.66it/s]Train Iter: 4522/5000. LR: 0.0016. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9261. T_Loss: 4.4198. Mask: 0.9219. :  21%|██        | 21/100 [00:05<00:13,  5.66it/s]Train Iter: 4522/5000. LR: 0.0016. Data: 0.09s. Batch: 0.26s. S_Loss: 0.9261. T_Loss: 4.4198. Mask: 0.9219. :  22%|██▏       | 22/100 [00:05<00:12,  6.23it/s]Train Iter: 4523/5000. LR: 0.0016. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9236. T_Loss: 4.3853. Mask: 0.9212. :  22%|██▏       | 22/100 [00:05<00:12,  6.23it/s]Train Iter: 4523/5000. LR: 0.0016. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9236. T_Loss: 4.3853. Mask: 0.9212. :  23%|██▎       | 23/100 [00:05<00:11,  6.68it/s]Train Iter: 4524/5000. LR: 0.0016. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9250. T_Loss: 4.3874. Mask: 0.9219. :  23%|██▎       | 23/100 [00:05<00:11,  6.68it/s]Train Iter: 4524/5000. LR: 0.0016. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9250. T_Loss: 4.3874. Mask: 0.9219. :  24%|██▍       | 24/100 [00:05<00:10,  7.34it/s]Train Iter: 4525/5000. LR: 0.0016. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9257. T_Loss: 4.3744. Mask: 0.9213. :  24%|██▍       | 24/100 [00:05<00:10,  7.34it/s]Train Iter: 4525/5000. LR: 0.0016. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9257. T_Loss: 4.3744. Mask: 0.9213. :  25%|██▌       | 25/100 [00:05<00:09,  7.78it/s]total : 5000  current step :  4501
total : 5000  current step :  4502
total : 5000  current step :  4503
total : 5000  current step :  4504
total : 5000  current step :  4505
total : 5000  current step :  4506
total : 5000  current step :  4507
total : 5000  current step :  4508
total : 5000  current step :  4509
total : 5000  current step :  4510
total : 5000  current step :  4511
total : 5000  current step :  4512
total : 5000  current step :  4513
total : 5000  current step :  4514
total : 5000  current step :  4515
total : 5000  current step :  4516
total : 5000  current step :  4517
total : 5000  current step :  4518
total : 5000  current step :  4519
total : 5000  current step :  4520
total : 5000  current step :  4521
total : 5000  current step :  4522
total : 5000  current step :  4523
total : 5000  current step :  4524
total : 5000  current step :  4525
Train Iter: 4526/5000. LR: 0.0016. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9273. T_Loss: 4.3742. Mask: 0.9207. :  25%|██▌       | 25/100 [00:08<00:09,  7.78it/s]Train Iter: 4526/5000. LR: 0.0016. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9273. T_Loss: 4.3742. Mask: 0.9207. :  26%|██▌       | 26/100 [00:08<00:53,  1.38it/s]Train Iter: 4527/5000. LR: 0.0015. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9315. T_Loss: 4.3896. Mask: 0.9190. :  26%|██▌       | 26/100 [00:08<00:53,  1.38it/s]Train Iter: 4527/5000. LR: 0.0015. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9315. T_Loss: 4.3896. Mask: 0.9190. :  27%|██▋       | 27/100 [00:08<00:39,  1.84it/s]Train Iter: 4528/5000. LR: 0.0015. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9300. T_Loss: 4.3734. Mask: 0.9185. :  27%|██▋       | 27/100 [00:08<00:39,  1.84it/s]Train Iter: 4528/5000. LR: 0.0015. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9300. T_Loss: 4.3734. Mask: 0.9185. :  28%|██▊       | 28/100 [00:08<00:30,  2.38it/s]Train Iter: 4529/5000. LR: 0.0015. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9308. T_Loss: 4.3672. Mask: 0.9170. :  28%|██▊       | 28/100 [00:08<00:30,  2.38it/s]Train Iter: 4529/5000. LR: 0.0015. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9308. T_Loss: 4.3672. Mask: 0.9170. :  29%|██▉       | 29/100 [00:08<00:28,  2.47it/s]Train Iter: 4530/5000. LR: 0.0015. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9316. T_Loss: 4.3571. Mask: 0.9177. :  29%|██▉       | 29/100 [00:08<00:28,  2.47it/s]Train Iter: 4530/5000. LR: 0.0015. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9316. T_Loss: 4.3571. Mask: 0.9177. :  30%|███       | 30/100 [00:08<00:22,  3.05it/s]Train Iter: 4531/5000. LR: 0.0015. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9361. T_Loss: 4.3966. Mask: 0.9204. :  30%|███       | 30/100 [00:09<00:22,  3.05it/s]Train Iter: 4531/5000. LR: 0.0015. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9361. T_Loss: 4.3966. Mask: 0.9204. :  31%|███       | 31/100 [00:09<00:18,  3.68it/s]Train Iter: 4532/5000. LR: 0.0015. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9355. T_Loss: 4.4164. Mask: 0.9219. :  31%|███       | 31/100 [00:09<00:18,  3.68it/s]Train Iter: 4532/5000. LR: 0.0015. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9355. T_Loss: 4.4164. Mask: 0.9219. :  32%|███▏      | 32/100 [00:09<00:15,  4.41it/s]Train Iter: 4533/5000. LR: 0.0015. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9374. T_Loss: 4.4161. Mask: 0.9205. :  32%|███▏      | 32/100 [00:09<00:15,  4.41it/s]Train Iter: 4533/5000. LR: 0.0015. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9374. T_Loss: 4.4161. Mask: 0.9205. :  33%|███▎      | 33/100 [00:09<00:13,  5.05it/s]Train Iter: 4534/5000. LR: 0.0015. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9365. T_Loss: 4.4337. Mask: 0.9219. :  33%|███▎      | 33/100 [00:09<00:13,  5.05it/s]Train Iter: 4534/5000. LR: 0.0015. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9365. T_Loss: 4.4337. Mask: 0.9219. :  34%|███▍      | 34/100 [00:09<00:11,  5.71it/s]Train Iter: 4535/5000. LR: 0.0015. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9348. T_Loss: 4.4371. Mask: 0.9232. :  34%|███▍      | 34/100 [00:09<00:11,  5.71it/s]Train Iter: 4535/5000. LR: 0.0015. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9348. T_Loss: 4.4371. Mask: 0.9232. :  35%|███▌      | 35/100 [00:09<00:10,  6.17it/s]Train Iter: 4536/5000. LR: 0.0015. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9358. T_Loss: 4.4375. Mask: 0.9219. :  35%|███▌      | 35/100 [00:09<00:10,  6.17it/s]Train Iter: 4536/5000. LR: 0.0015. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9358. T_Loss: 4.4375. Mask: 0.9219. :  36%|███▌      | 36/100 [00:09<00:09,  6.69it/s]Train Iter: 4537/5000. LR: 0.0015. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9361. T_Loss: 4.4561. Mask: 0.9223. :  36%|███▌      | 36/100 [00:09<00:09,  6.69it/s]Train Iter: 4537/5000. LR: 0.0015. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9361. T_Loss: 4.4561. Mask: 0.9223. :  37%|███▋      | 37/100 [00:09<00:08,  7.22it/s]Train Iter: 4538/5000. LR: 0.0015. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9365. T_Loss: 4.4304. Mask: 0.9211. :  37%|███▋      | 37/100 [00:09<00:08,  7.22it/s]Train Iter: 4538/5000. LR: 0.0015. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9365. T_Loss: 4.4304. Mask: 0.9211. :  38%|███▊      | 38/100 [00:09<00:08,  7.49it/s]Train Iter: 4539/5000. LR: 0.0015. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9372. T_Loss: 4.4324. Mask: 0.9231. :  38%|███▊      | 38/100 [00:10<00:08,  7.49it/s]Train Iter: 4539/5000. LR: 0.0015. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9372. T_Loss: 4.4324. Mask: 0.9231. :  39%|███▉      | 39/100 [00:10<00:10,  5.59it/s]Train Iter: 4540/5000. LR: 0.0015. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9348. T_Loss: 4.4192. Mask: 0.9242. :  39%|███▉      | 39/100 [00:10<00:10,  5.59it/s]Train Iter: 4540/5000. LR: 0.0015. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9348. T_Loss: 4.4192. Mask: 0.9242. :  40%|████      | 40/100 [00:10<00:10,  5.95it/s]Train Iter: 4541/5000. LR: 0.0015. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9336. T_Loss: 4.4207. Mask: 0.9238. :  40%|████      | 40/100 [00:10<00:10,  5.95it/s]Train Iter: 4541/5000. LR: 0.0015. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9336. T_Loss: 4.4207. Mask: 0.9238. :  41%|████      | 41/100 [00:10<00:09,  6.17it/s]Train Iter: 4542/5000. LR: 0.0015. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9358. T_Loss: 4.4359. Mask: 0.9241. :  41%|████      | 41/100 [00:10<00:09,  6.17it/s]Train Iter: 4542/5000. LR: 0.0015. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9358. T_Loss: 4.4359. Mask: 0.9241. :  42%|████▏     | 42/100 [00:10<00:08,  6.59it/s]Train Iter: 4543/5000. LR: 0.0014. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9346. T_Loss: 4.4197. Mask: 0.9237. :  42%|████▏     | 42/100 [00:10<00:08,  6.59it/s]Train Iter: 4543/5000. LR: 0.0014. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9346. T_Loss: 4.4197. Mask: 0.9237. :  43%|████▎     | 43/100 [00:10<00:08,  6.97it/s]Train Iter: 4544/5000. LR: 0.0014. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9354. T_Loss: 4.4064. Mask: 0.9233. :  43%|████▎     | 43/100 [00:10<00:08,  6.97it/s]Train Iter: 4544/5000. LR: 0.0014. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9354. T_Loss: 4.4064. Mask: 0.9233. :  44%|████▍     | 44/100 [00:10<00:07,  7.44it/s]Train Iter: 4545/5000. LR: 0.0014. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9352. T_Loss: 4.3939. Mask: 0.9229. :  44%|████▍     | 44/100 [00:11<00:07,  7.44it/s]Train Iter: 4545/5000. LR: 0.0014. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9352. T_Loss: 4.3939. Mask: 0.9229. :  45%|████▌     | 45/100 [00:11<00:11,  4.75it/s]Train Iter: 4546/5000. LR: 0.0014. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9355. T_Loss: 4.3988. Mask: 0.9232. :  45%|████▌     | 45/100 [00:11<00:11,  4.75it/s]Train Iter: 4546/5000. LR: 0.0014. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9355. T_Loss: 4.3988. Mask: 0.9232. :  46%|████▌     | 46/100 [00:11<00:10,  5.37it/s]Train Iter: 4547/5000. LR: 0.0014. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9340. T_Loss: 4.3876. Mask: 0.9235. :  46%|████▌     | 46/100 [00:11<00:10,  5.37it/s]Train Iter: 4547/5000. LR: 0.0014. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9340. T_Loss: 4.3876. Mask: 0.9235. :  47%|████▋     | 47/100 [00:11<00:09,  5.89it/s]Train Iter: 4548/5000. LR: 0.0014. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9371. T_Loss: 4.4027. Mask: 0.9219. :  47%|████▋     | 47/100 [00:11<00:09,  5.89it/s]Train Iter: 4548/5000. LR: 0.0014. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9371. T_Loss: 4.4027. Mask: 0.9219. :  48%|████▊     | 48/100 [00:11<00:08,  6.34it/s]Train Iter: 4549/5000. LR: 0.0014. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9347. T_Loss: 4.3906. Mask: 0.9228. :  48%|████▊     | 48/100 [00:11<00:08,  6.34it/s]Train Iter: 4549/5000. LR: 0.0014. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9347. T_Loss: 4.3906. Mask: 0.9228. :  49%|████▉     | 49/100 [00:11<00:08,  5.67it/s]Train Iter: 4550/5000. LR: 0.0014. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9334. T_Loss: 4.3984. Mask: 0.9244. :  49%|████▉     | 49/100 [00:11<00:08,  5.67it/s]Train Iter: 4550/5000. LR: 0.0014. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9334. T_Loss: 4.3984. Mask: 0.9244. :  50%|█████     | 50/100 [00:11<00:08,  6.15it/s]total : 5000  current step :  4526
total : 5000  current step :  4527
total : 5000  current step :  4528
total : 5000  current step :  4529
total : 5000  current step :  4530
total : 5000  current step :  4531
total : 5000  current step :  4532
total : 5000  current step :  4533
total : 5000  current step :  4534
total : 5000  current step :  4535
total : 5000  current step :  4536
total : 5000  current step :  4537
total : 5000  current step :  4538
total : 5000  current step :  4539
total : 5000  current step :  4540
total : 5000  current step :  4541
total : 5000  current step :  4542
total : 5000  current step :  4543
total : 5000  current step :  4544
total : 5000  current step :  4545
total : 5000  current step :  4546
total : 5000  current step :  4547
total : 5000  current step :  4548
total : 5000  current step :  4549
total : 5000  current step :  4550
Train Iter: 4551/5000. LR: 0.0014. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9351. T_Loss: 4.4038. Mask: 0.9234. :  50%|█████     | 50/100 [00:14<00:08,  6.15it/s]Train Iter: 4551/5000. LR: 0.0014. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9351. T_Loss: 4.4038. Mask: 0.9234. :  51%|█████     | 51/100 [00:14<00:39,  1.23it/s]Train Iter: 4552/5000. LR: 0.0014. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9350. T_Loss: 4.4176. Mask: 0.9249. :  51%|█████     | 51/100 [00:14<00:39,  1.23it/s]Train Iter: 4552/5000. LR: 0.0014. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9350. T_Loss: 4.4176. Mask: 0.9249. :  52%|█████▏    | 52/100 [00:14<00:29,  1.64it/s]Train Iter: 4553/5000. LR: 0.0014. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9365. T_Loss: 4.4277. Mask: 0.9245. :  52%|█████▏    | 52/100 [00:14<00:29,  1.64it/s]Train Iter: 4553/5000. LR: 0.0014. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9365. T_Loss: 4.4277. Mask: 0.9245. :  53%|█████▎    | 53/100 [00:14<00:21,  2.16it/s]Train Iter: 4554/5000. LR: 0.0014. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9386. T_Loss: 4.4558. Mask: 0.9253. :  53%|█████▎    | 53/100 [00:14<00:21,  2.16it/s]Train Iter: 4554/5000. LR: 0.0014. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9386. T_Loss: 4.4558. Mask: 0.9253. :  54%|█████▍    | 54/100 [00:14<00:16,  2.78it/s]Train Iter: 4555/5000. LR: 0.0014. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9381. T_Loss: 4.4482. Mask: 0.9250. :  54%|█████▍    | 54/100 [00:14<00:16,  2.78it/s]Train Iter: 4555/5000. LR: 0.0014. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9381. T_Loss: 4.4482. Mask: 0.9250. :  55%|█████▌    | 55/100 [00:14<00:14,  3.01it/s]Train Iter: 4556/5000. LR: 0.0014. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9374. T_Loss: 4.4503. Mask: 0.9263. :  55%|█████▌    | 55/100 [00:15<00:14,  3.01it/s]Train Iter: 4556/5000. LR: 0.0014. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9374. T_Loss: 4.4503. Mask: 0.9263. :  56%|█████▌    | 56/100 [00:15<00:12,  3.65it/s]Train Iter: 4557/5000. LR: 0.0014. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9365. T_Loss: 4.4458. Mask: 0.9265. :  56%|█████▌    | 56/100 [00:15<00:12,  3.65it/s]Train Iter: 4557/5000. LR: 0.0014. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9365. T_Loss: 4.4458. Mask: 0.9265. :  57%|█████▋    | 57/100 [00:15<00:10,  4.22it/s]Train Iter: 4558/5000. LR: 0.0014. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9392. T_Loss: 4.4459. Mask: 0.9251. :  57%|█████▋    | 57/100 [00:15<00:10,  4.22it/s]Train Iter: 4558/5000. LR: 0.0014. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9392. T_Loss: 4.4459. Mask: 0.9251. :  58%|█████▊    | 58/100 [00:15<00:08,  4.77it/s]Train Iter: 4559/5000. LR: 0.0013. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9395. T_Loss: 4.4447. Mask: 0.9253. :  58%|█████▊    | 58/100 [00:15<00:08,  4.77it/s]Train Iter: 4559/5000. LR: 0.0013. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9395. T_Loss: 4.4447. Mask: 0.9253. :  59%|█████▉    | 59/100 [00:15<00:09,  4.22it/s]Train Iter: 4560/5000. LR: 0.0013. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9393. T_Loss: 4.4459. Mask: 0.9255. :  59%|█████▉    | 59/100 [00:15<00:09,  4.22it/s]Train Iter: 4560/5000. LR: 0.0013. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9393. T_Loss: 4.4459. Mask: 0.9255. :  60%|██████    | 60/100 [00:15<00:08,  4.89it/s]Train Iter: 4561/5000. LR: 0.0013. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9385. T_Loss: 4.4438. Mask: 0.9257. :  60%|██████    | 60/100 [00:15<00:08,  4.89it/s]Train Iter: 4561/5000. LR: 0.0013. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9385. T_Loss: 4.4438. Mask: 0.9257. :  61%|██████    | 61/100 [00:15<00:07,  5.52it/s]Train Iter: 4562/5000. LR: 0.0013. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9381. T_Loss: 4.4382. Mask: 0.9254. :  61%|██████    | 61/100 [00:16<00:07,  5.52it/s]Train Iter: 4562/5000. LR: 0.0013. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9381. T_Loss: 4.4382. Mask: 0.9254. :  62%|██████▏   | 62/100 [00:16<00:06,  6.11it/s]Train Iter: 4563/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9381. T_Loss: 4.4343. Mask: 0.9251. :  62%|██████▏   | 62/100 [00:16<00:06,  6.11it/s]Train Iter: 4563/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9381. T_Loss: 4.4343. Mask: 0.9251. :  63%|██████▎   | 63/100 [00:16<00:05,  6.73it/s]Train Iter: 4564/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9384. T_Loss: 4.4242. Mask: 0.9238. :  63%|██████▎   | 63/100 [00:16<00:05,  6.73it/s]Train Iter: 4564/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9384. T_Loss: 4.4242. Mask: 0.9238. :  64%|██████▍   | 64/100 [00:16<00:04,  7.22it/s]Train Iter: 4565/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9398. T_Loss: 4.4331. Mask: 0.9240. :  64%|██████▍   | 64/100 [00:16<00:04,  7.22it/s]Train Iter: 4565/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9398. T_Loss: 4.4331. Mask: 0.9240. :  65%|██████▌   | 65/100 [00:16<00:04,  7.75it/s]Train Iter: 4566/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9392. T_Loss: 4.4252. Mask: 0.9238. :  65%|██████▌   | 65/100 [00:16<00:04,  7.75it/s]Train Iter: 4566/5000. LR: 0.0013. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9392. T_Loss: 4.4252. Mask: 0.9238. :  66%|██████▌   | 66/100 [00:16<00:04,  7.78it/s]Train Iter: 4567/5000. LR: 0.0013. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9374. T_Loss: 4.4137. Mask: 0.9244. :  66%|██████▌   | 66/100 [00:16<00:04,  7.78it/s]Train Iter: 4567/5000. LR: 0.0013. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9374. T_Loss: 4.4137. Mask: 0.9244. :  67%|██████▋   | 67/100 [00:16<00:04,  7.79it/s]Train Iter: 4568/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9365. T_Loss: 4.4045. Mask: 0.9246. :  67%|██████▋   | 67/100 [00:16<00:04,  7.79it/s]Train Iter: 4568/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9365. T_Loss: 4.4045. Mask: 0.9246. :  68%|██████▊   | 68/100 [00:16<00:04,  7.84it/s]Train Iter: 4569/5000. LR: 0.0013. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9353. T_Loss: 4.3931. Mask: 0.9239. :  68%|██████▊   | 68/100 [00:17<00:04,  7.84it/s]Train Iter: 4569/5000. LR: 0.0013. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9353. T_Loss: 4.3931. Mask: 0.9239. :  69%|██████▉   | 69/100 [00:17<00:05,  5.43it/s]Train Iter: 4570/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9349. T_Loss: 4.3918. Mask: 0.9237. :  69%|██████▉   | 69/100 [00:17<00:05,  5.43it/s]Train Iter: 4570/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9349. T_Loss: 4.3918. Mask: 0.9237. :  70%|███████   | 70/100 [00:17<00:05,  5.91it/s]Train Iter: 4571/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9353. T_Loss: 4.3971. Mask: 0.9247. :  70%|███████   | 70/100 [00:17<00:05,  5.91it/s]Train Iter: 4571/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9353. T_Loss: 4.3971. Mask: 0.9247. :  71%|███████   | 71/100 [00:17<00:04,  6.33it/s]Train Iter: 4572/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9359. T_Loss: 4.4080. Mask: 0.9258. :  71%|███████   | 71/100 [00:17<00:04,  6.33it/s]Train Iter: 4572/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9359. T_Loss: 4.4080. Mask: 0.9258. :  72%|███████▏  | 72/100 [00:17<00:04,  6.82it/s]Train Iter: 4573/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9349. T_Loss: 4.3955. Mask: 0.9255. :  72%|███████▏  | 72/100 [00:17<00:04,  6.82it/s]Train Iter: 4573/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9349. T_Loss: 4.3955. Mask: 0.9255. :  73%|███████▎  | 73/100 [00:17<00:03,  6.94it/s]Train Iter: 4574/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9353. T_Loss: 4.3968. Mask: 0.9253. :  73%|███████▎  | 73/100 [00:17<00:03,  6.94it/s]Train Iter: 4574/5000. LR: 0.0013. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9353. T_Loss: 4.3968. Mask: 0.9253. :  74%|███████▍  | 74/100 [00:17<00:03,  7.20it/s]Train Iter: 4575/5000. LR: 0.0013. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9355. T_Loss: 4.3922. Mask: 0.9246. :  74%|███████▍  | 74/100 [00:18<00:03,  7.20it/s]Train Iter: 4575/5000. LR: 0.0013. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9355. T_Loss: 4.3922. Mask: 0.9246. :  75%|███████▌  | 75/100 [00:18<00:04,  5.20it/s]total : 5000  current step :  4551
total : 5000  current step :  4552
total : 5000  current step :  4553
total : 5000  current step :  4554
total : 5000  current step :  4555
total : 5000  current step :  4556
total : 5000  current step :  4557
total : 5000  current step :  4558
total : 5000  current step :  4559
total : 5000  current step :  4560
total : 5000  current step :  4561
total : 5000  current step :  4562
total : 5000  current step :  4563
total : 5000  current step :  4564
total : 5000  current step :  4565
total : 5000  current step :  4566
total : 5000  current step :  4567
total : 5000  current step :  4568
total : 5000  current step :  4569
total : 5000  current step :  4570
total : 5000  current step :  4571
total : 5000  current step :  4572
total : 5000  current step :  4573
total : 5000  current step :  4574
total : 5000  current step :  4575
Train Iter: 4576/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9356. T_Loss: 4.3940. Mask: 0.9248. :  75%|███████▌  | 75/100 [00:20<00:04,  5.20it/s]Train Iter: 4576/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9356. T_Loss: 4.3940. Mask: 0.9248. :  76%|███████▌  | 76/100 [00:20<00:18,  1.27it/s]Train Iter: 4577/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9351. T_Loss: 4.3810. Mask: 0.9245. :  76%|███████▌  | 76/100 [00:20<00:18,  1.27it/s]Train Iter: 4577/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9351. T_Loss: 4.3810. Mask: 0.9245. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 4578/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9347. T_Loss: 4.3843. Mask: 0.9251. :  77%|███████▋  | 77/100 [00:20<00:13,  1.69it/s]Train Iter: 4578/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9347. T_Loss: 4.3843. Mask: 0.9251. :  78%|███████▊  | 78/100 [00:20<00:10,  2.19it/s]Train Iter: 4579/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9360. T_Loss: 4.3996. Mask: 0.9260. :  78%|███████▊  | 78/100 [00:20<00:10,  2.19it/s]Train Iter: 4579/5000. LR: 0.0012. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9360. T_Loss: 4.3996. Mask: 0.9260. :  79%|███████▉  | 79/100 [00:20<00:07,  2.66it/s]Train Iter: 4580/5000. LR: 0.0012. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9370. T_Loss: 4.4006. Mask: 0.9250. :  79%|███████▉  | 79/100 [00:20<00:07,  2.66it/s]Train Iter: 4580/5000. LR: 0.0012. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9370. T_Loss: 4.4006. Mask: 0.9250. :  80%|████████  | 80/100 [00:20<00:06,  3.33it/s]Train Iter: 4581/5000. LR: 0.0012. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9372. T_Loss: 4.4110. Mask: 0.9252. :  80%|████████  | 80/100 [00:20<00:06,  3.33it/s]Train Iter: 4581/5000. LR: 0.0012. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9372. T_Loss: 4.4110. Mask: 0.9252. :  81%|████████  | 81/100 [00:20<00:04,  4.04it/s]Train Iter: 4582/5000. LR: 0.0012. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9374. T_Loss: 4.4084. Mask: 0.9245. :  81%|████████  | 81/100 [00:21<00:04,  4.04it/s]Train Iter: 4582/5000. LR: 0.0012. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9374. T_Loss: 4.4084. Mask: 0.9245. :  82%|████████▏ | 82/100 [00:21<00:03,  4.67it/s]Train Iter: 4583/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9383. T_Loss: 4.4075. Mask: 0.9247. :  82%|████████▏ | 82/100 [00:21<00:03,  4.67it/s]Train Iter: 4583/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9383. T_Loss: 4.4075. Mask: 0.9247. :  83%|████████▎ | 83/100 [00:21<00:03,  5.19it/s]Train Iter: 4584/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9378. T_Loss: 4.4064. Mask: 0.9249. :  83%|████████▎ | 83/100 [00:21<00:03,  5.19it/s]Train Iter: 4584/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9378. T_Loss: 4.4064. Mask: 0.9249. :  84%|████████▍ | 84/100 [00:21<00:02,  5.73it/s]Train Iter: 4585/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9387. T_Loss: 4.4093. Mask: 0.9250. :  84%|████████▍ | 84/100 [00:21<00:02,  5.73it/s]Train Iter: 4585/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9387. T_Loss: 4.4093. Mask: 0.9250. :  85%|████████▌ | 85/100 [00:21<00:03,  4.97it/s]Train Iter: 4586/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9380. T_Loss: 4.4003. Mask: 0.9248. :  85%|████████▌ | 85/100 [00:21<00:03,  4.97it/s]Train Iter: 4586/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9380. T_Loss: 4.4003. Mask: 0.9248. :  86%|████████▌ | 86/100 [00:21<00:02,  5.72it/s]Train Iter: 4587/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9385. T_Loss: 4.3986. Mask: 0.9246. :  86%|████████▌ | 86/100 [00:21<00:02,  5.72it/s]Train Iter: 4587/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9385. T_Loss: 4.3986. Mask: 0.9246. :  87%|████████▋ | 87/100 [00:21<00:02,  6.10it/s]Train Iter: 4588/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9380. T_Loss: 4.4073. Mask: 0.9247. :  87%|████████▋ | 87/100 [00:21<00:02,  6.10it/s]Train Iter: 4588/5000. LR: 0.0012. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9380. T_Loss: 4.4073. Mask: 0.9247. :  88%|████████▊ | 88/100 [00:21<00:01,  6.29it/s]Train Iter: 4589/5000. LR: 0.0012. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9392. T_Loss: 4.4074. Mask: 0.9242. :  88%|████████▊ | 88/100 [00:22<00:01,  6.29it/s]Train Iter: 4589/5000. LR: 0.0012. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9392. T_Loss: 4.4074. Mask: 0.9242. :  89%|████████▉ | 89/100 [00:22<00:02,  5.13it/s]Train Iter: 4590/5000. LR: 0.0012. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9393. T_Loss: 4.4110. Mask: 0.9243. :  89%|████████▉ | 89/100 [00:22<00:02,  5.13it/s]Train Iter: 4590/5000. LR: 0.0012. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9393. T_Loss: 4.4110. Mask: 0.9243. :  90%|█████████ | 90/100 [00:22<00:01,  5.90it/s]Train Iter: 4591/5000. LR: 0.0012. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9387. T_Loss: 4.4060. Mask: 0.9245. :  90%|█████████ | 90/100 [00:22<00:01,  5.90it/s]Train Iter: 4591/5000. LR: 0.0012. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9387. T_Loss: 4.4060. Mask: 0.9245. :  91%|█████████ | 91/100 [00:22<00:01,  6.26it/s]Train Iter: 4592/5000. LR: 0.0012. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9397. T_Loss: 4.4027. Mask: 0.9243. :  91%|█████████ | 91/100 [00:22<00:01,  6.26it/s]Train Iter: 4592/5000. LR: 0.0012. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9397. T_Loss: 4.4027. Mask: 0.9243. :  92%|█████████▏| 92/100 [00:22<00:01,  6.66it/s]Train Iter: 4593/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4008. Mask: 0.9244. :  92%|█████████▏| 92/100 [00:22<00:01,  6.66it/s]Train Iter: 4593/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4008. Mask: 0.9244. :  93%|█████████▎| 93/100 [00:22<00:01,  6.90it/s]Train Iter: 4594/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4085. Mask: 0.9245. :  93%|█████████▎| 93/100 [00:22<00:01,  6.90it/s]Train Iter: 4594/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4085. Mask: 0.9245. :  94%|█████████▍| 94/100 [00:22<00:00,  7.30it/s]Train Iter: 4595/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9392. T_Loss: 4.4105. Mask: 0.9247. :  94%|█████████▍| 94/100 [00:23<00:00,  7.30it/s]Train Iter: 4595/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9392. T_Loss: 4.4105. Mask: 0.9247. :  95%|█████████▌| 95/100 [00:23<00:01,  4.60it/s]Train Iter: 4596/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9402. T_Loss: 4.4180. Mask: 0.9245. :  95%|█████████▌| 95/100 [00:23<00:01,  4.60it/s]Train Iter: 4596/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9402. T_Loss: 4.4180. Mask: 0.9245. :  96%|█████████▌| 96/100 [00:23<00:00,  5.27it/s]Train Iter: 4597/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9393. T_Loss: 4.4129. Mask: 0.9246. :  96%|█████████▌| 96/100 [00:23<00:00,  5.27it/s]Train Iter: 4597/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9393. T_Loss: 4.4129. Mask: 0.9246. :  97%|█████████▋| 97/100 [00:23<00:00,  5.66it/s]Train Iter: 4598/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9389. T_Loss: 4.4052. Mask: 0.9251. :  97%|█████████▋| 97/100 [00:23<00:00,  5.66it/s]Train Iter: 4598/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9389. T_Loss: 4.4052. Mask: 0.9251. :  98%|█████████▊| 98/100 [00:23<00:00,  6.22it/s]Train Iter: 4599/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9388. T_Loss: 4.4106. Mask: 0.9258. :  98%|█████████▊| 98/100 [00:23<00:00,  6.22it/s]Train Iter: 4599/5000. LR: 0.0011. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9388. T_Loss: 4.4106. Mask: 0.9258. :  99%|█████████▉| 99/100 [00:23<00:00,  5.64it/s]Train Iter: 4600/5000. LR: 0.0011. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9389. T_Loss: 4.4124. Mask: 0.9263. :  99%|█████████▉| 99/100 [00:24<00:00,  5.64it/s]Train Iter: 4600/5000. LR: 0.0011. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9389. T_Loss: 4.4124. Mask: 0.9263. : 100%|██████████| 100/100 [00:24<00:00,  4.17it/s]
total : 5000  current step :  4576
total : 5000  current step :  4577
total : 5000  current step :  4578
total : 5000  current step :  4579
total : 5000  current step :  4580
total : 5000  current step :  4581
total : 5000  current step :  4582
total : 5000  current step :  4583
total : 5000  current step :  4584
total : 5000  current step :  4585
total : 5000  current step :  4586
total : 5000  current step :  4587
total : 5000  current step :  4588
total : 5000  current step :  4589
total : 5000  current step :  4590
total : 5000  current step :  4591
total : 5000  current step :  4592
total : 5000  current step :  4593
total : 5000  current step :  4594
total : 5000  current step :  4595
total : 5000  current step :  4596
total : 5000  current step :  4597
total : 5000  current step :  4598
total : 5000  current step :  4599
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 0.8634. top1: 90.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 0.8634. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.95s. Loss: 0.8554. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.8301. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.8299. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 0.8184. top1: 92.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8147. top1: 93.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8280. top1: 92.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8257. top1: 92.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8271. top1: 92.01. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8271. top1: 92.01. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.16it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8308. top1: 91.88. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.16it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8212. top1: 92.61. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.16it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8242. top1: 92.19. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.16it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8191. top1: 92.79. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.16it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8150. top1: 93.08. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.16it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8142. top1: 93.12. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.16it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8154. top1: 92.97. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.16it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8154. top1: 92.97. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8139. top1: 93.01. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8150. top1: 93.06. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8145. top1: 92.93. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8137. top1: 92.97. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8158. top1: 93.15. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8139. top1: 93.32. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8105. top1: 93.61. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8080. top1: 93.75. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8056. top1: 93.75. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8102. top1: 93.51. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.90it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8102. top1: 93.51. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8102. top1: 93.52. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8134. top1: 93.42. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8109. top1: 93.53. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8104. top1: 93.44. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8094. top1: 93.55. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8348. top1: 92.38. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8494. top1: 91.48. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8648. top1: 90.62. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8846. top1: 89.55. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9116. top1: 88.45. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 21.88it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9116. top1: 88.45. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9217. top1: 87.92. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9356. top1: 87.34. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9515. top1: 86.62. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9646. top1: 85.86. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9736. top1: 85.37. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9909. top1: 84.67. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0036. top1: 84.08. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0121. top1: 83.59. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0175. top1: 83.19. top5: 99.51. :  57%|█████▋    | 36/63 [00:02<00:00, 32.66it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0175. top1: 83.19. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0279. top1: 82.61. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0353. top1: 82.05. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0424. top1: 81.64. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0502. top1: 81.31. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0570. top1: 80.94. top5: 99.44. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0715. top1: 80.21. top5: 99.45. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0770. top1: 79.87. top5: 99.40. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0858. top1: 79.42. top5: 99.41. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0965. top1: 78.94. top5: 99.31. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1004. top1: 78.52. top5: 99.32. :  71%|███████▏  | 45/63 [00:02<00:00, 42.08it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.1004. top1: 78.52. top5: 99.32. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1052. top1: 78.24. top5: 99.33. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1167. top1: 77.80. top5: 99.29. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1271. top1: 77.37. top5: 99.19. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1341. top1: 76.91. top5: 99.10. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1358. top1: 76.82. top5: 99.06. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1438. top1: 76.43. top5: 99.03. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1556. top1: 75.81. top5: 99.04. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1577. top1: 75.70. top5: 99.05. :  87%|████████▋ | 55/63 [00:02<00:00, 52.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1577. top1: 75.70. top5: 99.05. : 100%|██████████| 63/63 [00:02<00:00, 22.54it/s]
total : 5000  current step :  4600
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4601/5000. LR: 0.0011. Data: 1.90s. Batch: 2.04s. S_Loss: 1.0073. T_Loss: 5.5273. Mask: 0.9688. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4601/5000. LR: 0.0011. Data: 1.90s. Batch: 2.04s. S_Loss: 1.0073. T_Loss: 5.5273. Mask: 0.9688. :   1%|          | 1/100 [00:02<03:22,  2.04s/it]Train Iter: 4602/5000. LR: 0.0011. Data: 0.96s. Batch: 1.10s. S_Loss: 0.9852. T_Loss: 4.9155. Mask: 0.8906. :   1%|          | 1/100 [00:02<03:22,  2.04s/it]Train Iter: 4602/5000. LR: 0.0011. Data: 0.96s. Batch: 1.10s. S_Loss: 0.9852. T_Loss: 4.9155. Mask: 0.8906. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 4603/5000. LR: 0.0011. Data: 0.64s. Batch: 0.78s. S_Loss: 0.9342. T_Loss: 4.5831. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:31,  1.07it/s]Train Iter: 4603/5000. LR: 0.0011. Data: 0.64s. Batch: 0.78s. S_Loss: 0.9342. T_Loss: 4.5831. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:55,  1.76it/s]Train Iter: 4604/5000. LR: 0.0011. Data: 0.48s. Batch: 0.62s. S_Loss: 0.9213. T_Loss: 4.5743. Mask: 0.9141. :   3%|▎         | 3/100 [00:02<00:55,  1.76it/s]Train Iter: 4604/5000. LR: 0.0011. Data: 0.48s. Batch: 0.62s. S_Loss: 0.9213. T_Loss: 4.5743. Mask: 0.9141. :   4%|▍         | 4/100 [00:02<00:37,  2.53it/s]Train Iter: 4605/5000. LR: 0.0011. Data: 0.39s. Batch: 0.53s. S_Loss: 0.9403. T_Loss: 4.6677. Mask: 0.9125. :   4%|▍         | 4/100 [00:02<00:37,  2.53it/s]Train Iter: 4605/5000. LR: 0.0011. Data: 0.39s. Batch: 0.53s. S_Loss: 0.9403. T_Loss: 4.6677. Mask: 0.9125. :   5%|▌         | 5/100 [00:02<00:31,  3.05it/s]Train Iter: 4606/5000. LR: 0.0011. Data: 0.32s. Batch: 0.46s. S_Loss: 0.9658. T_Loss: 4.5039. Mask: 0.8958. :   5%|▌         | 5/100 [00:02<00:31,  3.05it/s]Train Iter: 4606/5000. LR: 0.0011. Data: 0.32s. Batch: 0.46s. S_Loss: 0.9658. T_Loss: 4.5039. Mask: 0.8958. :   6%|▌         | 6/100 [00:02<00:23,  3.96it/s]Train Iter: 4607/5000. LR: 0.0011. Data: 0.28s. Batch: 0.41s. S_Loss: 0.9654. T_Loss: 4.5007. Mask: 0.9018. :   6%|▌         | 6/100 [00:02<00:23,  3.96it/s]Train Iter: 4607/5000. LR: 0.0011. Data: 0.28s. Batch: 0.41s. S_Loss: 0.9654. T_Loss: 4.5007. Mask: 0.9018. :   7%|▋         | 7/100 [00:02<00:19,  4.78it/s]Train Iter: 4608/5000. LR: 0.0011. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9744. T_Loss: 4.6151. Mask: 0.9023. :   7%|▋         | 7/100 [00:03<00:19,  4.78it/s]Train Iter: 4608/5000. LR: 0.0011. Data: 0.24s. Batch: 0.38s. S_Loss: 0.9744. T_Loss: 4.6151. Mask: 0.9023. :   8%|▊         | 8/100 [00:03<00:16,  5.49it/s]Train Iter: 4609/5000. LR: 0.0011. Data: 0.22s. Batch: 0.38s. S_Loss: 0.9661. T_Loss: 4.4953. Mask: 0.9028. :   8%|▊         | 8/100 [00:03<00:16,  5.49it/s]Train Iter: 4609/5000. LR: 0.0011. Data: 0.22s. Batch: 0.38s. S_Loss: 0.9661. T_Loss: 4.4953. Mask: 0.9028. :   9%|▉         | 9/100 [00:03<00:22,  4.05it/s]Train Iter: 4610/5000. LR: 0.0011. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9633. T_Loss: 4.4284. Mask: 0.9000. :   9%|▉         | 9/100 [00:03<00:22,  4.05it/s]Train Iter: 4610/5000. LR: 0.0011. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9633. T_Loss: 4.4284. Mask: 0.9000. :  10%|█         | 10/100 [00:03<00:18,  4.88it/s]Train Iter: 4611/5000. LR: 0.0011. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9731. T_Loss: 4.4806. Mask: 0.9062. :  10%|█         | 10/100 [00:03<00:18,  4.88it/s]Train Iter: 4611/5000. LR: 0.0011. Data: 0.18s. Batch: 0.33s. S_Loss: 0.9731. T_Loss: 4.4806. Mask: 0.9062. :  11%|█         | 11/100 [00:03<00:16,  5.47it/s]Train Iter: 4612/5000. LR: 0.0010. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9775. T_Loss: 4.3951. Mask: 0.8958. :  11%|█         | 11/100 [00:03<00:16,  5.47it/s]Train Iter: 4612/5000. LR: 0.0010. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9775. T_Loss: 4.3951. Mask: 0.8958. :  12%|█▏        | 12/100 [00:03<00:14,  5.96it/s]Train Iter: 4613/5000. LR: 0.0010. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9688. T_Loss: 4.3524. Mask: 0.8990. :  12%|█▏        | 12/100 [00:03<00:14,  5.96it/s]Train Iter: 4613/5000. LR: 0.0010. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9688. T_Loss: 4.3524. Mask: 0.8990. :  13%|█▎        | 13/100 [00:03<00:13,  6.44it/s]Train Iter: 4614/5000. LR: 0.0010. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9593. T_Loss: 4.3332. Mask: 0.9040. :  13%|█▎        | 13/100 [00:04<00:13,  6.44it/s]Train Iter: 4614/5000. LR: 0.0010. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9593. T_Loss: 4.3332. Mask: 0.9040. :  14%|█▍        | 14/100 [00:04<00:12,  7.09it/s]Train Iter: 4615/5000. LR: 0.0010. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9653. T_Loss: 4.3786. Mask: 0.9083. :  14%|█▍        | 14/100 [00:04<00:12,  7.09it/s]Train Iter: 4615/5000. LR: 0.0010. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9653. T_Loss: 4.3786. Mask: 0.9083. :  15%|█▌        | 15/100 [00:04<00:17,  4.90it/s]Train Iter: 4616/5000. LR: 0.0010. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9637. T_Loss: 4.4011. Mask: 0.9141. :  15%|█▌        | 15/100 [00:04<00:17,  4.90it/s]Train Iter: 4616/5000. LR: 0.0010. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9637. T_Loss: 4.4011. Mask: 0.9141. :  16%|█▌        | 16/100 [00:04<00:15,  5.36it/s]Train Iter: 4617/5000. LR: 0.0010. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9572. T_Loss: 4.3508. Mask: 0.9099. :  16%|█▌        | 16/100 [00:04<00:15,  5.36it/s]Train Iter: 4617/5000. LR: 0.0010. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9572. T_Loss: 4.3508. Mask: 0.9099. :  17%|█▋        | 17/100 [00:04<00:14,  5.75it/s]Train Iter: 4618/5000. LR: 0.0010. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9566. T_Loss: 4.3879. Mask: 0.9115. :  17%|█▋        | 17/100 [00:04<00:14,  5.75it/s]Train Iter: 4618/5000. LR: 0.0010. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9566. T_Loss: 4.3879. Mask: 0.9115. :  18%|█▊        | 18/100 [00:04<00:13,  6.05it/s]Train Iter: 4619/5000. LR: 0.0010. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9588. T_Loss: 4.4071. Mask: 0.9145. :  18%|█▊        | 18/100 [00:04<00:13,  6.05it/s]Train Iter: 4619/5000. LR: 0.0010. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9588. T_Loss: 4.4071. Mask: 0.9145. :  19%|█▉        | 19/100 [00:04<00:12,  6.43it/s]Train Iter: 4620/5000. LR: 0.0010. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9607. T_Loss: 4.4143. Mask: 0.9141. :  19%|█▉        | 19/100 [00:05<00:12,  6.43it/s]Train Iter: 4620/5000. LR: 0.0010. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9607. T_Loss: 4.4143. Mask: 0.9141. :  20%|██        | 20/100 [00:05<00:11,  6.86it/s]Train Iter: 4621/5000. LR: 0.0010. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9626. T_Loss: 4.4488. Mask: 0.9122. :  20%|██        | 20/100 [00:05<00:11,  6.86it/s]Train Iter: 4621/5000. LR: 0.0010. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9626. T_Loss: 4.4488. Mask: 0.9122. :  21%|██        | 21/100 [00:05<00:11,  6.97it/s]Train Iter: 4622/5000. LR: 0.0010. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.4487. Mask: 0.9148. :  21%|██        | 21/100 [00:05<00:11,  6.97it/s]Train Iter: 4622/5000. LR: 0.0010. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9599. T_Loss: 4.4487. Mask: 0.9148. :  22%|██▏       | 22/100 [00:05<00:11,  6.90it/s]Train Iter: 4623/5000. LR: 0.0010. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9596. T_Loss: 4.4337. Mask: 0.9171. :  22%|██▏       | 22/100 [00:05<00:11,  6.90it/s]Train Iter: 4623/5000. LR: 0.0010. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9596. T_Loss: 4.4337. Mask: 0.9171. :  23%|██▎       | 23/100 [00:05<00:10,  7.05it/s]Train Iter: 4624/5000. LR: 0.0010. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9585. T_Loss: 4.4177. Mask: 0.9180. :  23%|██▎       | 23/100 [00:05<00:10,  7.05it/s]Train Iter: 4624/5000. LR: 0.0010. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9585. T_Loss: 4.4177. Mask: 0.9180. :  24%|██▍       | 24/100 [00:05<00:10,  6.93it/s]Train Iter: 4625/5000. LR: 0.0010. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9556. T_Loss: 4.4081. Mask: 0.9187. :  24%|██▍       | 24/100 [00:05<00:10,  6.93it/s]Train Iter: 4625/5000. LR: 0.0010. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9556. T_Loss: 4.4081. Mask: 0.9187. :  25%|██▌       | 25/100 [00:05<00:12,  5.77it/s]total : 5000  current step :  4601
total : 5000  current step :  4602
total : 5000  current step :  4603
total : 5000  current step :  4604
total : 5000  current step :  4605
total : 5000  current step :  4606
total : 5000  current step :  4607
total : 5000  current step :  4608
total : 5000  current step :  4609
total : 5000  current step :  4610
total : 5000  current step :  4611
total : 5000  current step :  4612
total : 5000  current step :  4613
total : 5000  current step :  4614
total : 5000  current step :  4615
total : 5000  current step :  4616
total : 5000  current step :  4617
total : 5000  current step :  4618
total : 5000  current step :  4619
total : 5000  current step :  4620
total : 5000  current step :  4621
total : 5000  current step :  4622
total : 5000  current step :  4623
total : 5000  current step :  4624
total : 5000  current step :  4625
Train Iter: 4626/5000. LR: 0.0010. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9536. T_Loss: 4.3922. Mask: 0.9183. :  25%|██▌       | 25/100 [00:08<00:12,  5.77it/s]Train Iter: 4626/5000. LR: 0.0010. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9536. T_Loss: 4.3922. Mask: 0.9183. :  26%|██▌       | 26/100 [00:08<00:56,  1.31it/s]Train Iter: 4627/5000. LR: 0.0010. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9594. T_Loss: 4.4327. Mask: 0.9167. :  26%|██▌       | 26/100 [00:08<00:56,  1.31it/s]Train Iter: 4627/5000. LR: 0.0010. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9594. T_Loss: 4.4327. Mask: 0.9167. :  27%|██▋       | 27/100 [00:08<00:42,  1.74it/s]Train Iter: 4628/5000. LR: 0.0010. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9566. T_Loss: 4.4323. Mask: 0.9196. :  27%|██▋       | 27/100 [00:08<00:42,  1.74it/s]Train Iter: 4628/5000. LR: 0.0010. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9566. T_Loss: 4.4323. Mask: 0.9196. :  28%|██▊       | 28/100 [00:08<00:31,  2.26it/s]Train Iter: 4629/5000. LR: 0.0010. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9559. T_Loss: 4.4314. Mask: 0.9170. :  28%|██▊       | 28/100 [00:08<00:31,  2.26it/s]Train Iter: 4629/5000. LR: 0.0010. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9559. T_Loss: 4.4314. Mask: 0.9170. :  29%|██▉       | 29/100 [00:08<00:30,  2.30it/s]Train Iter: 4630/5000. LR: 0.0010. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9595. T_Loss: 4.4318. Mask: 0.9167. :  29%|██▉       | 29/100 [00:08<00:30,  2.30it/s]Train Iter: 4630/5000. LR: 0.0010. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9595. T_Loss: 4.4318. Mask: 0.9167. :  30%|███       | 30/100 [00:08<00:24,  2.90it/s]Train Iter: 4631/5000. LR: 0.0009. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9554. T_Loss: 4.4112. Mask: 0.9183. :  30%|███       | 30/100 [00:08<00:24,  2.90it/s]Train Iter: 4631/5000. LR: 0.0009. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9554. T_Loss: 4.4112. Mask: 0.9183. :  31%|███       | 31/100 [00:08<00:19,  3.46it/s]Train Iter: 4632/5000. LR: 0.0009. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9549. T_Loss: 4.4351. Mask: 0.9199. :  31%|███       | 31/100 [00:09<00:19,  3.46it/s]Train Iter: 4632/5000. LR: 0.0009. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9549. T_Loss: 4.4351. Mask: 0.9199. :  32%|███▏      | 32/100 [00:09<00:16,  4.13it/s]Train Iter: 4633/5000. LR: 0.0009. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9574. T_Loss: 4.4300. Mask: 0.9176. :  32%|███▏      | 32/100 [00:09<00:16,  4.13it/s]Train Iter: 4633/5000. LR: 0.0009. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9574. T_Loss: 4.4300. Mask: 0.9176. :  33%|███▎      | 33/100 [00:09<00:13,  4.82it/s]Train Iter: 4634/5000. LR: 0.0009. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9615. T_Loss: 4.4535. Mask: 0.9182. :  33%|███▎      | 33/100 [00:09<00:13,  4.82it/s]Train Iter: 4634/5000. LR: 0.0009. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9615. T_Loss: 4.4535. Mask: 0.9182. :  34%|███▍      | 34/100 [00:09<00:12,  5.36it/s]Train Iter: 4635/5000. LR: 0.0009. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9591. T_Loss: 4.4329. Mask: 0.9187. :  34%|███▍      | 34/100 [00:09<00:12,  5.36it/s]Train Iter: 4635/5000. LR: 0.0009. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9591. T_Loss: 4.4329. Mask: 0.9187. :  35%|███▌      | 35/100 [00:09<00:16,  4.03it/s]Train Iter: 4636/5000. LR: 0.0009. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9596. T_Loss: 4.4336. Mask: 0.9193. :  35%|███▌      | 35/100 [00:09<00:16,  4.03it/s]Train Iter: 4636/5000. LR: 0.0009. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9596. T_Loss: 4.4336. Mask: 0.9193. :  36%|███▌      | 36/100 [00:09<00:13,  4.66it/s]Train Iter: 4637/5000. LR: 0.0009. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9611. T_Loss: 4.4510. Mask: 0.9215. :  36%|███▌      | 36/100 [00:10<00:13,  4.66it/s]Train Iter: 4637/5000. LR: 0.0009. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9611. T_Loss: 4.4510. Mask: 0.9215. :  37%|███▋      | 37/100 [00:10<00:12,  5.16it/s]Train Iter: 4638/5000. LR: 0.0009. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9587. T_Loss: 4.4491. Mask: 0.9235. :  37%|███▋      | 37/100 [00:10<00:12,  5.16it/s]Train Iter: 4639/5000. LR: 0.0009. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9607. T_Loss: 4.4617. Mask: 0.9239. :  38%|███▊      | 38/100 [00:10<00:12,  5.16it/s]Train Iter: 4639/5000. LR: 0.0009. Data: 0.10s. Batch: 0.27s. S_Loss: 0.9607. T_Loss: 4.4617. Mask: 0.9239. :  39%|███▉      | 39/100 [00:10<00:11,  5.35it/s]Train Iter: 4640/5000. LR: 0.0009. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9646. T_Loss: 4.4991. Mask: 0.9258. :  39%|███▉      | 39/100 [00:10<00:11,  5.35it/s]Train Iter: 4640/5000. LR: 0.0009. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9646. T_Loss: 4.4991. Mask: 0.9258. :  40%|████      | 40/100 [00:10<00:10,  5.83it/s]Train Iter: 4641/5000. LR: 0.0009. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9625. T_Loss: 4.4783. Mask: 0.9253. :  40%|████      | 40/100 [00:10<00:10,  5.83it/s]Train Iter: 4641/5000. LR: 0.0009. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9625. T_Loss: 4.4783. Mask: 0.9253. :  41%|████      | 41/100 [00:10<00:09,  6.01it/s]Train Iter: 4642/5000. LR: 0.0009. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9606. T_Loss: 4.4584. Mask: 0.9249. :  41%|████      | 41/100 [00:10<00:09,  6.01it/s]Train Iter: 4642/5000. LR: 0.0009. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9606. T_Loss: 4.4584. Mask: 0.9249. :  42%|████▏     | 42/100 [00:10<00:09,  6.38it/s]Train Iter: 4643/5000. LR: 0.0009. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9600. T_Loss: 4.4469. Mask: 0.9244. :  42%|████▏     | 42/100 [00:10<00:09,  6.38it/s]Train Iter: 4643/5000. LR: 0.0009. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9600. T_Loss: 4.4469. Mask: 0.9244. :  43%|████▎     | 43/100 [00:10<00:08,  6.74it/s]Train Iter: 4644/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9590. T_Loss: 4.4330. Mask: 0.9226. :  43%|████▎     | 43/100 [00:11<00:08,  6.74it/s]Train Iter: 4644/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9590. T_Loss: 4.4330. Mask: 0.9226. :  44%|████▍     | 44/100 [00:11<00:08,  6.89it/s]Train Iter: 4645/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9592. T_Loss: 4.4260. Mask: 0.9222. :  44%|████▍     | 44/100 [00:11<00:08,  6.89it/s]Train Iter: 4645/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9592. T_Loss: 4.4260. Mask: 0.9222. :  45%|████▌     | 45/100 [00:11<00:10,  5.04it/s]Train Iter: 4646/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9559. T_Loss: 4.4129. Mask: 0.9239. :  45%|████▌     | 45/100 [00:11<00:10,  5.04it/s]Train Iter: 4646/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9559. T_Loss: 4.4129. Mask: 0.9239. :  46%|████▌     | 46/100 [00:11<00:09,  5.88it/s]Train Iter: 4647/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9554. T_Loss: 4.4295. Mask: 0.9249. :  46%|████▌     | 46/100 [00:11<00:09,  5.88it/s]Train Iter: 4647/5000. LR: 0.0009. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9554. T_Loss: 4.4295. Mask: 0.9249. :  47%|████▋     | 47/100 [00:11<00:08,  6.36it/s]Train Iter: 4648/5000. LR: 0.0009. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9533. T_Loss: 4.4206. Mask: 0.9251. :  47%|████▋     | 47/100 [00:11<00:08,  6.36it/s]Train Iter: 4648/5000. LR: 0.0009. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9533. T_Loss: 4.4206. Mask: 0.9251. :  48%|████▊     | 48/100 [00:11<00:07,  6.95it/s]Train Iter: 4649/5000. LR: 0.0009. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9526. T_Loss: 4.4341. Mask: 0.9260. :  48%|████▊     | 48/100 [00:12<00:07,  6.95it/s]Train Iter: 4649/5000. LR: 0.0009. Data: 0.08s. Batch: 0.25s. S_Loss: 0.9526. T_Loss: 4.4341. Mask: 0.9260. :  49%|████▉     | 49/100 [00:12<00:09,  5.14it/s]Train Iter: 4650/5000. LR: 0.0009. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9526. T_Loss: 4.4306. Mask: 0.9256. :  49%|████▉     | 49/100 [00:12<00:09,  5.14it/s]Train Iter: 4650/5000. LR: 0.0009. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9526. T_Loss: 4.4306. Mask: 0.9256. :  50%|█████     | 50/100 [00:12<00:08,  5.74it/s]total : 5000  current step :  4626
total : 5000  current step :  4627
total : 5000  current step :  4628
total : 5000  current step :  4629
total : 5000  current step :  4630
total : 5000  current step :  4631
total : 5000  current step :  4632
total : 5000  current step :  4633
total : 5000  current step :  4634
total : 5000  current step :  4635
total : 5000  current step :  4636
total : 5000  current step :  4637
total : 5000  current step :  4638
total : 5000  current step :  4639
total : 5000  current step :  4640
total : 5000  current step :  4641
total : 5000  current step :  4642
total : 5000  current step :  4643
total : 5000  current step :  4644
total : 5000  current step :  4645
total : 5000  current step :  4646
total : 5000  current step :  4647
total : 5000  current step :  4648
total : 5000  current step :  4649
total : 5000  current step :  4650
Train Iter: 4651/5000. LR: 0.0008. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9529. T_Loss: 4.4280. Mask: 0.9252. :  50%|█████     | 50/100 [00:14<00:08,  5.74it/s]Train Iter: 4651/5000. LR: 0.0008. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9529. T_Loss: 4.4280. Mask: 0.9252. :  51%|█████     | 51/100 [00:14<00:38,  1.26it/s]Train Iter: 4652/5000. LR: 0.0008. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9525. T_Loss: 4.4198. Mask: 0.9237. :  51%|█████     | 51/100 [00:14<00:38,  1.26it/s]Train Iter: 4652/5000. LR: 0.0008. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9525. T_Loss: 4.4198. Mask: 0.9237. :  52%|█████▏    | 52/100 [00:14<00:28,  1.66it/s]Train Iter: 4653/5000. LR: 0.0008. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9515. T_Loss: 4.4194. Mask: 0.9245. :  52%|█████▏    | 52/100 [00:14<00:28,  1.66it/s]Train Iter: 4653/5000. LR: 0.0008. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9515. T_Loss: 4.4194. Mask: 0.9245. :  53%|█████▎    | 53/100 [00:14<00:22,  2.12it/s]Train Iter: 4654/5000. LR: 0.0008. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9520. T_Loss: 4.4184. Mask: 0.9236. :  53%|█████▎    | 53/100 [00:14<00:22,  2.12it/s]Train Iter: 4654/5000. LR: 0.0008. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9520. T_Loss: 4.4184. Mask: 0.9236. :  54%|█████▍    | 54/100 [00:14<00:16,  2.74it/s]Train Iter: 4655/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9548. T_Loss: 4.4231. Mask: 0.9227. :  54%|█████▍    | 54/100 [00:15<00:16,  2.74it/s]Train Iter: 4655/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9548. T_Loss: 4.4231. Mask: 0.9227. :  55%|█████▌    | 55/100 [00:15<00:13,  3.38it/s]Train Iter: 4656/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9530. T_Loss: 4.4127. Mask: 0.9219. :  55%|█████▌    | 55/100 [00:15<00:13,  3.38it/s]Train Iter: 4656/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9530. T_Loss: 4.4127. Mask: 0.9219. :  56%|█████▌    | 56/100 [00:15<00:10,  4.08it/s]Train Iter: 4657/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9531. T_Loss: 4.4260. Mask: 0.9221. :  56%|█████▌    | 56/100 [00:15<00:10,  4.08it/s]Train Iter: 4657/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9531. T_Loss: 4.4260. Mask: 0.9221. :  57%|█████▋    | 57/100 [00:15<00:09,  4.57it/s]Train Iter: 4658/5000. LR: 0.0008. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9513. T_Loss: 4.4162. Mask: 0.9219. :  57%|█████▋    | 57/100 [00:15<00:09,  4.57it/s]Train Iter: 4658/5000. LR: 0.0008. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9513. T_Loss: 4.4162. Mask: 0.9219. :  58%|█████▊    | 58/100 [00:15<00:08,  5.25it/s]Train Iter: 4659/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9520. T_Loss: 4.4196. Mask: 0.9221. :  58%|█████▊    | 58/100 [00:15<00:08,  5.25it/s]Train Iter: 4659/5000. LR: 0.0008. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9520. T_Loss: 4.4196. Mask: 0.9221. :  59%|█████▉    | 59/100 [00:15<00:09,  4.25it/s]Train Iter: 4660/5000. LR: 0.0008. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9511. T_Loss: 4.4257. Mask: 0.9234. :  59%|█████▉    | 59/100 [00:15<00:09,  4.25it/s]Train Iter: 4660/5000. LR: 0.0008. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9511. T_Loss: 4.4257. Mask: 0.9234. :  60%|██████    | 60/100 [00:15<00:07,  5.07it/s]Train Iter: 4661/5000. LR: 0.0008. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9499. T_Loss: 4.4255. Mask: 0.9237. :  60%|██████    | 60/100 [00:15<00:07,  5.07it/s]Train Iter: 4661/5000. LR: 0.0008. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9499. T_Loss: 4.4255. Mask: 0.9237. :  61%|██████    | 61/100 [00:15<00:06,  5.80it/s]Train Iter: 4662/5000. LR: 0.0008. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9489. T_Loss: 4.4143. Mask: 0.9239. :  61%|██████    | 61/100 [00:16<00:06,  5.80it/s]Train Iter: 4662/5000. LR: 0.0008. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9489. T_Loss: 4.4143. Mask: 0.9239. :  62%|██████▏   | 62/100 [00:16<00:05,  6.39it/s]Train Iter: 4663/5000. LR: 0.0008. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9478. T_Loss: 4.4080. Mask: 0.9241. :  62%|██████▏   | 62/100 [00:16<00:05,  6.39it/s]Train Iter: 4663/5000. LR: 0.0008. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9478. T_Loss: 4.4080. Mask: 0.9241. :  63%|██████▎   | 63/100 [00:16<00:05,  6.96it/s]Train Iter: 4664/5000. LR: 0.0008. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9465. T_Loss: 4.4104. Mask: 0.9248. :  63%|██████▎   | 63/100 [00:16<00:05,  6.96it/s]Train Iter: 4664/5000. LR: 0.0008. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9465. T_Loss: 4.4104. Mask: 0.9248. :  64%|██████▍   | 64/100 [00:16<00:04,  7.26it/s]Train Iter: 4665/5000. LR: 0.0008. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9469. T_Loss: 4.4140. Mask: 0.9250. :  64%|██████▍   | 64/100 [00:16<00:04,  7.26it/s]Train Iter: 4665/5000. LR: 0.0008. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9469. T_Loss: 4.4140. Mask: 0.9250. :  65%|██████▌   | 65/100 [00:16<00:06,  5.32it/s]Train Iter: 4666/5000. LR: 0.0008. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9487. T_Loss: 4.4157. Mask: 0.9238. :  65%|██████▌   | 65/100 [00:16<00:06,  5.32it/s]Train Iter: 4666/5000. LR: 0.0008. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9487. T_Loss: 4.4157. Mask: 0.9238. :  66%|██████▌   | 66/100 [00:16<00:05,  5.86it/s]Train Iter: 4667/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.4179. Mask: 0.9230. :  66%|██████▌   | 66/100 [00:16<00:05,  5.86it/s]Train Iter: 4667/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9492. T_Loss: 4.4179. Mask: 0.9230. :  67%|██████▋   | 67/100 [00:16<00:05,  6.41it/s]Train Iter: 4668/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9496. T_Loss: 4.4232. Mask: 0.9237. :  67%|██████▋   | 67/100 [00:17<00:05,  6.41it/s]Train Iter: 4668/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9496. T_Loss: 4.4232. Mask: 0.9237. :  68%|██████▊   | 68/100 [00:17<00:04,  6.82it/s]Train Iter: 4669/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9480. T_Loss: 4.4173. Mask: 0.9244. :  68%|██████▊   | 68/100 [00:17<00:04,  6.82it/s]Train Iter: 4669/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9480. T_Loss: 4.4173. Mask: 0.9244. :  69%|██████▉   | 69/100 [00:17<00:06,  4.86it/s]Train Iter: 4670/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.4074. Mask: 0.9237. :  69%|██████▉   | 69/100 [00:17<00:06,  4.86it/s]Train Iter: 4670/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.4074. Mask: 0.9237. :  70%|███████   | 70/100 [00:17<00:05,  5.70it/s]Train Iter: 4671/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9465. T_Loss: 4.3983. Mask: 0.9247. :  70%|███████   | 70/100 [00:17<00:05,  5.70it/s]Train Iter: 4671/5000. LR: 0.0008. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9465. T_Loss: 4.3983. Mask: 0.9247. :  71%|███████   | 71/100 [00:17<00:04,  6.37it/s]Train Iter: 4672/5000. LR: 0.0007. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9459. T_Loss: 4.4040. Mask: 0.9249. :  71%|███████   | 71/100 [00:17<00:04,  6.37it/s]Train Iter: 4672/5000. LR: 0.0007. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9459. T_Loss: 4.4040. Mask: 0.9249. :  72%|███████▏  | 72/100 [00:17<00:04,  6.82it/s]Train Iter: 4673/5000. LR: 0.0007. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9456. T_Loss: 4.3938. Mask: 0.9242. :  72%|███████▏  | 72/100 [00:17<00:04,  6.82it/s]Train Iter: 4673/5000. LR: 0.0007. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9456. T_Loss: 4.3938. Mask: 0.9242. :  73%|███████▎  | 73/100 [00:17<00:03,  7.20it/s]Train Iter: 4674/5000. LR: 0.0007. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9453. T_Loss: 4.3985. Mask: 0.9244. :  73%|███████▎  | 73/100 [00:17<00:03,  7.20it/s]Train Iter: 4674/5000. LR: 0.0007. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9453. T_Loss: 4.3985. Mask: 0.9244. :  74%|███████▍  | 74/100 [00:17<00:03,  7.20it/s]Train Iter: 4675/5000. LR: 0.0007. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9445. T_Loss: 4.3950. Mask: 0.9250. :  74%|███████▍  | 74/100 [00:18<00:03,  7.20it/s]Train Iter: 4675/5000. LR: 0.0007. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9445. T_Loss: 4.3950. Mask: 0.9250. :  75%|███████▌  | 75/100 [00:18<00:04,  5.26it/s]total : 5000  current step :  4651
total : 5000  current step :  4652
total : 5000  current step :  4653
total : 5000  current step :  4654
total : 5000  current step :  4655
total : 5000  current step :  4656
total : 5000  current step :  4657
total : 5000  current step :  4658
total : 5000  current step :  4659
total : 5000  current step :  4660
total : 5000  current step :  4661
total : 5000  current step :  4662
total : 5000  current step :  4663
total : 5000  current step :  4664
total : 5000  current step :  4665
total : 5000  current step :  4666
total : 5000  current step :  4667
total : 5000  current step :  4668
total : 5000  current step :  4669
total : 5000  current step :  4670
total : 5000  current step :  4671
total : 5000  current step :  4672
total : 5000  current step :  4673
total : 5000  current step :  4674
total : 5000  current step :  4675
Train Iter: 4676/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9438. T_Loss: 4.3888. Mask: 0.9252. :  75%|███████▌  | 75/100 [00:20<00:04,  5.26it/s]Train Iter: 4676/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9438. T_Loss: 4.3888. Mask: 0.9252. :  76%|███████▌  | 76/100 [00:20<00:19,  1.23it/s]Train Iter: 4677/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9425. T_Loss: 4.3836. Mask: 0.9249. :  76%|███████▌  | 76/100 [00:20<00:19,  1.23it/s]Train Iter: 4677/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9425. T_Loss: 4.3836. Mask: 0.9249. :  77%|███████▋  | 77/100 [00:20<00:14,  1.55it/s]Train Iter: 4678/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9438. T_Loss: 4.3887. Mask: 0.9239. :  77%|███████▋  | 77/100 [00:20<00:14,  1.55it/s]Train Iter: 4678/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9438. T_Loss: 4.3887. Mask: 0.9239. :  78%|███████▊  | 78/100 [00:20<00:10,  2.03it/s]Train Iter: 4679/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9442. T_Loss: 4.4028. Mask: 0.9241. :  78%|███████▊  | 78/100 [00:21<00:10,  2.03it/s]Train Iter: 4679/5000. LR: 0.0007. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9442. T_Loss: 4.4028. Mask: 0.9241. :  79%|███████▉  | 79/100 [00:21<00:08,  2.60it/s]Train Iter: 4680/5000. LR: 0.0007. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9454. T_Loss: 4.4060. Mask: 0.9227. :  79%|███████▉  | 79/100 [00:21<00:08,  2.60it/s]Train Iter: 4680/5000. LR: 0.0007. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9454. T_Loss: 4.4060. Mask: 0.9227. :  80%|████████  | 80/100 [00:21<00:06,  3.24it/s]Train Iter: 4681/5000. LR: 0.0007. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9450. T_Loss: 4.4008. Mask: 0.9221. :  80%|████████  | 80/100 [00:21<00:06,  3.24it/s]Train Iter: 4681/5000. LR: 0.0007. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9450. T_Loss: 4.4008. Mask: 0.9221. :  81%|████████  | 81/100 [00:21<00:04,  3.93it/s]Train Iter: 4682/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9446. T_Loss: 4.4033. Mask: 0.9211. :  81%|████████  | 81/100 [00:21<00:04,  3.93it/s]Train Iter: 4682/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9446. T_Loss: 4.4033. Mask: 0.9211. :  82%|████████▏ | 82/100 [00:21<00:03,  4.60it/s]Train Iter: 4683/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9450. T_Loss: 4.4028. Mask: 0.9213. :  82%|████████▏ | 82/100 [00:21<00:03,  4.60it/s]Train Iter: 4683/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9450. T_Loss: 4.4028. Mask: 0.9213. :  83%|████████▎ | 83/100 [00:21<00:03,  5.19it/s]Train Iter: 4684/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9448. T_Loss: 4.4020. Mask: 0.9211. :  83%|████████▎ | 83/100 [00:21<00:03,  5.19it/s]Train Iter: 4684/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9448. T_Loss: 4.4020. Mask: 0.9211. :  84%|████████▍ | 84/100 [00:21<00:02,  5.71it/s]Train Iter: 4685/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9438. T_Loss: 4.4000. Mask: 0.9210. :  84%|████████▍ | 84/100 [00:22<00:02,  5.71it/s]Train Iter: 4685/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9438. T_Loss: 4.4000. Mask: 0.9210. :  85%|████████▌ | 85/100 [00:22<00:03,  4.73it/s]Train Iter: 4686/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9432. T_Loss: 4.3962. Mask: 0.9215. :  85%|████████▌ | 85/100 [00:22<00:03,  4.73it/s]Train Iter: 4686/5000. LR: 0.0007. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9432. T_Loss: 4.3962. Mask: 0.9215. :  86%|████████▌ | 86/100 [00:22<00:02,  5.53it/s]Train Iter: 4687/5000. LR: 0.0007. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9430. T_Loss: 4.3913. Mask: 0.9213. :  86%|████████▌ | 86/100 [00:22<00:02,  5.53it/s]Train Iter: 4688/5000. LR: 0.0007. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9425. T_Loss: 4.4007. Mask: 0.9222. :  87%|████████▋ | 87/100 [00:22<00:02,  5.53it/s]Train Iter: 4688/5000. LR: 0.0007. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9425. T_Loss: 4.4007. Mask: 0.9222. :  88%|████████▊ | 88/100 [00:22<00:01,  6.79it/s]Train Iter: 4689/5000. LR: 0.0007. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9428. T_Loss: 4.4039. Mask: 0.9224. :  88%|████████▊ | 88/100 [00:22<00:01,  6.79it/s]Train Iter: 4689/5000. LR: 0.0007. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9428. T_Loss: 4.4039. Mask: 0.9224. :  89%|████████▉ | 89/100 [00:22<00:02,  4.93it/s]Train Iter: 4690/5000. LR: 0.0007. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9416. T_Loss: 4.3930. Mask: 0.9229. :  89%|████████▉ | 89/100 [00:22<00:02,  4.93it/s]Train Iter: 4690/5000. LR: 0.0007. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9416. T_Loss: 4.3930. Mask: 0.9229. :  90%|█████████ | 90/100 [00:22<00:01,  5.49it/s]Train Iter: 4691/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9422. T_Loss: 4.3937. Mask: 0.9220. :  90%|█████████ | 90/100 [00:22<00:01,  5.49it/s]Train Iter: 4691/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9422. T_Loss: 4.3937. Mask: 0.9220. :  91%|█████████ | 91/100 [00:22<00:01,  5.96it/s]Train Iter: 4692/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9419. T_Loss: 4.3926. Mask: 0.9222. :  91%|█████████ | 91/100 [00:23<00:01,  5.96it/s]Train Iter: 4692/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9419. T_Loss: 4.3926. Mask: 0.9222. :  92%|█████████▏| 92/100 [00:23<00:01,  6.23it/s]Train Iter: 4693/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9446. T_Loss: 4.4031. Mask: 0.9224. :  92%|█████████▏| 92/100 [00:23<00:01,  6.23it/s]Train Iter: 4693/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9446. T_Loss: 4.4031. Mask: 0.9224. :  93%|█████████▎| 93/100 [00:23<00:01,  6.62it/s]Train Iter: 4694/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9472. T_Loss: 4.4256. Mask: 0.9225. :  93%|█████████▎| 93/100 [00:23<00:01,  6.62it/s]Train Iter: 4694/5000. LR: 0.0007. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9472. T_Loss: 4.4256. Mask: 0.9225. :  94%|█████████▍| 94/100 [00:23<00:00,  6.87it/s]total : 5000  current step :  4676
total : 5000  current step :  4677
total : 5000  current step :  4678
total : 5000  current step :  4679
total : 5000  current step :  4680
total : 5000  current step :  4681
total : 5000  current step :  4682
total : 5000  current step :  4683
total : 5000  current step :  4684
total : 5000  current step :  4685
total : 5000  current step :  4686
total : 5000  current step :  4687
total : 5000  current step :  4688
total : 5000  current step :  4689
total : 5000  current step :  4690
total : 5000  current step :  4691
total : 5000  current step :  4692
total : 5000  current step :  4693
total : 5000  current step :  4694
Train Iter: 4695/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9491. T_Loss: 4.4445. Mask: 0.9224. :  94%|█████████▍| 94/100 [00:25<00:00,  6.87it/s]Train Iter: 4695/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9491. T_Loss: 4.4445. Mask: 0.9224. :  95%|█████████▌| 95/100 [00:25<00:03,  1.34it/s]Train Iter: 4696/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9496. T_Loss: 4.4455. Mask: 0.9219. :  95%|█████████▌| 95/100 [00:25<00:03,  1.34it/s]Train Iter: 4696/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9496. T_Loss: 4.4455. Mask: 0.9219. :  96%|█████████▌| 96/100 [00:25<00:02,  1.67it/s]Train Iter: 4697/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9494. T_Loss: 4.4453. Mask: 0.9220. :  96%|█████████▌| 96/100 [00:26<00:02,  1.67it/s]Train Iter: 4697/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9494. T_Loss: 4.4453. Mask: 0.9220. :  97%|█████████▋| 97/100 [00:26<00:01,  1.90it/s]Train Iter: 4698/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9503. T_Loss: 4.4483. Mask: 0.9219. :  97%|█████████▋| 97/100 [00:26<00:01,  1.90it/s]Train Iter: 4698/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9503. T_Loss: 4.4483. Mask: 0.9219. :  98%|█████████▊| 98/100 [00:26<00:00,  2.49it/s]Train Iter: 4699/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9513. T_Loss: 4.4557. Mask: 0.9220. :  98%|█████████▊| 98/100 [00:26<00:00,  2.49it/s]Train Iter: 4699/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9513. T_Loss: 4.4557. Mask: 0.9220. :  99%|█████████▉| 99/100 [00:26<00:00,  2.63it/s]Train Iter: 4700/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9510. T_Loss: 4.4632. Mask: 0.9222. :  99%|█████████▉| 99/100 [00:26<00:00,  2.63it/s]Train Iter: 4700/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9510. T_Loss: 4.4632. Mask: 0.9222. : 100%|██████████| 100/100 [00:26<00:00,  3.25it/s]Train Iter: 4700/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9510. T_Loss: 4.4632. Mask: 0.9222. : 100%|██████████| 100/100 [00:26<00:00,  3.74it/s]
total : 5000  current step :  4695
total : 5000  current step :  4696
total : 5000  current step :  4697
total : 5000  current step :  4698
total : 5000  current step :  4699
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 0.8683. top1: 90.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 0.8683. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 0.8612. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.8356. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.8369. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8250. top1: 92.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8215. top1: 92.71. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.8351. top1: 91.96. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8328. top1: 91.80. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8328. top1: 91.80. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8343. top1: 91.67. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8376. top1: 91.56. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8273. top1: 92.33. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8303. top1: 91.93. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8251. top1: 92.31. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8208. top1: 92.63. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8199. top1: 92.71. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8210. top1: 92.58. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.94it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8210. top1: 92.58. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8194. top1: 92.65. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8203. top1: 92.71. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8196. top1: 92.60. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8189. top1: 92.66. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8209. top1: 92.86. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8191. top1: 93.04. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8155. top1: 93.34. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.86it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8129. top1: 93.49. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.86it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8104. top1: 93.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.86it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8151. top1: 93.03. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.86it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8151. top1: 93.03. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8150. top1: 93.06. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8183. top1: 92.97. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8156. top1: 93.10. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8151. top1: 93.02. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8141. top1: 93.15. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8391. top1: 91.99. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8529. top1: 91.10. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8680. top1: 90.17. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8871. top1: 89.20. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 23.25it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8871. top1: 89.20. top5: 99.82. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9140. top1: 88.11. top5: 99.57. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9237. top1: 87.67. top5: 99.58. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9371. top1: 87.09. top5: 99.59. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9528. top1: 86.38. top5: 99.52. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9654. top1: 85.62. top5: 99.53. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9742. top1: 85.14. top5: 99.47. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9913. top1: 84.45. top5: 99.48. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0037. top1: 83.87. top5: 99.42. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0119. top1: 83.38. top5: 99.36. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0172. top1: 82.92. top5: 99.38. :  56%|█████▌    | 35/63 [00:02<00:00, 32.99it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0172. top1: 82.92. top5: 99.38. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0273. top1: 82.27. top5: 99.39. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0346. top1: 81.72. top5: 99.40. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0414. top1: 81.32. top5: 99.41. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0488. top1: 80.99. top5: 99.36. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0554. top1: 80.62. top5: 99.31. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0701. top1: 79.90. top5: 99.33. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0755. top1: 79.57. top5: 99.28. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0840. top1: 79.19. top5: 99.29. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0948. top1: 78.70. top5: 99.19. :  71%|███████▏  | 45/63 [00:02<00:00, 43.86it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0948. top1: 78.70. top5: 99.19. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0983. top1: 78.30. top5: 99.20. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1030. top1: 78.07. top5: 99.22. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1143. top1: 77.63. top5: 99.18. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1246. top1: 77.21. top5: 99.08. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1315. top1: 76.80. top5: 98.99. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1331. top1: 76.77. top5: 98.96. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1408. top1: 76.38. top5: 98.92. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1526. top1: 75.81. top5: 98.94. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1547. top1: 75.70. top5: 98.95. :  86%|████████▌ | 54/63 [00:02<00:00, 49.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1547. top1: 75.70. top5: 98.95. : 100%|██████████| 63/63 [00:02<00:00, 56.39it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1547. top1: 75.70. top5: 98.95. : 100%|██████████| 63/63 [00:02<00:00, 23.43it/s]
total : 5000  current step :  4700
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4701/5000. LR: 0.0006. Data: 2.03s. Batch: 2.17s. S_Loss: 0.9764. T_Loss: 3.9587. Mask: 0.8750. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4701/5000. LR: 0.0006. Data: 2.03s. Batch: 2.17s. S_Loss: 0.9764. T_Loss: 3.9587. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:35,  2.17s/it]Train Iter: 4702/5000. LR: 0.0006. Data: 1.02s. Batch: 1.16s. S_Loss: 0.9557. T_Loss: 4.4813. Mask: 0.9062. :   1%|          | 1/100 [00:02<03:35,  2.17s/it]Train Iter: 4702/5000. LR: 0.0006. Data: 1.02s. Batch: 1.16s. S_Loss: 0.9557. T_Loss: 4.4813. Mask: 0.9062. :   2%|▏         | 2/100 [00:02<01:35,  1.02it/s]Train Iter: 4703/5000. LR: 0.0006. Data: 0.68s. Batch: 0.81s. S_Loss: 1.0014. T_Loss: 4.6204. Mask: 0.8958. :   2%|▏         | 2/100 [00:02<01:35,  1.02it/s]Train Iter: 4703/5000. LR: 0.0006. Data: 0.68s. Batch: 0.81s. S_Loss: 1.0014. T_Loss: 4.6204. Mask: 0.8958. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 4704/5000. LR: 0.0006. Data: 0.51s. Batch: 0.64s. S_Loss: 0.9819. T_Loss: 4.6202. Mask: 0.9141. :   3%|▎         | 3/100 [00:02<00:57,  1.69it/s]Train Iter: 4704/5000. LR: 0.0006. Data: 0.51s. Batch: 0.64s. S_Loss: 0.9819. T_Loss: 4.6202. Mask: 0.9141. :   4%|▍         | 4/100 [00:02<00:38,  2.48it/s]Train Iter: 4705/5000. LR: 0.0006. Data: 0.41s. Batch: 0.58s. S_Loss: 0.9444. T_Loss: 4.5443. Mask: 0.9250. :   4%|▍         | 4/100 [00:02<00:38,  2.48it/s]Train Iter: 4705/5000. LR: 0.0006. Data: 0.41s. Batch: 0.58s. S_Loss: 0.9444. T_Loss: 4.5443. Mask: 0.9250. :   5%|▌         | 5/100 [00:02<00:36,  2.63it/s]Train Iter: 4706/5000. LR: 0.0006. Data: 0.34s. Batch: 0.50s. S_Loss: 0.9316. T_Loss: 4.4344. Mask: 0.9323. :   5%|▌         | 5/100 [00:03<00:36,  2.63it/s]Train Iter: 4706/5000. LR: 0.0006. Data: 0.34s. Batch: 0.50s. S_Loss: 0.9316. T_Loss: 4.4344. Mask: 0.9323. :   6%|▌         | 6/100 [00:03<00:27,  3.39it/s]Train Iter: 4707/5000. LR: 0.0006. Data: 0.29s. Batch: 0.45s. S_Loss: 0.9424. T_Loss: 4.5532. Mask: 0.9241. :   6%|▌         | 6/100 [00:03<00:27,  3.39it/s]Train Iter: 4707/5000. LR: 0.0006. Data: 0.29s. Batch: 0.45s. S_Loss: 0.9424. T_Loss: 4.5532. Mask: 0.9241. :   7%|▋         | 7/100 [00:03<00:22,  4.17it/s]Train Iter: 4708/5000. LR: 0.0006. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9527. T_Loss: 4.5627. Mask: 0.9258. :   7%|▋         | 7/100 [00:03<00:22,  4.17it/s]Train Iter: 4708/5000. LR: 0.0006. Data: 0.26s. Batch: 0.41s. S_Loss: 0.9527. T_Loss: 4.5627. Mask: 0.9258. :   8%|▊         | 8/100 [00:03<00:18,  4.89it/s]Train Iter: 4709/5000. LR: 0.0006. Data: 0.23s. Batch: 0.40s. S_Loss: 0.9425. T_Loss: 4.4871. Mask: 0.9306. :   8%|▊         | 8/100 [00:03<00:18,  4.89it/s]Train Iter: 4709/5000. LR: 0.0006. Data: 0.23s. Batch: 0.40s. S_Loss: 0.9425. T_Loss: 4.4871. Mask: 0.9306. :   9%|▉         | 9/100 [00:03<00:22,  4.12it/s]Train Iter: 4710/5000. LR: 0.0006. Data: 0.20s. Batch: 0.37s. S_Loss: 0.9390. T_Loss: 4.3833. Mask: 0.9219. :   9%|▉         | 9/100 [00:03<00:22,  4.12it/s]Train Iter: 4710/5000. LR: 0.0006. Data: 0.20s. Batch: 0.37s. S_Loss: 0.9390. T_Loss: 4.3833. Mask: 0.9219. :  10%|█         | 10/100 [00:03<00:18,  4.85it/s]Train Iter: 4711/5000. LR: 0.0006. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9346. T_Loss: 4.4171. Mask: 0.9261. :  10%|█         | 10/100 [00:03<00:18,  4.85it/s]Train Iter: 4711/5000. LR: 0.0006. Data: 0.19s. Batch: 0.35s. S_Loss: 0.9346. T_Loss: 4.4171. Mask: 0.9261. :  11%|█         | 11/100 [00:03<00:15,  5.59it/s]Train Iter: 4712/5000. LR: 0.0006. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9297. T_Loss: 4.3761. Mask: 0.9297. :  11%|█         | 11/100 [00:03<00:15,  5.59it/s]Train Iter: 4712/5000. LR: 0.0006. Data: 0.17s. Batch: 0.33s. S_Loss: 0.9297. T_Loss: 4.3761. Mask: 0.9297. :  12%|█▏        | 12/100 [00:03<00:14,  6.12it/s]Train Iter: 4713/5000. LR: 0.0006. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9295. T_Loss: 4.3702. Mask: 0.9231. :  12%|█▏        | 12/100 [00:04<00:14,  6.12it/s]Train Iter: 4713/5000. LR: 0.0006. Data: 0.16s. Batch: 0.32s. S_Loss: 0.9295. T_Loss: 4.3702. Mask: 0.9231. :  13%|█▎        | 13/100 [00:04<00:13,  6.42it/s]Train Iter: 4714/5000. LR: 0.0006. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9332. T_Loss: 4.3875. Mask: 0.9241. :  13%|█▎        | 13/100 [00:04<00:13,  6.42it/s]Train Iter: 4714/5000. LR: 0.0006. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9332. T_Loss: 4.3875. Mask: 0.9241. :  14%|█▍        | 14/100 [00:04<00:12,  7.08it/s]Train Iter: 4715/5000. LR: 0.0006. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9427. T_Loss: 4.4273. Mask: 0.9250. :  14%|█▍        | 14/100 [00:04<00:12,  7.08it/s]Train Iter: 4715/5000. LR: 0.0006. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9427. T_Loss: 4.4273. Mask: 0.9250. :  15%|█▌        | 15/100 [00:04<00:17,  4.77it/s]Train Iter: 4716/5000. LR: 0.0006. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9462. T_Loss: 4.4761. Mask: 0.9219. :  15%|█▌        | 15/100 [00:04<00:17,  4.77it/s]Train Iter: 4716/5000. LR: 0.0006. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9462. T_Loss: 4.4761. Mask: 0.9219. :  16%|█▌        | 16/100 [00:04<00:15,  5.37it/s]Train Iter: 4717/5000. LR: 0.0006. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9424. T_Loss: 4.4880. Mask: 0.9246. :  16%|█▌        | 16/100 [00:04<00:15,  5.37it/s]Train Iter: 4718/5000. LR: 0.0006. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9450. T_Loss: 4.5094. Mask: 0.9219. :  17%|█▋        | 17/100 [00:04<00:15,  5.37it/s]Train Iter: 4718/5000. LR: 0.0006. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9450. T_Loss: 4.5094. Mask: 0.9219. :  18%|█▊        | 18/100 [00:04<00:12,  6.71it/s]Train Iter: 4719/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9396. T_Loss: 4.4718. Mask: 0.9211. :  18%|█▊        | 18/100 [00:05<00:12,  6.71it/s]Train Iter: 4719/5000. LR: 0.0006. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9396. T_Loss: 4.4718. Mask: 0.9211. :  19%|█▉        | 19/100 [00:05<00:13,  5.83it/s]Train Iter: 4720/5000. LR: 0.0005. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9414. T_Loss: 4.4596. Mask: 0.9203. :  19%|█▉        | 19/100 [00:05<00:13,  5.83it/s]Train Iter: 4720/5000. LR: 0.0005. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9414. T_Loss: 4.4596. Mask: 0.9203. :  20%|██        | 20/100 [00:05<00:12,  6.27it/s]Train Iter: 4721/5000. LR: 0.0005. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9413. T_Loss: 4.4293. Mask: 0.9196. :  20%|██        | 20/100 [00:05<00:12,  6.27it/s]Train Iter: 4722/5000. LR: 0.0005. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9460. T_Loss: 4.4937. Mask: 0.9219. :  21%|██        | 21/100 [00:05<00:12,  6.27it/s]Train Iter: 4722/5000. LR: 0.0005. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9460. T_Loss: 4.4937. Mask: 0.9219. :  22%|██▏       | 22/100 [00:05<00:10,  7.32it/s]Train Iter: 4723/5000. LR: 0.0005. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5094. Mask: 0.9212. :  22%|██▏       | 22/100 [00:05<00:10,  7.32it/s]Train Iter: 4723/5000. LR: 0.0005. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5094. Mask: 0.9212. :  23%|██▎       | 23/100 [00:05<00:10,  7.57it/s]Train Iter: 4724/5000. LR: 0.0005. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9411. T_Loss: 4.4648. Mask: 0.9219. :  23%|██▎       | 23/100 [00:05<00:10,  7.57it/s]Train Iter: 4725/5000. LR: 0.0005. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9428. T_Loss: 4.4656. Mask: 0.9225. :  24%|██▍       | 24/100 [00:06<00:10,  7.57it/s]Train Iter: 4725/5000. LR: 0.0005. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9428. T_Loss: 4.4656. Mask: 0.9225. :  25%|██▌       | 25/100 [00:06<00:11,  6.51it/s]total : 5000  current step :  4701
total : 5000  current step :  4702
total : 5000  current step :  4703
total : 5000  current step :  4704
total : 5000  current step :  4705
total : 5000  current step :  4706
total : 5000  current step :  4707
total : 5000  current step :  4708
total : 5000  current step :  4709
total : 5000  current step :  4710
total : 5000  current step :  4711
total : 5000  current step :  4712
total : 5000  current step :  4713
total : 5000  current step :  4714
total : 5000  current step :  4715
total : 5000  current step :  4716
total : 5000  current step :  4717
total : 5000  current step :  4718
total : 5000  current step :  4719
total : 5000  current step :  4720
total : 5000  current step :  4721
total : 5000  current step :  4722
total : 5000  current step :  4723
total : 5000  current step :  4724
total : 5000  current step :  4725
Train Iter: 4726/5000. LR: 0.0005. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9439. T_Loss: 4.4746. Mask: 0.9231. :  25%|██▌       | 25/100 [00:08<00:11,  6.51it/s]Train Iter: 4726/5000. LR: 0.0005. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9439. T_Loss: 4.4746. Mask: 0.9231. :  26%|██▌       | 26/100 [00:08<00:43,  1.71it/s]Train Iter: 4727/5000. LR: 0.0005. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9404. T_Loss: 4.4455. Mask: 0.9236. :  26%|██▌       | 26/100 [00:08<00:43,  1.71it/s]Train Iter: 4727/5000. LR: 0.0005. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9404. T_Loss: 4.4455. Mask: 0.9236. :  27%|██▋       | 27/100 [00:08<00:34,  2.10it/s]Train Iter: 4728/5000. LR: 0.0005. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9409. T_Loss: 4.4498. Mask: 0.9230. :  27%|██▋       | 27/100 [00:08<00:34,  2.10it/s]Train Iter: 4728/5000. LR: 0.0005. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9409. T_Loss: 4.4498. Mask: 0.9230. :  28%|██▊       | 28/100 [00:08<00:27,  2.59it/s]Train Iter: 4729/5000. LR: 0.0005. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9412. T_Loss: 4.4567. Mask: 0.9246. :  28%|██▊       | 28/100 [00:08<00:27,  2.59it/s]Train Iter: 4729/5000. LR: 0.0005. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9412. T_Loss: 4.4567. Mask: 0.9246. :  29%|██▉       | 29/100 [00:08<00:26,  2.70it/s]Train Iter: 4730/5000. LR: 0.0005. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9433. T_Loss: 4.4524. Mask: 0.9240. :  29%|██▉       | 29/100 [00:08<00:26,  2.70it/s]Train Iter: 4730/5000. LR: 0.0005. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9433. T_Loss: 4.4524. Mask: 0.9240. :  30%|███       | 30/100 [00:08<00:21,  3.30it/s]Train Iter: 4731/5000. LR: 0.0005. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9439. T_Loss: 4.4628. Mask: 0.9244. :  30%|███       | 30/100 [00:08<00:21,  3.30it/s]Train Iter: 4731/5000. LR: 0.0005. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9439. T_Loss: 4.4628. Mask: 0.9244. :  31%|███       | 31/100 [00:08<00:17,  4.00it/s]Train Iter: 4732/5000. LR: 0.0005. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9416. T_Loss: 4.4465. Mask: 0.9219. :  31%|███       | 31/100 [00:09<00:17,  4.00it/s]Train Iter: 4732/5000. LR: 0.0005. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9416. T_Loss: 4.4465. Mask: 0.9219. :  32%|███▏      | 32/100 [00:09<00:14,  4.72it/s]Train Iter: 4733/5000. LR: 0.0005. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9423. T_Loss: 4.4609. Mask: 0.9242. :  32%|███▏      | 32/100 [00:09<00:14,  4.72it/s]Train Iter: 4733/5000. LR: 0.0005. Data: 0.12s. Batch: 0.28s. S_Loss: 0.9423. T_Loss: 4.4609. Mask: 0.9242. :  33%|███▎      | 33/100 [00:09<00:12,  5.58it/s]Train Iter: 4734/5000. LR: 0.0005. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9408. T_Loss: 4.4478. Mask: 0.9256. :  33%|███▎      | 33/100 [00:09<00:12,  5.58it/s]Train Iter: 4734/5000. LR: 0.0005. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9408. T_Loss: 4.4478. Mask: 0.9256. :  34%|███▍      | 34/100 [00:09<00:10,  6.28it/s]Train Iter: 4735/5000. LR: 0.0005. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9444. T_Loss: 4.4674. Mask: 0.9259. :  34%|███▍      | 34/100 [00:09<00:10,  6.28it/s]Train Iter: 4735/5000. LR: 0.0005. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9444. T_Loss: 4.4674. Mask: 0.9259. :  35%|███▌      | 35/100 [00:09<00:13,  4.64it/s]Train Iter: 4736/5000. LR: 0.0005. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9407. T_Loss: 4.4490. Mask: 0.9271. :  35%|███▌      | 35/100 [00:09<00:13,  4.64it/s]Train Iter: 4737/5000. LR: 0.0005. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9462. T_Loss: 4.4665. Mask: 0.9257. :  36%|███▌      | 36/100 [00:09<00:13,  4.64it/s]Train Iter: 4737/5000. LR: 0.0005. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9462. T_Loss: 4.4665. Mask: 0.9257. :  37%|███▋      | 37/100 [00:09<00:10,  6.11it/s]Train Iter: 4738/5000. LR: 0.0005. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9466. T_Loss: 4.4560. Mask: 0.9252. :  37%|███▋      | 37/100 [00:09<00:10,  6.11it/s]Train Iter: 4738/5000. LR: 0.0005. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9466. T_Loss: 4.4560. Mask: 0.9252. :  38%|███▊      | 38/100 [00:09<00:09,  6.58it/s]Train Iter: 4739/5000. LR: 0.0005. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9501. T_Loss: 4.4628. Mask: 0.9247. :  38%|███▊      | 38/100 [00:10<00:09,  6.58it/s]Train Iter: 4739/5000. LR: 0.0005. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9501. T_Loss: 4.4628. Mask: 0.9247. :  39%|███▉      | 39/100 [00:10<00:12,  4.92it/s]Train Iter: 4740/5000. LR: 0.0005. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9494. T_Loss: 4.4823. Mask: 0.9258. :  39%|███▉      | 39/100 [00:10<00:12,  4.92it/s]Train Iter: 4740/5000. LR: 0.0005. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9494. T_Loss: 4.4823. Mask: 0.9258. :  40%|████      | 40/100 [00:10<00:10,  5.62it/s]Train Iter: 4741/5000. LR: 0.0005. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9495. T_Loss: 4.4892. Mask: 0.9268. :  40%|████      | 40/100 [00:10<00:10,  5.62it/s]Train Iter: 4741/5000. LR: 0.0005. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9495. T_Loss: 4.4892. Mask: 0.9268. :  41%|████      | 41/100 [00:10<00:10,  5.85it/s]Train Iter: 4742/5000. LR: 0.0005. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9488. T_Loss: 4.4904. Mask: 0.9286. :  41%|████      | 41/100 [00:10<00:10,  5.85it/s]Train Iter: 4742/5000. LR: 0.0005. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9488. T_Loss: 4.4904. Mask: 0.9286. :  42%|████▏     | 42/100 [00:10<00:09,  6.20it/s]Train Iter: 4743/5000. LR: 0.0005. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.5063. Mask: 0.9295. :  42%|████▏     | 42/100 [00:10<00:09,  6.20it/s]Train Iter: 4743/5000. LR: 0.0005. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9478. T_Loss: 4.5063. Mask: 0.9295. :  43%|████▎     | 43/100 [00:10<00:08,  6.96it/s]Train Iter: 4744/5000. LR: 0.0005. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9489. T_Loss: 4.5140. Mask: 0.9290. :  43%|████▎     | 43/100 [00:10<00:08,  6.96it/s]Train Iter: 4744/5000. LR: 0.0005. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9489. T_Loss: 4.5140. Mask: 0.9290. :  44%|████▍     | 44/100 [00:10<00:07,  7.30it/s]Train Iter: 4745/5000. LR: 0.0005. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9481. T_Loss: 4.5126. Mask: 0.9299. :  44%|████▍     | 44/100 [00:11<00:07,  7.30it/s]Train Iter: 4745/5000. LR: 0.0005. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9481. T_Loss: 4.5126. Mask: 0.9299. :  45%|████▌     | 45/100 [00:11<00:07,  7.39it/s]Train Iter: 4746/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9466. T_Loss: 4.5230. Mask: 0.9314. :  45%|████▌     | 45/100 [00:11<00:07,  7.39it/s]Train Iter: 4746/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9466. T_Loss: 4.5230. Mask: 0.9314. :  46%|████▌     | 46/100 [00:11<00:07,  7.50it/s]Train Iter: 4747/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5244. Mask: 0.9322. :  46%|████▌     | 46/100 [00:11<00:07,  7.50it/s]Train Iter: 4747/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9463. T_Loss: 4.5244. Mask: 0.9322. :  47%|████▋     | 47/100 [00:11<00:06,  7.65it/s]Train Iter: 4748/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9441. T_Loss: 4.5154. Mask: 0.9329. :  47%|████▋     | 47/100 [00:11<00:06,  7.65it/s]Train Iter: 4748/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9441. T_Loss: 4.5154. Mask: 0.9329. :  48%|████▊     | 48/100 [00:11<00:06,  7.75it/s]Train Iter: 4749/5000. LR: 0.0004. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9449. T_Loss: 4.5299. Mask: 0.9343. :  48%|████▊     | 48/100 [00:11<00:06,  7.75it/s]Train Iter: 4749/5000. LR: 0.0004. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9449. T_Loss: 4.5299. Mask: 0.9343. :  49%|████▉     | 49/100 [00:11<00:10,  4.92it/s]Train Iter: 4750/5000. LR: 0.0004. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9435. T_Loss: 4.5218. Mask: 0.9350. :  49%|████▉     | 49/100 [00:11<00:10,  4.92it/s]Train Iter: 4750/5000. LR: 0.0004. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9435. T_Loss: 4.5218. Mask: 0.9350. :  50%|█████     | 50/100 [00:11<00:08,  5.58it/s]total : 5000  current step :  4726
total : 5000  current step :  4727
total : 5000  current step :  4728
total : 5000  current step :  4729
total : 5000  current step :  4730
total : 5000  current step :  4731
total : 5000  current step :  4732
total : 5000  current step :  4733
total : 5000  current step :  4734
total : 5000  current step :  4735
total : 5000  current step :  4736
total : 5000  current step :  4737
total : 5000  current step :  4738
total : 5000  current step :  4739
total : 5000  current step :  4740
total : 5000  current step :  4741
total : 5000  current step :  4742
total : 5000  current step :  4743
total : 5000  current step :  4744
total : 5000  current step :  4745
total : 5000  current step :  4746
total : 5000  current step :  4747
total : 5000  current step :  4748
total : 5000  current step :  4749
total : 5000  current step :  4750
Train Iter: 4751/5000. LR: 0.0004. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9438. T_Loss: 4.5263. Mask: 0.9344. :  50%|█████     | 50/100 [00:14<00:08,  5.58it/s]Train Iter: 4751/5000. LR: 0.0004. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9438. T_Loss: 4.5263. Mask: 0.9344. :  51%|█████     | 51/100 [00:14<00:37,  1.30it/s]Train Iter: 4752/5000. LR: 0.0004. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9437. T_Loss: 4.5063. Mask: 0.9339. :  51%|█████     | 51/100 [00:14<00:37,  1.30it/s]Train Iter: 4752/5000. LR: 0.0004. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9437. T_Loss: 4.5063. Mask: 0.9339. :  52%|█████▏    | 52/100 [00:14<00:27,  1.72it/s]Train Iter: 4753/5000. LR: 0.0004. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9435. T_Loss: 4.4917. Mask: 0.9334. :  52%|█████▏    | 52/100 [00:14<00:27,  1.72it/s]Train Iter: 4753/5000. LR: 0.0004. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9435. T_Loss: 4.4917. Mask: 0.9334. :  53%|█████▎    | 53/100 [00:14<00:20,  2.25it/s]Train Iter: 4754/5000. LR: 0.0004. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9422. T_Loss: 4.4992. Mask: 0.9346. :  53%|█████▎    | 53/100 [00:14<00:20,  2.25it/s]Train Iter: 4754/5000. LR: 0.0004. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9422. T_Loss: 4.4992. Mask: 0.9346. :  54%|█████▍    | 54/100 [00:14<00:16,  2.86it/s]Train Iter: 4755/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9453. T_Loss: 4.5215. Mask: 0.9347. :  54%|█████▍    | 54/100 [00:14<00:16,  2.86it/s]Train Iter: 4755/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9453. T_Loss: 4.5215. Mask: 0.9347. :  55%|█████▌    | 55/100 [00:14<00:13,  3.40it/s]Train Iter: 4756/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9443. T_Loss: 4.5166. Mask: 0.9353. :  55%|█████▌    | 55/100 [00:14<00:13,  3.40it/s]Train Iter: 4756/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9443. T_Loss: 4.5166. Mask: 0.9353. :  56%|█████▌    | 56/100 [00:14<00:11,  3.94it/s]Train Iter: 4757/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9430. T_Loss: 4.5073. Mask: 0.9353. :  56%|█████▌    | 56/100 [00:14<00:11,  3.94it/s]Train Iter: 4757/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9430. T_Loss: 4.5073. Mask: 0.9353. :  57%|█████▋    | 57/100 [00:14<00:09,  4.68it/s]Train Iter: 4758/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9420. T_Loss: 4.4997. Mask: 0.9353. :  57%|█████▋    | 57/100 [00:15<00:09,  4.68it/s]Train Iter: 4758/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9420. T_Loss: 4.4997. Mask: 0.9353. :  58%|█████▊    | 58/100 [00:15<00:08,  4.97it/s]Train Iter: 4759/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9422. T_Loss: 4.5076. Mask: 0.9359. :  58%|█████▊    | 58/100 [00:15<00:08,  4.97it/s]Train Iter: 4759/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9422. T_Loss: 4.5076. Mask: 0.9359. :  59%|█████▉    | 59/100 [00:15<00:10,  3.88it/s]Train Iter: 4760/5000. LR: 0.0004. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9446. T_Loss: 4.5293. Mask: 0.9365. :  59%|█████▉    | 59/100 [00:15<00:10,  3.88it/s]Train Iter: 4760/5000. LR: 0.0004. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9446. T_Loss: 4.5293. Mask: 0.9365. :  60%|██████    | 60/100 [00:15<00:08,  4.54it/s]Train Iter: 4761/5000. LR: 0.0004. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9436. T_Loss: 4.5094. Mask: 0.9349. :  60%|██████    | 60/100 [00:15<00:08,  4.54it/s]Train Iter: 4761/5000. LR: 0.0004. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9436. T_Loss: 4.5094. Mask: 0.9349. :  61%|██████    | 61/100 [00:15<00:07,  5.17it/s]Train Iter: 4762/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9425. T_Loss: 4.5025. Mask: 0.9345. :  61%|██████    | 61/100 [00:15<00:07,  5.17it/s]Train Iter: 4762/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9425. T_Loss: 4.5025. Mask: 0.9345. :  62%|██████▏   | 62/100 [00:15<00:06,  5.67it/s]Train Iter: 4763/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9417. T_Loss: 4.5027. Mask: 0.9340. :  62%|██████▏   | 62/100 [00:15<00:06,  5.67it/s]Train Iter: 4763/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9417. T_Loss: 4.5027. Mask: 0.9340. :  63%|██████▎   | 63/100 [00:15<00:06,  6.14it/s]Train Iter: 4764/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9410. T_Loss: 4.5028. Mask: 0.9346. :  63%|██████▎   | 63/100 [00:16<00:06,  6.14it/s]Train Iter: 4764/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9410. T_Loss: 4.5028. Mask: 0.9346. :  64%|██████▍   | 64/100 [00:16<00:05,  6.51it/s]Train Iter: 4765/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9391. T_Loss: 4.4958. Mask: 0.9351. :  64%|██████▍   | 64/100 [00:16<00:05,  6.51it/s]Train Iter: 4765/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9391. T_Loss: 4.4958. Mask: 0.9351. :  65%|██████▌   | 65/100 [00:16<00:06,  5.15it/s]Train Iter: 4766/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9382. T_Loss: 4.5013. Mask: 0.9351. :  65%|██████▌   | 65/100 [00:16<00:06,  5.15it/s]Train Iter: 4766/5000. LR: 0.0004. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9382. T_Loss: 4.5013. Mask: 0.9351. :  66%|██████▌   | 66/100 [00:16<00:06,  5.56it/s]Train Iter: 4767/5000. LR: 0.0004. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9386. T_Loss: 4.5002. Mask: 0.9352. :  66%|██████▌   | 66/100 [00:16<00:06,  5.56it/s]Train Iter: 4767/5000. LR: 0.0004. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9386. T_Loss: 4.5002. Mask: 0.9352. :  67%|██████▋   | 67/100 [00:16<00:05,  6.18it/s]Train Iter: 4768/5000. LR: 0.0004. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9412. T_Loss: 4.5044. Mask: 0.9343. :  67%|██████▋   | 67/100 [00:16<00:05,  6.18it/s]Train Iter: 4768/5000. LR: 0.0004. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9412. T_Loss: 4.5044. Mask: 0.9343. :  68%|██████▊   | 68/100 [00:16<00:04,  6.48it/s]Train Iter: 4769/5000. LR: 0.0004. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9406. T_Loss: 4.5025. Mask: 0.9339. :  68%|██████▊   | 68/100 [00:17<00:04,  6.48it/s]Train Iter: 4769/5000. LR: 0.0004. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9406. T_Loss: 4.5025. Mask: 0.9339. :  69%|██████▉   | 69/100 [00:17<00:05,  6.05it/s]Train Iter: 4770/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9420. T_Loss: 4.5140. Mask: 0.9335. :  69%|██████▉   | 69/100 [00:17<00:05,  6.05it/s]Train Iter: 4770/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9420. T_Loss: 4.5140. Mask: 0.9335. :  70%|███████   | 70/100 [00:17<00:04,  6.62it/s]Train Iter: 4771/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9417. T_Loss: 4.5082. Mask: 0.9335. :  70%|███████   | 70/100 [00:17<00:04,  6.62it/s]Train Iter: 4771/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9417. T_Loss: 4.5082. Mask: 0.9335. :  71%|███████   | 71/100 [00:17<00:04,  6.93it/s]Train Iter: 4772/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9450. T_Loss: 4.5163. Mask: 0.9327. :  71%|███████   | 71/100 [00:17<00:04,  6.93it/s]Train Iter: 4772/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9450. T_Loss: 4.5163. Mask: 0.9327. :  72%|███████▏  | 72/100 [00:17<00:03,  7.35it/s]Train Iter: 4773/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9459. T_Loss: 4.5092. Mask: 0.9324. :  72%|███████▏  | 72/100 [00:17<00:03,  7.35it/s]Train Iter: 4773/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9459. T_Loss: 4.5092. Mask: 0.9324. :  73%|███████▎  | 73/100 [00:17<00:03,  7.40it/s]Train Iter: 4774/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.5078. Mask: 0.9329. :  73%|███████▎  | 73/100 [00:17<00:03,  7.40it/s]Train Iter: 4774/5000. LR: 0.0004. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.5078. Mask: 0.9329. :  74%|███████▍  | 74/100 [00:17<00:03,  7.55it/s]Train Iter: 4775/5000. LR: 0.0004. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9451. T_Loss: 4.5109. Mask: 0.9337. :  74%|███████▍  | 74/100 [00:17<00:03,  7.55it/s]Train Iter: 4775/5000. LR: 0.0004. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9451. T_Loss: 4.5109. Mask: 0.9337. :  75%|███████▌  | 75/100 [00:17<00:04,  5.48it/s]total : 5000  current step :  4751
total : 5000  current step :  4752
total : 5000  current step :  4753
total : 5000  current step :  4754
total : 5000  current step :  4755
total : 5000  current step :  4756
total : 5000  current step :  4757
total : 5000  current step :  4758
total : 5000  current step :  4759
total : 5000  current step :  4760
total : 5000  current step :  4761
total : 5000  current step :  4762
total : 5000  current step :  4763
total : 5000  current step :  4764
total : 5000  current step :  4765
total : 5000  current step :  4766
total : 5000  current step :  4767
total : 5000  current step :  4768
total : 5000  current step :  4769
total : 5000  current step :  4770
total : 5000  current step :  4771
total : 5000  current step :  4772
total : 5000  current step :  4773
total : 5000  current step :  4774
total : 5000  current step :  4775
Train Iter: 4776/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9465. T_Loss: 4.5122. Mask: 0.9326. :  75%|███████▌  | 75/100 [00:19<00:04,  5.48it/s]Train Iter: 4776/5000. LR: 0.0004. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9465. T_Loss: 4.5122. Mask: 0.9326. :  76%|███████▌  | 76/100 [00:19<00:17,  1.34it/s]Train Iter: 4777/5000. LR: 0.0003. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9453. T_Loss: 4.5016. Mask: 0.9330. :  76%|███████▌  | 76/100 [00:20<00:17,  1.34it/s]Train Iter: 4777/5000. LR: 0.0003. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9453. T_Loss: 4.5016. Mask: 0.9330. :  77%|███████▋  | 77/100 [00:20<00:13,  1.75it/s]Train Iter: 4778/5000. LR: 0.0003. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9455. T_Loss: 4.5101. Mask: 0.9339. :  77%|███████▋  | 77/100 [00:20<00:13,  1.75it/s]Train Iter: 4778/5000. LR: 0.0003. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9455. T_Loss: 4.5101. Mask: 0.9339. :  78%|███████▊  | 78/100 [00:20<00:09,  2.29it/s]Train Iter: 4779/5000. LR: 0.0003. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5080. Mask: 0.9339. :  78%|███████▊  | 78/100 [00:20<00:09,  2.29it/s]Train Iter: 4779/5000. LR: 0.0003. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5080. Mask: 0.9339. :  79%|███████▉  | 79/100 [00:20<00:07,  2.88it/s]Train Iter: 4780/5000. LR: 0.0003. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5099. Mask: 0.9336. :  79%|███████▉  | 79/100 [00:20<00:07,  2.88it/s]Train Iter: 4780/5000. LR: 0.0003. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9449. T_Loss: 4.5099. Mask: 0.9336. :  80%|████████  | 80/100 [00:20<00:05,  3.66it/s]Train Iter: 4781/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9460. T_Loss: 4.5115. Mask: 0.9336. :  80%|████████  | 80/100 [00:20<00:05,  3.66it/s]Train Iter: 4782/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9451. T_Loss: 4.5115. Mask: 0.9341. :  81%|████████  | 81/100 [00:20<00:05,  3.66it/s]Train Iter: 4782/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9451. T_Loss: 4.5115. Mask: 0.9341. :  82%|████████▏ | 82/100 [00:20<00:03,  5.14it/s]Train Iter: 4783/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9465. T_Loss: 4.5150. Mask: 0.9337. :  82%|████████▏ | 82/100 [00:20<00:03,  5.14it/s]Train Iter: 4783/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9465. T_Loss: 4.5150. Mask: 0.9337. :  83%|████████▎ | 83/100 [00:20<00:02,  5.74it/s]Train Iter: 4784/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9471. T_Loss: 4.5016. Mask: 0.9327. :  83%|████████▎ | 83/100 [00:20<00:02,  5.74it/s]Train Iter: 4785/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9461. T_Loss: 4.4996. Mask: 0.9327. :  84%|████████▍ | 84/100 [00:21<00:02,  5.74it/s]Train Iter: 4785/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9461. T_Loss: 4.4996. Mask: 0.9327. :  85%|████████▌ | 85/100 [00:21<00:02,  5.44it/s]Train Iter: 4786/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9457. T_Loss: 4.4932. Mask: 0.9331. :  85%|████████▌ | 85/100 [00:21<00:02,  5.44it/s]Train Iter: 4786/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9457. T_Loss: 4.4932. Mask: 0.9331. :  86%|████████▌ | 86/100 [00:21<00:02,  5.86it/s]Train Iter: 4787/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9461. T_Loss: 4.4940. Mask: 0.9325. :  86%|████████▌ | 86/100 [00:21<00:02,  5.86it/s]Train Iter: 4787/5000. LR: 0.0003. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9461. T_Loss: 4.4940. Mask: 0.9325. :  87%|████████▋ | 87/100 [00:21<00:02,  6.19it/s]Train Iter: 4788/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9449. T_Loss: 4.4860. Mask: 0.9322. :  87%|████████▋ | 87/100 [00:21<00:02,  6.19it/s]Train Iter: 4788/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9449. T_Loss: 4.4860. Mask: 0.9322. :  88%|████████▊ | 88/100 [00:21<00:01,  6.50it/s]Train Iter: 4789/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9452. T_Loss: 4.4820. Mask: 0.9315. :  88%|████████▊ | 88/100 [00:21<00:01,  6.50it/s]Train Iter: 4789/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9452. T_Loss: 4.4820. Mask: 0.9315. :  89%|████████▉ | 89/100 [00:21<00:01,  6.65it/s]Train Iter: 4790/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9459. T_Loss: 4.4895. Mask: 0.9319. :  89%|████████▉ | 89/100 [00:21<00:01,  6.65it/s]Train Iter: 4790/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9459. T_Loss: 4.4895. Mask: 0.9319. :  90%|█████████ | 90/100 [00:21<00:01,  6.98it/s]Train Iter: 4791/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.4957. Mask: 0.9323. :  90%|█████████ | 90/100 [00:22<00:01,  6.98it/s]Train Iter: 4791/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9457. T_Loss: 4.4957. Mask: 0.9323. :  91%|█████████ | 91/100 [00:22<00:01,  7.12it/s]Train Iter: 4792/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9458. T_Loss: 4.5027. Mask: 0.9331. :  91%|█████████ | 91/100 [00:22<00:01,  7.12it/s]Train Iter: 4792/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9458. T_Loss: 4.5027. Mask: 0.9331. :  92%|█████████▏| 92/100 [00:22<00:01,  7.35it/s]Train Iter: 4793/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9456. T_Loss: 4.5040. Mask: 0.9321. :  92%|█████████▏| 92/100 [00:22<00:01,  7.35it/s]Train Iter: 4793/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9456. T_Loss: 4.5040. Mask: 0.9321. :  93%|█████████▎| 93/100 [00:22<00:00,  7.50it/s]Train Iter: 4794/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9443. T_Loss: 4.4984. Mask: 0.9325. :  93%|█████████▎| 93/100 [00:22<00:00,  7.50it/s]Train Iter: 4794/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9443. T_Loss: 4.4984. Mask: 0.9325. :  94%|█████████▍| 94/100 [00:22<00:00,  7.57it/s]Train Iter: 4795/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9449. T_Loss: 4.4978. Mask: 0.9326. :  94%|█████████▍| 94/100 [00:22<00:00,  7.57it/s]Train Iter: 4795/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9449. T_Loss: 4.4978. Mask: 0.9326. :  95%|█████████▌| 95/100 [00:22<00:00,  5.65it/s]Train Iter: 4796/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.5056. Mask: 0.9333. :  95%|█████████▌| 95/100 [00:22<00:00,  5.65it/s]Train Iter: 4796/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9454. T_Loss: 4.5056. Mask: 0.9333. :  96%|█████████▌| 96/100 [00:22<00:00,  5.96it/s]Train Iter: 4797/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9464. T_Loss: 4.5118. Mask: 0.9336. :  96%|█████████▌| 96/100 [00:22<00:00,  5.96it/s]Train Iter: 4797/5000. LR: 0.0003. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9464. T_Loss: 4.5118. Mask: 0.9336. :  97%|█████████▋| 97/100 [00:22<00:00,  6.50it/s]Train Iter: 4798/5000. LR: 0.0003. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9452. T_Loss: 4.5006. Mask: 0.9334. :  97%|█████████▋| 97/100 [00:23<00:00,  6.50it/s]Train Iter: 4798/5000. LR: 0.0003. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9452. T_Loss: 4.5006. Mask: 0.9334. :  98%|█████████▊| 98/100 [00:23<00:00,  6.84it/s]Train Iter: 4799/5000. LR: 0.0003. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9471. T_Loss: 4.5069. Mask: 0.9331. :  98%|█████████▊| 98/100 [00:23<00:00,  6.84it/s]Train Iter: 4799/5000. LR: 0.0003. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9471. T_Loss: 4.5069. Mask: 0.9331. :  99%|█████████▉| 99/100 [00:23<00:00,  4.39it/s]Train Iter: 4800/5000. LR: 0.0003. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9486. T_Loss: 4.5197. Mask: 0.9331. :  99%|█████████▉| 99/100 [00:23<00:00,  4.39it/s]Train Iter: 4800/5000. LR: 0.0003. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9486. T_Loss: 4.5197. Mask: 0.9331. : 100%|██████████| 100/100 [00:23<00:00,  5.05it/s]Train Iter: 4800/5000. LR: 0.0003. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9486. T_Loss: 4.5197. Mask: 0.9331. : 100%|██████████| 100/100 [00:23<00:00,  4.23it/s]
total : 5000  current step :  4776
total : 5000  current step :  4777
total : 5000  current step :  4778
total : 5000  current step :  4779
total : 5000  current step :  4780
total : 5000  current step :  4781
total : 5000  current step :  4782
total : 5000  current step :  4783
total : 5000  current step :  4784
total : 5000  current step :  4785
total : 5000  current step :  4786
total : 5000  current step :  4787
total : 5000  current step :  4788
total : 5000  current step :  4789
total : 5000  current step :  4790
total : 5000  current step :  4791
total : 5000  current step :  4792
total : 5000  current step :  4793
total : 5000  current step :  4794
total : 5000  current step :  4795
total : 5000  current step :  4796
total : 5000  current step :  4797
total : 5000  current step :  4798
total : 5000  current step :  4799
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.79s. Loss: 0.8799. top1: 90.62. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.79s. Loss: 0.8799. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 0.8716. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 0.8447. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.8475. top1: 91.41. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8345. top1: 92.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8307. top1: 92.71. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8307. top1: 92.71. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8452. top1: 91.96. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8428. top1: 91.41. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8443. top1: 91.32. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8475. top1: 91.25. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8365. top1: 92.05. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8396. top1: 91.67. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8344. top1: 92.07. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8297. top1: 92.41. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8287. top1: 92.50. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.16it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8297. top1: 92.38. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:13,  4.16it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8297. top1: 92.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8280. top1: 92.46. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8289. top1: 92.53. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8283. top1: 92.43. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8276. top1: 92.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8297. top1: 92.56. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8277. top1: 92.61. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8240. top1: 92.93. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8213. top1: 93.10. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8186. top1: 93.12. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8236. top1: 92.67. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8236. top1: 92.71. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.02it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8236. top1: 92.71. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8270. top1: 92.63. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8241. top1: 92.78. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8236. top1: 92.71. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8224. top1: 92.74. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8466. top1: 91.60. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8592. top1: 90.91. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8732. top1: 90.26. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8911. top1: 89.29. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9169. top1: 88.28. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9255. top1: 87.84. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9382. top1: 87.34. top5: 99.67. :  43%|████▎     | 27/63 [00:02<00:01, 24.24it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9382. top1: 87.34. top5: 99.67. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9532. top1: 86.62. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9650. top1: 85.86. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9735. top1: 85.37. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9900. top1: 84.67. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0021. top1: 84.16. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0097. top1: 83.74. top5: 99.43. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0147. top1: 83.33. top5: 99.44. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0242. top1: 82.81. top5: 99.46. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0309. top1: 82.31. top5: 99.47. :  60%|██████    | 38/63 [00:02<00:00, 35.95it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0309. top1: 82.31. top5: 99.47. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0370. top1: 81.90. top5: 99.48. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0440. top1: 81.63. top5: 99.43. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0500. top1: 81.31. top5: 99.38. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0642. top1: 80.58. top5: 99.39. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0693. top1: 80.29. top5: 99.34. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0775. top1: 79.89. top5: 99.35. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0879. top1: 79.40. top5: 99.25. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0910. top1: 78.98. top5: 99.26. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0953. top1: 78.74. top5: 99.27. :  75%|███████▍  | 47/63 [00:02<00:00, 43.91it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0953. top1: 78.74. top5: 99.27. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1060. top1: 78.29. top5: 99.23. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1160. top1: 77.86. top5: 99.14. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1226. top1: 77.49. top5: 99.05. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1239. top1: 77.45. top5: 99.01. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1310. top1: 77.10. top5: 98.98. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1423. top1: 76.51. top5: 98.99. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1442. top1: 76.35. top5: 99.00. :  89%|████████▉ | 56/63 [00:02<00:00, 51.41it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1442. top1: 76.35. top5: 99.00. : 100%|██████████| 63/63 [00:02<00:00, 22.85it/s]
total : 5000  current step :  4800
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4801/5000. LR: 0.0003. Data: 1.96s. Batch: 2.09s. S_Loss: 0.9291. T_Loss: 4.3267. Mask: 0.8750. :   0%|          | 0/100 [00:02<?, ?it/s]Train Iter: 4801/5000. LR: 0.0003. Data: 1.96s. Batch: 2.09s. S_Loss: 0.9291. T_Loss: 4.3267. Mask: 0.8750. :   1%|          | 1/100 [00:02<03:26,  2.09s/it]Train Iter: 4802/5000. LR: 0.0003. Data: 0.99s. Batch: 1.10s. S_Loss: 1.0158. T_Loss: 4.8369. Mask: 0.9219. :   1%|          | 1/100 [00:02<03:26,  2.09s/it]Train Iter: 4802/5000. LR: 0.0003. Data: 0.99s. Batch: 1.10s. S_Loss: 1.0158. T_Loss: 4.8369. Mask: 0.9219. :   2%|▏         | 2/100 [00:02<01:31,  1.08it/s]Train Iter: 4803/5000. LR: 0.0003. Data: 0.66s. Batch: 0.78s. S_Loss: 1.0022. T_Loss: 4.9311. Mask: 0.9479. :   2%|▏         | 2/100 [00:02<01:31,  1.08it/s]Train Iter: 4803/5000. LR: 0.0003. Data: 0.66s. Batch: 0.78s. S_Loss: 1.0022. T_Loss: 4.9311. Mask: 0.9479. :   3%|▎         | 3/100 [00:02<00:54,  1.78it/s]Train Iter: 4804/5000. LR: 0.0003. Data: 0.49s. Batch: 0.61s. S_Loss: 0.9679. T_Loss: 4.8103. Mask: 0.9531. :   3%|▎         | 3/100 [00:02<00:54,  1.78it/s]Train Iter: 4804/5000. LR: 0.0003. Data: 0.49s. Batch: 0.61s. S_Loss: 0.9679. T_Loss: 4.8103. Mask: 0.9531. :   4%|▍         | 4/100 [00:02<00:37,  2.54it/s]Train Iter: 4805/5000. LR: 0.0003. Data: 0.40s. Batch: 0.56s. S_Loss: 0.9588. T_Loss: 4.7749. Mask: 0.9375. :   4%|▍         | 4/100 [00:02<00:37,  2.54it/s]Train Iter: 4805/5000. LR: 0.0003. Data: 0.40s. Batch: 0.56s. S_Loss: 0.9588. T_Loss: 4.7749. Mask: 0.9375. :   5%|▌         | 5/100 [00:02<00:35,  2.69it/s]Train Iter: 4806/5000. LR: 0.0003. Data: 0.33s. Batch: 0.49s. S_Loss: 0.9756. T_Loss: 4.8686. Mask: 0.9323. :   5%|▌         | 5/100 [00:02<00:35,  2.69it/s]Train Iter: 4806/5000. LR: 0.0003. Data: 0.33s. Batch: 0.49s. S_Loss: 0.9756. T_Loss: 4.8686. Mask: 0.9323. :   6%|▌         | 6/100 [00:02<00:26,  3.48it/s]Train Iter: 4807/5000. LR: 0.0003. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9570. T_Loss: 4.7274. Mask: 0.9330. :   6%|▌         | 6/100 [00:03<00:26,  3.48it/s]Train Iter: 4807/5000. LR: 0.0003. Data: 0.29s. Batch: 0.44s. S_Loss: 0.9570. T_Loss: 4.7274. Mask: 0.9330. :   7%|▋         | 7/100 [00:03<00:22,  4.18it/s]Train Iter: 4808/5000. LR: 0.0003. Data: 0.25s. Batch: 0.40s. S_Loss: 0.9537. T_Loss: 4.6881. Mask: 0.9336. :   7%|▋         | 7/100 [00:03<00:22,  4.18it/s]Train Iter: 4808/5000. LR: 0.0003. Data: 0.25s. Batch: 0.40s. S_Loss: 0.9537. T_Loss: 4.6881. Mask: 0.9336. :   8%|▊         | 8/100 [00:03<00:18,  4.96it/s]Train Iter: 4809/5000. LR: 0.0003. Data: 0.22s. Batch: 0.37s. S_Loss: 0.9595. T_Loss: 4.6215. Mask: 0.9306. :   8%|▊         | 8/100 [00:03<00:18,  4.96it/s]Train Iter: 4809/5000. LR: 0.0003. Data: 0.22s. Batch: 0.37s. S_Loss: 0.9595. T_Loss: 4.6215. Mask: 0.9306. :   9%|▉         | 9/100 [00:03<00:16,  5.58it/s]Train Iter: 4810/5000. LR: 0.0003. Data: 0.20s. Batch: 0.34s. S_Loss: 0.9544. T_Loss: 4.6050. Mask: 0.9313. :   9%|▉         | 9/100 [00:03<00:16,  5.58it/s]Train Iter: 4810/5000. LR: 0.0003. Data: 0.20s. Batch: 0.34s. S_Loss: 0.9544. T_Loss: 4.6050. Mask: 0.9313. :  10%|█         | 10/100 [00:03<00:14,  6.15it/s]Train Iter: 4811/5000. LR: 0.0002. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9414. T_Loss: 4.5005. Mask: 0.9233. :  10%|█         | 10/100 [00:03<00:14,  6.15it/s]Train Iter: 4811/5000. LR: 0.0002. Data: 0.18s. Batch: 0.32s. S_Loss: 0.9414. T_Loss: 4.5005. Mask: 0.9233. :  11%|█         | 11/100 [00:03<00:13,  6.58it/s]Train Iter: 4812/5000. LR: 0.0002. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9421. T_Loss: 4.5221. Mask: 0.9271. :  11%|█         | 11/100 [00:03<00:13,  6.58it/s]Train Iter: 4812/5000. LR: 0.0002. Data: 0.17s. Batch: 0.30s. S_Loss: 0.9421. T_Loss: 4.5221. Mask: 0.9271. :  12%|█▏        | 12/100 [00:03<00:12,  7.32it/s]Train Iter: 4813/5000. LR: 0.0002. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9425. T_Loss: 4.5567. Mask: 0.9303. :  12%|█▏        | 12/100 [00:03<00:12,  7.32it/s]Train Iter: 4813/5000. LR: 0.0002. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9425. T_Loss: 4.5567. Mask: 0.9303. :  13%|█▎        | 13/100 [00:03<00:11,  7.54it/s]Train Iter: 4814/5000. LR: 0.0002. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9430. T_Loss: 4.5739. Mask: 0.9353. :  13%|█▎        | 13/100 [00:03<00:11,  7.54it/s]Train Iter: 4814/5000. LR: 0.0002. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9430. T_Loss: 4.5739. Mask: 0.9353. :  14%|█▍        | 14/100 [00:03<00:11,  7.64it/s]Train Iter: 4815/5000. LR: 0.0002. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9413. T_Loss: 4.5796. Mask: 0.9354. :  14%|█▍        | 14/100 [00:04<00:11,  7.64it/s]Train Iter: 4815/5000. LR: 0.0002. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9413. T_Loss: 4.5796. Mask: 0.9354. :  15%|█▌        | 15/100 [00:04<00:15,  5.43it/s]Train Iter: 4816/5000. LR: 0.0002. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9437. T_Loss: 4.5407. Mask: 0.9355. :  15%|█▌        | 15/100 [00:04<00:15,  5.43it/s]Train Iter: 4816/5000. LR: 0.0002. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9437. T_Loss: 4.5407. Mask: 0.9355. :  16%|█▌        | 16/100 [00:04<00:13,  6.14it/s]Train Iter: 4817/5000. LR: 0.0002. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9391. T_Loss: 4.4594. Mask: 0.9320. :  16%|█▌        | 16/100 [00:04<00:13,  6.14it/s]Train Iter: 4817/5000. LR: 0.0002. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9391. T_Loss: 4.4594. Mask: 0.9320. :  17%|█▋        | 17/100 [00:04<00:12,  6.67it/s]Train Iter: 4818/5000. LR: 0.0002. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9364. T_Loss: 4.4814. Mask: 0.9340. :  17%|█▋        | 17/100 [00:04<00:12,  6.67it/s]Train Iter: 4818/5000. LR: 0.0002. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9364. T_Loss: 4.4814. Mask: 0.9340. :  18%|█▊        | 18/100 [00:04<00:11,  6.93it/s]Train Iter: 4819/5000. LR: 0.0002. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9381. T_Loss: 4.5259. Mask: 0.9326. :  18%|█▊        | 18/100 [00:04<00:11,  6.93it/s]Train Iter: 4819/5000. LR: 0.0002. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9381. T_Loss: 4.5259. Mask: 0.9326. :  19%|█▉        | 19/100 [00:04<00:16,  4.90it/s]Train Iter: 4820/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9343. T_Loss: 4.4992. Mask: 0.9344. :  19%|█▉        | 19/100 [00:05<00:16,  4.90it/s]Train Iter: 4820/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9343. T_Loss: 4.4992. Mask: 0.9344. :  20%|██        | 20/100 [00:05<00:14,  5.54it/s]Train Iter: 4821/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9318. T_Loss: 4.4997. Mask: 0.9360. :  20%|██        | 20/100 [00:05<00:14,  5.54it/s]Train Iter: 4821/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9318. T_Loss: 4.4997. Mask: 0.9360. :  21%|██        | 21/100 [00:05<00:13,  6.05it/s]Train Iter: 4822/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9355. T_Loss: 4.5197. Mask: 0.9347. :  21%|██        | 21/100 [00:05<00:13,  6.05it/s]Train Iter: 4822/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9355. T_Loss: 4.5197. Mask: 0.9347. :  22%|██▏       | 22/100 [00:05<00:12,  6.46it/s]Train Iter: 4823/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9346. T_Loss: 4.5013. Mask: 0.9321. :  22%|██▏       | 22/100 [00:05<00:12,  6.46it/s]Train Iter: 4823/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9346. T_Loss: 4.5013. Mask: 0.9321. :  23%|██▎       | 23/100 [00:05<00:11,  6.76it/s]Train Iter: 4824/5000. LR: 0.0002. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9379. T_Loss: 4.5045. Mask: 0.9336. :  23%|██▎       | 23/100 [00:05<00:11,  6.76it/s]Train Iter: 4824/5000. LR: 0.0002. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9379. T_Loss: 4.5045. Mask: 0.9336. :  24%|██▍       | 24/100 [00:05<00:10,  7.05it/s]Train Iter: 4825/5000. LR: 0.0002. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9413. T_Loss: 4.5314. Mask: 0.9337. :  24%|██▍       | 24/100 [00:05<00:10,  7.05it/s]Train Iter: 4825/5000. LR: 0.0002. Data: 0.08s. Batch: 0.24s. S_Loss: 0.9413. T_Loss: 4.5314. Mask: 0.9337. :  25%|██▌       | 25/100 [00:05<00:16,  4.59it/s]total : 5000  current step :  4801
total : 5000  current step :  4802
total : 5000  current step :  4803
total : 5000  current step :  4804
total : 5000  current step :  4805
total : 5000  current step :  4806
total : 5000  current step :  4807
total : 5000  current step :  4808
total : 5000  current step :  4809
total : 5000  current step :  4810
total : 5000  current step :  4811
total : 5000  current step :  4812
total : 5000  current step :  4813
total : 5000  current step :  4814
total : 5000  current step :  4815
total : 5000  current step :  4816
total : 5000  current step :  4817
total : 5000  current step :  4818
total : 5000  current step :  4819
total : 5000  current step :  4820
total : 5000  current step :  4821
total : 5000  current step :  4822
total : 5000  current step :  4823
total : 5000  current step :  4824
total : 5000  current step :  4825
Train Iter: 4826/5000. LR: 0.0002. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9393. T_Loss: 4.5068. Mask: 0.9339. :  25%|██▌       | 25/100 [00:08<00:16,  4.59it/s]Train Iter: 4826/5000. LR: 0.0002. Data: 0.16s. Batch: 0.31s. S_Loss: 0.9393. T_Loss: 4.5068. Mask: 0.9339. :  26%|██▌       | 26/100 [00:08<00:59,  1.24it/s]Train Iter: 4827/5000. LR: 0.0002. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9469. T_Loss: 4.5654. Mask: 0.9352. :  26%|██▌       | 26/100 [00:08<00:59,  1.24it/s]Train Iter: 4827/5000. LR: 0.0002. Data: 0.15s. Batch: 0.31s. S_Loss: 0.9469. T_Loss: 4.5654. Mask: 0.9352. :  27%|██▋       | 27/100 [00:08<00:43,  1.66it/s]Train Iter: 4828/5000. LR: 0.0002. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9489. T_Loss: 4.5709. Mask: 0.9342. :  27%|██▋       | 27/100 [00:08<00:43,  1.66it/s]Train Iter: 4828/5000. LR: 0.0002. Data: 0.15s. Batch: 0.30s. S_Loss: 0.9489. T_Loss: 4.5709. Mask: 0.9342. :  28%|██▊       | 28/100 [00:08<00:33,  2.17it/s]Train Iter: 4829/5000. LR: 0.0002. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9499. T_Loss: 4.5676. Mask: 0.9343. :  28%|██▊       | 28/100 [00:08<00:33,  2.17it/s]Train Iter: 4829/5000. LR: 0.0002. Data: 0.14s. Batch: 0.30s. S_Loss: 0.9499. T_Loss: 4.5676. Mask: 0.9343. :  29%|██▉       | 29/100 [00:08<00:29,  2.38it/s]Train Iter: 4830/5000. LR: 0.0002. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9492. T_Loss: 4.5814. Mask: 0.9354. :  29%|██▉       | 29/100 [00:08<00:29,  2.38it/s]Train Iter: 4831/5000. LR: 0.0002. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9481. T_Loss: 4.5820. Mask: 0.9355. :  30%|███       | 30/100 [00:08<00:29,  2.38it/s]Train Iter: 4831/5000. LR: 0.0002. Data: 0.13s. Batch: 0.29s. S_Loss: 0.9481. T_Loss: 4.5820. Mask: 0.9355. :  31%|███       | 31/100 [00:08<00:18,  3.81it/s]Train Iter: 4832/5000. LR: 0.0002. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9454. T_Loss: 4.5729. Mask: 0.9355. :  31%|███       | 31/100 [00:09<00:18,  3.81it/s]Train Iter: 4832/5000. LR: 0.0002. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9454. T_Loss: 4.5729. Mask: 0.9355. :  32%|███▏      | 32/100 [00:09<00:15,  4.32it/s]Train Iter: 4833/5000. LR: 0.0002. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9453. T_Loss: 4.5863. Mask: 0.9356. :  32%|███▏      | 32/100 [00:09<00:15,  4.32it/s]Train Iter: 4833/5000. LR: 0.0002. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9453. T_Loss: 4.5863. Mask: 0.9356. :  33%|███▎      | 33/100 [00:09<00:13,  4.91it/s]Train Iter: 4834/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9482. T_Loss: 4.5784. Mask: 0.9366. :  33%|███▎      | 33/100 [00:09<00:13,  4.91it/s]Train Iter: 4834/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9482. T_Loss: 4.5784. Mask: 0.9366. :  34%|███▍      | 34/100 [00:09<00:12,  5.46it/s]Train Iter: 4835/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9507. T_Loss: 4.5766. Mask: 0.9357. :  34%|███▍      | 34/100 [00:09<00:12,  5.46it/s]Train Iter: 4835/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9507. T_Loss: 4.5766. Mask: 0.9357. :  35%|███▌      | 35/100 [00:09<00:14,  4.38it/s]Train Iter: 4836/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9497. T_Loss: 4.5692. Mask: 0.9358. :  35%|███▌      | 35/100 [00:09<00:14,  4.38it/s]Train Iter: 4836/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9497. T_Loss: 4.5692. Mask: 0.9358. :  36%|███▌      | 36/100 [00:09<00:12,  4.96it/s]Train Iter: 4837/5000. LR: 0.0002. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9495. T_Loss: 4.5873. Mask: 0.9350. :  36%|███▌      | 36/100 [00:09<00:12,  4.96it/s]Train Iter: 4837/5000. LR: 0.0002. Data: 0.11s. Batch: 0.27s. S_Loss: 0.9495. T_Loss: 4.5873. Mask: 0.9350. :  37%|███▋      | 37/100 [00:09<00:11,  5.55it/s]Train Iter: 4838/5000. LR: 0.0002. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9481. T_Loss: 4.5900. Mask: 0.9350. :  37%|███▋      | 37/100 [00:10<00:11,  5.55it/s]Train Iter: 4838/5000. LR: 0.0002. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9481. T_Loss: 4.5900. Mask: 0.9350. :  38%|███▊      | 38/100 [00:10<00:10,  6.01it/s]Train Iter: 4839/5000. LR: 0.0002. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9512. T_Loss: 4.6013. Mask: 0.9343. :  38%|███▊      | 38/100 [00:10<00:10,  6.01it/s]Train Iter: 4839/5000. LR: 0.0002. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9512. T_Loss: 4.6013. Mask: 0.9343. :  39%|███▉      | 39/100 [00:10<00:10,  5.95it/s]Train Iter: 4840/5000. LR: 0.0002. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9511. T_Loss: 4.5992. Mask: 0.9344. :  39%|███▉      | 39/100 [00:10<00:10,  5.95it/s]Train Iter: 4840/5000. LR: 0.0002. Data: 0.10s. Batch: 0.26s. S_Loss: 0.9511. T_Loss: 4.5992. Mask: 0.9344. :  40%|████      | 40/100 [00:10<00:09,  6.48it/s]Train Iter: 4841/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9520. T_Loss: 4.6176. Mask: 0.9352. :  40%|████      | 40/100 [00:10<00:09,  6.48it/s]Train Iter: 4841/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9520. T_Loss: 4.6176. Mask: 0.9352. :  41%|████      | 41/100 [00:10<00:08,  6.91it/s]Train Iter: 4842/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9535. T_Loss: 4.6100. Mask: 0.9338. :  41%|████      | 41/100 [00:10<00:08,  6.91it/s]Train Iter: 4842/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9535. T_Loss: 4.6100. Mask: 0.9338. :  42%|████▏     | 42/100 [00:10<00:08,  7.13it/s]Train Iter: 4843/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9537. T_Loss: 4.6024. Mask: 0.9324. :  42%|████▏     | 42/100 [00:10<00:08,  7.13it/s]Train Iter: 4843/5000. LR: 0.0002. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9537. T_Loss: 4.6024. Mask: 0.9324. :  43%|████▎     | 43/100 [00:10<00:07,  7.31it/s]Train Iter: 4844/5000. LR: 0.0002. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9561. T_Loss: 4.5961. Mask: 0.9304. :  43%|████▎     | 43/100 [00:10<00:07,  7.31it/s]Train Iter: 4844/5000. LR: 0.0002. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9561. T_Loss: 4.5961. Mask: 0.9304. :  44%|████▍     | 44/100 [00:10<00:07,  7.32it/s]Train Iter: 4845/5000. LR: 0.0002. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9557. T_Loss: 4.6055. Mask: 0.9313. :  44%|████▍     | 44/100 [00:11<00:07,  7.32it/s]Train Iter: 4845/5000. LR: 0.0002. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9557. T_Loss: 4.6055. Mask: 0.9313. :  45%|████▌     | 45/100 [00:11<00:10,  5.29it/s]Train Iter: 4846/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9554. T_Loss: 4.5996. Mask: 0.9293. :  45%|████▌     | 45/100 [00:11<00:10,  5.29it/s]Train Iter: 4846/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9554. T_Loss: 4.5996. Mask: 0.9293. :  46%|████▌     | 46/100 [00:11<00:08,  6.15it/s]Train Iter: 4847/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9558. T_Loss: 4.5943. Mask: 0.9289. :  46%|████▌     | 46/100 [00:11<00:08,  6.15it/s]Train Iter: 4848/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9601. T_Loss: 4.5917. Mask: 0.9264. :  47%|████▋     | 47/100 [00:11<00:08,  6.15it/s]Train Iter: 4848/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9601. T_Loss: 4.5917. Mask: 0.9264. :  48%|████▊     | 48/100 [00:11<00:06,  8.00it/s]Train Iter: 4849/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9607. T_Loss: 4.5894. Mask: 0.9260. :  48%|████▊     | 48/100 [00:11<00:06,  8.00it/s]Train Iter: 4849/5000. LR: 0.0002. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9607. T_Loss: 4.5894. Mask: 0.9260. :  49%|████▉     | 49/100 [00:11<00:08,  6.23it/s]Train Iter: 4850/5000. LR: 0.0002. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9627. T_Loss: 4.5990. Mask: 0.9256. :  49%|████▉     | 49/100 [00:11<00:08,  6.23it/s]total : 5000  current step :  4826
total : 5000  current step :  4827
total : 5000  current step :  4828
total : 5000  current step :  4829
total : 5000  current step :  4830
total : 5000  current step :  4831
total : 5000  current step :  4832
total : 5000  current step :  4833
total : 5000  current step :  4834
total : 5000  current step :  4835
total : 5000  current step :  4836
total : 5000  current step :  4837
total : 5000  current step :  4838
total : 5000  current step :  4839
total : 5000  current step :  4840
total : 5000  current step :  4841
total : 5000  current step :  4842
total : 5000  current step :  4843
total : 5000  current step :  4844
total : 5000  current step :  4845
total : 5000  current step :  4846
total : 5000  current step :  4847
total : 5000  current step :  4848
total : 5000  current step :  4849
total : 5000  current step :  4850
Train Iter: 4851/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9620. T_Loss: 4.5761. Mask: 0.9246. :  50%|█████     | 50/100 [00:13<00:08,  6.23it/s]Train Iter: 4851/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9620. T_Loss: 4.5761. Mask: 0.9246. :  51%|█████     | 51/100 [00:13<00:26,  1.84it/s]Train Iter: 4852/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9612. T_Loss: 4.5587. Mask: 0.9237. :  51%|█████     | 51/100 [00:13<00:26,  1.84it/s]Train Iter: 4852/5000. LR: 0.0002. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9612. T_Loss: 4.5587. Mask: 0.9237. :  52%|█████▏    | 52/100 [00:13<00:21,  2.25it/s]Train Iter: 4853/5000. LR: 0.0002. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9620. T_Loss: 4.5732. Mask: 0.9239. :  52%|█████▏    | 52/100 [00:14<00:21,  2.25it/s]Train Iter: 4853/5000. LR: 0.0002. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9620. T_Loss: 4.5732. Mask: 0.9239. :  53%|█████▎    | 53/100 [00:14<00:17,  2.71it/s]Train Iter: 4854/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9632. T_Loss: 4.5760. Mask: 0.9242. :  53%|█████▎    | 53/100 [00:14<00:17,  2.71it/s]Train Iter: 4854/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9632. T_Loss: 4.5760. Mask: 0.9242. :  54%|█████▍    | 54/100 [00:14<00:14,  3.28it/s]Train Iter: 4855/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9609. T_Loss: 4.5691. Mask: 0.9256. :  54%|█████▍    | 54/100 [00:14<00:14,  3.28it/s]Train Iter: 4855/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9609. T_Loss: 4.5691. Mask: 0.9256. :  55%|█████▌    | 55/100 [00:14<00:14,  3.20it/s]Train Iter: 4856/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9589. T_Loss: 4.5528. Mask: 0.9241. :  55%|█████▌    | 55/100 [00:14<00:14,  3.20it/s]Train Iter: 4856/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9589. T_Loss: 4.5528. Mask: 0.9241. :  56%|█████▌    | 56/100 [00:14<00:11,  3.86it/s]Train Iter: 4857/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9581. T_Loss: 4.5445. Mask: 0.9238. :  56%|█████▌    | 56/100 [00:14<00:11,  3.86it/s]Train Iter: 4857/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9581. T_Loss: 4.5445. Mask: 0.9238. :  57%|█████▋    | 57/100 [00:14<00:09,  4.38it/s]Train Iter: 4858/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9576. T_Loss: 4.5435. Mask: 0.9230. :  57%|█████▋    | 57/100 [00:14<00:09,  4.38it/s]Train Iter: 4858/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9576. T_Loss: 4.5435. Mask: 0.9230. :  58%|█████▊    | 58/100 [00:14<00:08,  4.85it/s]Train Iter: 4859/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9596. T_Loss: 4.5591. Mask: 0.9211. :  58%|█████▊    | 58/100 [00:15<00:08,  4.85it/s]Train Iter: 4859/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9596. T_Loss: 4.5591. Mask: 0.9211. :  59%|█████▉    | 59/100 [00:15<00:09,  4.37it/s]Train Iter: 4860/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9593. T_Loss: 4.5548. Mask: 0.9208. :  59%|█████▉    | 59/100 [00:15<00:09,  4.37it/s]Train Iter: 4860/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9593. T_Loss: 4.5548. Mask: 0.9208. :  60%|██████    | 60/100 [00:15<00:07,  5.06it/s]Train Iter: 4861/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9590. T_Loss: 4.5595. Mask: 0.9221. :  60%|██████    | 60/100 [00:15<00:07,  5.06it/s]Train Iter: 4861/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9590. T_Loss: 4.5595. Mask: 0.9221. :  61%|██████    | 61/100 [00:15<00:06,  5.76it/s]Train Iter: 4862/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9581. T_Loss: 4.5590. Mask: 0.9224. :  61%|██████    | 61/100 [00:15<00:06,  5.76it/s]Train Iter: 4863/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9581. T_Loss: 4.5549. Mask: 0.9221. :  62%|██████▏   | 62/100 [00:15<00:06,  5.76it/s]Train Iter: 4863/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9581. T_Loss: 4.5549. Mask: 0.9221. :  63%|██████▎   | 63/100 [00:15<00:05,  6.98it/s]Train Iter: 4864/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9584. T_Loss: 4.5461. Mask: 0.9204. :  63%|██████▎   | 63/100 [00:15<00:05,  6.98it/s]Train Iter: 4864/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9584. T_Loss: 4.5461. Mask: 0.9204. :  64%|██████▍   | 64/100 [00:15<00:05,  7.20it/s]Train Iter: 4865/5000. LR: 0.0001. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9600. T_Loss: 4.5633. Mask: 0.9207. :  64%|██████▍   | 64/100 [00:15<00:05,  7.20it/s]Train Iter: 4865/5000. LR: 0.0001. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9600. T_Loss: 4.5633. Mask: 0.9207. :  65%|██████▌   | 65/100 [00:15<00:04,  7.42it/s]Train Iter: 4866/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9583. T_Loss: 4.5578. Mask: 0.9209. :  65%|██████▌   | 65/100 [00:16<00:04,  7.42it/s]Train Iter: 4866/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9583. T_Loss: 4.5578. Mask: 0.9209. :  66%|██████▌   | 66/100 [00:16<00:04,  7.45it/s]Train Iter: 4867/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9580. T_Loss: 4.5609. Mask: 0.9216. :  66%|██████▌   | 66/100 [00:16<00:04,  7.45it/s]Train Iter: 4867/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9580. T_Loss: 4.5609. Mask: 0.9216. :  67%|██████▋   | 67/100 [00:16<00:04,  7.51it/s]Train Iter: 4868/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9604. T_Loss: 4.5788. Mask: 0.9223. :  67%|██████▋   | 67/100 [00:16<00:04,  7.51it/s]Train Iter: 4868/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9604. T_Loss: 4.5788. Mask: 0.9223. :  68%|██████▊   | 68/100 [00:16<00:04,  7.47it/s]Train Iter: 4869/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9590. T_Loss: 4.5637. Mask: 0.9221. :  68%|██████▊   | 68/100 [00:16<00:04,  7.47it/s]Train Iter: 4869/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9590. T_Loss: 4.5637. Mask: 0.9221. :  69%|██████▉   | 69/100 [00:16<00:05,  5.55it/s]Train Iter: 4870/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9595. T_Loss: 4.5679. Mask: 0.9219. :  69%|██████▉   | 69/100 [00:16<00:05,  5.55it/s]Train Iter: 4870/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9595. T_Loss: 4.5679. Mask: 0.9219. :  70%|███████   | 70/100 [00:16<00:04,  6.12it/s]Train Iter: 4871/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9589. T_Loss: 4.5696. Mask: 0.9230. :  70%|███████   | 70/100 [00:16<00:04,  6.12it/s]Train Iter: 4871/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9589. T_Loss: 4.5696. Mask: 0.9230. :  71%|███████   | 71/100 [00:16<00:04,  6.46it/s]Train Iter: 4872/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9585. T_Loss: 4.5700. Mask: 0.9236. :  71%|███████   | 71/100 [00:17<00:04,  6.46it/s]Train Iter: 4872/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9585. T_Loss: 4.5700. Mask: 0.9236. :  72%|███████▏  | 72/100 [00:17<00:04,  6.87it/s]Train Iter: 4873/5000. LR: 0.0001. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9589. T_Loss: 4.5868. Mask: 0.9238. :  72%|███████▏  | 72/100 [00:17<00:04,  6.87it/s]Train Iter: 4873/5000. LR: 0.0001. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9589. T_Loss: 4.5868. Mask: 0.9238. :  73%|███████▎  | 73/100 [00:17<00:03,  7.45it/s]Train Iter: 4874/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9588. T_Loss: 4.5876. Mask: 0.9236. :  73%|███████▎  | 73/100 [00:17<00:03,  7.45it/s]Train Iter: 4874/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9588. T_Loss: 4.5876. Mask: 0.9236. :  74%|███████▍  | 74/100 [00:17<00:03,  7.65it/s]Train Iter: 4875/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9586. T_Loss: 4.5926. Mask: 0.9242. :  74%|███████▍  | 74/100 [00:17<00:03,  7.65it/s]Train Iter: 4875/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9586. T_Loss: 4.5926. Mask: 0.9242. :  75%|███████▌  | 75/100 [00:17<00:04,  5.07it/s]total : 5000  current step :  4851
total : 5000  current step :  4852
total : 5000  current step :  4853
total : 5000  current step :  4854
total : 5000  current step :  4855
total : 5000  current step :  4856
total : 5000  current step :  4857
total : 5000  current step :  4858
total : 5000  current step :  4859
total : 5000  current step :  4860
total : 5000  current step :  4861
total : 5000  current step :  4862
total : 5000  current step :  4863
total : 5000  current step :  4864
total : 5000  current step :  4865
total : 5000  current step :  4866
total : 5000  current step :  4867
total : 5000  current step :  4868
total : 5000  current step :  4869
total : 5000  current step :  4870
total : 5000  current step :  4871
total : 5000  current step :  4872
total : 5000  current step :  4873
total : 5000  current step :  4874
total : 5000  current step :  4875
Train Iter: 4876/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9608. T_Loss: 4.6064. Mask: 0.9239. :  75%|███████▌  | 75/100 [00:19<00:04,  5.07it/s]Train Iter: 4876/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9608. T_Loss: 4.6064. Mask: 0.9239. :  76%|███████▌  | 76/100 [00:19<00:17,  1.35it/s]Train Iter: 4877/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9596. T_Loss: 4.5927. Mask: 0.9233. :  76%|███████▌  | 76/100 [00:19<00:17,  1.35it/s]Train Iter: 4877/5000. LR: 0.0001. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9596. T_Loss: 4.5927. Mask: 0.9233. :  77%|███████▋  | 77/100 [00:19<00:12,  1.80it/s]Train Iter: 4878/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.6061. Mask: 0.9231. :  77%|███████▋  | 77/100 [00:19<00:12,  1.80it/s]Train Iter: 4878/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9615. T_Loss: 4.6061. Mask: 0.9231. :  78%|███████▊  | 78/100 [00:19<00:09,  2.38it/s]Train Iter: 4879/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9633. T_Loss: 4.6111. Mask: 0.9233. :  78%|███████▊  | 78/100 [00:20<00:09,  2.38it/s]Train Iter: 4879/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9633. T_Loss: 4.6111. Mask: 0.9233. :  79%|███████▉  | 79/100 [00:20<00:08,  2.52it/s]Train Iter: 4880/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9647. T_Loss: 4.6099. Mask: 0.9230. :  79%|███████▉  | 79/100 [00:20<00:08,  2.52it/s]Train Iter: 4880/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9647. T_Loss: 4.6099. Mask: 0.9230. :  80%|████████  | 80/100 [00:20<00:06,  3.24it/s]Train Iter: 4881/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6093. Mask: 0.9240. :  80%|████████  | 80/100 [00:20<00:06,  3.24it/s]Train Iter: 4881/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9634. T_Loss: 4.6093. Mask: 0.9240. :  81%|████████  | 81/100 [00:20<00:04,  3.99it/s]Train Iter: 4882/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9621. T_Loss: 4.6006. Mask: 0.9230. :  81%|████████  | 81/100 [00:20<00:04,  3.99it/s]Train Iter: 4882/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9621. T_Loss: 4.6006. Mask: 0.9230. :  82%|████████▏ | 82/100 [00:20<00:03,  4.71it/s]Train Iter: 4883/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9642. T_Loss: 4.6148. Mask: 0.9228. :  82%|████████▏ | 82/100 [00:20<00:03,  4.71it/s]Train Iter: 4883/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9642. T_Loss: 4.6148. Mask: 0.9228. :  83%|████████▎ | 83/100 [00:20<00:03,  5.32it/s]Train Iter: 4884/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9635. T_Loss: 4.6141. Mask: 0.9234. :  83%|████████▎ | 83/100 [00:20<00:03,  5.32it/s]Train Iter: 4884/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9635. T_Loss: 4.6141. Mask: 0.9234. :  84%|████████▍ | 84/100 [00:20<00:02,  5.80it/s]Train Iter: 4885/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9643. T_Loss: 4.6185. Mask: 0.9228. :  84%|████████▍ | 84/100 [00:21<00:02,  5.80it/s]Train Iter: 4885/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9643. T_Loss: 4.6185. Mask: 0.9228. :  85%|████████▌ | 85/100 [00:21<00:03,  4.07it/s]Train Iter: 4886/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9637. T_Loss: 4.6184. Mask: 0.9233. :  85%|████████▌ | 85/100 [00:21<00:03,  4.07it/s]Train Iter: 4886/5000. LR: 0.0001. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9637. T_Loss: 4.6184. Mask: 0.9233. :  86%|████████▌ | 86/100 [00:21<00:02,  4.73it/s]Train Iter: 4887/5000. LR: 0.0001. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9639. T_Loss: 4.6240. Mask: 0.9231. :  86%|████████▌ | 86/100 [00:21<00:02,  4.73it/s]Train Iter: 4887/5000. LR: 0.0001. Data: 0.09s. Batch: 0.25s. S_Loss: 0.9639. T_Loss: 4.6240. Mask: 0.9231. :  87%|████████▋ | 87/100 [00:21<00:02,  5.37it/s]Train Iter: 4888/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9647. T_Loss: 4.6249. Mask: 0.9222. :  87%|████████▋ | 87/100 [00:21<00:02,  5.37it/s]Train Iter: 4888/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9647. T_Loss: 4.6249. Mask: 0.9222. :  88%|████████▊ | 88/100 [00:21<00:02,  5.87it/s]Train Iter: 4889/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9640. T_Loss: 4.6191. Mask: 0.9221. :  88%|████████▊ | 88/100 [00:21<00:02,  5.87it/s]Train Iter: 4889/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9640. T_Loss: 4.6191. Mask: 0.9221. :  89%|████████▉ | 89/100 [00:21<00:01,  6.27it/s]Train Iter: 4890/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9649. T_Loss: 4.6300. Mask: 0.9219. :  89%|████████▉ | 89/100 [00:21<00:01,  6.27it/s]Train Iter: 4890/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9649. T_Loss: 4.6300. Mask: 0.9219. :  90%|█████████ | 90/100 [00:21<00:01,  6.72it/s]Train Iter: 4891/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9663. T_Loss: 4.6357. Mask: 0.9220. :  90%|█████████ | 90/100 [00:22<00:01,  6.72it/s]Train Iter: 4891/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9663. T_Loss: 4.6357. Mask: 0.9220. :  91%|█████████ | 91/100 [00:22<00:01,  6.95it/s]Train Iter: 4892/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9668. T_Loss: 4.6362. Mask: 0.9226. :  91%|█████████ | 91/100 [00:22<00:01,  6.95it/s]Train Iter: 4892/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9668. T_Loss: 4.6362. Mask: 0.9226. :  92%|█████████▏| 92/100 [00:22<00:01,  7.47it/s]Train Iter: 4893/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9665. T_Loss: 4.6340. Mask: 0.9220. :  92%|█████████▏| 92/100 [00:22<00:01,  7.47it/s]Train Iter: 4893/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9665. T_Loss: 4.6340. Mask: 0.9220. :  93%|█████████▎| 93/100 [00:22<00:00,  7.55it/s]Train Iter: 4894/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9689. T_Loss: 4.6483. Mask: 0.9219. :  93%|█████████▎| 93/100 [00:22<00:00,  7.55it/s]Train Iter: 4894/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9689. T_Loss: 4.6483. Mask: 0.9219. :  94%|█████████▍| 94/100 [00:22<00:00,  7.72it/s]Train Iter: 4895/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9677. T_Loss: 4.6435. Mask: 0.9220. :  94%|█████████▍| 94/100 [00:22<00:00,  7.72it/s]Train Iter: 4895/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9677. T_Loss: 4.6435. Mask: 0.9220. :  95%|█████████▌| 95/100 [00:22<00:00,  6.28it/s]Train Iter: 4896/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9673. T_Loss: 4.6444. Mask: 0.9229. :  95%|█████████▌| 95/100 [00:22<00:00,  6.28it/s]Train Iter: 4896/5000. LR: 0.0001. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9673. T_Loss: 4.6444. Mask: 0.9229. :  96%|█████████▌| 96/100 [00:22<00:00,  6.74it/s]Train Iter: 4897/5000. LR: 0.0001. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9681. T_Loss: 4.6525. Mask: 0.9233. :  96%|█████████▌| 96/100 [00:22<00:00,  6.74it/s]Train Iter: 4897/5000. LR: 0.0001. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9681. T_Loss: 4.6525. Mask: 0.9233. :  97%|█████████▋| 97/100 [00:22<00:00,  6.78it/s]Train Iter: 4898/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9690. T_Loss: 4.6524. Mask: 0.9228. :  97%|█████████▋| 97/100 [00:22<00:00,  6.78it/s]Train Iter: 4898/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9690. T_Loss: 4.6524. Mask: 0.9228. :  98%|█████████▊| 98/100 [00:22<00:00,  6.99it/s]Train Iter: 4899/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9681. T_Loss: 4.6475. Mask: 0.9236. :  98%|█████████▊| 98/100 [00:23<00:00,  6.99it/s]Train Iter: 4899/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9681. T_Loss: 4.6475. Mask: 0.9236. :  99%|█████████▉| 99/100 [00:23<00:00,  4.82it/s]Train Iter: 4900/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9686. T_Loss: 4.6533. Mask: 0.9241. :  99%|█████████▉| 99/100 [00:23<00:00,  4.82it/s]Train Iter: 4900/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9686. T_Loss: 4.6533. Mask: 0.9241. : 100%|██████████| 100/100 [00:23<00:00,  5.46it/s]Train Iter: 4900/5000. LR: 0.0001. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9686. T_Loss: 4.6533. Mask: 0.9241. : 100%|██████████| 100/100 [00:23<00:00,  4.26it/s]
total : 5000  current step :  4876
total : 5000  current step :  4877
total : 5000  current step :  4878
total : 5000  current step :  4879
total : 5000  current step :  4880
total : 5000  current step :  4881
total : 5000  current step :  4882
total : 5000  current step :  4883
total : 5000  current step :  4884
total : 5000  current step :  4885
total : 5000  current step :  4886
total : 5000  current step :  4887
total : 5000  current step :  4888
total : 5000  current step :  4889
total : 5000  current step :  4890
total : 5000  current step :  4891
total : 5000  current step :  4892
total : 5000  current step :  4893
total : 5000  current step :  4894
total : 5000  current step :  4895
total : 5000  current step :  4896
total : 5000  current step :  4897
total : 5000  current step :  4898
total : 5000  current step :  4899
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 0.8980. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 0.8980. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.88s. Loss: 0.8878. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.59s. Loss: 0.8581. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 0.8623. top1: 89.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 0.8476. top1: 91.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8438. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8438. top1: 91.67. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.8590. top1: 91.07. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8568. top1: 90.62. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8582. top1: 90.62. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8613. top1: 90.62. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8493. top1: 91.48. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8526. top1: 91.15. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8473. top1: 91.11. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8421. top1: 91.52. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8409. top1: 91.67. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.32it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8409. top1: 91.67. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.66it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8419. top1: 91.60. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.66it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8400. top1: 91.54. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.66it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8409. top1: 91.67. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.66it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8405. top1: 91.61. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.66it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8398. top1: 91.72. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.66it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8420. top1: 91.52. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.66it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8398. top1: 91.62. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:03, 12.66it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8398. top1: 91.62. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8357. top1: 91.98. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8329. top1: 92.19. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8300. top1: 92.25. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8354. top1: 91.71. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8355. top1: 91.78. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8392. top1: 91.63. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8360. top1: 91.81. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8354. top1: 91.77. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8341. top1: 91.83. top5: 100.00. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8571. top1: 90.82. top5: 99.90. :  35%|███▍      | 22/63 [00:02<00:02, 19.52it/s] Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8571. top1: 90.82. top5: 99.90. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8681. top1: 90.25. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8808. top1: 89.61. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8971. top1: 88.66. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9214. top1: 87.76. top5: 99.65. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9287. top1: 87.33. top5: 99.66. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9404. top1: 86.84. top5: 99.67. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9544. top1: 86.14. top5: 99.60. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9652. top1: 85.55. top5: 99.61. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9729. top1: 85.06. top5: 99.54. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.38. top5: 99.48. :  51%|█████     | 32/63 [00:02<00:00, 31.26it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.38. top5: 99.48. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0001. top1: 83.87. top5: 99.42. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0069. top1: 83.59. top5: 99.43. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0114. top1: 83.33. top5: 99.44. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0200. top1: 82.95. top5: 99.46. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0258. top1: 82.45. top5: 99.47. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0313. top1: 82.23. top5: 99.48. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0377. top1: 82.08. top5: 99.43. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0430. top1: 81.81. top5: 99.38. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0561. top1: 81.07. top5: 99.39. :  67%|██████▋   | 42/63 [00:02<00:00, 42.89it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0561. top1: 81.07. top5: 99.39. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0608. top1: 80.77. top5: 99.34. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0685. top1: 80.42. top5: 99.35. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0784. top1: 79.98. top5: 99.25. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0810. top1: 79.60. top5: 99.26. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0846. top1: 79.46. top5: 99.27. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0947. top1: 79.00. top5: 99.23. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1041. top1: 78.56. top5: 99.14. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1102. top1: 78.23. top5: 99.05. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1112. top1: 78.23. top5: 99.01. :  81%|████████  | 51/63 [00:02<00:00, 51.02it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1112. top1: 78.23. top5: 99.01. :  95%|█████████▌| 60/63 [00:02<00:00, 56.36it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1178. top1: 77.87. top5: 98.98. :  95%|█████████▌| 60/63 [00:02<00:00, 56.36it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1283. top1: 77.27. top5: 98.99. :  95%|█████████▌| 60/63 [00:02<00:00, 56.36it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1301. top1: 77.20. top5: 99.00. :  95%|█████████▌| 60/63 [00:02<00:00, 56.36it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1301. top1: 77.20. top5: 99.00. : 100%|██████████| 63/63 [00:02<00:00, 22.91it/s]
total : 5000  current step :  4900
  0%|          | 0/100 [00:00<?, ?it/s]Train Iter: 4901/5000. LR: 0.0001. Data: 1.84s. Batch: 1.97s. S_Loss: 0.9852. T_Loss: 4.8371. Mask: 0.9062. :   0%|          | 0/100 [00:01<?, ?it/s]Train Iter: 4901/5000. LR: 0.0001. Data: 1.84s. Batch: 1.97s. S_Loss: 0.9852. T_Loss: 4.8371. Mask: 0.9062. :   1%|          | 1/100 [00:01<03:14,  1.97s/it]Train Iter: 4902/5000. LR: 0.0001. Data: 0.92s. Batch: 1.05s. S_Loss: 0.9551. T_Loss: 4.6012. Mask: 0.9375. :   1%|          | 1/100 [00:02<03:14,  1.97s/it]Train Iter: 4902/5000. LR: 0.0001. Data: 0.92s. Batch: 1.05s. S_Loss: 0.9551. T_Loss: 4.6012. Mask: 0.9375. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 4903/5000. LR: 0.0001. Data: 0.62s. Batch: 0.74s. S_Loss: 0.9364. T_Loss: 4.4125. Mask: 0.9167. :   2%|▏         | 2/100 [00:02<01:27,  1.12it/s]Train Iter: 4903/5000. LR: 0.0001. Data: 0.62s. Batch: 0.74s. S_Loss: 0.9364. T_Loss: 4.4125. Mask: 0.9167. :   3%|▎         | 3/100 [00:02<00:52,  1.86it/s]Train Iter: 4904/5000. LR: 0.0001. Data: 0.46s. Batch: 0.58s. S_Loss: 0.9411. T_Loss: 4.3601. Mask: 0.9062. :   3%|▎         | 3/100 [00:02<00:52,  1.86it/s]Train Iter: 4904/5000. LR: 0.0001. Data: 0.46s. Batch: 0.58s. S_Loss: 0.9411. T_Loss: 4.3601. Mask: 0.9062. :   4%|▍         | 4/100 [00:02<00:35,  2.68it/s]Train Iter: 4905/5000. LR: 0.0001. Data: 0.37s. Batch: 0.53s. S_Loss: 0.9454. T_Loss: 4.4544. Mask: 0.9062. :   4%|▍         | 4/100 [00:02<00:35,  2.68it/s]Train Iter: 4905/5000. LR: 0.0001. Data: 0.37s. Batch: 0.53s. S_Loss: 0.9454. T_Loss: 4.4544. Mask: 0.9062. :   5%|▌         | 5/100 [00:02<00:34,  2.78it/s]Train Iter: 4906/5000. LR: 0.0001. Data: 0.31s. Batch: 0.47s. S_Loss: 0.9470. T_Loss: 4.3756. Mask: 0.9167. :   5%|▌         | 5/100 [00:02<00:34,  2.78it/s]Train Iter: 4906/5000. LR: 0.0001. Data: 0.31s. Batch: 0.47s. S_Loss: 0.9470. T_Loss: 4.3756. Mask: 0.9167. :   6%|▌         | 6/100 [00:02<00:27,  3.39it/s]Train Iter: 4907/5000. LR: 0.0001. Data: 0.27s. Batch: 0.43s. S_Loss: 0.9363. T_Loss: 4.3051. Mask: 0.9196. :   6%|▌         | 6/100 [00:03<00:27,  3.39it/s]Train Iter: 4907/5000. LR: 0.0001. Data: 0.27s. Batch: 0.43s. S_Loss: 0.9363. T_Loss: 4.3051. Mask: 0.9196. :   7%|▋         | 7/100 [00:03<00:23,  3.99it/s]Train Iter: 4908/5000. LR: 0.0001. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9382. T_Loss: 4.3192. Mask: 0.9219. :   7%|▋         | 7/100 [00:03<00:23,  3.99it/s]Train Iter: 4908/5000. LR: 0.0001. Data: 0.24s. Batch: 0.39s. S_Loss: 0.9382. T_Loss: 4.3192. Mask: 0.9219. :   8%|▊         | 8/100 [00:03<00:19,  4.74it/s]Train Iter: 4909/5000. LR: 0.0001. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9379. T_Loss: 4.4189. Mask: 0.9236. :   8%|▊         | 8/100 [00:03<00:19,  4.74it/s]Train Iter: 4909/5000. LR: 0.0001. Data: 0.21s. Batch: 0.36s. S_Loss: 0.9379. T_Loss: 4.4189. Mask: 0.9236. :   9%|▉         | 9/100 [00:03<00:16,  5.40it/s]Train Iter: 4910/5000. LR: 0.0001. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9349. T_Loss: 4.4621. Mask: 0.9187. :   9%|▉         | 9/100 [00:03<00:16,  5.40it/s]Train Iter: 4910/5000. LR: 0.0001. Data: 0.19s. Batch: 0.33s. S_Loss: 0.9349. T_Loss: 4.4621. Mask: 0.9187. :  10%|█         | 10/100 [00:03<00:14,  6.28it/s]Train Iter: 4911/5000. LR: 0.0001. Data: 0.17s. Batch: 0.31s. S_Loss: 0.9398. T_Loss: 4.4600. Mask: 0.9205. :  10%|█         | 10/100 [00:03<00:14,  6.28it/s]Train Iter: 4912/5000. LR: 0.0001. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9405. T_Loss: 4.4736. Mask: 0.9193. :  11%|█         | 11/100 [00:03<00:14,  6.28it/s]Train Iter: 4912/5000. LR: 0.0001. Data: 0.16s. Batch: 0.29s. S_Loss: 0.9405. T_Loss: 4.4736. Mask: 0.9193. :  12%|█▏        | 12/100 [00:03<00:11,  7.73it/s]Train Iter: 4913/5000. LR: 0.0001. Data: 0.15s. Batch: 0.28s. S_Loss: 0.9362. T_Loss: 4.4942. Mask: 0.9255. :  12%|█▏        | 12/100 [00:03<00:11,  7.73it/s]Train Iter: 4913/5000. LR: 0.0001. Data: 0.15s. Batch: 0.28s. S_Loss: 0.9362. T_Loss: 4.4942. Mask: 0.9255. :  13%|█▎        | 13/100 [00:03<00:11,  7.76it/s]Train Iter: 4914/5000. LR: 0.0001. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9372. T_Loss: 4.4867. Mask: 0.9241. :  13%|█▎        | 13/100 [00:03<00:11,  7.76it/s]Train Iter: 4914/5000. LR: 0.0001. Data: 0.14s. Batch: 0.27s. S_Loss: 0.9372. T_Loss: 4.4867. Mask: 0.9241. :  14%|█▍        | 14/100 [00:03<00:10,  7.99it/s]Train Iter: 4915/5000. LR: 0.0001. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9393. T_Loss: 4.5262. Mask: 0.9271. :  14%|█▍        | 14/100 [00:04<00:10,  7.99it/s]Train Iter: 4915/5000. LR: 0.0001. Data: 0.13s. Batch: 0.27s. S_Loss: 0.9393. T_Loss: 4.5262. Mask: 0.9271. :  15%|█▌        | 15/100 [00:04<00:15,  5.65it/s]Train Iter: 4916/5000. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9456. T_Loss: 4.5655. Mask: 0.9316. :  15%|█▌        | 15/100 [00:04<00:15,  5.65it/s]Train Iter: 4916/5000. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9456. T_Loss: 4.5655. Mask: 0.9316. :  16%|█▌        | 16/100 [00:04<00:14,  5.96it/s]Train Iter: 4917/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9463. T_Loss: 4.5876. Mask: 0.9320. :  16%|█▌        | 16/100 [00:04<00:14,  5.96it/s]Train Iter: 4917/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9463. T_Loss: 4.5876. Mask: 0.9320. :  17%|█▋        | 17/100 [00:04<00:13,  6.36it/s]Train Iter: 4918/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9432. T_Loss: 4.5756. Mask: 0.9323. :  17%|█▋        | 17/100 [00:04<00:13,  6.36it/s]Train Iter: 4918/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9432. T_Loss: 4.5756. Mask: 0.9323. :  18%|█▊        | 18/100 [00:04<00:12,  6.62it/s]Train Iter: 4919/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9389. T_Loss: 4.5520. Mask: 0.9326. :  18%|█▊        | 18/100 [00:04<00:12,  6.62it/s]Train Iter: 4919/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9389. T_Loss: 4.5520. Mask: 0.9326. :  19%|█▉        | 19/100 [00:04<00:16,  4.93it/s]Train Iter: 4920/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9419. T_Loss: 4.5991. Mask: 0.9344. :  19%|█▉        | 19/100 [00:04<00:16,  4.93it/s]Train Iter: 4920/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9419. T_Loss: 4.5991. Mask: 0.9344. :  20%|██        | 20/100 [00:04<00:14,  5.65it/s]Train Iter: 4921/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9462. T_Loss: 4.5863. Mask: 0.9286. :  20%|██        | 20/100 [00:05<00:14,  5.65it/s]Train Iter: 4921/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9462. T_Loss: 4.5863. Mask: 0.9286. :  21%|██        | 21/100 [00:05<00:12,  6.11it/s]Train Iter: 4922/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9481. T_Loss: 4.5585. Mask: 0.9290. :  21%|██        | 21/100 [00:05<00:12,  6.11it/s]Train Iter: 4922/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9481. T_Loss: 4.5585. Mask: 0.9290. :  22%|██▏       | 22/100 [00:05<00:12,  6.40it/s]Train Iter: 4923/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9452. T_Loss: 4.5580. Mask: 0.9321. :  22%|██▏       | 22/100 [00:05<00:12,  6.40it/s]Train Iter: 4923/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9452. T_Loss: 4.5580. Mask: 0.9321. :  23%|██▎       | 23/100 [00:05<00:11,  6.74it/s]Train Iter: 4924/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9479. T_Loss: 4.5661. Mask: 0.9297. :  23%|██▎       | 23/100 [00:05<00:11,  6.74it/s]Train Iter: 4924/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9479. T_Loss: 4.5661. Mask: 0.9297. :  24%|██▍       | 24/100 [00:05<00:10,  7.08it/s]Train Iter: 4925/5000. LR: 0.0000. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9438. T_Loss: 4.5179. Mask: 0.9287. :  24%|██▍       | 24/100 [00:05<00:10,  7.08it/s]Train Iter: 4925/5000. LR: 0.0000. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9438. T_Loss: 4.5179. Mask: 0.9287. :  25%|██▌       | 25/100 [00:05<00:10,  7.22it/s]total : 5000  current step :  4901
total : 5000  current step :  4902
total : 5000  current step :  4903
total : 5000  current step :  4904
total : 5000  current step :  4905
total : 5000  current step :  4906
total : 5000  current step :  4907
total : 5000  current step :  4908
total : 5000  current step :  4909
total : 5000  current step :  4910
total : 5000  current step :  4911
total : 5000  current step :  4912
total : 5000  current step :  4913
total : 5000  current step :  4914
total : 5000  current step :  4915
total : 5000  current step :  4916
total : 5000  current step :  4917
total : 5000  current step :  4918
total : 5000  current step :  4919
total : 5000  current step :  4920
total : 5000  current step :  4921
total : 5000  current step :  4922
total : 5000  current step :  4923
total : 5000  current step :  4924
total : 5000  current step :  4925
Train Iter: 4926/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9456. T_Loss: 4.5255. Mask: 0.9279. :  25%|██▌       | 25/100 [00:07<00:10,  7.22it/s]Train Iter: 4926/5000. LR: 0.0000. Data: 0.15s. Batch: 0.29s. S_Loss: 0.9456. T_Loss: 4.5255. Mask: 0.9279. :  26%|██▌       | 26/100 [00:07<00:51,  1.44it/s]Train Iter: 4927/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9432. T_Loss: 4.5047. Mask: 0.9271. :  26%|██▌       | 26/100 [00:07<00:51,  1.44it/s]Train Iter: 4927/5000. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 0.9432. T_Loss: 4.5047. Mask: 0.9271. :  27%|██▋       | 27/100 [00:07<00:38,  1.91it/s]Train Iter: 4928/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9412. T_Loss: 4.5289. Mask: 0.9286. :  27%|██▋       | 27/100 [00:07<00:38,  1.91it/s]Train Iter: 4928/5000. LR: 0.0000. Data: 0.14s. Batch: 0.28s. S_Loss: 0.9412. T_Loss: 4.5289. Mask: 0.9286. :  28%|██▊       | 28/100 [00:07<00:29,  2.45it/s]Train Iter: 4929/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9383. T_Loss: 4.5240. Mask: 0.9278. :  28%|██▊       | 28/100 [00:08<00:29,  2.45it/s]Train Iter: 4929/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9383. T_Loss: 4.5240. Mask: 0.9278. :  29%|██▉       | 29/100 [00:08<00:27,  2.54it/s]Train Iter: 4930/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9353. T_Loss: 4.5086. Mask: 0.9281. :  29%|██▉       | 29/100 [00:08<00:27,  2.54it/s]Train Iter: 4930/5000. LR: 0.0000. Data: 0.13s. Batch: 0.28s. S_Loss: 0.9353. T_Loss: 4.5086. Mask: 0.9281. :  30%|███       | 30/100 [00:08<00:22,  3.18it/s]Train Iter: 4931/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9346. T_Loss: 4.4814. Mask: 0.9274. :  30%|███       | 30/100 [00:08<00:22,  3.18it/s]Train Iter: 4931/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9346. T_Loss: 4.4814. Mask: 0.9274. :  31%|███       | 31/100 [00:08<00:17,  3.88it/s]Train Iter: 4932/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9339. T_Loss: 4.4917. Mask: 0.9297. :  31%|███       | 31/100 [00:08<00:17,  3.88it/s]Train Iter: 4932/5000. LR: 0.0000. Data: 0.12s. Batch: 0.27s. S_Loss: 0.9339. T_Loss: 4.4917. Mask: 0.9297. :  32%|███▏      | 32/100 [00:08<00:14,  4.71it/s]Train Iter: 4933/5000. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9359. T_Loss: 4.4932. Mask: 0.9290. :  32%|███▏      | 32/100 [00:08<00:14,  4.71it/s]Train Iter: 4933/5000. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 0.9359. T_Loss: 4.4932. Mask: 0.9290. :  33%|███▎      | 33/100 [00:08<00:12,  5.40it/s]Train Iter: 4934/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9341. T_Loss: 4.4900. Mask: 0.9311. :  33%|███▎      | 33/100 [00:08<00:12,  5.40it/s]Train Iter: 4934/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9341. T_Loss: 4.4900. Mask: 0.9311. :  34%|███▍      | 34/100 [00:08<00:11,  5.98it/s]Train Iter: 4935/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9317. T_Loss: 4.4590. Mask: 0.9295. :  34%|███▍      | 34/100 [00:08<00:11,  5.98it/s]Train Iter: 4935/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9317. T_Loss: 4.4590. Mask: 0.9295. :  35%|███▌      | 35/100 [00:08<00:10,  6.41it/s]Train Iter: 4936/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9316. T_Loss: 4.4617. Mask: 0.9297. :  35%|███▌      | 35/100 [00:09<00:10,  6.41it/s]Train Iter: 4936/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9316. T_Loss: 4.4617. Mask: 0.9297. :  36%|███▌      | 36/100 [00:09<00:09,  6.89it/s]Train Iter: 4937/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.4336. Mask: 0.9282. :  36%|███▌      | 36/100 [00:09<00:09,  6.89it/s]Train Iter: 4937/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.4336. Mask: 0.9282. :  37%|███▋      | 37/100 [00:09<00:09,  6.82it/s]Train Iter: 4938/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9257. T_Loss: 4.4200. Mask: 0.9285. :  37%|███▋      | 37/100 [00:09<00:09,  6.82it/s]Train Iter: 4938/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9257. T_Loss: 4.4200. Mask: 0.9285. :  38%|███▊      | 38/100 [00:09<00:09,  6.29it/s]Train Iter: 4939/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9265. T_Loss: 4.4153. Mask: 0.9271. :  38%|███▊      | 38/100 [00:09<00:09,  6.29it/s]Train Iter: 4939/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9265. T_Loss: 4.4153. Mask: 0.9271. :  39%|███▉      | 39/100 [00:09<00:12,  4.94it/s]Train Iter: 4940/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9251. T_Loss: 4.4116. Mask: 0.9273. :  39%|███▉      | 39/100 [00:09<00:12,  4.94it/s]Train Iter: 4940/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9251. T_Loss: 4.4116. Mask: 0.9273. :  40%|████      | 40/100 [00:09<00:11,  5.42it/s]Train Iter: 4941/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9252. T_Loss: 4.4094. Mask: 0.9276. :  40%|████      | 40/100 [00:09<00:11,  5.42it/s]Train Iter: 4941/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9252. T_Loss: 4.4094. Mask: 0.9276. :  41%|████      | 41/100 [00:09<00:09,  6.24it/s]Train Iter: 4942/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9244. T_Loss: 4.4117. Mask: 0.9286. :  41%|████      | 41/100 [00:10<00:09,  6.24it/s]Train Iter: 4942/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9244. T_Loss: 4.4117. Mask: 0.9286. :  42%|████▏     | 42/100 [00:10<00:08,  6.94it/s]Train Iter: 4943/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9239. T_Loss: 4.4077. Mask: 0.9288. :  42%|████▏     | 42/100 [00:10<00:08,  6.94it/s]Train Iter: 4943/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9239. T_Loss: 4.4077. Mask: 0.9288. :  43%|████▎     | 43/100 [00:10<00:07,  7.46it/s]Train Iter: 4944/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9230. T_Loss: 4.4124. Mask: 0.9290. :  43%|████▎     | 43/100 [00:10<00:07,  7.46it/s]Train Iter: 4944/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9230. T_Loss: 4.4124. Mask: 0.9290. :  44%|████▍     | 44/100 [00:10<00:07,  7.51it/s]Train Iter: 4945/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9247. T_Loss: 4.4297. Mask: 0.9292. :  44%|████▍     | 44/100 [00:10<00:07,  7.51it/s]Train Iter: 4945/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9247. T_Loss: 4.4297. Mask: 0.9292. :  45%|████▌     | 45/100 [00:10<00:09,  5.58it/s]Train Iter: 4946/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9249. T_Loss: 4.4201. Mask: 0.9280. :  45%|████▌     | 45/100 [00:10<00:09,  5.58it/s]Train Iter: 4946/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9249. T_Loss: 4.4201. Mask: 0.9280. :  46%|████▌     | 46/100 [00:10<00:08,  6.17it/s]Train Iter: 4947/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9237. T_Loss: 4.3957. Mask: 0.9262. :  46%|████▌     | 46/100 [00:10<00:08,  6.17it/s]Train Iter: 4947/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9237. T_Loss: 4.3957. Mask: 0.9262. :  47%|████▋     | 47/100 [00:10<00:07,  6.67it/s]Train Iter: 4948/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9230. T_Loss: 4.3963. Mask: 0.9264. :  47%|████▋     | 47/100 [00:10<00:07,  6.67it/s]Train Iter: 4948/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9230. T_Loss: 4.3963. Mask: 0.9264. :  48%|████▊     | 48/100 [00:10<00:07,  7.02it/s]Train Iter: 4949/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9222. T_Loss: 4.3962. Mask: 0.9267. :  48%|████▊     | 48/100 [00:11<00:07,  7.02it/s]Train Iter: 4949/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9222. T_Loss: 4.3962. Mask: 0.9267. :  49%|████▉     | 49/100 [00:11<00:06,  7.38it/s]Train Iter: 4950/5000. LR: 0.0000. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9235. T_Loss: 4.4055. Mask: 0.9275. :  49%|████▉     | 49/100 [00:11<00:06,  7.38it/s]Train Iter: 4950/5000. LR: 0.0000. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9235. T_Loss: 4.4055. Mask: 0.9275. :  50%|█████     | 50/100 [00:11<00:06,  7.35it/s]total : 5000  current step :  4926
total : 5000  current step :  4927
total : 5000  current step :  4928
total : 5000  current step :  4929
total : 5000  current step :  4930
total : 5000  current step :  4931
total : 5000  current step :  4932
total : 5000  current step :  4933
total : 5000  current step :  4934
total : 5000  current step :  4935
total : 5000  current step :  4936
total : 5000  current step :  4937
total : 5000  current step :  4938
total : 5000  current step :  4939
total : 5000  current step :  4940
total : 5000  current step :  4941
total : 5000  current step :  4942
total : 5000  current step :  4943
total : 5000  current step :  4944
total : 5000  current step :  4945
total : 5000  current step :  4946
total : 5000  current step :  4947
total : 5000  current step :  4948
total : 5000  current step :  4949
total : 5000  current step :  4950
Train Iter: 4951/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9247. T_Loss: 4.4232. Mask: 0.9283. :  50%|█████     | 50/100 [00:13<00:06,  7.35it/s]Train Iter: 4951/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9247. T_Loss: 4.4232. Mask: 0.9283. :  51%|█████     | 51/100 [00:13<00:33,  1.45it/s]Train Iter: 4952/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9271. T_Loss: 4.4427. Mask: 0.9291. :  51%|█████     | 51/100 [00:13<00:33,  1.45it/s]Train Iter: 4952/5000. LR: 0.0000. Data: 0.11s. Batch: 0.26s. S_Loss: 0.9271. T_Loss: 4.4427. Mask: 0.9291. :  52%|█████▏    | 52/100 [00:13<00:25,  1.90it/s]Train Iter: 4953/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9306. T_Loss: 4.4619. Mask: 0.9292. :  52%|█████▏    | 52/100 [00:13<00:25,  1.90it/s]Train Iter: 4953/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9306. T_Loss: 4.4619. Mask: 0.9292. :  53%|█████▎    | 53/100 [00:13<00:19,  2.45it/s]Train Iter: 4954/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9304. T_Loss: 4.4726. Mask: 0.9300. :  53%|█████▎    | 53/100 [00:13<00:19,  2.45it/s]Train Iter: 4954/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9304. T_Loss: 4.4726. Mask: 0.9300. :  54%|█████▍    | 54/100 [00:13<00:15,  3.01it/s]Train Iter: 4955/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9308. T_Loss: 4.4701. Mask: 0.9284. :  54%|█████▍    | 54/100 [00:14<00:15,  3.01it/s]Train Iter: 4955/5000. LR: 0.0000. Data: 0.11s. Batch: 0.25s. S_Loss: 0.9308. T_Loss: 4.4701. Mask: 0.9284. :  55%|█████▌    | 55/100 [00:14<00:16,  2.76it/s]Train Iter: 4956/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9299. T_Loss: 4.4698. Mask: 0.9291. :  55%|█████▌    | 55/100 [00:14<00:16,  2.76it/s]Train Iter: 4956/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9299. T_Loss: 4.4698. Mask: 0.9291. :  56%|█████▌    | 56/100 [00:14<00:12,  3.40it/s]Train Iter: 4957/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.4602. Mask: 0.9293. :  56%|█████▌    | 56/100 [00:14<00:12,  3.40it/s]Train Iter: 4957/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.4602. Mask: 0.9293. :  57%|█████▋    | 57/100 [00:14<00:10,  4.11it/s]Train Iter: 4958/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.4636. Mask: 0.9294. :  57%|█████▋    | 57/100 [00:14<00:10,  4.11it/s]Train Iter: 4958/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9290. T_Loss: 4.4636. Mask: 0.9294. :  58%|█████▊    | 58/100 [00:14<00:08,  4.76it/s]Train Iter: 4959/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9271. T_Loss: 4.4478. Mask: 0.9296. :  58%|█████▊    | 58/100 [00:14<00:08,  4.76it/s]Train Iter: 4959/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9271. T_Loss: 4.4478. Mask: 0.9296. :  59%|█████▉    | 59/100 [00:14<00:09,  4.33it/s]Train Iter: 4960/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9276. T_Loss: 4.4538. Mask: 0.9297. :  59%|█████▉    | 59/100 [00:14<00:09,  4.33it/s]Train Iter: 4961/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9269. T_Loss: 4.4498. Mask: 0.9293. :  60%|██████    | 60/100 [00:14<00:09,  4.33it/s]Train Iter: 4961/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9269. T_Loss: 4.4498. Mask: 0.9293. :  61%|██████    | 61/100 [00:14<00:06,  5.78it/s]Train Iter: 4962/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9262. T_Loss: 4.4468. Mask: 0.9299. :  61%|██████    | 61/100 [00:15<00:06,  5.78it/s]Train Iter: 4962/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9262. T_Loss: 4.4468. Mask: 0.9299. :  62%|██████▏   | 62/100 [00:15<00:05,  6.44it/s]Train Iter: 4963/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9267. T_Loss: 4.4473. Mask: 0.9301. :  62%|██████▏   | 62/100 [00:15<00:05,  6.44it/s]Train Iter: 4963/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9267. T_Loss: 4.4473. Mask: 0.9301. :  63%|██████▎   | 63/100 [00:15<00:05,  6.73it/s]Train Iter: 4964/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9256. T_Loss: 4.4404. Mask: 0.9302. :  63%|██████▎   | 63/100 [00:15<00:05,  6.73it/s]Train Iter: 4964/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9256. T_Loss: 4.4404. Mask: 0.9302. :  64%|██████▍   | 64/100 [00:15<00:05,  7.07it/s]Train Iter: 4965/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9275. T_Loss: 4.4591. Mask: 0.9303. :  64%|██████▍   | 64/100 [00:15<00:05,  7.07it/s]Train Iter: 4965/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9275. T_Loss: 4.4591. Mask: 0.9303. :  65%|██████▌   | 65/100 [00:15<00:04,  7.30it/s]Train Iter: 4966/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9274. T_Loss: 4.4590. Mask: 0.9295. :  65%|██████▌   | 65/100 [00:15<00:04,  7.30it/s]Train Iter: 4966/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9274. T_Loss: 4.4590. Mask: 0.9295. :  66%|██████▌   | 66/100 [00:15<00:04,  7.13it/s]Train Iter: 4967/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9263. T_Loss: 4.4502. Mask: 0.9296. :  66%|██████▌   | 66/100 [00:15<00:04,  7.13it/s]Train Iter: 4967/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9263. T_Loss: 4.4502. Mask: 0.9296. :  67%|██████▋   | 67/100 [00:15<00:04,  7.40it/s]Train Iter: 4968/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9259. T_Loss: 4.4401. Mask: 0.9288. :  67%|██████▋   | 67/100 [00:15<00:04,  7.40it/s]Train Iter: 4968/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9259. T_Loss: 4.4401. Mask: 0.9288. :  68%|██████▊   | 68/100 [00:15<00:04,  7.61it/s]Train Iter: 4969/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9261. T_Loss: 4.4430. Mask: 0.9284. :  68%|██████▊   | 68/100 [00:16<00:04,  7.61it/s]Train Iter: 4969/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9261. T_Loss: 4.4430. Mask: 0.9284. :  69%|██████▉   | 69/100 [00:16<00:05,  5.77it/s]Train Iter: 4970/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9264. T_Loss: 4.4400. Mask: 0.9290. :  69%|██████▉   | 69/100 [00:16<00:05,  5.77it/s]Train Iter: 4970/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9264. T_Loss: 4.4400. Mask: 0.9290. :  70%|███████   | 70/100 [00:16<00:04,  6.24it/s]Train Iter: 4971/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9293. T_Loss: 4.4530. Mask: 0.9287. :  70%|███████   | 70/100 [00:16<00:04,  6.24it/s]Train Iter: 4971/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9293. T_Loss: 4.4530. Mask: 0.9287. :  71%|███████   | 71/100 [00:16<00:04,  6.53it/s]Train Iter: 4972/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9292. T_Loss: 4.4524. Mask: 0.9275. :  71%|███████   | 71/100 [00:16<00:04,  6.53it/s]Train Iter: 4972/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9292. T_Loss: 4.4524. Mask: 0.9275. :  72%|███████▏  | 72/100 [00:16<00:04,  6.89it/s]Train Iter: 4973/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9304. T_Loss: 4.4585. Mask: 0.9277. :  72%|███████▏  | 72/100 [00:16<00:04,  6.89it/s]Train Iter: 4973/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9304. T_Loss: 4.4585. Mask: 0.9277. :  73%|███████▎  | 73/100 [00:16<00:03,  7.14it/s]Train Iter: 4974/5000. LR: 0.0000. Data: 0.08s. Batch: 0.22s. S_Loss: 0.9313. T_Loss: 4.4611. Mask: 0.9278. :  73%|███████▎  | 73/100 [00:16<00:03,  7.14it/s]Train Iter: 4975/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9308. T_Loss: 4.4553. Mask: 0.9279. :  74%|███████▍  | 74/100 [00:17<00:03,  7.14it/s]Train Iter: 4975/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9308. T_Loss: 4.4553. Mask: 0.9279. :  75%|███████▌  | 75/100 [00:17<00:04,  6.09it/s]total : 5000  current step :  4951
total : 5000  current step :  4952
total : 5000  current step :  4953
total : 5000  current step :  4954
total : 5000  current step :  4955
total : 5000  current step :  4956
total : 5000  current step :  4957
total : 5000  current step :  4958
total : 5000  current step :  4959
total : 5000  current step :  4960
total : 5000  current step :  4961
total : 5000  current step :  4962
total : 5000  current step :  4963
total : 5000  current step :  4964
total : 5000  current step :  4965
total : 5000  current step :  4966
total : 5000  current step :  4967
total : 5000  current step :  4968
total : 5000  current step :  4969
total : 5000  current step :  4970
total : 5000  current step :  4971
total : 5000  current step :  4972
total : 5000  current step :  4973
total : 5000  current step :  4974
total : 5000  current step :  4975
Train Iter: 4976/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9314. T_Loss: 4.4595. Mask: 0.9276. :  75%|███████▌  | 75/100 [00:19<00:04,  6.09it/s]Train Iter: 4976/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9314. T_Loss: 4.4595. Mask: 0.9276. :  76%|███████▌  | 76/100 [00:19<00:15,  1.54it/s]Train Iter: 4977/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9310. T_Loss: 4.4564. Mask: 0.9278. :  76%|███████▌  | 76/100 [00:19<00:15,  1.54it/s]Train Iter: 4977/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9310. T_Loss: 4.4564. Mask: 0.9278. :  77%|███████▋  | 77/100 [00:19<00:11,  1.93it/s]Train Iter: 4978/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9319. T_Loss: 4.4611. Mask: 0.9279. :  77%|███████▋  | 77/100 [00:19<00:11,  1.93it/s]Train Iter: 4979/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9329. T_Loss: 4.4644. Mask: 0.9272. :  78%|███████▊  | 78/100 [00:19<00:11,  1.93it/s]Train Iter: 4979/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9329. T_Loss: 4.4644. Mask: 0.9272. :  79%|███████▉  | 79/100 [00:19<00:08,  2.54it/s]Train Iter: 4980/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9347. T_Loss: 4.4768. Mask: 0.9273. :  79%|███████▉  | 79/100 [00:19<00:08,  2.54it/s]Train Iter: 4980/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9347. T_Loss: 4.4768. Mask: 0.9273. :  80%|████████  | 80/100 [00:19<00:06,  3.01it/s]Train Iter: 4981/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9355. T_Loss: 4.4872. Mask: 0.9279. :  80%|████████  | 80/100 [00:20<00:06,  3.01it/s]Train Iter: 4981/5000. LR: 0.0000. Data: 0.10s. Batch: 0.25s. S_Loss: 0.9355. T_Loss: 4.4872. Mask: 0.9279. :  81%|████████  | 81/100 [00:20<00:05,  3.53it/s]Train Iter: 4982/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9376. T_Loss: 4.4943. Mask: 0.9272. :  81%|████████  | 81/100 [00:20<00:05,  3.53it/s]Train Iter: 4982/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9376. T_Loss: 4.4943. Mask: 0.9272. :  82%|████████▏ | 82/100 [00:20<00:04,  4.07it/s]Train Iter: 4983/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9384. T_Loss: 4.5052. Mask: 0.9270. :  82%|████████▏ | 82/100 [00:20<00:04,  4.07it/s]Train Iter: 4983/5000. LR: 0.0000. Data: 0.10s. Batch: 0.24s. S_Loss: 0.9384. T_Loss: 4.5052. Mask: 0.9270. :  83%|████████▎ | 83/100 [00:20<00:03,  4.73it/s]Train Iter: 4984/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9387. T_Loss: 4.5000. Mask: 0.9271. :  83%|████████▎ | 83/100 [00:20<00:03,  4.73it/s]Train Iter: 4984/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9387. T_Loss: 4.5000. Mask: 0.9271. :  84%|████████▍ | 84/100 [00:20<00:02,  5.37it/s]Train Iter: 4985/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9379. T_Loss: 4.5031. Mask: 0.9272. :  84%|████████▍ | 84/100 [00:20<00:02,  5.37it/s]Train Iter: 4985/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9379. T_Loss: 4.5031. Mask: 0.9272. :  85%|████████▌ | 85/100 [00:20<00:03,  4.25it/s]Train Iter: 4986/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9382. T_Loss: 4.4997. Mask: 0.9262. :  85%|████████▌ | 85/100 [00:20<00:03,  4.25it/s]Train Iter: 4986/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9382. T_Loss: 4.4997. Mask: 0.9262. :  86%|████████▌ | 86/100 [00:20<00:02,  4.91it/s]Train Iter: 4987/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9382. T_Loss: 4.4935. Mask: 0.9260. :  86%|████████▌ | 86/100 [00:21<00:02,  4.91it/s]Train Iter: 4987/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9382. T_Loss: 4.4935. Mask: 0.9260. :  87%|████████▋ | 87/100 [00:21<00:02,  5.53it/s]Train Iter: 4988/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9388. T_Loss: 4.4937. Mask: 0.9254. :  87%|████████▋ | 87/100 [00:21<00:02,  5.53it/s]Train Iter: 4988/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9388. T_Loss: 4.4937. Mask: 0.9254. :  88%|████████▊ | 88/100 [00:21<00:01,  6.09it/s]Train Iter: 4989/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4999. Mask: 0.9256. :  88%|████████▊ | 88/100 [00:21<00:01,  6.09it/s]Train Iter: 4989/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4999. Mask: 0.9256. :  89%|████████▉ | 89/100 [00:21<00:02,  4.74it/s]Train Iter: 4990/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9391. T_Loss: 4.4969. Mask: 0.9253. :  89%|████████▉ | 89/100 [00:21<00:02,  4.74it/s]Train Iter: 4990/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9391. T_Loss: 4.4969. Mask: 0.9253. :  90%|█████████ | 90/100 [00:21<00:01,  5.30it/s]Train Iter: 4991/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9392. T_Loss: 4.4991. Mask: 0.9258. :  90%|█████████ | 90/100 [00:21<00:01,  5.30it/s]Train Iter: 4991/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9392. T_Loss: 4.4991. Mask: 0.9258. :  91%|█████████ | 91/100 [00:21<00:01,  5.77it/s]Train Iter: 4992/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4996. Mask: 0.9263. :  91%|█████████ | 91/100 [00:21<00:01,  5.77it/s]Train Iter: 4992/5000. LR: 0.0000. Data: 0.09s. Batch: 0.24s. S_Loss: 0.9390. T_Loss: 4.4996. Mask: 0.9263. :  92%|█████████▏| 92/100 [00:21<00:01,  6.45it/s]Train Iter: 4993/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9383. T_Loss: 4.4953. Mask: 0.9261. :  92%|█████████▏| 92/100 [00:21<00:01,  6.45it/s]Train Iter: 4993/5000. LR: 0.0000. Data: 0.09s. Batch: 0.23s. S_Loss: 0.9383. T_Loss: 4.4953. Mask: 0.9261. :  93%|█████████▎| 93/100 [00:21<00:01,  6.83it/s]Train Iter: 4994/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9379. T_Loss: 4.4920. Mask: 0.9262. :  93%|█████████▎| 93/100 [00:22<00:01,  6.83it/s]Train Iter: 4994/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9379. T_Loss: 4.4920. Mask: 0.9262. :  94%|█████████▍| 94/100 [00:22<00:00,  7.23it/s]Train Iter: 4995/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9378. T_Loss: 4.4898. Mask: 0.9270. :  94%|█████████▍| 94/100 [00:22<00:00,  7.23it/s]Train Iter: 4995/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9378. T_Loss: 4.4898. Mask: 0.9270. :  95%|█████████▌| 95/100 [00:22<00:00,  7.37it/s]Train Iter: 4996/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9368. T_Loss: 4.4856. Mask: 0.9271. :  95%|█████████▌| 95/100 [00:22<00:00,  7.37it/s]Train Iter: 4996/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9368. T_Loss: 4.4856. Mask: 0.9271. :  96%|█████████▌| 96/100 [00:22<00:00,  7.13it/s]Train Iter: 4997/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9364. T_Loss: 4.4825. Mask: 0.9269. :  96%|█████████▌| 96/100 [00:22<00:00,  7.13it/s]Train Iter: 4997/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9364. T_Loss: 4.4825. Mask: 0.9269. :  97%|█████████▋| 97/100 [00:22<00:00,  7.18it/s]Train Iter: 4998/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9358. T_Loss: 4.4881. Mask: 0.9276. :  97%|█████████▋| 97/100 [00:22<00:00,  7.18it/s]Train Iter: 4998/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9358. T_Loss: 4.4881. Mask: 0.9276. :  98%|█████████▊| 98/100 [00:22<00:00,  7.53it/s]Train Iter: 4999/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9375. T_Loss: 4.4960. Mask: 0.9271. :  98%|█████████▊| 98/100 [00:22<00:00,  7.53it/s]Train Iter: 4999/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9375. T_Loss: 4.4960. Mask: 0.9271. :  99%|█████████▉| 99/100 [00:22<00:00,  5.54it/s]Train Iter: 5000/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9383. T_Loss: 4.4954. Mask: 0.9269. :  99%|█████████▉| 99/100 [00:23<00:00,  5.54it/s]Train Iter: 5000/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9383. T_Loss: 4.4954. Mask: 0.9269. : 100%|██████████| 100/100 [00:23<00:00,  6.09it/s]Train Iter: 5000/5000. LR: 0.0000. Data: 0.08s. Batch: 0.23s. S_Loss: 0.9383. T_Loss: 4.4954. Mask: 0.9269. : 100%|██████████| 100/100 [00:23<00:00,  4.34it/s]
total : 5000  current step :  4976
total : 5000  current step :  4977
total : 5000  current step :  4978
total : 5000  current step :  4979
total : 5000  current step :  4980
total : 5000  current step :  4981
total : 5000  current step :  4982
total : 5000  current step :  4983
total : 5000  current step :  4984
total : 5000  current step :  4985
total : 5000  current step :  4986
total : 5000  current step :  4987
total : 5000  current step :  4988
total : 5000  current step :  4989
total : 5000  current step :  4990
total : 5000  current step :  4991
total : 5000  current step :  4992
total : 5000  current step :  4993
total : 5000  current step :  4994
total : 5000  current step :  4995
total : 5000  current step :  4996
total : 5000  current step :  4997
total : 5000  current step :  4998
total : 5000  current step :  4999
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.74s. Loss: 0.9182. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.74s. Loss: 0.9182. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.88s. Loss: 0.9061. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.59s. Loss: 0.8731. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 0.8788. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 0.8623. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8587. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.8747. top1: 89.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.8728. top1: 88.67. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8741. top1: 88.89. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.74s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8741. top1: 88.89. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8770. top1: 89.06. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8641. top1: 90.06. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8674. top1: 89.58. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8619. top1: 89.66. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8563. top1: 90.18. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8548. top1: 90.42. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8557. top1: 90.43. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8557. top1: 90.43. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.35it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8537. top1: 90.44. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.35it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8547. top1: 90.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8544. top1: 90.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8536. top1: 90.47. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8559. top1: 90.33. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8533. top1: 90.48. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8490. top1: 90.90. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8460. top1: 91.15. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8430. top1: 91.25. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8487. top1: 90.75. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8489. top1: 90.86. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.35it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8489. top1: 90.86. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8528. top1: 90.62. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8494. top1: 90.84. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8487. top1: 90.83. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8473. top1: 90.93. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8690. top1: 90.04. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8785. top1: 89.49. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8898. top1: 88.97. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9046. top1: 88.12. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9276. top1: 87.33. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9336. top1: 86.91. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9443. top1: 86.51. top5: 99.67. :  43%|████▎     | 27/63 [00:02<00:01, 23.74it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9443. top1: 86.51. top5: 99.67. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9572. top1: 85.98. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9670. top1: 85.55. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9739. top1: 85.14. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9888. top1: 84.45. top5: 99.48. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9996. top1: 84.01. top5: 99.42. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0057. top1: 83.81. top5: 99.43. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 83.61. top5: 99.44. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0172. top1: 83.29. top5: 99.46. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0222. top1: 82.91. top5: 99.47. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0270. top1: 82.75. top5: 99.48. :  60%|██████    | 38/63 [00:02<00:00, 35.90it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0270. top1: 82.75. top5: 99.48. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0327. top1: 82.65. top5: 99.43. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0374. top1: 82.38. top5: 99.38. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0496. top1: 81.62. top5: 99.39. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0538. top1: 81.37. top5: 99.34. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0609. top1: 81.07. top5: 99.35. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0702. top1: 80.61. top5: 99.25. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0722. top1: 80.40. top5: 99.26. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0753. top1: 80.25. top5: 99.27. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0848. top1: 79.77. top5: 99.23. :  76%|███████▌  | 48/63 [00:02<00:00, 46.32it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0848. top1: 79.77. top5: 99.23. :  90%|█████████ | 57/63 [00:02<00:00, 52.03it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0936. top1: 79.31. top5: 99.14. :  90%|█████████ | 57/63 [00:02<00:00, 52.03it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0992. top1: 79.03. top5: 99.05. :  90%|█████████ | 57/63 [00:02<00:00, 52.03it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0999. top1: 79.01. top5: 99.01. :  90%|█████████ | 57/63 [00:02<00:00, 52.03it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1060. top1: 78.69. top5: 98.98. :  90%|█████████ | 57/63 [00:02<00:00, 52.03it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1159. top1: 78.07. top5: 98.99. :  90%|█████████ | 57/63 [00:02<00:00, 52.03it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1174. top1: 78.00. top5: 99.00. :  90%|█████████ | 57/63 [00:02<00:00, 52.03it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1174. top1: 78.00. top5: 99.00. : 100%|██████████| 63/63 [00:02<00:00, 22.91it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  1/60. Data: 1.82s. Batch: 1.88s. Loss: 1.0193. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  1/60. Data: 1.82s. Batch: 1.88s. Loss: 1.0193. :   4%|▍         | 1/25 [00:01<00:45,  1.88s/it]Finetune Epoch:  1/60. Data: 1.85s. Batch: 2.29s. Loss: 0.9283. :   4%|▍         | 1/25 [00:02<00:45,  1.88s/it]Finetune Epoch:  1/60. Data: 1.85s. Batch: 2.29s. Loss: 0.9283. :   8%|▊         | 2/25 [00:02<00:28,  1.26s/it]Finetune Epoch:  1/60. Data: 2.14s. Batch: 2.45s. Loss: 0.9853. :   8%|▊         | 2/25 [00:02<00:28,  1.26s/it]Finetune Epoch:  1/60. Data: 2.30s. Batch: 2.54s. Loss: 0.9733. :   8%|▊         | 2/25 [00:02<00:28,  1.26s/it]Finetune Epoch:  1/60. Data: 2.30s. Batch: 2.54s. Loss: 0.9733. :  16%|█▌        | 4/25 [00:02<00:10,  1.98it/s]Finetune Epoch:  1/60. Data: 2.40s. Batch: 2.60s. Loss: 0.9554. :  16%|█▌        | 4/25 [00:02<00:10,  1.98it/s]Finetune Epoch:  1/60. Data: 2.48s. Batch: 2.66s. Loss: 0.9351. :  16%|█▌        | 4/25 [00:02<00:10,  1.98it/s]Finetune Epoch:  1/60. Data: 2.54s. Batch: 2.70s. Loss: 0.9491. :  16%|█▌        | 4/25 [00:02<00:10,  1.98it/s]Finetune Epoch:  1/60. Data: 2.54s. Batch: 2.70s. Loss: 0.9491. :  28%|██▊       | 7/25 [00:02<00:04,  4.13it/s]Finetune Epoch:  1/60. Data: 2.59s. Batch: 2.74s. Loss: 0.9385. :  28%|██▊       | 7/25 [00:02<00:04,  4.13it/s]Finetune Epoch:  1/60. Data: 2.64s. Batch: 2.77s. Loss: 0.9325. :  28%|██▊       | 7/25 [00:03<00:04,  4.13it/s]Finetune Epoch:  1/60. Data: 2.68s. Batch: 2.80s. Loss: 0.9438. :  28%|██▊       | 7/25 [00:03<00:04,  4.13it/s]Finetune Epoch:  1/60. Data: 2.68s. Batch: 2.80s. Loss: 0.9438. :  40%|████      | 10/25 [00:03<00:02,  6.60it/s]Finetune Epoch:  1/60. Data: 2.71s. Batch: 2.83s. Loss: 0.9585. :  40%|████      | 10/25 [00:03<00:02,  6.60it/s]Finetune Epoch:  1/60. Data: 2.75s. Batch: 2.86s. Loss: 0.9837. :  40%|████      | 10/25 [00:03<00:02,  6.60it/s]Finetune Epoch:  1/60. Data: 2.78s. Batch: 2.89s. Loss: 0.9793. :  40%|████      | 10/25 [00:03<00:02,  6.60it/s]Finetune Epoch:  1/60. Data: 2.78s. Batch: 2.89s. Loss: 0.9793. :  52%|█████▏    | 13/25 [00:03<00:01,  9.05it/s]Finetune Epoch:  1/60. Data: 2.81s. Batch: 2.91s. Loss: 0.9844. :  52%|█████▏    | 13/25 [00:03<00:01,  9.05it/s]Finetune Epoch:  1/60. Data: 2.84s. Batch: 2.94s. Loss: 0.9903. :  52%|█████▏    | 13/25 [00:03<00:01,  9.05it/s]Finetune Epoch:  1/60. Data: 2.87s. Batch: 2.97s. Loss: 0.9870. :  52%|█████▏    | 13/25 [00:03<00:01,  9.05it/s]Finetune Epoch:  1/60. Data: 2.87s. Batch: 2.97s. Loss: 0.9870. :  64%|██████▍   | 16/25 [00:03<00:00, 11.14it/s]Finetune Epoch:  1/60. Data: 2.90s. Batch: 2.99s. Loss: 0.9949. :  64%|██████▍   | 16/25 [00:03<00:00, 11.14it/s]Finetune Epoch:  1/60. Data: 2.93s. Batch: 3.02s. Loss: 0.9916. :  64%|██████▍   | 16/25 [00:03<00:00, 11.14it/s]Finetune Epoch:  1/60. Data: 2.93s. Batch: 3.02s. Loss: 0.9916. :  72%|███████▏  | 18/25 [00:03<00:00, 12.44it/s]Finetune Epoch:  1/60. Data: 2.96s. Batch: 3.05s. Loss: 1.0002. :  72%|███████▏  | 18/25 [00:03<00:00, 12.44it/s]Finetune Epoch:  1/60. Data: 2.99s. Batch: 3.07s. Loss: 1.0023. :  72%|███████▏  | 18/25 [00:03<00:00, 12.44it/s]Finetune Epoch:  1/60. Data: 3.02s. Batch: 3.10s. Loss: 1.0038. :  72%|███████▏  | 18/25 [00:03<00:00, 12.44it/s]Finetune Epoch:  1/60. Data: 3.02s. Batch: 3.10s. Loss: 1.0038. :  84%|████████▍ | 21/25 [00:03<00:00, 14.36it/s]Finetune Epoch:  1/60. Data: 3.04s. Batch: 3.13s. Loss: 1.0080. :  84%|████████▍ | 21/25 [00:03<00:00, 14.36it/s]Finetune Epoch:  1/60. Data: 3.07s. Batch: 3.15s. Loss: 1.0014. :  84%|████████▍ | 21/25 [00:03<00:00, 14.36it/s]Finetune Epoch:  1/60. Data: 3.07s. Batch: 3.15s. Loss: 1.0014. :  92%|█████████▏| 23/25 [00:03<00:00, 15.34it/s]Finetune Epoch:  1/60. Data: 3.10s. Batch: 3.18s. Loss: 1.0014. :  92%|█████████▏| 23/25 [00:03<00:00, 15.34it/s]Finetune Epoch:  1/60. Data: 3.13s. Batch: 3.21s. Loss: 1.0150. :  92%|█████████▏| 23/25 [00:03<00:00, 15.34it/s]Finetune Epoch:  1/60. Data: 3.13s. Batch: 3.21s. Loss: 1.0150. : 100%|██████████| 25/25 [00:03<00:00, 16.34it/s]Finetune Epoch:  1/60. Data: 3.13s. Batch: 3.21s. Loss: 1.0150. : 100%|██████████| 25/25 [00:04<00:00,  6.12it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 0.9218. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 0.9218. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 0.9095. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 0.8758. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.8818. top1: 88.28. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8650. top1: 90.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8613. top1: 90.10. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8776. top1: 88.84. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8776. top1: 88.84. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.85it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8756. top1: 88.28. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.85it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8770. top1: 88.54. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.85it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8799. top1: 88.75. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.85it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8668. top1: 89.77. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.85it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8702. top1: 89.32. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.85it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8646. top1: 89.18. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.85it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8589. top1: 89.73. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.85it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8574. top1: 90.00. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.85it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8583. top1: 90.04. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.85it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8583. top1: 90.04. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8563. top1: 90.07. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8573. top1: 90.28. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8570. top1: 90.30. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8562. top1: 90.16. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8585. top1: 90.03. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8558. top1: 90.20. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8514. top1: 90.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8484. top1: 90.89. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8453. top1: 91.00. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8512. top1: 90.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8514. top1: 90.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.56it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8514. top1: 90.62. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8553. top1: 90.29. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8518. top1: 90.52. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8511. top1: 90.52. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8497. top1: 90.62. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8712. top1: 89.75. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8805. top1: 89.20. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8915. top1: 88.69. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9060. top1: 87.86. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9287. top1: 87.07. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9345. top1: 86.66. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 23.59it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9345. top1: 86.66. top5: 99.66. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9450. top1: 86.27. top5: 99.67. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9578. top1: 85.74. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9673. top1: 85.39. top5: 99.61. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9741. top1: 85.06. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9888. top1: 84.38. top5: 99.48. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9994. top1: 83.94. top5: 99.42. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0054. top1: 83.74. top5: 99.43. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0090. top1: 83.54. top5: 99.44. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0166. top1: 83.22. top5: 99.46. :  59%|█████▊    | 37/63 [00:02<00:00, 34.21it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0166. top1: 83.22. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0214. top1: 82.85. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0261. top1: 82.68. top5: 99.48. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0317. top1: 82.59. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0363. top1: 82.31. top5: 99.38. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0483. top1: 81.56. top5: 99.39. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0524. top1: 81.31. top5: 99.34. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0594. top1: 81.01. top5: 99.35. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0686. top1: 80.56. top5: 99.25. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0705. top1: 80.34. top5: 99.26. :  73%|███████▎  | 46/63 [00:02<00:00, 43.34it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0705. top1: 80.34. top5: 99.26. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0736. top1: 80.25. top5: 99.27. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0829. top1: 79.77. top5: 99.23. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0916. top1: 79.31. top5: 99.14. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0971. top1: 79.08. top5: 99.05. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0978. top1: 79.06. top5: 99.01. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1038. top1: 78.79. top5: 98.98. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1135. top1: 78.18. top5: 98.99. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1150. top1: 78.10. top5: 99.00. :  87%|████████▋ | 55/63 [00:02<00:00, 52.06it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1150. top1: 78.10. top5: 99.00. : 100%|██████████| 63/63 [00:02<00:00, 23.04it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  2/60. Data: 1.71s. Batch: 1.80s. Loss: 0.8669. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  2/60. Data: 1.71s. Batch: 1.80s. Loss: 0.8669. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch:  2/60. Data: 1.76s. Batch: 1.82s. Loss: 0.9449. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch:  2/60. Data: 1.79s. Batch: 1.86s. Loss: 0.9274. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch:  2/60. Data: 1.79s. Batch: 1.86s. Loss: 0.9274. :  12%|█▏        | 3/25 [00:01<00:11,  1.95it/s]Finetune Epoch:  2/60. Data: 1.82s. Batch: 1.89s. Loss: 1.0417. :  12%|█▏        | 3/25 [00:01<00:11,  1.95it/s]Finetune Epoch:  2/60. Data: 1.85s. Batch: 1.92s. Loss: 1.0215. :  12%|█▏        | 3/25 [00:02<00:11,  1.95it/s]Finetune Epoch:  2/60. Data: 1.85s. Batch: 1.92s. Loss: 1.0215. :  20%|██        | 5/25 [00:02<00:05,  3.60it/s]Finetune Epoch:  2/60. Data: 1.88s. Batch: 1.95s. Loss: 1.0368. :  20%|██        | 5/25 [00:02<00:05,  3.60it/s]Finetune Epoch:  2/60. Data: 1.91s. Batch: 1.97s. Loss: 1.0302. :  20%|██        | 5/25 [00:02<00:05,  3.60it/s]Finetune Epoch:  2/60. Data: 1.91s. Batch: 1.97s. Loss: 1.0302. :  28%|██▊       | 7/25 [00:02<00:03,  5.47it/s]Finetune Epoch:  2/60. Data: 1.94s. Batch: 2.00s. Loss: 1.0204. :  28%|██▊       | 7/25 [00:02<00:03,  5.47it/s]Finetune Epoch:  2/60. Data: 1.97s. Batch: 2.03s. Loss: 1.0193. :  28%|██▊       | 7/25 [00:02<00:03,  5.47it/s]Finetune Epoch:  2/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0253. :  28%|██▊       | 7/25 [00:02<00:03,  5.47it/s]Finetune Epoch:  2/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0253. :  40%|████      | 10/25 [00:02<00:01,  8.37it/s]Finetune Epoch:  2/60. Data: 2.02s. Batch: 2.08s. Loss: 1.0309. :  40%|████      | 10/25 [00:02<00:01,  8.37it/s]Finetune Epoch:  2/60. Data: 2.05s. Batch: 2.11s. Loss: 1.0303. :  40%|████      | 10/25 [00:02<00:01,  8.37it/s]Finetune Epoch:  2/60. Data: 2.05s. Batch: 2.11s. Loss: 1.0303. :  48%|████▊     | 12/25 [00:02<00:01, 10.14it/s]Finetune Epoch:  2/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0279. :  48%|████▊     | 12/25 [00:02<00:01, 10.14it/s]Finetune Epoch:  2/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0308. :  48%|████▊     | 12/25 [00:02<00:01, 10.14it/s]Finetune Epoch:  2/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0308. :  56%|█████▌    | 14/25 [00:02<00:00, 11.74it/s]Finetune Epoch:  2/60. Data: 2.13s. Batch: 2.19s. Loss: 1.0225. :  56%|█████▌    | 14/25 [00:02<00:00, 11.74it/s]Finetune Epoch:  2/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0188. :  56%|█████▌    | 14/25 [00:02<00:00, 11.74it/s]Finetune Epoch:  2/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0188. :  64%|██████▍   | 16/25 [00:02<00:00, 12.83it/s]Finetune Epoch:  2/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0108. :  64%|██████▍   | 16/25 [00:02<00:00, 12.83it/s]Finetune Epoch:  2/60. Data: 2.21s. Batch: 2.27s. Loss: 1.0204. :  64%|██████▍   | 16/25 [00:02<00:00, 12.83it/s]Finetune Epoch:  2/60. Data: 2.24s. Batch: 2.30s. Loss: 1.0214. :  64%|██████▍   | 16/25 [00:02<00:00, 12.83it/s]Finetune Epoch:  2/60. Data: 2.24s. Batch: 2.30s. Loss: 1.0214. :  76%|███████▌  | 19/25 [00:02<00:00, 15.00it/s]Finetune Epoch:  2/60. Data: 2.27s. Batch: 2.32s. Loss: 1.0122. :  76%|███████▌  | 19/25 [00:02<00:00, 15.00it/s]Finetune Epoch:  2/60. Data: 2.30s. Batch: 2.35s. Loss: 1.0038. :  76%|███████▌  | 19/25 [00:02<00:00, 15.00it/s]Finetune Epoch:  2/60. Data: 2.30s. Batch: 2.35s. Loss: 1.0038. :  84%|████████▍ | 21/25 [00:02<00:00, 16.03it/s]Finetune Epoch:  2/60. Data: 2.32s. Batch: 2.37s. Loss: 1.0011. :  84%|████████▍ | 21/25 [00:02<00:00, 16.03it/s]Finetune Epoch:  2/60. Data: 2.35s. Batch: 2.40s. Loss: 0.9983. :  84%|████████▍ | 21/25 [00:02<00:00, 16.03it/s]Finetune Epoch:  2/60. Data: 2.35s. Batch: 2.40s. Loss: 0.9983. :  92%|█████████▏| 23/25 [00:02<00:00, 16.76it/s]Finetune Epoch:  2/60. Data: 2.37s. Batch: 2.43s. Loss: 0.9990. :  92%|█████████▏| 23/25 [00:03<00:00, 16.76it/s]Finetune Epoch:  2/60. Data: 2.40s. Batch: 2.45s. Loss: 1.0073. :  92%|█████████▏| 23/25 [00:03<00:00, 16.76it/s]Finetune Epoch:  2/60. Data: 2.40s. Batch: 2.45s. Loss: 1.0073. : 100%|██████████| 25/25 [00:03<00:00,  7.66it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9251. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9251. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.83s. Loss: 0.9126. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.8783. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.8845. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.8674. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8637. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8802. top1: 88.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8783. top1: 87.89. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8796. top1: 88.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8826. top1: 88.44. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8826. top1: 88.44. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8693. top1: 89.49. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8727. top1: 89.06. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8671. top1: 88.94. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8613. top1: 89.51. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8598. top1: 89.79. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8606. top1: 89.84. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8586. top1: 89.89. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8597. top1: 90.10. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  7.71it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8597. top1: 90.10. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8594. top1: 90.13. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8585. top1: 90.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8608. top1: 89.88. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8581. top1: 90.06. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8537. top1: 90.49. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8507. top1: 90.76. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8475. top1: 90.88. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8534. top1: 90.38. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8536. top1: 90.51. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8576. top1: 90.18. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8541. top1: 90.41. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.96it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8541. top1: 90.41. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 26.92it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8534. top1: 90.42. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 26.92it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8520. top1: 90.52. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 26.92it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8733. top1: 89.65. top5: 99.90. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8823. top1: 89.20. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8930. top1: 88.69. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9072. top1: 87.86. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9296. top1: 87.15. top5: 99.65. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9353. top1: 86.74. top5: 99.66. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9456. top1: 86.35. top5: 99.67. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9581. top1: 85.82. top5: 99.60. :  46%|████▌     | 29/63 [00:02<00:01, 26.92it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9581. top1: 85.82. top5: 99.60. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9675. top1: 85.47. top5: 99.61. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9741. top1: 85.14. top5: 99.54. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9887. top1: 84.45. top5: 99.48. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9992. top1: 84.01. top5: 99.42. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0051. top1: 83.81. top5: 99.43. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0086. top1: 83.61. top5: 99.44. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0159. top1: 83.29. top5: 99.46. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0206. top1: 82.91. top5: 99.47. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0252. top1: 82.75. top5: 99.48. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0307. top1: 82.72. top5: 99.43. :  62%|██████▏   | 39/63 [00:02<00:00, 37.63it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0307. top1: 82.72. top5: 99.43. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0351. top1: 82.44. top5: 99.38. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0470. top1: 81.68. top5: 99.39. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0510. top1: 81.43. top5: 99.34. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0579. top1: 81.13. top5: 99.35. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0670. top1: 80.67. top5: 99.25. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0688. top1: 80.45. top5: 99.26. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0718. top1: 80.36. top5: 99.27. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0810. top1: 79.88. top5: 99.23. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0896. top1: 79.42. top5: 99.14. :  78%|███████▊  | 49/63 [00:02<00:00, 47.99it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0896. top1: 79.42. top5: 99.14. :  92%|█████████▏| 58/63 [00:02<00:00, 53.59it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0950. top1: 79.18. top5: 99.05. :  92%|█████████▏| 58/63 [00:02<00:00, 53.59it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0956. top1: 79.17. top5: 99.01. :  92%|█████████▏| 58/63 [00:02<00:00, 53.59it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1015. top1: 78.89. top5: 98.98. :  92%|█████████▏| 58/63 [00:02<00:00, 53.59it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1111. top1: 78.28. top5: 98.99. :  92%|█████████▏| 58/63 [00:02<00:00, 53.59it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1126. top1: 78.20. top5: 99.00. :  92%|█████████▏| 58/63 [00:02<00:00, 53.59it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1126. top1: 78.20. top5: 99.00. : 100%|██████████| 63/63 [00:02<00:00, 24.06it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  3/60. Data: 1.64s. Batch: 1.70s. Loss: 0.8706. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  3/60. Data: 1.64s. Batch: 1.70s. Loss: 0.8706. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch:  3/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0809. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch:  3/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0522. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch:  3/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0223. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch:  3/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0223. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch:  3/60. Data: 1.75s. Batch: 1.79s. Loss: 1.0358. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch:  3/60. Data: 1.77s. Batch: 1.81s. Loss: 1.0223. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch:  3/60. Data: 1.79s. Batch: 1.83s. Loss: 1.0144. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch:  3/60. Data: 1.79s. Batch: 1.83s. Loss: 1.0144. :  28%|██▊       | 7/25 [00:01<00:03,  5.43it/s]Finetune Epoch:  3/60. Data: 1.81s. Batch: 1.84s. Loss: 1.0000. :  28%|██▊       | 7/25 [00:01<00:03,  5.43it/s]Finetune Epoch:  3/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9825. :  28%|██▊       | 7/25 [00:02<00:03,  5.43it/s]Finetune Epoch:  3/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9692. :  28%|██▊       | 7/25 [00:02<00:03,  5.43it/s]Finetune Epoch:  3/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9692. :  40%|████      | 10/25 [00:02<00:01,  8.12it/s]Finetune Epoch:  3/60. Data: 1.86s. Batch: 1.90s. Loss: 0.9820. :  40%|████      | 10/25 [00:02<00:01,  8.12it/s]Finetune Epoch:  3/60. Data: 1.89s. Batch: 1.93s. Loss: 0.9935. :  40%|████      | 10/25 [00:02<00:01,  8.12it/s]Finetune Epoch:  3/60. Data: 1.91s. Batch: 1.95s. Loss: 1.0118. :  40%|████      | 10/25 [00:02<00:01,  8.12it/s]Finetune Epoch:  3/60. Data: 1.91s. Batch: 1.95s. Loss: 1.0118. :  52%|█████▏    | 13/25 [00:02<00:01, 10.44it/s]Finetune Epoch:  3/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9996. :  52%|█████▏    | 13/25 [00:02<00:01, 10.44it/s]Finetune Epoch:  3/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9952. :  52%|█████▏    | 13/25 [00:02<00:01, 10.44it/s]Finetune Epoch:  3/60. Data: 1.98s. Batch: 2.02s. Loss: 0.9912. :  52%|█████▏    | 13/25 [00:02<00:01, 10.44it/s]Finetune Epoch:  3/60. Data: 1.98s. Batch: 2.02s. Loss: 0.9912. :  64%|██████▍   | 16/25 [00:02<00:00, 12.37it/s]Finetune Epoch:  3/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9997. :  64%|██████▍   | 16/25 [00:02<00:00, 12.37it/s]Finetune Epoch:  3/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9943. :  64%|██████▍   | 16/25 [00:02<00:00, 12.37it/s]Finetune Epoch:  3/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9915. :  64%|██████▍   | 16/25 [00:02<00:00, 12.37it/s]Finetune Epoch:  3/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9915. :  76%|███████▌  | 19/25 [00:02<00:00, 14.42it/s]Finetune Epoch:  3/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9910. :  76%|███████▌  | 19/25 [00:02<00:00, 14.42it/s]Finetune Epoch:  3/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9838. :  76%|███████▌  | 19/25 [00:02<00:00, 14.42it/s]Finetune Epoch:  3/60. Data: 2.12s. Batch: 2.16s. Loss: 0.9857. :  76%|███████▌  | 19/25 [00:02<00:00, 14.42it/s]Finetune Epoch:  3/60. Data: 2.12s. Batch: 2.16s. Loss: 0.9857. :  88%|████████▊ | 22/25 [00:02<00:00, 16.06it/s]Finetune Epoch:  3/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9894. :  88%|████████▊ | 22/25 [00:02<00:00, 16.06it/s]Finetune Epoch:  3/60. Data: 2.17s. Batch: 2.21s. Loss: 0.9876. :  88%|████████▊ | 22/25 [00:02<00:00, 16.06it/s]Finetune Epoch:  3/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9902. :  88%|████████▊ | 22/25 [00:02<00:00, 16.06it/s]Finetune Epoch:  3/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9902. : 100%|██████████| 25/25 [00:02<00:00, 18.24it/s]Finetune Epoch:  3/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9902. : 100%|██████████| 25/25 [00:02<00:00,  8.43it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.83s. Loss: 0.9285. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.83s. Loss: 0.9285. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 0.9158. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 0.8809. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.8873. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8699. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.8663. top1: 89.58. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8829. top1: 88.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8810. top1: 87.89. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8823. top1: 88.19. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8823. top1: 88.19. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.26it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8853. top1: 88.44. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.26it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8719. top1: 89.49. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.26it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8754. top1: 89.06. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.26it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8697. top1: 88.94. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.26it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8638. top1: 89.51. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.26it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8622. top1: 89.79. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.26it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8631. top1: 89.84. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.26it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8631. top1: 89.84. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8611. top1: 89.89. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8622. top1: 90.10. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8619. top1: 90.13. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8610. top1: 90.00. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8633. top1: 89.88. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8606. top1: 90.06. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8561. top1: 90.49. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8530. top1: 90.76. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8499. top1: 90.88. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.92it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8499. top1: 90.88. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8558. top1: 90.38. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8560. top1: 90.51. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8600. top1: 90.18. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8565. top1: 90.41. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8558. top1: 90.42. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8544. top1: 90.52. top5: 100.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8754. top1: 89.65. top5: 99.90. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8841. top1: 89.20. top5: 99.91. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8947. top1: 88.69. top5: 99.91. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9086. top1: 87.86. top5: 99.91. :  40%|███▉      | 25/63 [00:02<00:01, 20.83it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9086. top1: 87.86. top5: 99.91. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9307. top1: 87.15. top5: 99.65. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9361. top1: 86.74. top5: 99.66. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9462. top1: 86.35. top5: 99.67. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9586. top1: 85.82. top5: 99.60. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9678. top1: 85.47. top5: 99.61. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9743. top1: 85.14. top5: 99.54. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9886. top1: 84.45. top5: 99.48. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9990. top1: 84.08. top5: 99.42. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0047. top1: 83.88. top5: 99.43. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 83.68. top5: 99.44. :  56%|█████▌    | 35/63 [00:02<00:00, 31.72it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 83.68. top5: 99.44. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0153. top1: 83.36. top5: 99.46. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0198. top1: 82.98. top5: 99.47. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0242. top1: 82.81. top5: 99.48. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0297. top1: 82.78. top5: 99.43. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0340. top1: 82.50. top5: 99.38. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0457. top1: 81.74. top5: 99.39. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0495. top1: 81.49. top5: 99.34. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0564. top1: 81.19. top5: 99.35. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0653. top1: 80.73. top5: 99.25. :  71%|███████▏  | 45/63 [00:02<00:00, 42.57it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0653. top1: 80.73. top5: 99.25. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0671. top1: 80.57. top5: 99.26. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0700. top1: 80.47. top5: 99.27. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0790. top1: 79.99. top5: 99.23. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0875. top1: 79.53. top5: 99.14. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0929. top1: 79.29. top5: 99.10. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0934. top1: 79.27. top5: 99.06. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0992. top1: 79.00. top5: 99.03. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1087. top1: 78.38. top5: 99.04. :  86%|████████▌ | 54/63 [00:02<00:00, 49.25it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1087. top1: 78.38. top5: 99.04. :  98%|█████████▊| 62/63 [00:02<00:00, 52.21it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1101. top1: 78.30. top5: 99.05. :  98%|█████████▊| 62/63 [00:02<00:00, 52.21it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1101. top1: 78.30. top5: 99.05. : 100%|██████████| 63/63 [00:02<00:00, 22.34it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  4/60. Data: 1.55s. Batch: 1.60s. Loss: 0.9106. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  4/60. Data: 1.55s. Batch: 1.60s. Loss: 0.9106. :   4%|▍         | 1/25 [00:01<00:38,  1.61s/it]Finetune Epoch:  4/60. Data: 1.58s. Batch: 1.63s. Loss: 1.0305. :   4%|▍         | 1/25 [00:01<00:38,  1.61s/it]Finetune Epoch:  4/60. Data: 1.61s. Batch: 1.66s. Loss: 0.9716. :   4%|▍         | 1/25 [00:01<00:38,  1.61s/it]Finetune Epoch:  4/60. Data: 1.61s. Batch: 1.66s. Loss: 0.9716. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch:  4/60. Data: 1.64s. Batch: 1.69s. Loss: 0.9525. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch:  4/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9547. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch:  4/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9547. :  20%|██        | 5/25 [00:01<00:05,  3.98it/s]Finetune Epoch:  4/60. Data: 1.70s. Batch: 1.75s. Loss: 1.0073. :  20%|██        | 5/25 [00:01<00:05,  3.98it/s]Finetune Epoch:  4/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0097. :  20%|██        | 5/25 [00:01<00:05,  3.98it/s]Finetune Epoch:  4/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0097. :  28%|██▊       | 7/25 [00:01<00:03,  5.87it/s]Finetune Epoch:  4/60. Data: 1.76s. Batch: 1.81s. Loss: 1.0191. :  28%|██▊       | 7/25 [00:02<00:03,  5.87it/s]Finetune Epoch:  4/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0272. :  28%|██▊       | 7/25 [00:02<00:03,  5.87it/s]Finetune Epoch:  4/60. Data: 1.81s. Batch: 1.86s. Loss: 1.0255. :  28%|██▊       | 7/25 [00:02<00:03,  5.87it/s]Finetune Epoch:  4/60. Data: 1.81s. Batch: 1.86s. Loss: 1.0255. :  40%|████      | 10/25 [00:02<00:01,  9.00it/s]Finetune Epoch:  4/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0150. :  40%|████      | 10/25 [00:02<00:01,  9.00it/s]Finetune Epoch:  4/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0132. :  40%|████      | 10/25 [00:02<00:01,  9.00it/s]Finetune Epoch:  4/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0132. :  48%|████▊     | 12/25 [00:02<00:01, 10.74it/s]Finetune Epoch:  4/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0259. :  48%|████▊     | 12/25 [00:02<00:01, 10.74it/s]Finetune Epoch:  4/60. Data: 1.91s. Batch: 1.96s. Loss: 1.0197. :  48%|████▊     | 12/25 [00:02<00:01, 10.74it/s]Finetune Epoch:  4/60. Data: 1.94s. Batch: 1.99s. Loss: 1.0154. :  48%|████▊     | 12/25 [00:02<00:01, 10.74it/s]Finetune Epoch:  4/60. Data: 1.94s. Batch: 1.99s. Loss: 1.0154. :  60%|██████    | 15/25 [00:02<00:00, 13.16it/s]Finetune Epoch:  4/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0202. :  60%|██████    | 15/25 [00:02<00:00, 13.16it/s]Finetune Epoch:  4/60. Data: 1.99s. Batch: 2.04s. Loss: 1.0186. :  60%|██████    | 15/25 [00:02<00:00, 13.16it/s]Finetune Epoch:  4/60. Data: 1.99s. Batch: 2.04s. Loss: 1.0186. :  68%|██████▊   | 17/25 [00:02<00:00, 13.91it/s]Finetune Epoch:  4/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0190. :  68%|██████▊   | 17/25 [00:02<00:00, 13.91it/s]Finetune Epoch:  4/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0141. :  68%|██████▊   | 17/25 [00:02<00:00, 13.91it/s]Finetune Epoch:  4/60. Data: 2.07s. Batch: 2.12s. Loss: 1.0134. :  68%|██████▊   | 17/25 [00:02<00:00, 13.91it/s]Finetune Epoch:  4/60. Data: 2.07s. Batch: 2.12s. Loss: 1.0134. :  80%|████████  | 20/25 [00:02<00:00, 15.59it/s]Finetune Epoch:  4/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0100. :  80%|████████  | 20/25 [00:02<00:00, 15.59it/s]Finetune Epoch:  4/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0113. :  80%|████████  | 20/25 [00:02<00:00, 15.59it/s]Finetune Epoch:  4/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0141. :  80%|████████  | 20/25 [00:02<00:00, 15.59it/s]Finetune Epoch:  4/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0141. :  92%|█████████▏| 23/25 [00:02<00:00, 16.91it/s]Finetune Epoch:  4/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0067. :  92%|█████████▏| 23/25 [00:02<00:00, 16.91it/s]Finetune Epoch:  4/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0001. :  92%|█████████▏| 23/25 [00:02<00:00, 16.91it/s]Finetune Epoch:  4/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0001. : 100%|██████████| 25/25 [00:03<00:00,  7.96it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.59s. Loss: 0.9319. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.59s. Loss: 0.9319. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.80s. Loss: 0.9190. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.54s. Loss: 0.8834. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.41s. Loss: 0.8900. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.8724. top1: 89.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8688. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8856. top1: 87.95. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8856. top1: 87.95. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8837. top1: 87.50. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8851. top1: 87.85. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8880. top1: 88.12. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8745. top1: 89.20. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8780. top1: 88.80. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8722. top1: 88.70. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8663. top1: 89.29. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8647. top1: 89.58. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8647. top1: 89.58. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.36it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8656. top1: 89.65. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.36it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8636. top1: 89.71. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.36it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8647. top1: 89.93. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.36it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8644. top1: 89.97. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.36it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8634. top1: 89.84. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.36it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8658. top1: 89.73. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.36it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8658. top1: 89.73. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8630. top1: 89.91. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8585. top1: 90.35. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8554. top1: 90.62. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8522. top1: 90.75. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8582. top1: 90.26. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8584. top1: 90.39. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8624. top1: 90.07. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8589. top1: 90.30. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.94it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8581. top1: 90.31. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 18.94it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8567. top1: 90.42. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 18.94it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8775. top1: 89.55. top5: 99.90. :  33%|███▎      | 21/63 [00:02<00:02, 18.94it/s] Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8775. top1: 89.55. top5: 99.90. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8860. top1: 89.11. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8963. top1: 88.60. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9099. top1: 87.77. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9317. top1: 87.07. top5: 99.65. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9369. top1: 86.66. top5: 99.66. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9469. top1: 86.27. top5: 99.67. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9590. top1: 85.74. top5: 99.60. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9680. top1: 85.39. top5: 99.61. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9744. top1: 85.06. top5: 99.54. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.38. top5: 99.48. :  51%|█████     | 32/63 [00:02<00:00, 32.35it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.38. top5: 99.48. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9988. top1: 84.01. top5: 99.42. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0044. top1: 83.81. top5: 99.43. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0076. top1: 83.61. top5: 99.44. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0146. top1: 83.29. top5: 99.46. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0190. top1: 82.91. top5: 99.47. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0233. top1: 82.75. top5: 99.48. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0287. top1: 82.72. top5: 99.43. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0329. top1: 82.44. top5: 99.38. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0444. top1: 81.68. top5: 99.39. :  67%|██████▋   | 42/63 [00:02<00:00, 44.28it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0444. top1: 81.68. top5: 99.39. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0481. top1: 81.43. top5: 99.34. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0549. top1: 81.13. top5: 99.35. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0637. top1: 80.67. top5: 99.25. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0654. top1: 80.51. top5: 99.26. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0681. top1: 80.41. top5: 99.27. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0771. top1: 79.93. top5: 99.23. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0854. top1: 79.47. top5: 99.14. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0907. top1: 79.24. top5: 99.10. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0913. top1: 79.22. top5: 99.06. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0970. top1: 78.94. top5: 99.03. :  81%|████████  | 51/63 [00:02<00:00, 53.35it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0970. top1: 78.94. top5: 99.03. :  97%|█████████▋| 61/63 [00:02<00:00, 61.00it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1063. top1: 78.38. top5: 99.04. :  97%|█████████▋| 61/63 [00:02<00:00, 61.00it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1077. top1: 78.30. top5: 99.05. :  97%|█████████▋| 61/63 [00:02<00:00, 61.00it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1077. top1: 78.30. top5: 99.05. : 100%|██████████| 63/63 [00:02<00:00, 24.62it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  5/60. Data: 1.61s. Batch: 1.67s. Loss: 1.0068. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  5/60. Data: 1.61s. Batch: 1.67s. Loss: 1.0068. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch:  5/60. Data: 1.64s. Batch: 1.70s. Loss: 0.9837. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch:  5/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0500. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch:  5/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0500. :  12%|█▏        | 3/25 [00:01<00:10,  2.08it/s]Finetune Epoch:  5/60. Data: 1.71s. Batch: 1.76s. Loss: 1.0495. :  12%|█▏        | 3/25 [00:01<00:10,  2.08it/s]Finetune Epoch:  5/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0436. :  12%|█▏        | 3/25 [00:01<00:10,  2.08it/s]Finetune Epoch:  5/60. Data: 1.76s. Batch: 1.81s. Loss: 1.0437. :  12%|█▏        | 3/25 [00:01<00:10,  2.08it/s]Finetune Epoch:  5/60. Data: 1.76s. Batch: 1.81s. Loss: 1.0437. :  24%|██▍       | 6/25 [00:01<00:04,  4.74it/s]Finetune Epoch:  5/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0273. :  24%|██▍       | 6/25 [00:01<00:04,  4.74it/s]Finetune Epoch:  5/60. Data: 1.81s. Batch: 1.85s. Loss: 1.0256. :  24%|██▍       | 6/25 [00:02<00:04,  4.74it/s]Finetune Epoch:  5/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0027. :  24%|██▍       | 6/25 [00:02<00:04,  4.74it/s]Finetune Epoch:  5/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0027. :  36%|███▌      | 9/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  5/60. Data: 1.86s. Batch: 1.90s. Loss: 1.0008. :  36%|███▌      | 9/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  5/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0154. :  36%|███▌      | 9/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  5/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0154. :  44%|████▍     | 11/25 [00:02<00:01,  8.96it/s]Finetune Epoch:  5/60. Data: 1.91s. Batch: 1.96s. Loss: 1.0389. :  44%|████▍     | 11/25 [00:02<00:01,  8.96it/s]Finetune Epoch:  5/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0339. :  44%|████▍     | 11/25 [00:02<00:01,  8.96it/s]Finetune Epoch:  5/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0328. :  44%|████▍     | 11/25 [00:02<00:01,  8.96it/s]Finetune Epoch:  5/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0328. :  56%|█████▌    | 14/25 [00:02<00:00, 11.56it/s]Finetune Epoch:  5/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0298. :  56%|█████▌    | 14/25 [00:02<00:00, 11.56it/s]Finetune Epoch:  5/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0407. :  56%|█████▌    | 14/25 [00:02<00:00, 11.56it/s]Finetune Epoch:  5/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0407. :  64%|██████▍   | 16/25 [00:02<00:00, 12.18it/s]Finetune Epoch:  5/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0321. :  64%|██████▍   | 16/25 [00:02<00:00, 12.18it/s]Finetune Epoch:  5/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0247. :  64%|██████▍   | 16/25 [00:02<00:00, 12.18it/s]Finetune Epoch:  5/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0210. :  64%|██████▍   | 16/25 [00:02<00:00, 12.18it/s]Finetune Epoch:  5/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0210. :  76%|███████▌  | 19/25 [00:02<00:00, 14.54it/s]Finetune Epoch:  5/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0277. :  76%|███████▌  | 19/25 [00:02<00:00, 14.54it/s]Finetune Epoch:  5/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0198. :  76%|███████▌  | 19/25 [00:02<00:00, 14.54it/s]Finetune Epoch:  5/60. Data: 2.17s. Batch: 2.22s. Loss: 1.0186. :  76%|███████▌  | 19/25 [00:02<00:00, 14.54it/s]Finetune Epoch:  5/60. Data: 2.17s. Batch: 2.22s. Loss: 1.0186. :  88%|████████▊ | 22/25 [00:02<00:00, 16.24it/s]Finetune Epoch:  5/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0110. :  88%|████████▊ | 22/25 [00:02<00:00, 16.24it/s]Finetune Epoch:  5/60. Data: 2.22s. Batch: 2.27s. Loss: 1.0207. :  88%|████████▊ | 22/25 [00:02<00:00, 16.24it/s]Finetune Epoch:  5/60. Data: 2.22s. Batch: 2.27s. Loss: 1.0207. :  96%|█████████▌| 24/25 [00:02<00:00, 16.77it/s]Finetune Epoch:  5/60. Data: 2.25s. Batch: 2.29s. Loss: 1.0219. :  96%|█████████▌| 24/25 [00:02<00:00, 16.77it/s]Finetune Epoch:  5/60. Data: 2.25s. Batch: 2.29s. Loss: 1.0219. : 100%|██████████| 25/25 [00:03<00:00,  8.07it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.62s. Loss: 0.9347. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.62s. Loss: 0.9347. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 0.9217. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.8855. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.8924. top1: 86.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8745. top1: 88.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8745. top1: 88.75. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8709. top1: 88.54. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8879. top1: 87.50. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8860. top1: 87.11. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8874. top1: 87.50. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8903. top1: 87.81. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8767. top1: 88.92. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8802. top1: 88.54. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8744. top1: 88.46. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:15,  3.78it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8744. top1: 88.46. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8684. top1: 89.06. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8667. top1: 89.38. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8676. top1: 89.45. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8656. top1: 89.52. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8667. top1: 89.76. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8664. top1: 89.80. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8655. top1: 89.69. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8678. top1: 89.58. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 11.56it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8678. top1: 89.58. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 20.17it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8650. top1: 89.77. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 20.17it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8605. top1: 90.22. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 20.17it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8574. top1: 90.49. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 20.17it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8541. top1: 90.62. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 20.17it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8602. top1: 90.14. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 20.17it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8604. top1: 90.28. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 20.17it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8645. top1: 89.96. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 20.17it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8609. top1: 90.19. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 20.17it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8601. top1: 90.21. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 20.17it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8587. top1: 90.32. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 20.17it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8793. top1: 89.45. top5: 99.90. :  33%|███▎      | 21/63 [00:02<00:02, 20.17it/s] Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8793. top1: 89.45. top5: 99.90. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8876. top1: 89.02. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8977. top1: 88.51. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9111. top1: 87.77. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9326. top1: 87.15. top5: 99.65. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9376. top1: 86.74. top5: 99.66. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9475. top1: 86.35. top5: 99.67. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9594. top1: 85.82. top5: 99.60. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9683. top1: 85.47. top5: 99.61. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9745. top1: 85.14. top5: 99.54. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.45. top5: 99.48. :  51%|█████     | 32/63 [00:02<00:00, 32.69it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.45. top5: 99.48. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9987. top1: 84.08. top5: 99.42. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0042. top1: 83.88. top5: 99.43. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0073. top1: 83.68. top5: 99.44. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0142. top1: 83.36. top5: 99.46. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0185. top1: 82.98. top5: 99.47. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0227. top1: 82.81. top5: 99.48. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0279. top1: 82.78. top5: 99.43. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0320. top1: 82.50. top5: 99.38. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0433. top1: 81.74. top5: 99.39. :  67%|██████▋   | 42/63 [00:02<00:00, 43.69it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0433. top1: 81.74. top5: 99.39. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0470. top1: 81.55. top5: 99.34. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0537. top1: 81.25. top5: 99.35. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0624. top1: 80.79. top5: 99.25. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0640. top1: 80.62. top5: 99.26. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0667. top1: 80.52. top5: 99.27. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0756. top1: 80.04. top5: 99.23. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0838. top1: 79.63. top5: 99.14. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0890. top1: 79.40. top5: 99.10. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0895. top1: 79.38. top5: 99.06. :  81%|████████  | 51/63 [00:02<00:00, 52.63it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0895. top1: 79.38. top5: 99.06. :  95%|█████████▌| 60/63 [00:02<00:00, 59.16it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0952. top1: 79.10. top5: 99.03. :  95%|█████████▌| 60/63 [00:02<00:00, 59.16it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1043. top1: 78.53. top5: 99.04. :  95%|█████████▌| 60/63 [00:02<00:00, 59.16it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1057. top1: 78.45. top5: 99.05. :  95%|█████████▌| 60/63 [00:02<00:00, 59.16it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1057. top1: 78.45. top5: 99.05. : 100%|██████████| 63/63 [00:02<00:00, 24.04it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  6/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9122. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  6/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9122. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  6/60. Data: 1.79s. Batch: 1.84s. Loss: 0.9976. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  6/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9576. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  6/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9762. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  6/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9762. :  16%|█▌        | 4/25 [00:01<00:07,  2.67it/s]Finetune Epoch:  6/60. Data: 1.86s. Batch: 1.90s. Loss: 0.9547. :  16%|█▌        | 4/25 [00:02<00:07,  2.67it/s]Finetune Epoch:  6/60. Data: 1.89s. Batch: 1.93s. Loss: 1.0159. :  16%|█▌        | 4/25 [00:02<00:07,  2.67it/s]Finetune Epoch:  6/60. Data: 1.89s. Batch: 1.93s. Loss: 1.0159. :  24%|██▍       | 6/25 [00:02<00:04,  4.18it/s]Finetune Epoch:  6/60. Data: 1.91s. Batch: 1.96s. Loss: 0.9983. :  24%|██▍       | 6/25 [00:02<00:04,  4.18it/s]Finetune Epoch:  6/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9913. :  24%|██▍       | 6/25 [00:02<00:04,  4.18it/s]Finetune Epoch:  6/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9913. :  32%|███▏      | 8/25 [00:02<00:02,  5.97it/s]Finetune Epoch:  6/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0140. :  32%|███▏      | 8/25 [00:02<00:02,  5.97it/s]Finetune Epoch:  6/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0033. :  32%|███▏      | 8/25 [00:02<00:02,  5.97it/s]Finetune Epoch:  6/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0033. :  40%|████      | 10/25 [00:02<00:01,  7.93it/s]Finetune Epoch:  6/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0000. :  40%|████      | 10/25 [00:02<00:01,  7.93it/s]Finetune Epoch:  6/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9984. :  40%|████      | 10/25 [00:02<00:01,  7.93it/s]Finetune Epoch:  6/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9984. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch:  6/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9980. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch:  6/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9965. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch:  6/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9965. :  56%|█████▌    | 14/25 [00:02<00:00, 11.82it/s]Finetune Epoch:  6/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9952. :  56%|█████▌    | 14/25 [00:02<00:00, 11.82it/s]Finetune Epoch:  6/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9888. :  56%|█████▌    | 14/25 [00:02<00:00, 11.82it/s]Finetune Epoch:  6/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9888. :  64%|██████▍   | 16/25 [00:02<00:00, 13.52it/s]Finetune Epoch:  6/60. Data: 2.17s. Batch: 2.21s. Loss: 0.9895. :  64%|██████▍   | 16/25 [00:02<00:00, 13.52it/s]Finetune Epoch:  6/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9881. :  64%|██████▍   | 16/25 [00:02<00:00, 13.52it/s]Finetune Epoch:  6/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9881. :  72%|███████▏  | 18/25 [00:02<00:00, 15.03it/s]Finetune Epoch:  6/60. Data: 2.22s. Batch: 2.26s. Loss: 0.9856. :  72%|███████▏  | 18/25 [00:02<00:00, 15.03it/s]Finetune Epoch:  6/60. Data: 2.24s. Batch: 2.29s. Loss: 0.9902. :  72%|███████▏  | 18/25 [00:02<00:00, 15.03it/s]Finetune Epoch:  6/60. Data: 2.27s. Batch: 2.31s. Loss: 0.9878. :  72%|███████▏  | 18/25 [00:02<00:00, 15.03it/s]Finetune Epoch:  6/60. Data: 2.27s. Batch: 2.31s. Loss: 0.9878. :  84%|████████▍ | 21/25 [00:02<00:00, 16.95it/s]Finetune Epoch:  6/60. Data: 2.29s. Batch: 2.34s. Loss: 0.9854. :  84%|████████▍ | 21/25 [00:02<00:00, 16.95it/s]Finetune Epoch:  6/60. Data: 2.32s. Batch: 2.36s. Loss: 0.9891. :  84%|████████▍ | 21/25 [00:02<00:00, 16.95it/s]Finetune Epoch:  6/60. Data: 2.34s. Batch: 2.39s. Loss: 0.9956. :  84%|████████▍ | 21/25 [00:02<00:00, 16.95it/s]Finetune Epoch:  6/60. Data: 2.34s. Batch: 2.39s. Loss: 0.9956. :  96%|█████████▌| 24/25 [00:02<00:00, 18.84it/s]Finetune Epoch:  6/60. Data: 2.37s. Batch: 2.41s. Loss: 0.9957. :  96%|█████████▌| 24/25 [00:02<00:00, 18.84it/s]Finetune Epoch:  6/60. Data: 2.37s. Batch: 2.41s. Loss: 0.9957. : 100%|██████████| 25/25 [00:03<00:00,  7.82it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 0.9385. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.67s. Loss: 0.9385. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 0.9251. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.8882. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.8952. top1: 86.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.8770. top1: 88.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8734. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8905. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8887. top1: 86.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8900. top1: 87.15. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8930. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:43,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8930. top1: 87.50. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.56it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8793. top1: 88.64. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.56it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8828. top1: 88.28. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.56it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8770. top1: 88.22. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.56it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8709. top1: 88.84. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.56it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8692. top1: 89.17. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.56it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8701. top1: 89.26. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.56it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8701. top1: 89.26. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8681. top1: 89.34. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8692. top1: 89.58. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8689. top1: 89.64. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8679. top1: 89.53. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8703. top1: 89.43. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8674. top1: 89.63. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8628. top1: 90.08. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8597. top1: 90.36. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8564. top1: 90.50. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8625. top1: 90.02. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.76it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8625. top1: 90.02. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 23.63it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8627. top1: 90.05. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8669. top1: 89.73. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8632. top1: 89.98. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8625. top1: 90.00. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8611. top1: 90.12. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8814. top1: 89.36. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8895. top1: 88.92. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8993. top1: 88.42. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9124. top1: 87.68. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9337. top1: 87.07. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 23.63it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9337. top1: 87.07. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9385. top1: 86.74. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9481. top1: 86.35. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9599. top1: 85.82. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9686. top1: 85.47. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9747. top1: 85.14. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.45. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9986. top1: 84.08. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0039. top1: 83.88. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 34.84it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0039. top1: 83.88. top5: 99.50. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0070. top1: 83.68. top5: 99.51. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0136. top1: 83.42. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0178. top1: 83.05. top5: 99.53. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0218. top1: 82.88. top5: 99.54. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0270. top1: 82.84. top5: 99.49. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0310. top1: 82.56. top5: 99.44. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0421. top1: 81.80. top5: 99.45. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0456. top1: 81.61. top5: 99.40. :  70%|██████▉   | 44/63 [00:02<00:00, 40.48it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0456. top1: 81.61. top5: 99.40. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0522. top1: 81.31. top5: 99.41. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0609. top1: 80.84. top5: 99.31. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0624. top1: 80.68. top5: 99.32. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0650. top1: 80.58. top5: 99.33. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0737. top1: 80.10. top5: 99.29. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0819. top1: 79.69. top5: 99.19. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0870. top1: 79.45. top5: 99.15. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0875. top1: 79.43. top5: 99.11. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0931. top1: 79.15. top5: 99.08. :  83%|████████▎ | 52/63 [00:02<00:00, 46.24it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0931. top1: 79.15. top5: 99.08. :  97%|█████████▋| 61/63 [00:02<00:00, 54.90it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1021. top1: 78.58. top5: 99.09. :  97%|█████████▋| 61/63 [00:02<00:00, 54.90it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1034. top1: 78.50. top5: 99.10. :  97%|█████████▋| 61/63 [00:02<00:00, 54.90it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1034. top1: 78.50. top5: 99.10. : 100%|██████████| 63/63 [00:02<00:00, 23.76it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  7/60. Data: 1.58s. Batch: 1.64s. Loss: 0.8059. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  7/60. Data: 1.58s. Batch: 1.64s. Loss: 0.8059. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch:  7/60. Data: 1.62s. Batch: 1.67s. Loss: 0.8434. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch:  7/60. Data: 1.64s. Batch: 1.69s. Loss: 0.9273. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch:  7/60. Data: 1.64s. Batch: 1.69s. Loss: 0.9273. :  12%|█▏        | 3/25 [00:01<00:10,  2.16it/s]Finetune Epoch:  7/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9169. :  12%|█▏        | 3/25 [00:01<00:10,  2.16it/s]Finetune Epoch:  7/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9262. :  12%|█▏        | 3/25 [00:01<00:10,  2.16it/s]Finetune Epoch:  7/60. Data: 1.71s. Batch: 1.76s. Loss: 0.9406. :  12%|█▏        | 3/25 [00:01<00:10,  2.16it/s]Finetune Epoch:  7/60. Data: 1.71s. Batch: 1.76s. Loss: 0.9406. :  24%|██▍       | 6/25 [00:01<00:03,  4.89it/s]Finetune Epoch:  7/60. Data: 1.74s. Batch: 1.78s. Loss: 0.9528. :  24%|██▍       | 6/25 [00:01<00:03,  4.89it/s]Finetune Epoch:  7/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9590. :  24%|██▍       | 6/25 [00:01<00:03,  4.89it/s]Finetune Epoch:  7/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9645. :  24%|██▍       | 6/25 [00:01<00:03,  4.89it/s]Finetune Epoch:  7/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9645. :  36%|███▌      | 9/25 [00:01<00:02,  7.79it/s]Finetune Epoch:  7/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9692. :  36%|███▌      | 9/25 [00:02<00:02,  7.79it/s]Finetune Epoch:  7/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9811. :  36%|███▌      | 9/25 [00:02<00:02,  7.79it/s]Finetune Epoch:  7/60. Data: 1.84s. Batch: 1.88s. Loss: 1.0129. :  36%|███▌      | 9/25 [00:02<00:02,  7.79it/s]Finetune Epoch:  7/60. Data: 1.84s. Batch: 1.88s. Loss: 1.0129. :  48%|████▊     | 12/25 [00:02<00:01, 10.82it/s]Finetune Epoch:  7/60. Data: 1.86s. Batch: 1.90s. Loss: 1.0057. :  48%|████▊     | 12/25 [00:02<00:01, 10.82it/s]Finetune Epoch:  7/60. Data: 1.88s. Batch: 1.92s. Loss: 1.0006. :  48%|████▊     | 12/25 [00:02<00:01, 10.82it/s]Finetune Epoch:  7/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9948. :  48%|████▊     | 12/25 [00:02<00:01, 10.82it/s]Finetune Epoch:  7/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9948. :  60%|██████    | 15/25 [00:02<00:00, 13.92it/s]Finetune Epoch:  7/60. Data: 1.92s. Batch: 1.96s. Loss: 0.9976. :  60%|██████    | 15/25 [00:02<00:00, 13.92it/s]Finetune Epoch:  7/60. Data: 1.94s. Batch: 1.98s. Loss: 1.0091. :  60%|██████    | 15/25 [00:02<00:00, 13.92it/s]Finetune Epoch:  7/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0037. :  60%|██████    | 15/25 [00:02<00:00, 13.92it/s]Finetune Epoch:  7/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0037. :  72%|███████▏  | 18/25 [00:02<00:00, 15.10it/s]Finetune Epoch:  7/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0063. :  72%|███████▏  | 18/25 [00:02<00:00, 15.10it/s]Finetune Epoch:  7/60. Data: 2.01s. Batch: 2.05s. Loss: 1.0000. :  72%|███████▏  | 18/25 [00:02<00:00, 15.10it/s]Finetune Epoch:  7/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0040. :  72%|███████▏  | 18/25 [00:02<00:00, 15.10it/s]Finetune Epoch:  7/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0040. :  84%|████████▍ | 21/25 [00:02<00:00, 16.39it/s]Finetune Epoch:  7/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0049. :  84%|████████▍ | 21/25 [00:02<00:00, 16.39it/s]Finetune Epoch:  7/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0016. :  84%|████████▍ | 21/25 [00:02<00:00, 16.39it/s]Finetune Epoch:  7/60. Data: 2.10s. Batch: 2.14s. Loss: 1.0003. :  84%|████████▍ | 21/25 [00:02<00:00, 16.39it/s]Finetune Epoch:  7/60. Data: 2.10s. Batch: 2.14s. Loss: 1.0003. :  96%|█████████▌| 24/25 [00:02<00:00, 17.29it/s]Finetune Epoch:  7/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0016. :  96%|█████████▌| 24/25 [00:02<00:00, 17.29it/s]Finetune Epoch:  7/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0016. : 100%|██████████| 25/25 [00:02<00:00,  8.53it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.79s. Loss: 0.9415. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.79s. Loss: 0.9415. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 0.9280. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.8904. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.8977. top1: 86.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.8793. top1: 88.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8757. top1: 88.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8930. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8911. top1: 86.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.79s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.8911. top1: 86.72. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8925. top1: 87.15. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.8955. top1: 87.50. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8817. top1: 88.64. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8852. top1: 88.28. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8793. top1: 88.22. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8732. top1: 88.84. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8714. top1: 89.17. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8723. top1: 89.26. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8703. top1: 89.34. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8714. top1: 89.41. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.66it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8711. top1: 89.47. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:09,  5.66it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8711. top1: 89.47. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8701. top1: 89.38. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8725. top1: 89.29. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8695. top1: 89.49. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8649. top1: 89.95. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8618. top1: 90.23. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8584. top1: 90.38. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8646. top1: 89.90. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8648. top1: 89.93. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8690. top1: 89.62. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8653. top1: 89.87. top5: 100.00. :  30%|███       | 19/63 [00:02<00:02, 15.46it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8653. top1: 89.87. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8646. top1: 89.90. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8632. top1: 90.02. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8833. top1: 89.26. top5: 99.90. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8912. top1: 88.83. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9008. top1: 88.42. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9137. top1: 87.68. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9346. top1: 87.07. top5: 99.65. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9393. top1: 86.74. top5: 99.66. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9488. top1: 86.35. top5: 99.67. :  46%|████▌     | 29/63 [00:02<00:01, 25.49it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9488. top1: 86.35. top5: 99.67. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9603. top1: 85.82. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9689. top1: 85.47. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9749. top1: 85.14. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.45. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9985. top1: 84.08. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0037. top1: 83.88. top5: 99.50. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0066. top1: 83.68. top5: 99.51. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0132. top1: 83.42. top5: 99.52. :  60%|██████    | 38/63 [00:02<00:00, 34.12it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0132. top1: 83.42. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0172. top1: 83.05. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0211. top1: 82.88. top5: 99.54. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0262. top1: 82.84. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0301. top1: 82.56. top5: 99.44. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0410. top1: 81.80. top5: 99.45. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0445. top1: 81.61. top5: 99.40. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0510. top1: 81.31. top5: 99.41. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0596. top1: 80.84. top5: 99.31. :  73%|███████▎  | 46/63 [00:02<00:00, 40.20it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0596. top1: 80.84. top5: 99.31. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0610. top1: 80.68. top5: 99.32. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0636. top1: 80.58. top5: 99.33. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0722. top1: 80.10. top5: 99.29. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0802. top1: 79.69. top5: 99.19. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0853. top1: 79.45. top5: 99.15. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0857. top1: 79.43. top5: 99.11. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0912. top1: 79.15. top5: 99.08. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1001. top1: 78.58. top5: 99.09. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1014. top1: 78.50. top5: 99.10. :  86%|████████▌ | 54/63 [00:02<00:00, 45.69it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.1014. top1: 78.50. top5: 99.10. : 100%|██████████| 63/63 [00:02<00:00, 22.99it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  8/60. Data: 1.70s. Batch: 1.76s. Loss: 1.0433. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  8/60. Data: 1.70s. Batch: 1.76s. Loss: 1.0433. :   4%|▍         | 1/25 [00:01<00:42,  1.76s/it]Finetune Epoch:  8/60. Data: 1.73s. Batch: 1.79s. Loss: 0.9366. :   4%|▍         | 1/25 [00:01<00:42,  1.76s/it]Finetune Epoch:  8/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9956. :   4%|▍         | 1/25 [00:01<00:42,  1.76s/it]Finetune Epoch:  8/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9956. :  12%|█▏        | 3/25 [00:01<00:11,  2.00it/s]Finetune Epoch:  8/60. Data: 1.79s. Batch: 1.85s. Loss: 1.0099. :  12%|█▏        | 3/25 [00:01<00:11,  2.00it/s]Finetune Epoch:  8/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0043. :  12%|█▏        | 3/25 [00:01<00:11,  2.00it/s]Finetune Epoch:  8/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0043. :  20%|██        | 5/25 [00:01<00:05,  3.72it/s]Finetune Epoch:  8/60. Data: 1.85s. Batch: 1.90s. Loss: 1.0426. :  20%|██        | 5/25 [00:02<00:05,  3.72it/s]Finetune Epoch:  8/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0326. :  20%|██        | 5/25 [00:02<00:05,  3.72it/s]Finetune Epoch:  8/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0326. :  28%|██▊       | 7/25 [00:02<00:03,  5.58it/s]Finetune Epoch:  8/60. Data: 1.90s. Batch: 1.96s. Loss: 1.0451. :  28%|██▊       | 7/25 [00:02<00:03,  5.58it/s]Finetune Epoch:  8/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0546. :  28%|██▊       | 7/25 [00:02<00:03,  5.58it/s]Finetune Epoch:  8/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0546. :  36%|███▌      | 9/25 [00:02<00:02,  7.65it/s]Finetune Epoch:  8/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0755. :  36%|███▌      | 9/25 [00:02<00:02,  7.65it/s]Finetune Epoch:  8/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0625. :  36%|███▌      | 9/25 [00:02<00:02,  7.65it/s]Finetune Epoch:  8/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0539. :  36%|███▌      | 9/25 [00:02<00:02,  7.65it/s]Finetune Epoch:  8/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0539. :  48%|████▊     | 12/25 [00:02<00:01, 10.72it/s]Finetune Epoch:  8/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0429. :  48%|████▊     | 12/25 [00:02<00:01, 10.72it/s]Finetune Epoch:  8/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0557. :  48%|████▊     | 12/25 [00:02<00:01, 10.72it/s]Finetune Epoch:  8/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0580. :  48%|████▊     | 12/25 [00:02<00:01, 10.72it/s]Finetune Epoch:  8/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0580. :  60%|██████    | 15/25 [00:02<00:00, 13.18it/s]Finetune Epoch:  8/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0470. :  60%|██████    | 15/25 [00:02<00:00, 13.18it/s]Finetune Epoch:  8/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0429. :  60%|██████    | 15/25 [00:02<00:00, 13.18it/s]Finetune Epoch:  8/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0429. :  68%|██████▊   | 17/25 [00:02<00:00, 13.80it/s]Finetune Epoch:  8/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0389. :  68%|██████▊   | 17/25 [00:02<00:00, 13.80it/s]Finetune Epoch:  8/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0352. :  68%|██████▊   | 17/25 [00:02<00:00, 13.80it/s]Finetune Epoch:  8/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0327. :  68%|██████▊   | 17/25 [00:02<00:00, 13.80it/s]Finetune Epoch:  8/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0327. :  80%|████████  | 20/25 [00:02<00:00, 16.36it/s]Finetune Epoch:  8/60. Data: 2.24s. Batch: 2.29s. Loss: 1.0263. :  80%|████████  | 20/25 [00:02<00:00, 16.36it/s]Finetune Epoch:  8/60. Data: 2.26s. Batch: 2.31s. Loss: 1.0251. :  80%|████████  | 20/25 [00:02<00:00, 16.36it/s]Finetune Epoch:  8/60. Data: 2.29s. Batch: 2.34s. Loss: 1.0250. :  80%|████████  | 20/25 [00:02<00:00, 16.36it/s]Finetune Epoch:  8/60. Data: 2.29s. Batch: 2.34s. Loss: 1.0250. :  92%|█████████▏| 23/25 [00:02<00:00, 17.81it/s]Finetune Epoch:  8/60. Data: 2.31s. Batch: 2.36s. Loss: 1.0178. :  92%|█████████▏| 23/25 [00:02<00:00, 17.81it/s]Finetune Epoch:  8/60. Data: 2.34s. Batch: 2.38s. Loss: 1.0153. :  92%|█████████▏| 23/25 [00:02<00:00, 17.81it/s]Finetune Epoch:  8/60. Data: 2.34s. Batch: 2.38s. Loss: 1.0153. : 100%|██████████| 25/25 [00:03<00:00,  7.95it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 0.9447. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 0.9447. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.83s. Loss: 0.9311. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.8929. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9003. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.8817. top1: 88.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8781. top1: 88.02. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8955. top1: 87.05. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8937. top1: 86.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8937. top1: 86.33. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8951. top1: 86.81. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.8980. top1: 87.19. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8841. top1: 88.35. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8877. top1: 88.02. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8818. top1: 87.98. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8755. top1: 88.62. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8737. top1: 88.96. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8746. top1: 89.06. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.12it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8746. top1: 89.06. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8726. top1: 89.15. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8738. top1: 89.24. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8735. top1: 89.31. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8724. top1: 89.22. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8748. top1: 89.14. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8717. top1: 89.35. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8672. top1: 89.81. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8640. top1: 90.10. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8606. top1: 90.25. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8668. top1: 89.78. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.41it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8668. top1: 89.78. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 24.19it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8671. top1: 89.70. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 24.19it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8713. top1: 89.40. top5: 100.00. :  41%|████▏     | 26/63 [00:01<00:01, 24.19it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8676. top1: 89.66. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8669. top1: 89.69. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8655. top1: 89.82. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8853. top1: 89.06. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8929. top1: 88.73. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9023. top1: 88.33. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9149. top1: 87.59. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9357. top1: 86.98. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 24.19it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9357. top1: 86.98. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9401. top1: 86.74. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9494. top1: 86.35. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9608. top1: 85.82. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9692. top1: 85.47. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9750. top1: 85.14. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 84.52. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9983. top1: 84.16. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0035. top1: 83.95. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 35.13it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0035. top1: 83.95. top5: 99.50. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0063. top1: 83.75. top5: 99.51. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0126. top1: 83.49. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0165. top1: 83.18. top5: 99.53. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0204. top1: 83.01. top5: 99.54. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0253. top1: 82.97. top5: 99.49. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0292. top1: 82.69. top5: 99.44. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0399. top1: 81.92. top5: 99.45. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0433. top1: 81.73. top5: 99.40. :  70%|██████▉   | 44/63 [00:02<00:00, 40.91it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0433. top1: 81.73. top5: 99.40. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0497. top1: 81.43. top5: 99.41. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0581. top1: 81.02. top5: 99.31. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0595. top1: 80.85. top5: 99.32. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0620. top1: 80.75. top5: 99.33. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0704. top1: 80.26. top5: 99.29. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0784. top1: 79.85. top5: 99.30. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0834. top1: 79.61. top5: 99.26. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0838. top1: 79.58. top5: 99.22. :  83%|████████▎ | 52/63 [00:02<00:00, 47.44it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0838. top1: 79.58. top5: 99.22. :  95%|█████████▌| 60/63 [00:02<00:00, 54.09it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0892. top1: 79.30. top5: 99.18. :  95%|█████████▌| 60/63 [00:02<00:00, 54.09it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0980. top1: 78.73. top5: 99.19. :  95%|█████████▌| 60/63 [00:02<00:00, 54.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0992. top1: 78.65. top5: 99.20. :  95%|█████████▌| 60/63 [00:02<00:00, 54.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0992. top1: 78.65. top5: 99.20. : 100%|██████████| 63/63 [00:02<00:00, 23.56it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  9/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9179. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  9/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9179. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  9/60. Data: 1.81s. Batch: 1.85s. Loss: 0.9810. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  9/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9965. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  9/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9958. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch:  9/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9958. :  16%|█▌        | 4/25 [00:01<00:08,  2.61it/s]Finetune Epoch:  9/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9556. :  16%|█▌        | 4/25 [00:02<00:08,  2.61it/s]Finetune Epoch:  9/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9777. :  16%|█▌        | 4/25 [00:02<00:08,  2.61it/s]Finetune Epoch:  9/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9777. :  24%|██▍       | 6/25 [00:02<00:04,  4.14it/s]Finetune Epoch:  9/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9874. :  24%|██▍       | 6/25 [00:02<00:04,  4.14it/s]Finetune Epoch:  9/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9725. :  24%|██▍       | 6/25 [00:02<00:04,  4.14it/s]Finetune Epoch:  9/60. Data: 1.98s. Batch: 2.02s. Loss: 1.0040. :  24%|██▍       | 6/25 [00:02<00:04,  4.14it/s]Finetune Epoch:  9/60. Data: 1.98s. Batch: 2.02s. Loss: 1.0040. :  36%|███▌      | 9/25 [00:02<00:02,  6.77it/s]Finetune Epoch:  9/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0283. :  36%|███▌      | 9/25 [00:02<00:02,  6.77it/s]Finetune Epoch:  9/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0103. :  36%|███▌      | 9/25 [00:02<00:02,  6.77it/s]Finetune Epoch:  9/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0103. :  44%|████▍     | 11/25 [00:02<00:01,  8.52it/s]Finetune Epoch:  9/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0041. :  44%|████▍     | 11/25 [00:02<00:01,  8.52it/s]Finetune Epoch:  9/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0165. :  44%|████▍     | 11/25 [00:02<00:01,  8.52it/s]Finetune Epoch:  9/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0165. :  52%|█████▏    | 13/25 [00:02<00:01, 10.27it/s]Finetune Epoch:  9/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0106. :  52%|█████▏    | 13/25 [00:02<00:01, 10.27it/s]Finetune Epoch:  9/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0150. :  52%|█████▏    | 13/25 [00:02<00:01, 10.27it/s]Finetune Epoch:  9/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0167. :  52%|█████▏    | 13/25 [00:02<00:01, 10.27it/s]Finetune Epoch:  9/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0167. :  64%|██████▍   | 16/25 [00:02<00:00, 12.73it/s]Finetune Epoch:  9/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0148. :  64%|██████▍   | 16/25 [00:02<00:00, 12.73it/s]Finetune Epoch:  9/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0025. :  64%|██████▍   | 16/25 [00:02<00:00, 12.73it/s]Finetune Epoch:  9/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9955. :  64%|██████▍   | 16/25 [00:02<00:00, 12.73it/s]Finetune Epoch:  9/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9955. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch:  9/60. Data: 2.25s. Batch: 2.30s. Loss: 1.0011. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch:  9/60. Data: 2.28s. Batch: 2.32s. Loss: 1.0015. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch:  9/60. Data: 2.30s. Batch: 2.35s. Loss: 1.0002. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch:  9/60. Data: 2.30s. Batch: 2.35s. Loss: 1.0002. :  88%|████████▊ | 22/25 [00:02<00:00, 16.71it/s]Finetune Epoch:  9/60. Data: 2.33s. Batch: 2.37s. Loss: 0.9994. :  88%|████████▊ | 22/25 [00:02<00:00, 16.71it/s]Finetune Epoch:  9/60. Data: 2.35s. Batch: 2.40s. Loss: 1.0032. :  88%|████████▊ | 22/25 [00:02<00:00, 16.71it/s]Finetune Epoch:  9/60. Data: 2.37s. Batch: 2.42s. Loss: 1.0038. :  88%|████████▊ | 22/25 [00:02<00:00, 16.71it/s]Finetune Epoch:  9/60. Data: 2.37s. Batch: 2.42s. Loss: 1.0038. : 100%|██████████| 25/25 [00:02<00:00, 18.32it/s]Finetune Epoch:  9/60. Data: 2.37s. Batch: 2.42s. Loss: 1.0038. : 100%|██████████| 25/25 [00:03<00:00,  7.95it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9474. top1: 84.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9474. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 0.9337. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.8949. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9026. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8837. top1: 88.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8801. top1: 88.02. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8801. top1: 88.02. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.8977. top1: 87.05. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.8958. top1: 86.33. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.8973. top1: 86.81. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9002. top1: 87.19. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8862. top1: 88.35. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8898. top1: 88.02. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8838. top1: 87.98. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8775. top1: 88.62. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8756. top1: 88.96. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8765. top1: 89.06. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8765. top1: 89.06. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8746. top1: 89.15. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8758. top1: 89.24. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8755. top1: 89.31. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8744. top1: 89.22. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8767. top1: 89.14. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8736. top1: 89.35. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8690. top1: 89.81. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8659. top1: 90.10. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8624. top1: 90.25. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8687. top1: 89.78. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8689. top1: 89.70. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.70it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8689. top1: 89.70. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.35it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8732. top1: 89.40. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8694. top1: 89.66. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8687. top1: 89.69. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8673. top1: 89.82. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8870. top1: 89.06. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8944. top1: 88.83. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9036. top1: 88.42. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9160. top1: 87.68. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9365. top1: 87.07. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9408. top1: 86.82. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 25.35it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9408. top1: 86.82. top5: 99.66. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9500. top1: 86.43. top5: 99.67. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9612. top1: 85.90. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9694. top1: 85.55. top5: 99.61. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9752. top1: 85.21. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9887. top1: 84.60. top5: 99.55. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9983. top1: 84.23. top5: 99.49. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0033. top1: 84.02. top5: 99.50. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0060. top1: 83.82. top5: 99.51. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0122. top1: 83.56. top5: 99.52. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0160. top1: 83.24. top5: 99.53. :  59%|█████▊    | 37/63 [00:02<00:00, 36.39it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0160. top1: 83.24. top5: 99.53. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0198. top1: 83.07. top5: 99.54. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0246. top1: 83.04. top5: 99.49. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0284. top1: 82.75. top5: 99.44. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0390. top1: 81.99. top5: 99.45. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0422. top1: 81.79. top5: 99.40. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0486. top1: 81.49. top5: 99.41. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0569. top1: 81.08. top5: 99.31. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0583. top1: 80.91. top5: 99.32. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0607. top1: 80.80. top5: 99.33. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0691. top1: 80.32. top5: 99.29. :  75%|███████▍  | 47/63 [00:02<00:00, 46.92it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0691. top1: 80.32. top5: 99.29. :  90%|█████████ | 57/63 [00:02<00:00, 56.45it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0769. top1: 79.90. top5: 99.30. :  90%|█████████ | 57/63 [00:02<00:00, 56.45it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0819. top1: 79.66. top5: 99.26. :  90%|█████████ | 57/63 [00:02<00:00, 56.45it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0822. top1: 79.64. top5: 99.22. :  90%|█████████ | 57/63 [00:02<00:00, 56.45it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0876. top1: 79.35. top5: 99.18. :  90%|█████████ | 57/63 [00:02<00:00, 56.45it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0962. top1: 78.83. top5: 99.19. :  90%|█████████ | 57/63 [00:02<00:00, 56.45it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0975. top1: 78.75. top5: 99.20. :  90%|█████████ | 57/63 [00:02<00:00, 56.45it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0975. top1: 78.75. top5: 99.20. : 100%|██████████| 63/63 [00:02<00:00, 24.31it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 10/60. Data: 1.62s. Batch: 1.68s. Loss: 1.1397. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 10/60. Data: 1.62s. Batch: 1.68s. Loss: 1.1397. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 10/60. Data: 1.65s. Batch: 1.70s. Loss: 1.0989. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 10/60. Data: 1.67s. Batch: 1.71s. Loss: 1.0393. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 10/60. Data: 1.69s. Batch: 1.74s. Loss: 1.0390. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 10/60. Data: 1.69s. Batch: 1.74s. Loss: 1.0390. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch: 10/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0314. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch: 10/60. Data: 1.74s. Batch: 1.80s. Loss: 1.0165. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch: 10/60. Data: 1.74s. Batch: 1.80s. Loss: 1.0165. :  24%|██▍       | 6/25 [00:01<00:04,  4.42it/s]Finetune Epoch: 10/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0233. :  24%|██▍       | 6/25 [00:01<00:04,  4.42it/s]Finetune Epoch: 10/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0038. :  24%|██▍       | 6/25 [00:02<00:04,  4.42it/s]Finetune Epoch: 10/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0038. :  32%|███▏      | 8/25 [00:02<00:02,  6.28it/s]Finetune Epoch: 10/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0005. :  32%|███▏      | 8/25 [00:02<00:02,  6.28it/s]Finetune Epoch: 10/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9931. :  32%|███▏      | 8/25 [00:02<00:02,  6.28it/s]Finetune Epoch: 10/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9865. :  32%|███▏      | 8/25 [00:02<00:02,  6.28it/s]Finetune Epoch: 10/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9865. :  44%|████▍     | 11/25 [00:02<00:01,  9.51it/s]Finetune Epoch: 10/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9816. :  44%|████▍     | 11/25 [00:02<00:01,  9.51it/s]Finetune Epoch: 10/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9829. :  44%|████▍     | 11/25 [00:02<00:01,  9.51it/s]Finetune Epoch: 10/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9803. :  44%|████▍     | 11/25 [00:02<00:01,  9.51it/s]Finetune Epoch: 10/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9803. :  56%|█████▌    | 14/25 [00:02<00:00, 12.81it/s]Finetune Epoch: 10/60. Data: 1.97s. Batch: 2.01s. Loss: 0.9896. :  56%|█████▌    | 14/25 [00:02<00:00, 12.81it/s]Finetune Epoch: 10/60. Data: 1.99s. Batch: 2.03s. Loss: 0.9847. :  56%|█████▌    | 14/25 [00:02<00:00, 12.81it/s]Finetune Epoch: 10/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9869. :  56%|█████▌    | 14/25 [00:02<00:00, 12.81it/s]Finetune Epoch: 10/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9869. :  68%|██████▊   | 17/25 [00:02<00:00, 15.53it/s]Finetune Epoch: 10/60. Data: 2.03s. Batch: 2.07s. Loss: 0.9826. :  68%|██████▊   | 17/25 [00:02<00:00, 15.53it/s]Finetune Epoch: 10/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9875. :  68%|██████▊   | 17/25 [00:02<00:00, 15.53it/s]Finetune Epoch: 10/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9945. :  68%|██████▊   | 17/25 [00:02<00:00, 15.53it/s]Finetune Epoch: 10/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9945. :  80%|████████  | 20/25 [00:02<00:00, 17.87it/s]Finetune Epoch: 10/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9941. :  80%|████████  | 20/25 [00:02<00:00, 17.87it/s]Finetune Epoch: 10/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0024. :  80%|████████  | 20/25 [00:02<00:00, 17.87it/s]Finetune Epoch: 10/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9972. :  80%|████████  | 20/25 [00:02<00:00, 17.87it/s]Finetune Epoch: 10/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9972. :  92%|█████████▏| 23/25 [00:02<00:00, 18.94it/s]Finetune Epoch: 10/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9953. :  92%|█████████▏| 23/25 [00:02<00:00, 18.94it/s]Finetune Epoch: 10/60. Data: 2.18s. Batch: 2.22s. Loss: 0.9962. :  92%|█████████▏| 23/25 [00:02<00:00, 18.94it/s]Finetune Epoch: 10/60. Data: 2.18s. Batch: 2.22s. Loss: 0.9962. : 100%|██████████| 25/25 [00:02<00:00,  8.55it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.54s. Loss: 0.9510. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.54s. Loss: 0.9510. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.79s. Loss: 0.9371. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 0.8977. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.41s. Loss: 0.9055. top1: 85.16. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.8864. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.8864. top1: 87.50. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8828. top1: 87.50. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9005. top1: 86.61. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.8987. top1: 85.94. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9001. top1: 86.46. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9031. top1: 86.88. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8890. top1: 88.07. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8926. top1: 87.76. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8866. top1: 87.74. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8802. top1: 88.39. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8782. top1: 88.75. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8792. top1: 88.87. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:14,  3.97it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8792. top1: 88.87. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8772. top1: 88.97. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8784. top1: 89.06. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8781. top1: 89.14. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8770. top1: 89.06. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8794. top1: 88.99. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8762. top1: 89.20. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8716. top1: 89.67. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8684. top1: 89.84. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8649. top1: 90.00. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 15.29it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8649. top1: 90.00. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8712. top1: 89.54. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8714. top1: 89.47. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8758. top1: 89.17. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8719. top1: 89.44. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8713. top1: 89.48. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8698. top1: 89.62. top5: 100.00. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8893. top1: 88.87. top5: 99.90. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8965. top1: 88.64. top5: 99.91. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9054. top1: 88.24. top5: 99.91. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9176. top1: 87.50. top5: 99.91. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9378. top1: 86.89. top5: 99.65. :  40%|███▉      | 25/63 [00:01<00:01, 24.99it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9378. top1: 86.89. top5: 99.65. :  57%|█████▋    | 36/63 [00:01<00:00, 38.31it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9419. top1: 86.66. top5: 99.66. :  57%|█████▋    | 36/63 [00:01<00:00, 38.31it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9509. top1: 86.27. top5: 99.67. :  57%|█████▋    | 36/63 [00:01<00:00, 38.31it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9619. top1: 85.74. top5: 99.60. :  57%|█████▋    | 36/63 [00:01<00:00, 38.31it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9699. top1: 85.39. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 38.31it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9756. top1: 85.06. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 38.31it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9889. top1: 84.45. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 38.31it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9983. top1: 84.08. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 38.31it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0032. top1: 83.88. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 38.31it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0058. top1: 83.68. top5: 99.51. :  57%|█████▋    | 36/63 [00:02<00:00, 38.31it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0058. top1: 83.68. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0119. top1: 83.42. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0155. top1: 83.11. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0191. top1: 82.94. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0239. top1: 82.91. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0275. top1: 82.62. top5: 99.44. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0379. top1: 81.86. top5: 99.45. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0411. top1: 81.67. top5: 99.40. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0474. top1: 81.37. top5: 99.41. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0556. top1: 80.96. top5: 99.36. :  71%|███████▏  | 45/63 [00:02<00:00, 46.99it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0556. top1: 80.96. top5: 99.36. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0568. top1: 80.80. top5: 99.38. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0592. top1: 80.69. top5: 99.39. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0674. top1: 80.21. top5: 99.34. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0752. top1: 79.80. top5: 99.35. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0800. top1: 79.56. top5: 99.31. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0803. top1: 79.53. top5: 99.27. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0857. top1: 79.25. top5: 99.23. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0941. top1: 78.78. top5: 99.24. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0954. top1: 78.70. top5: 99.25. :  86%|████████▌ | 54/63 [00:02<00:00, 52.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0954. top1: 78.70. top5: 99.25. : 100%|██████████| 63/63 [00:02<00:00, 25.12it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 11/60. Data: 1.72s. Batch: 1.78s. Loss: 1.0560. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 11/60. Data: 1.72s. Batch: 1.78s. Loss: 1.0560. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 11/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0263. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 11/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0484. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 11/60. Data: 1.80s. Batch: 1.86s. Loss: 1.0474. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 11/60. Data: 1.80s. Batch: 1.86s. Loss: 1.0474. :  16%|█▌        | 4/25 [00:01<00:07,  2.63it/s]Finetune Epoch: 11/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0789. :  16%|█▌        | 4/25 [00:01<00:07,  2.63it/s]Finetune Epoch: 11/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0696. :  16%|█▌        | 4/25 [00:02<00:07,  2.63it/s]Finetune Epoch: 11/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0696. :  24%|██▍       | 6/25 [00:02<00:04,  4.16it/s]Finetune Epoch: 11/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0499. :  24%|██▍       | 6/25 [00:02<00:04,  4.16it/s]Finetune Epoch: 11/60. Data: 1.92s. Batch: 1.97s. Loss: 1.0451. :  24%|██▍       | 6/25 [00:02<00:04,  4.16it/s]Finetune Epoch: 11/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0356. :  24%|██▍       | 6/25 [00:02<00:04,  4.16it/s]Finetune Epoch: 11/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0356. :  36%|███▌      | 9/25 [00:02<00:02,  6.74it/s]Finetune Epoch: 11/60. Data: 1.97s. Batch: 2.02s. Loss: 1.0287. :  36%|███▌      | 9/25 [00:02<00:02,  6.74it/s]Finetune Epoch: 11/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0243. :  36%|███▌      | 9/25 [00:02<00:02,  6.74it/s]Finetune Epoch: 11/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0243. :  44%|████▍     | 11/25 [00:02<00:01,  8.50it/s]Finetune Epoch: 11/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0096. :  44%|████▍     | 11/25 [00:02<00:01,  8.50it/s]Finetune Epoch: 11/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0044. :  44%|████▍     | 11/25 [00:02<00:01,  8.50it/s]Finetune Epoch: 11/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9949. :  44%|████▍     | 11/25 [00:02<00:01,  8.50it/s]Finetune Epoch: 11/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9949. :  56%|█████▌    | 14/25 [00:02<00:00, 11.04it/s]Finetune Epoch: 11/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9979. :  56%|█████▌    | 14/25 [00:02<00:00, 11.04it/s]Finetune Epoch: 11/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9999. :  56%|█████▌    | 14/25 [00:02<00:00, 11.04it/s]Finetune Epoch: 11/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9999. :  64%|██████▍   | 16/25 [00:02<00:00, 12.57it/s]Finetune Epoch: 11/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9965. :  64%|██████▍   | 16/25 [00:02<00:00, 12.57it/s]Finetune Epoch: 11/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9992. :  64%|██████▍   | 16/25 [00:02<00:00, 12.57it/s]Finetune Epoch: 11/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0080. :  64%|██████▍   | 16/25 [00:02<00:00, 12.57it/s]Finetune Epoch: 11/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0080. :  76%|███████▌  | 19/25 [00:02<00:00, 14.53it/s]Finetune Epoch: 11/60. Data: 2.23s. Batch: 2.28s. Loss: 1.0056. :  76%|███████▌  | 19/25 [00:02<00:00, 14.53it/s]Finetune Epoch: 11/60. Data: 2.26s. Batch: 2.31s. Loss: 1.0011. :  76%|███████▌  | 19/25 [00:02<00:00, 14.53it/s]Finetune Epoch: 11/60. Data: 2.26s. Batch: 2.31s. Loss: 1.0011. :  84%|████████▍ | 21/25 [00:02<00:00, 15.56it/s]Finetune Epoch: 11/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9953. :  84%|████████▍ | 21/25 [00:02<00:00, 15.56it/s]Finetune Epoch: 11/60. Data: 2.31s. Batch: 2.36s. Loss: 0.9948. :  84%|████████▍ | 21/25 [00:02<00:00, 15.56it/s]Finetune Epoch: 11/60. Data: 2.31s. Batch: 2.36s. Loss: 0.9948. :  92%|█████████▏| 23/25 [00:02<00:00, 16.31it/s]Finetune Epoch: 11/60. Data: 2.33s. Batch: 2.38s. Loss: 1.0036. :  92%|█████████▏| 23/25 [00:02<00:00, 16.31it/s]Finetune Epoch: 11/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0033. :  92%|█████████▏| 23/25 [00:03<00:00, 16.31it/s]Finetune Epoch: 11/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0033. : 100%|██████████| 25/25 [00:03<00:00, 16.99it/s]Finetune Epoch: 11/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0033. : 100%|██████████| 25/25 [00:03<00:00,  7.82it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.9547. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.9547. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 0.9406. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9005. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9086. top1: 85.16. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.8891. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.8855. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9034. top1: 86.61. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9017. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9031. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9061. top1: 86.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8918. top1: 88.07. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8918. top1: 88.07. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8954. top1: 87.76. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8894. top1: 87.74. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8829. top1: 88.39. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8809. top1: 88.75. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8818. top1: 88.87. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8798. top1: 88.97. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8811. top1: 89.06. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8808. top1: 89.14. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  8.38it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8808. top1: 89.14. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8796. top1: 89.06. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8820. top1: 88.99. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8788. top1: 89.20. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8741. top1: 89.67. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8709. top1: 89.84. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8674. top1: 90.00. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8738. top1: 89.42. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8740. top1: 89.35. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8784. top1: 89.06. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8745. top1: 89.33. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8738. top1: 89.38. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 15.50it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8738. top1: 89.38. top5: 100.00. :  48%|████▊     | 30/63 [00:01<00:01, 27.03it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8724. top1: 89.52. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8916. top1: 88.77. top5: 99.90. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8985. top1: 88.54. top5: 99.91. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9073. top1: 88.14. top5: 99.91. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9191. top1: 87.41. top5: 99.91. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9391. top1: 86.81. top5: 99.65. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9430. top1: 86.57. top5: 99.66. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9518. top1: 86.18. top5: 99.67. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9626. top1: 85.66. top5: 99.60. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9704. top1: 85.31. top5: 99.61. :  48%|████▊     | 30/63 [00:02<00:01, 27.03it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9704. top1: 85.31. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9759. top1: 84.98. top5: 99.54. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9891. top1: 84.38. top5: 99.55. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9984. top1: 84.01. top5: 99.49. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0032. top1: 83.81. top5: 99.50. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0057. top1: 83.61. top5: 99.51. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0115. top1: 83.36. top5: 99.52. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0150. top1: 83.05. top5: 99.53. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0185. top1: 82.88. top5: 99.54. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0232. top1: 82.84. top5: 99.49. :  63%|██████▎   | 40/63 [00:02<00:00, 37.90it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0232. top1: 82.84. top5: 99.49. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0267. top1: 82.62. top5: 99.44. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0369. top1: 81.86. top5: 99.45. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0400. top1: 81.67. top5: 99.40. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0461. top1: 81.43. top5: 99.41. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0543. top1: 81.02. top5: 99.36. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0554. top1: 80.85. top5: 99.38. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0577. top1: 80.75. top5: 99.39. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0658. top1: 80.26. top5: 99.34. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0734. top1: 79.85. top5: 99.35. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0782. top1: 79.66. top5: 99.31. :  78%|███████▊  | 49/63 [00:02<00:00, 47.04it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0782. top1: 79.66. top5: 99.31. :  94%|█████████▎| 59/63 [00:02<00:00, 55.32it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0785. top1: 79.64. top5: 99.27. :  94%|█████████▎| 59/63 [00:02<00:00, 55.32it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0837. top1: 79.35. top5: 99.23. :  94%|█████████▎| 59/63 [00:02<00:00, 55.32it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0921. top1: 78.88. top5: 99.24. :  94%|█████████▎| 59/63 [00:02<00:00, 55.32it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0933. top1: 78.80. top5: 99.25. :  94%|█████████▎| 59/63 [00:02<00:00, 55.32it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0933. top1: 78.80. top5: 99.25. : 100%|██████████| 63/63 [00:02<00:00, 24.58it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 12/60. Data: 1.51s. Batch: 1.58s. Loss: 1.1109. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 12/60. Data: 1.51s. Batch: 1.58s. Loss: 1.1109. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 12/60. Data: 1.54s. Batch: 1.60s. Loss: 1.0178. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 12/60. Data: 1.57s. Batch: 1.62s. Loss: 0.9800. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 12/60. Data: 1.60s. Batch: 1.65s. Loss: 1.0077. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 12/60. Data: 1.60s. Batch: 1.65s. Loss: 1.0077. :  16%|█▌        | 4/25 [00:01<00:07,  2.97it/s]Finetune Epoch: 12/60. Data: 1.62s. Batch: 1.67s. Loss: 1.0019. :  16%|█▌        | 4/25 [00:01<00:07,  2.97it/s]Finetune Epoch: 12/60. Data: 1.65s. Batch: 1.69s. Loss: 1.0288. :  16%|█▌        | 4/25 [00:01<00:07,  2.97it/s]Finetune Epoch: 12/60. Data: 1.67s. Batch: 1.72s. Loss: 1.0273. :  16%|█▌        | 4/25 [00:01<00:07,  2.97it/s]Finetune Epoch: 12/60. Data: 1.67s. Batch: 1.72s. Loss: 1.0273. :  28%|██▊       | 7/25 [00:01<00:03,  5.44it/s]Finetune Epoch: 12/60. Data: 1.70s. Batch: 1.75s. Loss: 1.0168. :  28%|██▊       | 7/25 [00:01<00:03,  5.44it/s]Finetune Epoch: 12/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0224. :  28%|██▊       | 7/25 [00:01<00:03,  5.44it/s]Finetune Epoch: 12/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0224. :  36%|███▌      | 9/25 [00:01<00:02,  7.15it/s]Finetune Epoch: 12/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0076. :  36%|███▌      | 9/25 [00:02<00:02,  7.15it/s]Finetune Epoch: 12/60. Data: 1.78s. Batch: 1.82s. Loss: 1.0213. :  36%|███▌      | 9/25 [00:02<00:02,  7.15it/s]Finetune Epoch: 12/60. Data: 1.78s. Batch: 1.82s. Loss: 1.0213. :  44%|████▍     | 11/25 [00:02<00:01,  8.98it/s]Finetune Epoch: 12/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0121. :  44%|████▍     | 11/25 [00:02<00:01,  8.98it/s]Finetune Epoch: 12/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0058. :  44%|████▍     | 11/25 [00:02<00:01,  8.98it/s]Finetune Epoch: 12/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0058. :  52%|█████▏    | 13/25 [00:02<00:01, 10.87it/s]Finetune Epoch: 12/60. Data: 1.85s. Batch: 1.90s. Loss: 1.0148. :  52%|█████▏    | 13/25 [00:02<00:01, 10.87it/s]Finetune Epoch: 12/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0131. :  52%|█████▏    | 13/25 [00:02<00:01, 10.87it/s]Finetune Epoch: 12/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0131. :  60%|██████    | 15/25 [00:02<00:00, 12.62it/s]Finetune Epoch: 12/60. Data: 1.91s. Batch: 1.95s. Loss: 1.0128. :  60%|██████    | 15/25 [00:02<00:00, 12.62it/s]Finetune Epoch: 12/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0100. :  60%|██████    | 15/25 [00:02<00:00, 12.62it/s]Finetune Epoch: 12/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0100. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 12/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0137. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 12/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0209. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 12/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0096. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 12/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0096. :  80%|████████  | 20/25 [00:02<00:00, 16.06it/s]Finetune Epoch: 12/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0135. :  80%|████████  | 20/25 [00:02<00:00, 16.06it/s]Finetune Epoch: 12/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0072. :  80%|████████  | 20/25 [00:02<00:00, 16.06it/s]Finetune Epoch: 12/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0072. :  88%|████████▊ | 22/25 [00:02<00:00, 16.80it/s]Finetune Epoch: 12/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0080. :  88%|████████▊ | 22/25 [00:02<00:00, 16.80it/s]Finetune Epoch: 12/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0071. :  88%|████████▊ | 22/25 [00:02<00:00, 16.80it/s]Finetune Epoch: 12/60. Data: 2.14s. Batch: 2.18s. Loss: 1.0075. :  88%|████████▊ | 22/25 [00:02<00:00, 16.80it/s]Finetune Epoch: 12/60. Data: 2.14s. Batch: 2.18s. Loss: 1.0075. : 100%|██████████| 25/25 [00:02<00:00, 18.34it/s]Finetune Epoch: 12/60. Data: 2.14s. Batch: 2.18s. Loss: 1.0075. : 100%|██████████| 25/25 [00:03<00:00,  8.30it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.62s. Loss: 0.9578. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.62s. Loss: 0.9578. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.82s. Loss: 0.9436. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9029. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9112. top1: 85.16. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.8916. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.8880. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9060. top1: 86.61. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9043. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:40,  1.62s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9043. top1: 85.94. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9058. top1: 86.46. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9087. top1: 86.88. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.8943. top1: 88.07. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8980. top1: 87.76. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8918. top1: 87.74. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8853. top1: 88.39. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8832. top1: 88.75. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.23it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8832. top1: 88.75. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.76it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8842. top1: 88.87. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.76it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8822. top1: 88.97. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.76it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8835. top1: 89.06. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.76it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8831. top1: 89.14. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.76it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8819. top1: 89.06. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.76it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8844. top1: 88.84. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 12.76it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8844. top1: 88.84. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8811. top1: 89.06. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8764. top1: 89.54. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8731. top1: 89.71. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8695. top1: 89.88. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8760. top1: 89.30. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8762. top1: 89.24. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8807. top1: 88.95. top5: 100.00. :  33%|███▎      | 21/63 [00:01<00:02, 18.78it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8768. top1: 89.22. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 18.78it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8761. top1: 89.27. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 18.78it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8747. top1: 89.42. top5: 100.00. :  33%|███▎      | 21/63 [00:02<00:02, 18.78it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8747. top1: 89.42. top5: 100.00. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8936. top1: 88.67. top5: 99.90. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9003. top1: 88.45. top5: 99.91. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9088. top1: 88.05. top5: 99.91. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9205. top1: 87.41. top5: 99.91. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9401. top1: 86.81. top5: 99.65. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9439. top1: 86.57. top5: 99.66. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9525. top1: 86.18. top5: 99.67. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9631. top1: 85.66. top5: 99.60. :  49%|████▉     | 31/63 [00:02<00:01, 31.20it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9631. top1: 85.66. top5: 99.60. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9708. top1: 85.39. top5: 99.61. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9762. top1: 85.06. top5: 99.54. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9892. top1: 84.45. top5: 99.55. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9984. top1: 84.08. top5: 99.49. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0030. top1: 83.88. top5: 99.50. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0054. top1: 83.68. top5: 99.51. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0111. top1: 83.42. top5: 99.52. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0144. top1: 83.18. top5: 99.53. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0178. top1: 83.01. top5: 99.54. :  62%|██████▏   | 39/63 [00:02<00:00, 39.93it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0178. top1: 83.01. top5: 99.54. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0224. top1: 82.97. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0259. top1: 82.75. top5: 99.44. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0359. top1: 81.99. top5: 99.45. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0388. top1: 81.79. top5: 99.40. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0449. top1: 81.54. top5: 99.41. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0529. top1: 81.13. top5: 99.36. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0540. top1: 80.97. top5: 99.38. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0562. top1: 80.86. top5: 99.39. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0642. top1: 80.37. top5: 99.34. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0718. top1: 79.96. top5: 99.35. :  76%|███████▌  | 48/63 [00:02<00:00, 49.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0718. top1: 79.96. top5: 99.35. :  92%|█████████▏| 58/63 [00:02<00:00, 59.14it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0765. top1: 79.77. top5: 99.31. :  92%|█████████▏| 58/63 [00:02<00:00, 59.14it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0767. top1: 79.74. top5: 99.27. :  92%|█████████▏| 58/63 [00:02<00:00, 59.14it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0819. top1: 79.46. top5: 99.23. :  92%|█████████▏| 58/63 [00:02<00:00, 59.14it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0901. top1: 79.03. top5: 99.24. :  92%|█████████▏| 58/63 [00:02<00:00, 59.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0912. top1: 78.95. top5: 99.25. :  92%|█████████▏| 58/63 [00:02<00:00, 59.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0912. top1: 78.95. top5: 99.25. : 100%|██████████| 63/63 [00:02<00:00, 23.98it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 13/60. Data: 1.64s. Batch: 1.70s. Loss: 1.2310. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 13/60. Data: 1.64s. Batch: 1.70s. Loss: 1.2310. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 13/60. Data: 1.67s. Batch: 1.72s. Loss: 1.1863. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 13/60. Data: 1.69s. Batch: 1.74s. Loss: 1.0726. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 13/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0479. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 13/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0479. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 13/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0191. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 13/60. Data: 1.75s. Batch: 1.79s. Loss: 1.0124. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 13/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9951. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 13/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9951. :  28%|██▊       | 7/25 [00:01<00:03,  5.32it/s]Finetune Epoch: 13/60. Data: 1.80s. Batch: 1.84s. Loss: 1.0099. :  28%|██▊       | 7/25 [00:01<00:03,  5.32it/s]Finetune Epoch: 13/60. Data: 1.82s. Batch: 1.86s. Loss: 1.0136. :  28%|██▊       | 7/25 [00:02<00:03,  5.32it/s]Finetune Epoch: 13/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0322. :  28%|██▊       | 7/25 [00:02<00:03,  5.32it/s]Finetune Epoch: 13/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0322. :  40%|████      | 10/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 13/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0166. :  40%|████      | 10/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 13/60. Data: 1.89s. Batch: 1.93s. Loss: 1.0065. :  40%|████      | 10/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 13/60. Data: 1.91s. Batch: 1.95s. Loss: 0.9985. :  40%|████      | 10/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 13/60. Data: 1.91s. Batch: 1.95s. Loss: 0.9985. :  52%|█████▏    | 13/25 [00:02<00:01, 10.62it/s]Finetune Epoch: 13/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9980. :  52%|█████▏    | 13/25 [00:02<00:01, 10.62it/s]Finetune Epoch: 13/60. Data: 1.95s. Batch: 1.99s. Loss: 1.0104. :  52%|█████▏    | 13/25 [00:02<00:01, 10.62it/s]Finetune Epoch: 13/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9958. :  52%|█████▏    | 13/25 [00:02<00:01, 10.62it/s]Finetune Epoch: 13/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9958. :  64%|██████▍   | 16/25 [00:02<00:00, 13.26it/s]Finetune Epoch: 13/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9994. :  64%|██████▍   | 16/25 [00:02<00:00, 13.26it/s]Finetune Epoch: 13/60. Data: 2.02s. Batch: 2.06s. Loss: 0.9961. :  64%|██████▍   | 16/25 [00:02<00:00, 13.26it/s]Finetune Epoch: 13/60. Data: 2.04s. Batch: 2.08s. Loss: 0.9962. :  64%|██████▍   | 16/25 [00:02<00:00, 13.26it/s]Finetune Epoch: 13/60. Data: 2.04s. Batch: 2.08s. Loss: 0.9962. :  76%|███████▌  | 19/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 13/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0026. :  76%|███████▌  | 19/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 13/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0001. :  76%|███████▌  | 19/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 13/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9948. :  76%|███████▌  | 19/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 13/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9948. :  88%|████████▊ | 22/25 [00:02<00:00, 18.42it/s]Finetune Epoch: 13/60. Data: 2.12s. Batch: 2.16s. Loss: 0.9975. :  88%|████████▊ | 22/25 [00:02<00:00, 18.42it/s]Finetune Epoch: 13/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9915. :  88%|████████▊ | 22/25 [00:02<00:00, 18.42it/s]Finetune Epoch: 13/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9886. :  88%|████████▊ | 22/25 [00:02<00:00, 18.42it/s]Finetune Epoch: 13/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9886. : 100%|██████████| 25/25 [00:02<00:00, 20.27it/s]Finetune Epoch: 13/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9886. : 100%|██████████| 25/25 [00:02<00:00,  8.71it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 0.9611. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 0.9611. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.86s. Loss: 0.9466. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.9053. top1: 85.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9138. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8938. top1: 86.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8903. top1: 86.46. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9084. top1: 85.71. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9067. top1: 85.16. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9082. top1: 85.76. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9082. top1: 85.76. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9111. top1: 86.25. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8967. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9003. top1: 87.24. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8941. top1: 87.26. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8876. top1: 87.95. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8854. top1: 88.33. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8863. top1: 88.48. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.69it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8863. top1: 88.48. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.71it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8844. top1: 88.42. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.71it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8857. top1: 88.54. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.71it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8854. top1: 88.65. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.71it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8841. top1: 88.59. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.71it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8865. top1: 88.39. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.71it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8832. top1: 88.64. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.71it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8785. top1: 89.13. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.71it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8752. top1: 89.32. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.71it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8716. top1: 89.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.71it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8781. top1: 88.94. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.71it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8781. top1: 88.94. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8784. top1: 88.89. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8828. top1: 88.62. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8789. top1: 88.90. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8782. top1: 88.96. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8768. top1: 89.11. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8955. top1: 88.38. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9021. top1: 88.16. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9104. top1: 87.78. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9218. top1: 87.14. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9412. top1: 86.55. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 23.33it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9412. top1: 86.55. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9448. top1: 86.40. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9533. top1: 86.02. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9637. top1: 85.50. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9713. top1: 85.23. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9765. top1: 84.91. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9894. top1: 84.30. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9984. top1: 83.94. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0030. top1: 83.74. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0052. top1: 83.54. top5: 99.51. :  57%|█████▋    | 36/63 [00:02<00:00, 34.59it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0052. top1: 83.54. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0108. top1: 83.29. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0140. top1: 83.05. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0173. top1: 82.88. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0218. top1: 82.84. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0252. top1: 82.62. top5: 99.44. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0350. top1: 81.92. top5: 99.45. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0379. top1: 81.73. top5: 99.40. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0439. top1: 81.49. top5: 99.41. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0518. top1: 81.08. top5: 99.36. :  71%|███████▏  | 45/63 [00:02<00:00, 43.98it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0518. top1: 81.08. top5: 99.36. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0529. top1: 80.91. top5: 99.38. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0550. top1: 80.80. top5: 99.39. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0629. top1: 80.32. top5: 99.34. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0703. top1: 79.90. top5: 99.35. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0750. top1: 79.71. top5: 99.31. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0752. top1: 79.69. top5: 99.27. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0803. top1: 79.41. top5: 99.23. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0884. top1: 78.98. top5: 99.24. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0895. top1: 78.90. top5: 99.25. :  86%|████████▌ | 54/63 [00:02<00:00, 53.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0895. top1: 78.90. top5: 99.25. : 100%|██████████| 63/63 [00:02<00:00, 24.15it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 14/60. Data: 1.69s. Batch: 1.75s. Loss: 0.9376. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 14/60. Data: 1.69s. Batch: 1.75s. Loss: 0.9376. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 14/60. Data: 1.73s. Batch: 1.78s. Loss: 0.9399. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 14/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9081. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 14/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9081. :  12%|█▏        | 3/25 [00:01<00:10,  2.03it/s]Finetune Epoch: 14/60. Data: 1.78s. Batch: 1.83s. Loss: 0.9127. :  12%|█▏        | 3/25 [00:01<00:10,  2.03it/s]Finetune Epoch: 14/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9545. :  12%|█▏        | 3/25 [00:01<00:10,  2.03it/s]Finetune Epoch: 14/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9368. :  12%|█▏        | 3/25 [00:01<00:10,  2.03it/s]Finetune Epoch: 14/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9368. :  24%|██▍       | 6/25 [00:01<00:04,  4.56it/s]Finetune Epoch: 14/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9803. :  24%|██▍       | 6/25 [00:02<00:04,  4.56it/s]Finetune Epoch: 14/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9934. :  24%|██▍       | 6/25 [00:02<00:04,  4.56it/s]Finetune Epoch: 14/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9934. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 14/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9854. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 14/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9755. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 14/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9972. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 14/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9972. :  44%|████▍     | 11/25 [00:02<00:01,  9.17it/s]Finetune Epoch: 14/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9932. :  44%|████▍     | 11/25 [00:02<00:01,  9.17it/s]Finetune Epoch: 14/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9994. :  44%|████▍     | 11/25 [00:02<00:01,  9.17it/s]Finetune Epoch: 14/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9994. :  52%|█████▏    | 13/25 [00:02<00:01, 10.77it/s]Finetune Epoch: 14/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9985. :  52%|█████▏    | 13/25 [00:02<00:01, 10.77it/s]Finetune Epoch: 14/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9957. :  52%|█████▏    | 13/25 [00:02<00:01, 10.77it/s]Finetune Epoch: 14/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9957. :  60%|██████    | 15/25 [00:02<00:00, 12.35it/s]Finetune Epoch: 14/60. Data: 2.08s. Batch: 2.12s. Loss: 0.9943. :  60%|██████    | 15/25 [00:02<00:00, 12.35it/s]Finetune Epoch: 14/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9928. :  60%|██████    | 15/25 [00:02<00:00, 12.35it/s]Finetune Epoch: 14/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9928. :  68%|██████▊   | 17/25 [00:02<00:00, 13.86it/s]Finetune Epoch: 14/60. Data: 2.13s. Batch: 2.17s. Loss: 1.0019. :  68%|██████▊   | 17/25 [00:02<00:00, 13.86it/s]Finetune Epoch: 14/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9957. :  68%|██████▊   | 17/25 [00:02<00:00, 13.86it/s]Finetune Epoch: 14/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9902. :  68%|██████▊   | 17/25 [00:02<00:00, 13.86it/s]Finetune Epoch: 14/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9902. :  80%|████████  | 20/25 [00:02<00:00, 15.96it/s]Finetune Epoch: 14/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9881. :  80%|████████  | 20/25 [00:02<00:00, 15.96it/s]Finetune Epoch: 14/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9867. :  80%|████████  | 20/25 [00:02<00:00, 15.96it/s]Finetune Epoch: 14/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9867. :  88%|████████▊ | 22/25 [00:02<00:00, 16.67it/s]Finetune Epoch: 14/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9900. :  88%|████████▊ | 22/25 [00:02<00:00, 16.67it/s]Finetune Epoch: 14/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9977. :  88%|████████▊ | 22/25 [00:02<00:00, 16.67it/s]Finetune Epoch: 14/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9977. :  96%|█████████▌| 24/25 [00:02<00:00, 17.37it/s]Finetune Epoch: 14/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9938. :  96%|█████████▌| 24/25 [00:02<00:00, 17.37it/s]Finetune Epoch: 14/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9938. : 100%|██████████| 25/25 [00:03<00:00,  7.99it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.9636. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 0.9636. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 0.9491. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.9071. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9158. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8957. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8921. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8921. top1: 85.94. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9103. top1: 85.27. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9086. top1: 84.77. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9101. top1: 85.42. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9131. top1: 85.94. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.8985. top1: 87.22. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9022. top1: 86.98. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8960. top1: 87.02. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8894. top1: 87.72. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8872. top1: 88.12. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8881. top1: 88.28. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.45it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8881. top1: 88.28. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8862. top1: 88.24. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8875. top1: 88.37. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8872. top1: 88.49. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8859. top1: 88.44. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8884. top1: 88.24. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8849. top1: 88.49. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8803. top1: 88.99. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.47it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8770. top1: 89.19. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.47it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8733. top1: 89.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.47it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8799. top1: 88.82. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.47it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8799. top1: 88.82. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8801. top1: 88.77. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8846. top1: 88.50. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8806. top1: 88.79. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8800. top1: 88.85. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8785. top1: 89.01. top5: 100.00. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8971. top1: 88.28. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9035. top1: 88.07. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9116. top1: 87.68. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9229. top1: 87.05. top5: 99.91. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9229. top1: 87.05. top5: 99.91. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9421. top1: 86.46. top5: 99.74. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9455. top1: 86.32. top5: 99.75. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9539. top1: 85.94. top5: 99.75. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9642. top1: 85.42. top5: 99.68. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9716. top1: 85.16. top5: 99.69. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9768. top1: 84.83. top5: 99.62. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9895. top1: 84.23. top5: 99.63. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9985. top1: 83.87. top5: 99.56. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.66. top5: 99.57. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0051. top1: 83.47. top5: 99.58. :  56%|█████▌    | 35/63 [00:02<00:00, 33.44it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0051. top1: 83.47. top5: 99.58. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0106. top1: 83.22. top5: 99.59. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0137. top1: 82.98. top5: 99.60. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0169. top1: 82.81. top5: 99.61. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0213. top1: 82.78. top5: 99.55. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0246. top1: 82.56. top5: 99.50. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0343. top1: 81.92. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0371. top1: 81.79. top5: 99.46. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0431. top1: 81.54. top5: 99.47. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0510. top1: 81.13. top5: 99.42. :  71%|███████▏  | 45/63 [00:02<00:00, 44.23it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0510. top1: 81.13. top5: 99.42. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0519. top1: 80.97. top5: 99.43. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0540. top1: 80.86. top5: 99.44. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0618. top1: 80.37. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0692. top1: 79.96. top5: 99.41. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0738. top1: 79.77. top5: 99.36. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0739. top1: 79.74. top5: 99.32. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0790. top1: 79.46. top5: 99.28. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0870. top1: 79.03. top5: 99.29. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0881. top1: 78.95. top5: 99.30. :  86%|████████▌ | 54/63 [00:02<00:00, 53.05it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0881. top1: 78.95. top5: 99.30. : 100%|██████████| 63/63 [00:02<00:00, 23.91it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 15/60. Data: 1.65s. Batch: 1.71s. Loss: 0.9485. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 15/60. Data: 1.65s. Batch: 1.71s. Loss: 0.9485. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 15/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0034. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 15/60. Data: 1.71s. Batch: 1.76s. Loss: 1.0086. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 15/60. Data: 1.73s. Batch: 1.78s. Loss: 0.9945. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 15/60. Data: 1.73s. Batch: 1.78s. Loss: 0.9945. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 15/60. Data: 1.76s. Batch: 1.80s. Loss: 1.0127. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 15/60. Data: 1.78s. Batch: 1.83s. Loss: 0.9912. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 15/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0013. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 15/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0013. :  28%|██▊       | 7/25 [00:01<00:03,  5.23it/s]Finetune Epoch: 15/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9926. :  28%|██▊       | 7/25 [00:02<00:03,  5.23it/s]Finetune Epoch: 15/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9871. :  28%|██▊       | 7/25 [00:02<00:03,  5.23it/s]Finetune Epoch: 15/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9771. :  28%|██▊       | 7/25 [00:02<00:03,  5.23it/s]Finetune Epoch: 15/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9771. :  40%|████      | 10/25 [00:02<00:01,  7.74it/s]Finetune Epoch: 15/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9763. :  40%|████      | 10/25 [00:02<00:01,  7.74it/s]Finetune Epoch: 15/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9964. :  40%|████      | 10/25 [00:02<00:01,  7.74it/s]Finetune Epoch: 15/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9964. :  48%|████▊     | 12/25 [00:02<00:01,  9.35it/s]Finetune Epoch: 15/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9950. :  48%|████▊     | 12/25 [00:02<00:01,  9.35it/s]Finetune Epoch: 15/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9998. :  48%|████▊     | 12/25 [00:02<00:01,  9.35it/s]Finetune Epoch: 15/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9997. :  48%|████▊     | 12/25 [00:02<00:01,  9.35it/s]Finetune Epoch: 15/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9997. :  60%|██████    | 15/25 [00:02<00:00, 11.80it/s]Finetune Epoch: 15/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0061. :  60%|██████    | 15/25 [00:02<00:00, 11.80it/s]Finetune Epoch: 15/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0036. :  60%|██████    | 15/25 [00:02<00:00, 11.80it/s]Finetune Epoch: 15/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0036. :  68%|██████▊   | 17/25 [00:02<00:00, 12.93it/s]Finetune Epoch: 15/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9910. :  68%|██████▊   | 17/25 [00:02<00:00, 12.93it/s]Finetune Epoch: 15/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9896. :  68%|██████▊   | 17/25 [00:02<00:00, 12.93it/s]Finetune Epoch: 15/60. Data: 2.12s. Batch: 2.17s. Loss: 0.9884. :  68%|██████▊   | 17/25 [00:02<00:00, 12.93it/s]Finetune Epoch: 15/60. Data: 2.12s. Batch: 2.17s. Loss: 0.9884. :  80%|████████  | 20/25 [00:02<00:00, 15.18it/s]Finetune Epoch: 15/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9887. :  80%|████████  | 20/25 [00:02<00:00, 15.18it/s]Finetune Epoch: 15/60. Data: 2.17s. Batch: 2.21s. Loss: 1.0063. :  80%|████████  | 20/25 [00:02<00:00, 15.18it/s]Finetune Epoch: 15/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0003. :  80%|████████  | 20/25 [00:02<00:00, 15.18it/s]Finetune Epoch: 15/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0003. :  92%|█████████▏| 23/25 [00:02<00:00, 16.70it/s]Finetune Epoch: 15/60. Data: 2.22s. Batch: 2.26s. Loss: 0.9951. :  92%|█████████▏| 23/25 [00:02<00:00, 16.70it/s]Finetune Epoch: 15/60. Data: 2.24s. Batch: 2.29s. Loss: 0.9977. :  92%|█████████▏| 23/25 [00:02<00:00, 16.70it/s]Finetune Epoch: 15/60. Data: 2.24s. Batch: 2.29s. Loss: 0.9977. : 100%|██████████| 25/25 [00:02<00:00, 17.10it/s]Finetune Epoch: 15/60. Data: 2.24s. Batch: 2.29s. Loss: 0.9977. : 100%|██████████| 25/25 [00:03<00:00,  7.98it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.69s. Loss: 0.9663. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.69s. Loss: 0.9663. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.86s. Loss: 0.9516. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.9092. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9181. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.8978. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.8943. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9125. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9125. top1: 85.27. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.18it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9108. top1: 84.77. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.18it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9124. top1: 85.42. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.18it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9153. top1: 85.94. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.18it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9007. top1: 87.22. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.18it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9043. top1: 86.98. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.18it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8981. top1: 87.02. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.18it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8981. top1: 87.02. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 10.47it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8914. top1: 87.72. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 10.47it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8892. top1: 88.12. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 10.47it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8901. top1: 88.09. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 10.47it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8882. top1: 88.05. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 10.47it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8895. top1: 88.19. top5: 100.00. :  21%|██        | 13/63 [00:01<00:04, 10.47it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8892. top1: 88.32. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.47it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8879. top1: 88.28. top5: 100.00. :  21%|██        | 13/63 [00:02<00:04, 10.47it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8879. top1: 88.28. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8903. top1: 88.10. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8868. top1: 88.35. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8821. top1: 88.86. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8789. top1: 89.06. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8751. top1: 89.25. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8817. top1: 88.70. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8820. top1: 88.66. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8865. top1: 88.39. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8825. top1: 88.69. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.72it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8825. top1: 88.69. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8818. top1: 88.75. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8804. top1: 88.91. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8988. top1: 88.18. top5: 99.90. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9050. top1: 87.97. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9130. top1: 87.68. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9240. top1: 87.14. top5: 99.91. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9431. top1: 86.55. top5: 99.74. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9463. top1: 86.40. top5: 99.75. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9546. top1: 86.02. top5: 99.75. :  46%|████▌     | 29/63 [00:02<00:01, 28.30it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9546. top1: 86.02. top5: 99.75. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9647. top1: 85.50. top5: 99.68. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9720. top1: 85.23. top5: 99.69. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9771. top1: 84.91. top5: 99.62. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9897. top1: 84.30. top5: 99.63. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9986. top1: 83.94. top5: 99.56. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.74. top5: 99.57. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0050. top1: 83.54. top5: 99.58. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0103. top1: 83.29. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0134. top1: 83.05. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 38.32it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0134. top1: 83.05. top5: 99.60. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0165. top1: 82.88. top5: 99.61. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0208. top1: 82.84. top5: 99.55. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0241. top1: 82.62. top5: 99.50. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0336. top1: 82.05. top5: 99.51. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0364. top1: 81.97. top5: 99.46. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0423. top1: 81.72. top5: 99.47. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0500. top1: 81.31. top5: 99.42. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0510. top1: 81.14. top5: 99.43. :  75%|███████▍  | 47/63 [00:02<00:00, 48.04it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0510. top1: 81.14. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0530. top1: 81.03. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0607. top1: 80.54. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0680. top1: 80.12. top5: 99.41. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0725. top1: 79.93. top5: 99.36. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0726. top1: 79.90. top5: 99.32. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0776. top1: 79.61. top5: 99.28. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0855. top1: 79.18. top5: 99.29. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0866. top1: 79.10. top5: 99.30. :  87%|████████▋ | 55/63 [00:02<00:00, 54.52it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0866. top1: 79.10. top5: 99.30. : 100%|██████████| 63/63 [00:02<00:00, 23.11it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 16/60. Data: 1.60s. Batch: 1.66s. Loss: 0.9857. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 16/60. Data: 1.60s. Batch: 1.66s. Loss: 0.9857. :   4%|▍         | 1/25 [00:01<00:39,  1.66s/it]Finetune Epoch: 16/60. Data: 1.63s. Batch: 1.68s. Loss: 0.9925. :   4%|▍         | 1/25 [00:01<00:39,  1.66s/it]Finetune Epoch: 16/60. Data: 1.66s. Batch: 1.71s. Loss: 1.0275. :   4%|▍         | 1/25 [00:01<00:39,  1.66s/it]Finetune Epoch: 16/60. Data: 1.68s. Batch: 1.73s. Loss: 0.9827. :   4%|▍         | 1/25 [00:01<00:39,  1.66s/it]Finetune Epoch: 16/60. Data: 1.68s. Batch: 1.73s. Loss: 0.9827. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 16/60. Data: 1.71s. Batch: 1.76s. Loss: 0.9731. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 16/60. Data: 1.73s. Batch: 1.78s. Loss: 0.9506. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 16/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9611. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 16/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9611. :  28%|██▊       | 7/25 [00:01<00:03,  5.32it/s]Finetune Epoch: 16/60. Data: 1.78s. Batch: 1.83s. Loss: 0.9842. :  28%|██▊       | 7/25 [00:01<00:03,  5.32it/s]Finetune Epoch: 16/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9941. :  28%|██▊       | 7/25 [00:02<00:03,  5.32it/s]Finetune Epoch: 16/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9941. :  36%|███▌      | 9/25 [00:02<00:02,  7.04it/s]Finetune Epoch: 16/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0100. :  36%|███▌      | 9/25 [00:02<00:02,  7.04it/s]Finetune Epoch: 16/60. Data: 1.86s. Batch: 1.90s. Loss: 1.0018. :  36%|███▌      | 9/25 [00:02<00:02,  7.04it/s]Finetune Epoch: 16/60. Data: 1.86s. Batch: 1.90s. Loss: 1.0018. :  44%|████▍     | 11/25 [00:02<00:01,  8.68it/s]Finetune Epoch: 16/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9982. :  44%|████▍     | 11/25 [00:02<00:01,  8.68it/s]Finetune Epoch: 16/60. Data: 1.91s. Batch: 1.96s. Loss: 1.0023. :  44%|████▍     | 11/25 [00:02<00:01,  8.68it/s]Finetune Epoch: 16/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0054. :  44%|████▍     | 11/25 [00:02<00:01,  8.68it/s]Finetune Epoch: 16/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0054. :  56%|█████▌    | 14/25 [00:02<00:00, 11.34it/s]Finetune Epoch: 16/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0152. :  56%|█████▌    | 14/25 [00:02<00:00, 11.34it/s]Finetune Epoch: 16/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0029. :  56%|█████▌    | 14/25 [00:02<00:00, 11.34it/s]Finetune Epoch: 16/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0029. :  64%|██████▍   | 16/25 [00:02<00:00, 12.65it/s]Finetune Epoch: 16/60. Data: 2.01s. Batch: 2.06s. Loss: 0.9933. :  64%|██████▍   | 16/25 [00:02<00:00, 12.65it/s]Finetune Epoch: 16/60. Data: 2.04s. Batch: 2.08s. Loss: 0.9860. :  64%|██████▍   | 16/25 [00:02<00:00, 12.65it/s]Finetune Epoch: 16/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9844. :  64%|██████▍   | 16/25 [00:02<00:00, 12.65it/s]Finetune Epoch: 16/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9844. :  76%|███████▌  | 19/25 [00:02<00:00, 14.93it/s]Finetune Epoch: 16/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9819. :  76%|███████▌  | 19/25 [00:02<00:00, 14.93it/s]Finetune Epoch: 16/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9772. :  76%|███████▌  | 19/25 [00:02<00:00, 14.93it/s]Finetune Epoch: 16/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9772. :  84%|████████▍ | 21/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 16/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9798. :  84%|████████▍ | 21/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 16/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9884. :  84%|████████▍ | 21/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 16/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9838. :  84%|████████▍ | 21/25 [00:02<00:00, 15.95it/s]Finetune Epoch: 16/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9838. :  96%|█████████▌| 24/25 [00:02<00:00, 17.04it/s]Finetune Epoch: 16/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9963. :  96%|█████████▌| 24/25 [00:02<00:00, 17.04it/s]Finetune Epoch: 16/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9963. : 100%|██████████| 25/25 [00:03<00:00,  8.08it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.81s. Loss: 0.9688. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.81s. Loss: 0.9688. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 0.9540. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 0.9110. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.9201. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.8996. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.8961. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9144. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9128. top1: 84.77. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9128. top1: 84.77. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.63it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9143. top1: 85.42. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.63it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9173. top1: 85.94. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.63it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9025. top1: 87.22. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.63it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9062. top1: 86.98. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.63it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.8999. top1: 87.02. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.63it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8932. top1: 87.72. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:09,  5.63it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8932. top1: 87.72. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.8910. top1: 88.12. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8919. top1: 88.09. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8900. top1: 88.05. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8913. top1: 88.19. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8910. top1: 88.32. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8896. top1: 88.28. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8921. top1: 88.10. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8886. top1: 88.35. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8839. top1: 88.86. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.70it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8839. top1: 88.86. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8806. top1: 89.06. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8768. top1: 89.25. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8834. top1: 88.70. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8837. top1: 88.66. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8883. top1: 88.39. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8842. top1: 88.69. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8836. top1: 88.75. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8821. top1: 88.91. top5: 100.00. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9004. top1: 88.18. top5: 99.90. :  37%|███▋      | 23/63 [00:02<00:02, 19.93it/s] Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9004. top1: 88.18. top5: 99.90. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9064. top1: 87.97. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9143. top1: 87.68. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9251. top1: 87.14. top5: 99.91. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9440. top1: 86.55. top5: 99.74. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9471. top1: 86.40. top5: 99.75. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9552. top1: 86.02. top5: 99.75. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9652. top1: 85.50. top5: 99.68. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9724. top1: 85.23. top5: 99.69. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9774. top1: 84.91. top5: 99.62. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9899. top1: 84.30. top5: 99.63. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9987. top1: 83.94. top5: 99.56. :  51%|█████     | 32/63 [00:02<00:01, 29.98it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9987. top1: 83.94. top5: 99.56. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.74. top5: 99.57. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0049. top1: 83.54. top5: 99.58. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0101. top1: 83.29. top5: 99.59. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0131. top1: 83.05. top5: 99.60. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0161. top1: 82.88. top5: 99.61. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0204. top1: 82.84. top5: 99.55. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0236. top1: 82.69. top5: 99.50. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0330. top1: 82.11. top5: 99.51. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0356. top1: 82.09. top5: 99.46. :  68%|██████▊   | 43/63 [00:02<00:00, 42.15it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0356. top1: 82.09. top5: 99.46. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0415. top1: 81.84. top5: 99.47. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0492. top1: 81.42. top5: 99.42. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0500. top1: 81.25. top5: 99.43. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0520. top1: 81.14. top5: 99.44. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0597. top1: 80.65. top5: 99.40. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0668. top1: 80.23. top5: 99.41. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0713. top1: 80.08. top5: 99.36. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0714. top1: 80.05. top5: 99.32. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0764. top1: 79.76. top5: 99.28. :  83%|████████▎ | 52/63 [00:02<00:00, 50.82it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0764. top1: 79.76. top5: 99.28. :  97%|█████████▋| 61/63 [00:02<00:00, 57.44it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0842. top1: 79.33. top5: 99.29. :  97%|█████████▋| 61/63 [00:02<00:00, 57.44it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0853. top1: 79.25. top5: 99.30. :  97%|█████████▋| 61/63 [00:02<00:00, 57.44it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0853. top1: 79.25. top5: 99.30. : 100%|██████████| 63/63 [00:02<00:00, 22.73it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 17/60. Data: 1.70s. Batch: 1.75s. Loss: 0.8695. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 17/60. Data: 1.70s. Batch: 1.75s. Loss: 0.8695. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 17/60. Data: 1.73s. Batch: 1.77s. Loss: 0.8785. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 17/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0122. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 17/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0030. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 17/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0030. :  16%|█▌        | 4/25 [00:01<00:07,  2.70it/s]Finetune Epoch: 17/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0173. :  16%|█▌        | 4/25 [00:01<00:07,  2.70it/s]Finetune Epoch: 17/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0274. :  16%|█▌        | 4/25 [00:02<00:07,  2.70it/s]Finetune Epoch: 17/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0274. :  24%|██▍       | 6/25 [00:02<00:04,  4.30it/s]Finetune Epoch: 17/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9996. :  24%|██▍       | 6/25 [00:02<00:04,  4.30it/s]Finetune Epoch: 17/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9880. :  24%|██▍       | 6/25 [00:02<00:04,  4.30it/s]Finetune Epoch: 17/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9880. :  32%|███▏      | 8/25 [00:02<00:02,  6.09it/s]Finetune Epoch: 17/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9849. :  32%|███▏      | 8/25 [00:02<00:02,  6.09it/s]Finetune Epoch: 17/60. Data: 1.93s. Batch: 1.98s. Loss: 0.9811. :  32%|███▏      | 8/25 [00:02<00:02,  6.09it/s]Finetune Epoch: 17/60. Data: 1.93s. Batch: 1.98s. Loss: 0.9811. :  40%|████      | 10/25 [00:02<00:01,  8.07it/s]Finetune Epoch: 17/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9940. :  40%|████      | 10/25 [00:02<00:01,  8.07it/s]Finetune Epoch: 17/60. Data: 1.98s. Batch: 2.03s. Loss: 0.9860. :  40%|████      | 10/25 [00:02<00:01,  8.07it/s]Finetune Epoch: 17/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9903. :  40%|████      | 10/25 [00:02<00:01,  8.07it/s]Finetune Epoch: 17/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9903. :  52%|█████▏    | 13/25 [00:02<00:01, 11.13it/s]Finetune Epoch: 17/60. Data: 2.03s. Batch: 2.08s. Loss: 0.9840. :  52%|█████▏    | 13/25 [00:02<00:01, 11.13it/s]Finetune Epoch: 17/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9947. :  52%|█████▏    | 13/25 [00:02<00:01, 11.13it/s]Finetune Epoch: 17/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9947. :  60%|██████    | 15/25 [00:02<00:00, 12.65it/s]Finetune Epoch: 17/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9956. :  60%|██████    | 15/25 [00:02<00:00, 12.65it/s]Finetune Epoch: 17/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9920. :  60%|██████    | 15/25 [00:02<00:00, 12.65it/s]Finetune Epoch: 17/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9920. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 17/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0081. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 17/60. Data: 2.16s. Batch: 2.20s. Loss: 1.0139. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 17/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0080. :  68%|██████▊   | 17/25 [00:02<00:00, 14.11it/s]Finetune Epoch: 17/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0080. :  80%|████████  | 20/25 [00:02<00:00, 16.37it/s]Finetune Epoch: 17/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0037. :  80%|████████  | 20/25 [00:02<00:00, 16.37it/s]Finetune Epoch: 17/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9986. :  80%|████████  | 20/25 [00:02<00:00, 16.37it/s]Finetune Epoch: 17/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9947. :  80%|████████  | 20/25 [00:02<00:00, 16.37it/s]Finetune Epoch: 17/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9947. :  92%|█████████▏| 23/25 [00:02<00:00, 17.74it/s]Finetune Epoch: 17/60. Data: 2.28s. Batch: 2.33s. Loss: 1.0000. :  92%|█████████▏| 23/25 [00:02<00:00, 17.74it/s]Finetune Epoch: 17/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9978. :  92%|█████████▏| 23/25 [00:02<00:00, 17.74it/s]Finetune Epoch: 17/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9978. : 100%|██████████| 25/25 [00:03<00:00,  7.92it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.57s. Loss: 0.9716. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.57s. Loss: 0.9716. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.79s. Loss: 0.9567. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 0.9132. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 0.9224. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9017. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.8983. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9167. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9151. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9166. top1: 85.07. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9196. top1: 85.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9196. top1: 85.62. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9048. top1: 86.93. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9085. top1: 86.72. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9021. top1: 86.78. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8954. top1: 87.50. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8930. top1: 87.92. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8940. top1: 87.89. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8921. top1: 87.87. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.07it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8921. top1: 87.87. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8934. top1: 88.02. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8931. top1: 88.16. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8917. top1: 88.12. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8942. top1: 87.95. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8906. top1: 88.21. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8859. top1: 88.72. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8826. top1: 88.93. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8788. top1: 89.12. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8854. top1: 88.58. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8857. top1: 88.54. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8903. top1: 88.28. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.58it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8903. top1: 88.28. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8862. top1: 88.58. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8856. top1: 88.65. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8842. top1: 88.81. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9022. top1: 88.09. top5: 99.90. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9080. top1: 87.88. top5: 99.91. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9157. top1: 87.59. top5: 99.91. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9263. top1: 87.14. top5: 99.91. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9450. top1: 86.55. top5: 99.74. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9479. top1: 86.40. top5: 99.75. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9559. top1: 86.02. top5: 99.75. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9657. top1: 85.50. top5: 99.68. :  44%|████▍     | 28/63 [00:01<00:01, 26.85it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9657. top1: 85.50. top5: 99.68. :  62%|██████▏   | 39/63 [00:01<00:00, 39.30it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9728. top1: 85.23. top5: 99.69. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9777. top1: 84.91. top5: 99.62. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9901. top1: 84.30. top5: 99.63. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9987. top1: 83.94. top5: 99.56. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.74. top5: 99.57. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0048. top1: 83.54. top5: 99.58. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0099. top1: 83.29. top5: 99.59. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0127. top1: 83.05. top5: 99.60. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0157. top1: 82.88. top5: 99.61. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0199. top1: 82.84. top5: 99.55. :  62%|██████▏   | 39/63 [00:02<00:00, 39.30it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0199. top1: 82.84. top5: 99.55. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0229. top1: 82.69. top5: 99.50. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0322. top1: 82.11. top5: 99.51. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0348. top1: 82.09. top5: 99.46. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0406. top1: 81.84. top5: 99.47. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0482. top1: 81.42. top5: 99.42. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0490. top1: 81.31. top5: 99.43. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0509. top1: 81.19. top5: 99.44. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0584. top1: 80.76. top5: 99.40. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0655. top1: 80.33. top5: 99.41. :  78%|███████▊  | 49/63 [00:02<00:00, 49.53it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0655. top1: 80.33. top5: 99.41. :  92%|█████████▏| 58/63 [00:02<00:00, 56.43it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0700. top1: 80.19. top5: 99.36. :  92%|█████████▏| 58/63 [00:02<00:00, 56.43it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0700. top1: 80.16. top5: 99.32. :  92%|█████████▏| 58/63 [00:02<00:00, 56.43it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0749. top1: 79.87. top5: 99.28. :  92%|█████████▏| 58/63 [00:02<00:00, 56.43it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0826. top1: 79.44. top5: 99.29. :  92%|█████████▏| 58/63 [00:02<00:00, 56.43it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0837. top1: 79.35. top5: 99.30. :  92%|█████████▏| 58/63 [00:02<00:00, 56.43it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0837. top1: 79.35. top5: 99.30. : 100%|██████████| 63/63 [00:02<00:00, 25.83it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 18/60. Data: 1.60s. Batch: 1.67s. Loss: 0.8466. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 18/60. Data: 1.60s. Batch: 1.67s. Loss: 0.8466. :   4%|▍         | 1/25 [00:01<00:39,  1.67s/it]Finetune Epoch: 18/60. Data: 1.63s. Batch: 1.69s. Loss: 0.9206. :   4%|▍         | 1/25 [00:01<00:39,  1.67s/it]Finetune Epoch: 18/60. Data: 1.66s. Batch: 1.72s. Loss: 0.9715. :   4%|▍         | 1/25 [00:01<00:39,  1.67s/it]Finetune Epoch: 18/60. Data: 1.66s. Batch: 1.72s. Loss: 0.9715. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 18/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9479. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 18/60. Data: 1.71s. Batch: 1.77s. Loss: 0.9696. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 18/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9638. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 18/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9638. :  24%|██▍       | 6/25 [00:01<00:04,  4.72it/s]Finetune Epoch: 18/60. Data: 1.76s. Batch: 1.82s. Loss: 0.9959. :  24%|██▍       | 6/25 [00:01<00:04,  4.72it/s]Finetune Epoch: 18/60. Data: 1.79s. Batch: 1.84s. Loss: 1.0098. :  24%|██▍       | 6/25 [00:02<00:04,  4.72it/s]Finetune Epoch: 18/60. Data: 1.79s. Batch: 1.84s. Loss: 1.0098. :  32%|███▏      | 8/25 [00:02<00:02,  6.53it/s]Finetune Epoch: 18/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0021. :  32%|███▏      | 8/25 [00:02<00:02,  6.53it/s]Finetune Epoch: 18/60. Data: 1.84s. Batch: 1.90s. Loss: 1.0201. :  32%|███▏      | 8/25 [00:02<00:02,  6.53it/s]Finetune Epoch: 18/60. Data: 1.84s. Batch: 1.90s. Loss: 1.0201. :  40%|████      | 10/25 [00:02<00:01,  8.36it/s]Finetune Epoch: 18/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0086. :  40%|████      | 10/25 [00:02<00:01,  8.36it/s]Finetune Epoch: 18/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0010. :  40%|████      | 10/25 [00:02<00:01,  8.36it/s]Finetune Epoch: 18/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0010. :  48%|████▊     | 12/25 [00:02<00:01, 10.33it/s]Finetune Epoch: 18/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9992. :  48%|████▊     | 12/25 [00:02<00:01, 10.33it/s]Finetune Epoch: 18/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0088. :  48%|████▊     | 12/25 [00:02<00:01, 10.33it/s]Finetune Epoch: 18/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0088. :  56%|█████▌    | 14/25 [00:02<00:00, 12.16it/s]Finetune Epoch: 18/60. Data: 1.97s. Batch: 2.03s. Loss: 1.0074. :  56%|█████▌    | 14/25 [00:02<00:00, 12.16it/s]Finetune Epoch: 18/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0115. :  56%|█████▌    | 14/25 [00:02<00:00, 12.16it/s]Finetune Epoch: 18/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0115. :  64%|██████▍   | 16/25 [00:02<00:00, 13.53it/s]Finetune Epoch: 18/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0104. :  64%|██████▍   | 16/25 [00:02<00:00, 13.53it/s]Finetune Epoch: 18/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0036. :  64%|██████▍   | 16/25 [00:02<00:00, 13.53it/s]Finetune Epoch: 18/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0018. :  64%|██████▍   | 16/25 [00:02<00:00, 13.53it/s]Finetune Epoch: 18/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0018. :  76%|███████▌  | 19/25 [00:02<00:00, 15.73it/s]Finetune Epoch: 18/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0057. :  76%|███████▌  | 19/25 [00:02<00:00, 15.73it/s]Finetune Epoch: 18/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0059. :  76%|███████▌  | 19/25 [00:02<00:00, 15.73it/s]Finetune Epoch: 18/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0059. :  84%|████████▍ | 21/25 [00:02<00:00, 16.56it/s]Finetune Epoch: 18/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0121. :  84%|████████▍ | 21/25 [00:02<00:00, 16.56it/s]Finetune Epoch: 18/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0097. :  84%|████████▍ | 21/25 [00:02<00:00, 16.56it/s]Finetune Epoch: 18/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0074. :  84%|████████▍ | 21/25 [00:02<00:00, 16.56it/s]Finetune Epoch: 18/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0074. :  96%|█████████▌| 24/25 [00:02<00:00, 18.13it/s]Finetune Epoch: 18/60. Data: 2.23s. Batch: 2.28s. Loss: 1.0080. :  96%|█████████▌| 24/25 [00:02<00:00, 18.13it/s]Finetune Epoch: 18/60. Data: 2.23s. Batch: 2.28s. Loss: 1.0080. : 100%|██████████| 25/25 [00:03<00:00,  8.09it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.61s. Loss: 0.9746. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.61s. Loss: 0.9746. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.82s. Loss: 0.9595. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.9155. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9249. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9040. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9005. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9191. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9175. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9175. top1: 84.38. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9190. top1: 85.07. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9220. top1: 85.62. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9071. top1: 86.65. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9108. top1: 86.46. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9045. top1: 86.54. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8976. top1: 87.28. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8952. top1: 87.71. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8962. top1: 87.70. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.25it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8962. top1: 87.70. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8943. top1: 87.68. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8957. top1: 87.85. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8953. top1: 87.99. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8939. top1: 87.97. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8964. top1: 87.80. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8928. top1: 88.07. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8880. top1: 88.59. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8847. top1: 88.80. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8809. top1: 89.00. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8876. top1: 88.46. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8879. top1: 88.43. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8879. top1: 88.43. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.97it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8925. top1: 88.17. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.97it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8884. top1: 88.47. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.97it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8877. top1: 88.54. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.97it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8863. top1: 88.71. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.97it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9041. top1: 87.99. top5: 99.90. :  43%|████▎     | 27/63 [00:01<00:01, 25.97it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9098. top1: 87.78. top5: 99.91. :  43%|████▎     | 27/63 [00:01<00:01, 25.97it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9173. top1: 87.50. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.97it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9277. top1: 87.05. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.97it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9461. top1: 86.46. top5: 99.74. :  43%|████▎     | 27/63 [00:02<00:01, 25.97it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9489. top1: 86.32. top5: 99.75. :  43%|████▎     | 27/63 [00:02<00:01, 25.97it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9489. top1: 86.32. top5: 99.75. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9567. top1: 85.94. top5: 99.75. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9664. top1: 85.50. top5: 99.68. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9733. top1: 85.23. top5: 99.69. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9781. top1: 84.91. top5: 99.62. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9903. top1: 84.30. top5: 99.63. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9989. top1: 83.94. top5: 99.56. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.74. top5: 99.57. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0047. top1: 83.61. top5: 99.58. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0096. top1: 83.36. top5: 99.59. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0124. top1: 83.11. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 37.29it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0124. top1: 83.11. top5: 99.60. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0152. top1: 82.94. top5: 99.61. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0193. top1: 82.91. top5: 99.55. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0223. top1: 82.75. top5: 99.50. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0314. top1: 82.17. top5: 99.51. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0339. top1: 82.15. top5: 99.46. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0396. top1: 81.90. top5: 99.47. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0471. top1: 81.54. top5: 99.42. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0479. top1: 81.42. top5: 99.43. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0497. top1: 81.36. top5: 99.44. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0572. top1: 80.92. top5: 99.40. :  75%|███████▍  | 47/63 [00:02<00:00, 48.06it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0572. top1: 80.92. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 57.57it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0642. top1: 80.50. top5: 99.41. :  90%|█████████ | 57/63 [00:02<00:00, 57.57it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0685. top1: 80.35. top5: 99.36. :  90%|█████████ | 57/63 [00:02<00:00, 57.57it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0686. top1: 80.31. top5: 99.32. :  90%|█████████ | 57/63 [00:02<00:00, 57.57it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0734. top1: 80.02. top5: 99.28. :  90%|█████████ | 57/63 [00:02<00:00, 57.57it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0810. top1: 79.59. top5: 99.29. :  90%|█████████ | 57/63 [00:02<00:00, 57.57it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0820. top1: 79.50. top5: 99.30. :  90%|█████████ | 57/63 [00:02<00:00, 57.57it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0820. top1: 79.50. top5: 99.30. : 100%|██████████| 63/63 [00:02<00:00, 25.54it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 19/60. Data: 1.58s. Batch: 1.63s. Loss: 0.9761. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 19/60. Data: 1.58s. Batch: 1.63s. Loss: 0.9761. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 19/60. Data: 1.60s. Batch: 1.64s. Loss: 1.1107. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 19/60. Data: 1.62s. Batch: 1.66s. Loss: 1.0915. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 19/60. Data: 1.64s. Batch: 1.67s. Loss: 1.0375. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 19/60. Data: 1.66s. Batch: 1.69s. Loss: 1.0097. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 19/60. Data: 1.66s. Batch: 1.69s. Loss: 1.0097. :  20%|██        | 5/25 [00:01<00:05,  3.71it/s]Finetune Epoch: 19/60. Data: 1.67s. Batch: 1.71s. Loss: 1.0240. :  20%|██        | 5/25 [00:01<00:05,  3.71it/s]Finetune Epoch: 19/60. Data: 1.69s. Batch: 1.73s. Loss: 1.0271. :  20%|██        | 5/25 [00:01<00:05,  3.71it/s]Finetune Epoch: 19/60. Data: 1.71s. Batch: 1.74s. Loss: 1.0030. :  20%|██        | 5/25 [00:01<00:05,  3.71it/s]Finetune Epoch: 19/60. Data: 1.71s. Batch: 1.74s. Loss: 1.0030. :  32%|███▏      | 8/25 [00:01<00:02,  6.29it/s]Finetune Epoch: 19/60. Data: 1.73s. Batch: 1.76s. Loss: 1.0145. :  32%|███▏      | 8/25 [00:01<00:02,  6.29it/s]Finetune Epoch: 19/60. Data: 1.74s. Batch: 1.78s. Loss: 1.0031. :  32%|███▏      | 8/25 [00:01<00:02,  6.29it/s]Finetune Epoch: 19/60. Data: 1.76s. Batch: 1.79s. Loss: 1.0180. :  32%|███▏      | 8/25 [00:01<00:02,  6.29it/s]Finetune Epoch: 19/60. Data: 1.78s. Batch: 1.81s. Loss: 1.0265. :  32%|███▏      | 8/25 [00:02<00:02,  6.29it/s]Finetune Epoch: 19/60. Data: 1.78s. Batch: 1.81s. Loss: 1.0265. :  48%|████▊     | 12/25 [00:02<00:01, 10.08it/s]Finetune Epoch: 19/60. Data: 1.79s. Batch: 1.83s. Loss: 1.0149. :  48%|████▊     | 12/25 [00:02<00:01, 10.08it/s]Finetune Epoch: 19/60. Data: 1.81s. Batch: 1.85s. Loss: 1.0052. :  48%|████▊     | 12/25 [00:02<00:01, 10.08it/s]Finetune Epoch: 19/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9965. :  48%|████▊     | 12/25 [00:02<00:01, 10.08it/s]Finetune Epoch: 19/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9965. :  60%|██████    | 15/25 [00:02<00:00, 11.72it/s]Finetune Epoch: 19/60. Data: 1.86s. Batch: 1.89s. Loss: 0.9988. :  60%|██████    | 15/25 [00:02<00:00, 11.72it/s]Finetune Epoch: 19/60. Data: 1.88s. Batch: 1.91s. Loss: 0.9974. :  60%|██████    | 15/25 [00:02<00:00, 11.72it/s]Finetune Epoch: 19/60. Data: 1.90s. Batch: 1.93s. Loss: 0.9930. :  60%|██████    | 15/25 [00:02<00:00, 11.72it/s]Finetune Epoch: 19/60. Data: 1.90s. Batch: 1.93s. Loss: 0.9930. :  72%|███████▏  | 18/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 19/60. Data: 1.92s. Batch: 1.95s. Loss: 0.9903. :  72%|███████▏  | 18/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 19/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9889. :  72%|███████▏  | 18/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 19/60. Data: 1.96s. Batch: 2.00s. Loss: 0.9883. :  72%|███████▏  | 18/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 19/60. Data: 1.96s. Batch: 2.00s. Loss: 0.9883. :  84%|████████▍ | 21/25 [00:02<00:00, 15.61it/s]Finetune Epoch: 19/60. Data: 1.98s. Batch: 2.02s. Loss: 0.9867. :  84%|████████▍ | 21/25 [00:02<00:00, 15.61it/s]Finetune Epoch: 19/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9826. :  84%|████████▍ | 21/25 [00:02<00:00, 15.61it/s]Finetune Epoch: 19/60. Data: 2.03s. Batch: 2.07s. Loss: 0.9897. :  84%|████████▍ | 21/25 [00:02<00:00, 15.61it/s]Finetune Epoch: 19/60. Data: 2.03s. Batch: 2.07s. Loss: 0.9897. :  96%|█████████▌| 24/25 [00:02<00:00, 16.71it/s]Finetune Epoch: 19/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9936. :  96%|█████████▌| 24/25 [00:02<00:00, 16.71it/s]Finetune Epoch: 19/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9936. : 100%|██████████| 25/25 [00:02<00:00,  8.83it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.59s. Loss: 0.9763. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.59s. Loss: 0.9763. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.81s. Loss: 0.9612. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.54s. Loss: 0.9169. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.41s. Loss: 0.9263. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9053. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9018. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9204. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9188. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9188. top1: 84.38. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9204. top1: 85.07. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9233. top1: 85.62. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9084. top1: 86.65. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9121. top1: 86.46. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9057. top1: 86.54. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.8989. top1: 87.28. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8965. top1: 87.71. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8974. top1: 87.70. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.31it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8974. top1: 87.70. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8955. top1: 87.68. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8969. top1: 87.85. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8966. top1: 87.99. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8951. top1: 87.97. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8976. top1: 87.80. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8940. top1: 88.07. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8892. top1: 88.59. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8859. top1: 88.80. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8820. top1: 89.00. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8888. top1: 88.46. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8891. top1: 88.43. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8891. top1: 88.43. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8938. top1: 88.17. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8896. top1: 88.47. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8889. top1: 88.54. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8875. top1: 88.71. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9052. top1: 87.99. top5: 99.90. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9108. top1: 87.78. top5: 99.91. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9181. top1: 87.50. top5: 99.91. :  43%|████▎     | 27/63 [00:01<00:01, 26.01it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9284. top1: 87.05. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 26.01it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9467. top1: 86.46. top5: 99.74. :  43%|████▎     | 27/63 [00:02<00:01, 26.01it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9467. top1: 86.46. top5: 99.74. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9494. top1: 86.32. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9571. top1: 85.94. top5: 99.75. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9667. top1: 85.50. top5: 99.68. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9736. top1: 85.23. top5: 99.69. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9783. top1: 84.91. top5: 99.62. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9904. top1: 84.30. top5: 99.63. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9989. top1: 83.94. top5: 99.56. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.74. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0047. top1: 83.61. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 83.36. top5: 99.59. :  57%|█████▋    | 36/63 [00:02<00:00, 35.72it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 83.36. top5: 99.59. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0122. top1: 83.11. top5: 99.60. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0150. top1: 82.94. top5: 99.61. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0190. top1: 82.91. top5: 99.55. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0220. top1: 82.75. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0310. top1: 82.17. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0334. top1: 82.15. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0391. top1: 81.90. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0466. top1: 81.54. top5: 99.42. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0473. top1: 81.42. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0491. top1: 81.36. top5: 99.44. :  73%|███████▎  | 46/63 [00:02<00:00, 46.35it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0491. top1: 81.36. top5: 99.44. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0565. top1: 80.92. top5: 99.40. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0634. top1: 80.55. top5: 99.41. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0678. top1: 80.40. top5: 99.36. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0678. top1: 80.36. top5: 99.32. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0725. top1: 80.07. top5: 99.28. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0801. top1: 79.64. top5: 99.29. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0811. top1: 79.55. top5: 99.30. :  89%|████████▉ | 56/63 [00:02<00:00, 56.43it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0811. top1: 79.55. top5: 99.30. : 100%|██████████| 63/63 [00:02<00:00, 25.17it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 20/60. Data: 1.79s. Batch: 1.85s. Loss: 1.3002. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 20/60. Data: 1.79s. Batch: 1.85s. Loss: 1.3002. :   4%|▍         | 1/25 [00:01<00:44,  1.85s/it]Finetune Epoch: 20/60. Data: 1.82s. Batch: 1.87s. Loss: 1.1768. :   4%|▍         | 1/25 [00:01<00:44,  1.85s/it]Finetune Epoch: 20/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0742. :   4%|▍         | 1/25 [00:01<00:44,  1.85s/it]Finetune Epoch: 20/60. Data: 1.87s. Batch: 1.91s. Loss: 1.1259. :   4%|▍         | 1/25 [00:01<00:44,  1.85s/it]Finetune Epoch: 20/60. Data: 1.87s. Batch: 1.91s. Loss: 1.1259. :  16%|█▌        | 4/25 [00:01<00:08,  2.60it/s]Finetune Epoch: 20/60. Data: 1.89s. Batch: 1.93s. Loss: 1.1395. :  16%|█▌        | 4/25 [00:02<00:08,  2.60it/s]Finetune Epoch: 20/60. Data: 1.91s. Batch: 1.96s. Loss: 1.1020. :  16%|█▌        | 4/25 [00:02<00:08,  2.60it/s]Finetune Epoch: 20/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0744. :  16%|█▌        | 4/25 [00:02<00:08,  2.60it/s]Finetune Epoch: 20/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0744. :  28%|██▊       | 7/25 [00:02<00:03,  4.91it/s]Finetune Epoch: 20/60. Data: 1.96s. Batch: 2.00s. Loss: 1.0533. :  28%|██▊       | 7/25 [00:02<00:03,  4.91it/s]Finetune Epoch: 20/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0544. :  28%|██▊       | 7/25 [00:02<00:03,  4.91it/s]Finetune Epoch: 20/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0544. :  36%|███▌      | 9/25 [00:02<00:02,  6.41it/s]Finetune Epoch: 20/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0574. :  36%|███▌      | 9/25 [00:02<00:02,  6.41it/s]Finetune Epoch: 20/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0439. :  36%|███▌      | 9/25 [00:02<00:02,  6.41it/s]Finetune Epoch: 20/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0439. :  44%|████▍     | 11/25 [00:02<00:01,  8.00it/s]Finetune Epoch: 20/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0287. :  44%|████▍     | 11/25 [00:02<00:01,  8.00it/s]Finetune Epoch: 20/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0311. :  44%|████▍     | 11/25 [00:02<00:01,  8.00it/s]Finetune Epoch: 20/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0311. :  52%|█████▏    | 13/25 [00:02<00:01,  9.82it/s]Finetune Epoch: 20/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0273. :  52%|█████▏    | 13/25 [00:02<00:01,  9.82it/s]Finetune Epoch: 20/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0350. :  52%|█████▏    | 13/25 [00:02<00:01,  9.82it/s]Finetune Epoch: 20/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0350. :  60%|██████    | 15/25 [00:02<00:00, 11.54it/s]Finetune Epoch: 20/60. Data: 2.17s. Batch: 2.22s. Loss: 1.0303. :  60%|██████    | 15/25 [00:02<00:00, 11.54it/s]Finetune Epoch: 20/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0317. :  60%|██████    | 15/25 [00:02<00:00, 11.54it/s]Finetune Epoch: 20/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0317. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch: 20/60. Data: 2.23s. Batch: 2.28s. Loss: 1.0438. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch: 20/60. Data: 2.26s. Batch: 2.31s. Loss: 1.0386. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch: 20/60. Data: 2.28s. Batch: 2.33s. Loss: 1.0354. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch: 20/60. Data: 2.28s. Batch: 2.33s. Loss: 1.0354. :  80%|████████  | 20/25 [00:02<00:00, 14.96it/s]Finetune Epoch: 20/60. Data: 2.31s. Batch: 2.36s. Loss: 1.0378. :  80%|████████  | 20/25 [00:02<00:00, 14.96it/s]Finetune Epoch: 20/60. Data: 2.34s. Batch: 2.39s. Loss: 1.0373. :  80%|████████  | 20/25 [00:02<00:00, 14.96it/s]Finetune Epoch: 20/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0374. :  80%|████████  | 20/25 [00:02<00:00, 14.96it/s]Finetune Epoch: 20/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0374. :  92%|█████████▏| 23/25 [00:02<00:00, 16.68it/s]Finetune Epoch: 20/60. Data: 2.39s. Batch: 2.44s. Loss: 1.0298. :  92%|█████████▏| 23/25 [00:03<00:00, 16.68it/s]Finetune Epoch: 20/60. Data: 2.41s. Batch: 2.46s. Loss: 1.0357. :  92%|█████████▏| 23/25 [00:03<00:00, 16.68it/s]Finetune Epoch: 20/60. Data: 2.41s. Batch: 2.46s. Loss: 1.0357. : 100%|██████████| 25/25 [00:03<00:00,  7.68it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9784. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 0.9784. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 0.9633. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9186. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9281. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9070. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9035. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9035. top1: 85.94. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9222. top1: 85.27. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9206. top1: 84.38. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9222. top1: 85.07. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9252. top1: 85.62. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9102. top1: 86.65. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9139. top1: 86.46. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9075. top1: 86.54. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9006. top1: 87.28. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8981. top1: 87.71. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8991. top1: 87.70. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8991. top1: 87.70. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8972. top1: 87.68. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8986. top1: 87.85. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8982. top1: 87.99. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.8968. top1: 87.97. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8993. top1: 87.80. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8956. top1: 88.07. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8909. top1: 88.59. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8875. top1: 88.80. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8836. top1: 89.00. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8904. top1: 88.46. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8907. top1: 88.43. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.84it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8907. top1: 88.43. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.54it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8954. top1: 88.17. top5: 100.00. :  43%|████▎     | 27/63 [00:01<00:01, 25.54it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8912. top1: 88.47. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8906. top1: 88.54. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8892. top1: 88.71. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9067. top1: 87.99. top5: 99.90. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9121. top1: 87.78. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9193. top1: 87.50. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9294. top1: 87.05. top5: 99.91. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9475. top1: 86.46. top5: 99.74. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9500. top1: 86.32. top5: 99.75. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9577. top1: 85.94. top5: 99.75. :  43%|████▎     | 27/63 [00:02<00:01, 25.54it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9577. top1: 85.94. top5: 99.75. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9671. top1: 85.50. top5: 99.68. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9739. top1: 85.23. top5: 99.69. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9785. top1: 84.91. top5: 99.62. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9906. top1: 84.30. top5: 99.63. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9990. top1: 83.94. top5: 99.56. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0028. top1: 83.74. top5: 99.57. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0046. top1: 83.61. top5: 99.58. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0093. top1: 83.36. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0119. top1: 83.11. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 37.72it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0119. top1: 83.11. top5: 99.60. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0146. top1: 82.94. top5: 99.61. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0186. top1: 82.91. top5: 99.55. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0215. top1: 82.75. top5: 99.50. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0303. top1: 82.17. top5: 99.51. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0327. top1: 82.15. top5: 99.46. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0383. top1: 81.90. top5: 99.47. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0457. top1: 81.54. top5: 99.42. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0464. top1: 81.42. top5: 99.43. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0481. top1: 81.36. top5: 99.44. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0554. top1: 80.92. top5: 99.40. :  75%|███████▍  | 47/63 [00:02<00:00, 46.28it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0554. top1: 80.92. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 54.38it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0623. top1: 80.55. top5: 99.41. :  90%|█████████ | 57/63 [00:02<00:00, 54.38it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0666. top1: 80.40. top5: 99.36. :  90%|█████████ | 57/63 [00:02<00:00, 54.38it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0666. top1: 80.36. top5: 99.32. :  90%|█████████ | 57/63 [00:02<00:00, 54.38it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0713. top1: 80.07. top5: 99.33. :  90%|█████████ | 57/63 [00:02<00:00, 54.38it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0787. top1: 79.64. top5: 99.34. :  90%|█████████ | 57/63 [00:02<00:00, 54.38it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0797. top1: 79.55. top5: 99.35. :  90%|█████████ | 57/63 [00:02<00:00, 54.38it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0797. top1: 79.55. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 24.64it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 21/60. Data: 1.63s. Batch: 1.69s. Loss: 0.9393. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 21/60. Data: 1.63s. Batch: 1.69s. Loss: 0.9393. :   4%|▍         | 1/25 [00:01<00:40,  1.69s/it]Finetune Epoch: 21/60. Data: 1.66s. Batch: 1.71s. Loss: 0.8870. :   4%|▍         | 1/25 [00:01<00:40,  1.69s/it]Finetune Epoch: 21/60. Data: 1.69s. Batch: 1.73s. Loss: 0.8897. :   4%|▍         | 1/25 [00:01<00:40,  1.69s/it]Finetune Epoch: 21/60. Data: 1.71s. Batch: 1.75s. Loss: 0.8870. :   4%|▍         | 1/25 [00:01<00:40,  1.69s/it]Finetune Epoch: 21/60. Data: 1.71s. Batch: 1.75s. Loss: 0.8870. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 21/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9074. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 21/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9171. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 21/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9267. :  16%|█▌        | 4/25 [00:01<00:07,  2.83it/s]Finetune Epoch: 21/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9267. :  28%|██▊       | 7/25 [00:01<00:03,  5.30it/s]Finetune Epoch: 21/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9777. :  28%|██▊       | 7/25 [00:01<00:03,  5.30it/s]Finetune Epoch: 21/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9631. :  28%|██▊       | 7/25 [00:02<00:03,  5.30it/s]Finetune Epoch: 21/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9772. :  28%|██▊       | 7/25 [00:02<00:03,  5.30it/s]Finetune Epoch: 21/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9772. :  40%|████      | 10/25 [00:02<00:01,  8.02it/s]Finetune Epoch: 21/60. Data: 1.86s. Batch: 1.91s. Loss: 0.9650. :  40%|████      | 10/25 [00:02<00:01,  8.02it/s]Finetune Epoch: 21/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9737. :  40%|████      | 10/25 [00:02<00:01,  8.02it/s]Finetune Epoch: 21/60. Data: 1.91s. Batch: 1.95s. Loss: 0.9797. :  40%|████      | 10/25 [00:02<00:01,  8.02it/s]Finetune Epoch: 21/60. Data: 1.91s. Batch: 1.95s. Loss: 0.9797. :  52%|█████▏    | 13/25 [00:02<00:01, 10.59it/s]Finetune Epoch: 21/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9816. :  52%|█████▏    | 13/25 [00:02<00:01, 10.59it/s]Finetune Epoch: 21/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9902. :  52%|█████▏    | 13/25 [00:02<00:01, 10.59it/s]Finetune Epoch: 21/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9974. :  52%|█████▏    | 13/25 [00:02<00:01, 10.59it/s]Finetune Epoch: 21/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9974. :  64%|██████▍   | 16/25 [00:02<00:00, 12.43it/s]Finetune Epoch: 21/60. Data: 2.00s. Batch: 2.04s. Loss: 1.0005. :  64%|██████▍   | 16/25 [00:02<00:00, 12.43it/s]Finetune Epoch: 21/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9944. :  64%|██████▍   | 16/25 [00:02<00:00, 12.43it/s]Finetune Epoch: 21/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0044. :  64%|██████▍   | 16/25 [00:02<00:00, 12.43it/s]Finetune Epoch: 21/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0044. :  76%|███████▌  | 19/25 [00:02<00:00, 14.86it/s]Finetune Epoch: 21/60. Data: 2.07s. Batch: 2.11s. Loss: 1.0152. :  76%|███████▌  | 19/25 [00:02<00:00, 14.86it/s]Finetune Epoch: 21/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0074. :  76%|███████▌  | 19/25 [00:02<00:00, 14.86it/s]Finetune Epoch: 21/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0010. :  76%|███████▌  | 19/25 [00:02<00:00, 14.86it/s]Finetune Epoch: 21/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0010. :  88%|████████▊ | 22/25 [00:02<00:00, 15.84it/s]Finetune Epoch: 21/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9938. :  88%|████████▊ | 22/25 [00:02<00:00, 15.84it/s]Finetune Epoch: 21/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9915. :  88%|████████▊ | 22/25 [00:02<00:00, 15.84it/s]Finetune Epoch: 21/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9964. :  88%|████████▊ | 22/25 [00:02<00:00, 15.84it/s]Finetune Epoch: 21/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9964. : 100%|██████████| 25/25 [00:02<00:00, 17.02it/s]Finetune Epoch: 21/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9964. : 100%|██████████| 25/25 [00:02<00:00,  8.35it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 0.9808. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 0.9808. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.83s. Loss: 0.9655. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9203. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9301. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9089. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9054. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9241. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9226. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9241. top1: 84.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9241. top1: 84.72. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9271. top1: 85.31. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9120. top1: 86.36. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9158. top1: 86.20. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9093. top1: 86.30. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9024. top1: 87.05. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.8998. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9008. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8989. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.8989. top1: 87.50. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9004. top1: 87.67. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9000. top1: 87.83. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8985. top1: 87.81. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9010. top1: 87.50. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8973. top1: 87.78. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8925. top1: 88.32. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8892. top1: 88.54. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8852. top1: 88.75. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8921. top1: 88.22. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8924. top1: 88.19. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8971. top1: 87.95. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.28it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8971. top1: 87.95. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.24it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8929. top1: 88.25. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.24it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8922. top1: 88.33. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.24it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8908. top1: 88.51. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 26.24it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9082. top1: 87.79. top5: 99.90. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9135. top1: 87.59. top5: 99.91. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9205. top1: 87.32. top5: 99.91. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9305. top1: 86.88. top5: 99.91. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9484. top1: 86.28. top5: 99.74. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9508. top1: 86.15. top5: 99.75. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9583. top1: 85.77. top5: 99.75. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9676. top1: 85.34. top5: 99.68. :  44%|████▍     | 28/63 [00:02<00:01, 26.24it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9676. top1: 85.34. top5: 99.68. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9743. top1: 85.08. top5: 99.69. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9789. top1: 84.83. top5: 99.62. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9908. top1: 84.23. top5: 99.63. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9991. top1: 83.87. top5: 99.56. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.66. top5: 99.57. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0046. top1: 83.54. top5: 99.58. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0092. top1: 83.29. top5: 99.59. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0117. top1: 83.05. top5: 99.60. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0143. top1: 82.88. top5: 99.61. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0182. top1: 82.84. top5: 99.55. :  62%|██████▏   | 39/63 [00:02<00:00, 38.58it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0182. top1: 82.84. top5: 99.55. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0211. top1: 82.69. top5: 99.50. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0298. top1: 82.11. top5: 99.51. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0321. top1: 82.09. top5: 99.46. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0377. top1: 81.84. top5: 99.47. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0450. top1: 81.48. top5: 99.42. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0456. top1: 81.36. top5: 99.43. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0473. top1: 81.31. top5: 99.44. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0545. top1: 80.87. top5: 99.40. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0613. top1: 80.50. top5: 99.41. :  78%|███████▊  | 49/63 [00:02<00:00, 49.16it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0613. top1: 80.50. top5: 99.41. :  92%|█████████▏| 58/63 [00:02<00:00, 56.15it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0656. top1: 80.35. top5: 99.36. :  92%|█████████▏| 58/63 [00:02<00:00, 56.15it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0656. top1: 80.31. top5: 99.32. :  92%|█████████▏| 58/63 [00:02<00:00, 56.15it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0702. top1: 80.02. top5: 99.33. :  92%|█████████▏| 58/63 [00:02<00:00, 56.15it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0776. top1: 79.59. top5: 99.34. :  92%|█████████▏| 58/63 [00:02<00:00, 56.15it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0785. top1: 79.50. top5: 99.35. :  92%|█████████▏| 58/63 [00:02<00:00, 56.15it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0785. top1: 79.50. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 25.07it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 22/60. Data: 1.59s. Batch: 1.64s. Loss: 0.8951. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 22/60. Data: 1.59s. Batch: 1.64s. Loss: 0.8951. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 22/60. Data: 1.62s. Batch: 1.66s. Loss: 0.9540. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 22/60. Data: 1.64s. Batch: 1.68s. Loss: 0.9141. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 22/60. Data: 1.66s. Batch: 1.70s. Loss: 0.9490. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 22/60. Data: 1.66s. Batch: 1.70s. Loss: 0.9490. :  16%|█▌        | 4/25 [00:01<00:07,  2.95it/s]Finetune Epoch: 22/60. Data: 1.68s. Batch: 1.71s. Loss: 0.9639. :  16%|█▌        | 4/25 [00:01<00:07,  2.95it/s]Finetune Epoch: 22/60. Data: 1.69s. Batch: 1.73s. Loss: 0.9545. :  16%|█▌        | 4/25 [00:01<00:07,  2.95it/s]Finetune Epoch: 22/60. Data: 1.71s. Batch: 1.75s. Loss: 0.9782. :  16%|█▌        | 4/25 [00:01<00:07,  2.95it/s]Finetune Epoch: 22/60. Data: 1.71s. Batch: 1.75s. Loss: 0.9782. :  28%|██▊       | 7/25 [00:01<00:03,  5.59it/s]Finetune Epoch: 22/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9813. :  28%|██▊       | 7/25 [00:01<00:03,  5.59it/s]Finetune Epoch: 22/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9772. :  28%|██▊       | 7/25 [00:01<00:03,  5.59it/s]Finetune Epoch: 22/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9763. :  28%|██▊       | 7/25 [00:02<00:03,  5.59it/s]Finetune Epoch: 22/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9763. :  40%|████      | 10/25 [00:02<00:01,  8.06it/s]Finetune Epoch: 22/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9960. :  40%|████      | 10/25 [00:02<00:01,  8.06it/s]Finetune Epoch: 22/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9970. :  40%|████      | 10/25 [00:02<00:01,  8.06it/s]Finetune Epoch: 22/60. Data: 1.85s. Batch: 1.89s. Loss: 0.9936. :  40%|████      | 10/25 [00:02<00:01,  8.06it/s]Finetune Epoch: 22/60. Data: 1.85s. Batch: 1.89s. Loss: 0.9936. :  52%|█████▏    | 13/25 [00:02<00:01, 10.35it/s]Finetune Epoch: 22/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9895. :  52%|█████▏    | 13/25 [00:02<00:01, 10.35it/s]Finetune Epoch: 22/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9840. :  52%|█████▏    | 13/25 [00:02<00:01, 10.35it/s]Finetune Epoch: 22/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9840. :  60%|██████    | 15/25 [00:02<00:00, 11.52it/s]Finetune Epoch: 22/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9795. :  60%|██████    | 15/25 [00:02<00:00, 11.52it/s]Finetune Epoch: 22/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9798. :  60%|██████    | 15/25 [00:02<00:00, 11.52it/s]Finetune Epoch: 22/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9831. :  60%|██████    | 15/25 [00:02<00:00, 11.52it/s]Finetune Epoch: 22/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9831. :  72%|███████▏  | 18/25 [00:02<00:00, 14.02it/s]Finetune Epoch: 22/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9868. :  72%|███████▏  | 18/25 [00:02<00:00, 14.02it/s]Finetune Epoch: 22/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9877. :  72%|███████▏  | 18/25 [00:02<00:00, 14.02it/s]Finetune Epoch: 22/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9839. :  72%|███████▏  | 18/25 [00:02<00:00, 14.02it/s]Finetune Epoch: 22/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9839. :  84%|████████▍ | 21/25 [00:02<00:00, 16.25it/s]Finetune Epoch: 22/60. Data: 2.07s. Batch: 2.11s. Loss: 0.9920. :  84%|████████▍ | 21/25 [00:02<00:00, 16.25it/s]Finetune Epoch: 22/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0017. :  84%|████████▍ | 21/25 [00:02<00:00, 16.25it/s]Finetune Epoch: 22/60. Data: 2.12s. Batch: 2.16s. Loss: 1.0023. :  84%|████████▍ | 21/25 [00:02<00:00, 16.25it/s]Finetune Epoch: 22/60. Data: 2.12s. Batch: 2.16s. Loss: 1.0023. :  96%|█████████▌| 24/25 [00:02<00:00, 17.53it/s]Finetune Epoch: 22/60. Data: 2.14s. Batch: 2.18s. Loss: 1.0017. :  96%|█████████▌| 24/25 [00:02<00:00, 17.53it/s]Finetune Epoch: 22/60. Data: 2.14s. Batch: 2.18s. Loss: 1.0017. : 100%|██████████| 25/25 [00:02<00:00,  8.50it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 0.9832. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 0.9832. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 0.9679. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9222. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9322. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9322. top1: 83.59. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9108. top1: 86.25. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9073. top1: 85.94. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9262. top1: 85.27. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9246. top1: 84.38. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9262. top1: 84.72. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9292. top1: 85.31. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9140. top1: 86.36. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9178. top1: 86.20. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9113. top1: 86.30. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9043. top1: 87.05. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9017. top1: 87.50. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:20,  2.93it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9017. top1: 87.50. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9027. top1: 87.50. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9008. top1: 87.50. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9023. top1: 87.67. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9019. top1: 87.83. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9004. top1: 87.81. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9029. top1: 87.50. top5: 99.85. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8991. top1: 87.78. top5: 99.86. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8944. top1: 88.32. top5: 99.86. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8910. top1: 88.54. top5: 99.87. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8871. top1: 88.75. top5: 99.88. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8939. top1: 88.22. top5: 99.88. :  24%|██▍       | 15/63 [00:01<00:03, 13.74it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8939. top1: 88.22. top5: 99.88. :  41%|████▏     | 26/63 [00:01<00:01, 25.65it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8942. top1: 88.19. top5: 99.88. :  41%|████▏     | 26/63 [00:01<00:01, 25.65it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8990. top1: 87.95. top5: 99.89. :  41%|████▏     | 26/63 [00:01<00:01, 25.65it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8947. top1: 88.25. top5: 99.89. :  41%|████▏     | 26/63 [00:01<00:01, 25.65it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8941. top1: 88.33. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8927. top1: 88.51. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9098. top1: 87.79. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9150. top1: 87.59. top5: 99.81. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9219. top1: 87.32. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9317. top1: 86.88. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9493. top1: 86.28. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9516. top1: 86.15. top5: 99.66. :  41%|████▏     | 26/63 [00:02<00:01, 25.65it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9516. top1: 86.15. top5: 99.66. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9590. top1: 85.77. top5: 99.67. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9682. top1: 85.34. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9747. top1: 85.08. top5: 99.61. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9792. top1: 84.83. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9911. top1: 84.23. top5: 99.55. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9993. top1: 83.87. top5: 99.49. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.66. top5: 99.50. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.54. top5: 99.51. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0090. top1: 83.29. top5: 99.52. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0115. top1: 83.11. top5: 99.53. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0140. top1: 82.94. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 38.29it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0140. top1: 82.94. top5: 99.54. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0179. top1: 82.91. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0206. top1: 82.75. top5: 99.44. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0292. top1: 82.17. top5: 99.45. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0315. top1: 82.15. top5: 99.40. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0369. top1: 81.90. top5: 99.41. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0442. top1: 81.54. top5: 99.36. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0448. top1: 81.48. top5: 99.38. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0464. top1: 81.42. top5: 99.39. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0536. top1: 80.98. top5: 99.34. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0603. top1: 80.60. top5: 99.35. :  76%|███████▌  | 48/63 [00:02<00:00, 50.29it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0603. top1: 80.60. top5: 99.35. :  92%|█████████▏| 58/63 [00:02<00:00, 60.09it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0645. top1: 80.46. top5: 99.31. :  92%|█████████▏| 58/63 [00:02<00:00, 60.09it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0644. top1: 80.42. top5: 99.32. :  92%|█████████▏| 58/63 [00:02<00:00, 60.09it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0690. top1: 80.12. top5: 99.33. :  92%|█████████▏| 58/63 [00:02<00:00, 60.09it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0763. top1: 79.69. top5: 99.34. :  92%|█████████▏| 58/63 [00:02<00:00, 60.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0772. top1: 79.65. top5: 99.35. :  92%|█████████▏| 58/63 [00:02<00:00, 60.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0772. top1: 79.65. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 24.75it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 23/60. Data: 1.58s. Batch: 1.64s. Loss: 0.8735. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 23/60. Data: 1.58s. Batch: 1.64s. Loss: 0.8735. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 23/60. Data: 1.62s. Batch: 1.67s. Loss: 0.9703. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 23/60. Data: 1.65s. Batch: 1.70s. Loss: 0.9829. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 23/60. Data: 1.65s. Batch: 1.70s. Loss: 0.9829. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 23/60. Data: 1.67s. Batch: 1.73s. Loss: 0.9999. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 23/60. Data: 1.70s. Batch: 1.75s. Loss: 1.0479. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 23/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0585. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 23/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0585. :  24%|██▍       | 6/25 [00:01<00:03,  4.78it/s]Finetune Epoch: 23/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0522. :  24%|██▍       | 6/25 [00:01<00:03,  4.78it/s]Finetune Epoch: 23/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0435. :  24%|██▍       | 6/25 [00:01<00:03,  4.78it/s]Finetune Epoch: 23/60. Data: 1.80s. Batch: 1.84s. Loss: 1.0466. :  24%|██▍       | 6/25 [00:02<00:03,  4.78it/s]Finetune Epoch: 23/60. Data: 1.80s. Batch: 1.84s. Loss: 1.0466. :  36%|███▌      | 9/25 [00:02<00:02,  7.62it/s]Finetune Epoch: 23/60. Data: 1.82s. Batch: 1.86s. Loss: 1.0480. :  36%|███▌      | 9/25 [00:02<00:02,  7.62it/s]Finetune Epoch: 23/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0406. :  36%|███▌      | 9/25 [00:02<00:02,  7.62it/s]Finetune Epoch: 23/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0291. :  36%|███▌      | 9/25 [00:02<00:02,  7.62it/s]Finetune Epoch: 23/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0291. :  48%|████▊     | 12/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 23/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0284. :  48%|████▊     | 12/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 23/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0133. :  48%|████▊     | 12/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 23/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0056. :  48%|████▊     | 12/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 23/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0056. :  60%|██████    | 15/25 [00:02<00:00, 13.48it/s]Finetune Epoch: 23/60. Data: 1.95s. Batch: 1.99s. Loss: 1.0070. :  60%|██████    | 15/25 [00:02<00:00, 13.48it/s]Finetune Epoch: 23/60. Data: 1.97s. Batch: 2.01s. Loss: 1.0149. :  60%|██████    | 15/25 [00:02<00:00, 13.48it/s]Finetune Epoch: 23/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0186. :  60%|██████    | 15/25 [00:02<00:00, 13.48it/s]Finetune Epoch: 23/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0186. :  72%|███████▏  | 18/25 [00:02<00:00, 14.94it/s]Finetune Epoch: 23/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0172. :  72%|███████▏  | 18/25 [00:02<00:00, 14.94it/s]Finetune Epoch: 23/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0135. :  72%|███████▏  | 18/25 [00:02<00:00, 14.94it/s]Finetune Epoch: 23/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0198. :  72%|███████▏  | 18/25 [00:02<00:00, 14.94it/s]Finetune Epoch: 23/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0198. :  84%|████████▍ | 21/25 [00:02<00:00, 16.10it/s]Finetune Epoch: 23/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0154. :  84%|████████▍ | 21/25 [00:02<00:00, 16.10it/s]Finetune Epoch: 23/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0147. :  84%|████████▍ | 21/25 [00:02<00:00, 16.10it/s]Finetune Epoch: 23/60. Data: 2.13s. Batch: 2.17s. Loss: 1.0082. :  84%|████████▍ | 21/25 [00:02<00:00, 16.10it/s]Finetune Epoch: 23/60. Data: 2.13s. Batch: 2.17s. Loss: 1.0082. :  96%|█████████▌| 24/25 [00:02<00:00, 17.68it/s]Finetune Epoch: 23/60. Data: 2.15s. Batch: 2.19s. Loss: 1.0037. :  96%|█████████▌| 24/25 [00:02<00:00, 17.68it/s]Finetune Epoch: 23/60. Data: 2.15s. Batch: 2.19s. Loss: 1.0037. : 100%|██████████| 25/25 [00:02<00:00,  8.50it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.77s. Loss: 0.9853. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.77s. Loss: 0.9853. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.89s. Loss: 0.9699. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 0.9238. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 0.9340. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9125. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9090. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9279. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9263. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9263. top1: 84.38. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9279. top1: 84.72. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9309. top1: 85.31. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9157. top1: 86.36. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9194. top1: 86.20. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9129. top1: 86.30. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9059. top1: 87.05. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9059. top1: 87.05. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:04, 10.90it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9032. top1: 87.50. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:04, 10.90it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9042. top1: 87.50. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9023. top1: 87.50. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9038. top1: 87.50. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9034. top1: 87.66. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9019. top1: 87.66. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9044. top1: 87.35. top5: 99.85. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9006. top1: 87.50. top5: 99.86. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8958. top1: 88.04. top5: 99.86. :  22%|██▏       | 14/63 [00:02<00:04, 10.90it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8958. top1: 88.04. top5: 99.86. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8925. top1: 88.28. top5: 99.87. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8885. top1: 88.50. top5: 99.88. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8953. top1: 87.98. top5: 99.88. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8956. top1: 87.96. top5: 99.88. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9004. top1: 87.72. top5: 99.89. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8962. top1: 88.04. top5: 99.89. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8955. top1: 88.12. top5: 99.90. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8941. top1: 88.31. top5: 99.90. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9111. top1: 87.60. top5: 99.80. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9161. top1: 87.41. top5: 99.81. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9229. top1: 87.13. top5: 99.82. :  37%|███▋      | 23/63 [00:02<00:01, 20.39it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9229. top1: 87.13. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9326. top1: 86.70. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9501. top1: 86.11. top5: 99.65. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9523. top1: 85.98. top5: 99.66. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9596. top1: 85.61. top5: 99.67. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9686. top1: 85.18. top5: 99.60. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9751. top1: 84.92. top5: 99.61. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9795. top1: 84.68. top5: 99.54. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9912. top1: 84.08. top5: 99.55. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9993. top1: 83.72. top5: 99.49. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0029. top1: 83.52. top5: 99.50. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.47. top5: 99.51. :  54%|█████▍    | 34/63 [00:02<00:00, 33.26it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.47. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0089. top1: 83.22. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0112. top1: 83.05. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0137. top1: 82.88. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0175. top1: 82.84. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0202. top1: 82.69. top5: 99.44. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0287. top1: 82.11. top5: 99.45. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0309. top1: 82.09. top5: 99.40. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0363. top1: 81.84. top5: 99.41. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0435. top1: 81.48. top5: 99.36. :  71%|███████▏  | 45/63 [00:02<00:00, 45.81it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0435. top1: 81.48. top5: 99.36. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0440. top1: 81.42. top5: 99.38. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0456. top1: 81.36. top5: 99.39. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0527. top1: 80.92. top5: 99.34. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0594. top1: 80.55. top5: 99.35. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0635. top1: 80.40. top5: 99.31. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0634. top1: 80.42. top5: 99.32. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0680. top1: 80.12. top5: 99.33. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0752. top1: 79.69. top5: 99.34. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0761. top1: 79.65. top5: 99.35. :  86%|████████▌ | 54/63 [00:02<00:00, 52.10it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0761. top1: 79.65. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 23.48it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 24/60. Data: 1.60s. Batch: 1.67s. Loss: 0.9925. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 24/60. Data: 1.60s. Batch: 1.67s. Loss: 0.9925. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch: 24/60. Data: 1.64s. Batch: 1.70s. Loss: 0.9735. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch: 24/60. Data: 1.67s. Batch: 1.73s. Loss: 0.9591. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch: 24/60. Data: 1.67s. Batch: 1.73s. Loss: 0.9591. :  12%|█▏        | 3/25 [00:01<00:10,  2.12it/s]Finetune Epoch: 24/60. Data: 1.70s. Batch: 1.76s. Loss: 1.0084. :  12%|█▏        | 3/25 [00:01<00:10,  2.12it/s]Finetune Epoch: 24/60. Data: 1.73s. Batch: 1.79s. Loss: 1.0185. :  12%|█▏        | 3/25 [00:01<00:10,  2.12it/s]Finetune Epoch: 24/60. Data: 1.73s. Batch: 1.79s. Loss: 1.0185. :  20%|██        | 5/25 [00:01<00:05,  3.83it/s]Finetune Epoch: 24/60. Data: 1.76s. Batch: 1.81s. Loss: 0.9957. :  20%|██        | 5/25 [00:01<00:05,  3.83it/s]Finetune Epoch: 24/60. Data: 1.79s. Batch: 1.84s. Loss: 0.9820. :  20%|██        | 5/25 [00:01<00:05,  3.83it/s]Finetune Epoch: 24/60. Data: 1.81s. Batch: 1.86s. Loss: 0.9748. :  20%|██        | 5/25 [00:02<00:05,  3.83it/s]Finetune Epoch: 24/60. Data: 1.81s. Batch: 1.86s. Loss: 0.9748. :  32%|███▏      | 8/25 [00:02<00:02,  6.76it/s]Finetune Epoch: 24/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9974. :  32%|███▏      | 8/25 [00:02<00:02,  6.76it/s]Finetune Epoch: 24/60. Data: 1.86s. Batch: 1.91s. Loss: 0.9910. :  32%|███▏      | 8/25 [00:02<00:02,  6.76it/s]Finetune Epoch: 24/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9845. :  32%|███▏      | 8/25 [00:02<00:02,  6.76it/s]Finetune Epoch: 24/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9845. :  44%|████▍     | 11/25 [00:02<00:01,  9.45it/s]Finetune Epoch: 24/60. Data: 1.91s. Batch: 1.96s. Loss: 1.0212. :  44%|████▍     | 11/25 [00:02<00:01,  9.45it/s]Finetune Epoch: 24/60. Data: 1.94s. Batch: 1.98s. Loss: 1.0093. :  44%|████▍     | 11/25 [00:02<00:01,  9.45it/s]Finetune Epoch: 24/60. Data: 1.96s. Batch: 2.00s. Loss: 1.0159. :  44%|████▍     | 11/25 [00:02<00:01,  9.45it/s]Finetune Epoch: 24/60. Data: 1.96s. Batch: 2.00s. Loss: 1.0159. :  56%|█████▌    | 14/25 [00:02<00:00, 12.67it/s]Finetune Epoch: 24/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0127. :  56%|█████▌    | 14/25 [00:02<00:00, 12.67it/s]Finetune Epoch: 24/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0117. :  56%|█████▌    | 14/25 [00:02<00:00, 12.67it/s]Finetune Epoch: 24/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0027. :  56%|█████▌    | 14/25 [00:02<00:00, 12.67it/s]Finetune Epoch: 24/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0027. :  68%|██████▊   | 17/25 [00:02<00:00, 15.06it/s]Finetune Epoch: 24/60. Data: 2.05s. Batch: 2.09s. Loss: 1.0050. :  68%|██████▊   | 17/25 [00:02<00:00, 15.06it/s]Finetune Epoch: 24/60. Data: 2.07s. Batch: 2.11s. Loss: 1.0058. :  68%|██████▊   | 17/25 [00:02<00:00, 15.06it/s]Finetune Epoch: 24/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0070. :  68%|██████▊   | 17/25 [00:02<00:00, 15.06it/s]Finetune Epoch: 24/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0070. :  80%|████████  | 20/25 [00:02<00:00, 16.83it/s]Finetune Epoch: 24/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0066. :  80%|████████  | 20/25 [00:02<00:00, 16.83it/s]Finetune Epoch: 24/60. Data: 2.14s. Batch: 2.18s. Loss: 1.0021. :  80%|████████  | 20/25 [00:02<00:00, 16.83it/s]Finetune Epoch: 24/60. Data: 2.16s. Batch: 2.20s. Loss: 1.0071. :  80%|████████  | 20/25 [00:02<00:00, 16.83it/s]Finetune Epoch: 24/60. Data: 2.16s. Batch: 2.20s. Loss: 1.0071. :  92%|█████████▏| 23/25 [00:02<00:00, 17.28it/s]Finetune Epoch: 24/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0060. :  92%|█████████▏| 23/25 [00:02<00:00, 17.28it/s]Finetune Epoch: 24/60. Data: 2.21s. Batch: 2.25s. Loss: 1.0040. :  92%|█████████▏| 23/25 [00:02<00:00, 17.28it/s]Finetune Epoch: 24/60. Data: 2.21s. Batch: 2.25s. Loss: 1.0040. : 100%|██████████| 25/25 [00:03<00:00,  8.29it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.63s. Loss: 0.9873. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.63s. Loss: 0.9873. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.83s. Loss: 0.9717. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.9252. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9355. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9138. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9104. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9293. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9278. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9294. top1: 84.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9294. top1: 84.72. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9324. top1: 85.31. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9172. top1: 86.36. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9209. top1: 86.20. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9144. top1: 86.30. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9073. top1: 87.05. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9046. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9056. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9038. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9053. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9048. top1: 87.66. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9048. top1: 87.66. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9033. top1: 87.66. top5: 100.00. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9058. top1: 87.35. top5: 99.85. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9020. top1: 87.50. top5: 99.86. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8972. top1: 88.04. top5: 99.86. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8939. top1: 88.28. top5: 99.87. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8898. top1: 88.50. top5: 99.88. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8967. top1: 87.98. top5: 99.88. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8970. top1: 87.85. top5: 99.88. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9018. top1: 87.61. top5: 99.89. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8976. top1: 87.93. top5: 99.89. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8969. top1: 88.02. top5: 99.90. :  30%|███       | 19/63 [00:01<00:02, 16.51it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8969. top1: 88.02. top5: 99.90. :  48%|████▊     | 30/63 [00:01<00:01, 28.38it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8955. top1: 88.21. top5: 99.90. :  48%|████▊     | 30/63 [00:01<00:01, 28.38it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9124. top1: 87.50. top5: 99.80. :  48%|████▊     | 30/63 [00:01<00:01, 28.38it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9173. top1: 87.31. top5: 99.81. :  48%|████▊     | 30/63 [00:01<00:01, 28.38it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9240. top1: 87.04. top5: 99.82. :  48%|████▊     | 30/63 [00:01<00:01, 28.38it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9335. top1: 86.61. top5: 99.82. :  48%|████▊     | 30/63 [00:02<00:01, 28.38it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9508. top1: 86.02. top5: 99.65. :  48%|████▊     | 30/63 [00:02<00:01, 28.38it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9529. top1: 85.90. top5: 99.66. :  48%|████▊     | 30/63 [00:02<00:01, 28.38it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9601. top1: 85.53. top5: 99.67. :  48%|████▊     | 30/63 [00:02<00:01, 28.38it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9690. top1: 85.10. top5: 99.60. :  48%|████▊     | 30/63 [00:02<00:01, 28.38it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9690. top1: 85.10. top5: 99.60. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9754. top1: 84.84. top5: 99.61. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9797. top1: 84.60. top5: 99.54. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9914. top1: 84.00. top5: 99.55. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9994. top1: 83.72. top5: 99.49. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0030. top1: 83.52. top5: 99.50. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.47. top5: 99.51. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0088. top1: 83.22. top5: 99.52. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0111. top1: 83.05. top5: 99.53. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0135. top1: 82.88. top5: 99.54. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0172. top1: 82.84. top5: 99.49. :  62%|██████▏   | 39/63 [00:02<00:00, 37.62it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0172. top1: 82.84. top5: 99.49. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0199. top1: 82.69. top5: 99.44. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0283. top1: 82.11. top5: 99.45. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0304. top1: 82.09. top5: 99.40. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0358. top1: 81.84. top5: 99.41. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0429. top1: 81.48. top5: 99.36. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0434. top1: 81.42. top5: 99.38. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0449. top1: 81.36. top5: 99.39. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0519. top1: 80.92. top5: 99.34. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0586. top1: 80.55. top5: 99.35. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0627. top1: 80.40. top5: 99.31. :  78%|███████▊  | 49/63 [00:02<00:00, 48.34it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0627. top1: 80.40. top5: 99.31. :  94%|█████████▎| 59/63 [00:02<00:00, 58.12it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0626. top1: 80.42. top5: 99.32. :  94%|█████████▎| 59/63 [00:02<00:00, 58.12it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0671. top1: 80.12. top5: 99.33. :  94%|█████████▎| 59/63 [00:02<00:00, 58.12it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0742. top1: 79.69. top5: 99.34. :  94%|█████████▎| 59/63 [00:02<00:00, 58.12it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0751. top1: 79.65. top5: 99.35. :  94%|█████████▎| 59/63 [00:02<00:00, 58.12it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0751. top1: 79.65. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 25.17it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 25/60. Data: 1.58s. Batch: 1.62s. Loss: 0.8695. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 25/60. Data: 1.58s. Batch: 1.62s. Loss: 0.8695. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 25/60. Data: 1.60s. Batch: 1.64s. Loss: 0.8591. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 25/60. Data: 1.62s. Batch: 1.66s. Loss: 0.8907. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 25/60. Data: 1.64s. Batch: 1.68s. Loss: 0.8856. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 25/60. Data: 1.64s. Batch: 1.68s. Loss: 0.8856. :  16%|█▌        | 4/25 [00:01<00:07,  2.96it/s]Finetune Epoch: 25/60. Data: 1.66s. Batch: 1.70s. Loss: 0.9387. :  16%|█▌        | 4/25 [00:01<00:07,  2.96it/s]Finetune Epoch: 25/60. Data: 1.68s. Batch: 1.72s. Loss: 0.9589. :  16%|█▌        | 4/25 [00:01<00:07,  2.96it/s]Finetune Epoch: 25/60. Data: 1.68s. Batch: 1.72s. Loss: 0.9589. :  24%|██▍       | 6/25 [00:01<00:04,  4.69it/s]Finetune Epoch: 25/60. Data: 1.70s. Batch: 1.75s. Loss: 0.9526. :  24%|██▍       | 6/25 [00:01<00:04,  4.69it/s]Finetune Epoch: 25/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9546. :  24%|██▍       | 6/25 [00:01<00:04,  4.69it/s]Finetune Epoch: 25/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9546. :  32%|███▏      | 8/25 [00:01<00:02,  6.58it/s]Finetune Epoch: 25/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9599. :  32%|███▏      | 8/25 [00:01<00:02,  6.58it/s]Finetune Epoch: 25/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9663. :  32%|███▏      | 8/25 [00:02<00:02,  6.58it/s]Finetune Epoch: 25/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9663. :  40%|████      | 10/25 [00:02<00:01,  8.49it/s]Finetune Epoch: 25/60. Data: 1.81s. Batch: 1.85s. Loss: 0.9574. :  40%|████      | 10/25 [00:02<00:01,  8.49it/s]Finetune Epoch: 25/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9550. :  40%|████      | 10/25 [00:02<00:01,  8.49it/s]Finetune Epoch: 25/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9761. :  40%|████      | 10/25 [00:02<00:01,  8.49it/s]Finetune Epoch: 25/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9761. :  52%|█████▏    | 13/25 [00:02<00:01, 11.41it/s]Finetune Epoch: 25/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9670. :  52%|█████▏    | 13/25 [00:02<00:01, 11.41it/s]Finetune Epoch: 25/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9879. :  52%|█████▏    | 13/25 [00:02<00:01, 11.41it/s]Finetune Epoch: 25/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9879. :  60%|██████    | 15/25 [00:02<00:00, 12.83it/s]Finetune Epoch: 25/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0095. :  60%|██████    | 15/25 [00:02<00:00, 12.83it/s]Finetune Epoch: 25/60. Data: 1.96s. Batch: 2.00s. Loss: 1.0029. :  60%|██████    | 15/25 [00:02<00:00, 12.83it/s]Finetune Epoch: 25/60. Data: 1.96s. Batch: 2.00s. Loss: 1.0029. :  68%|██████▊   | 17/25 [00:02<00:00, 14.00it/s]Finetune Epoch: 25/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0052. :  68%|██████▊   | 17/25 [00:02<00:00, 14.00it/s]Finetune Epoch: 25/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0039. :  68%|██████▊   | 17/25 [00:02<00:00, 14.00it/s]Finetune Epoch: 25/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0039. :  76%|███████▌  | 19/25 [00:02<00:00, 15.23it/s]Finetune Epoch: 25/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0088. :  76%|███████▌  | 19/25 [00:02<00:00, 15.23it/s]Finetune Epoch: 25/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0088. :  76%|███████▌  | 19/25 [00:02<00:00, 15.23it/s]Finetune Epoch: 25/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0088. :  84%|████████▍ | 21/25 [00:02<00:00, 16.26it/s]Finetune Epoch: 25/60. Data: 2.09s. Batch: 2.13s. Loss: 1.0132. :  84%|████████▍ | 21/25 [00:02<00:00, 16.26it/s]Finetune Epoch: 25/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0109. :  84%|████████▍ | 21/25 [00:02<00:00, 16.26it/s]Finetune Epoch: 25/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0096. :  84%|████████▍ | 21/25 [00:02<00:00, 16.26it/s]Finetune Epoch: 25/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0096. :  96%|█████████▌| 24/25 [00:02<00:00, 17.59it/s]Finetune Epoch: 25/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0044. :  96%|█████████▌| 24/25 [00:02<00:00, 17.59it/s]Finetune Epoch: 25/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0044. : 100%|██████████| 25/25 [00:02<00:00,  8.37it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.54s. Loss: 0.9891. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.54s. Loss: 0.9891. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.78s. Loss: 0.9735. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 0.9267. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 0.9371. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9153. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9118. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9308. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9293. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9309. top1: 84.72. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9309. top1: 84.72. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9339. top1: 85.31. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9186. top1: 86.36. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9224. top1: 86.20. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9158. top1: 86.30. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9087. top1: 87.05. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9060. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9069. top1: 87.50. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.34it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9069. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9051. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9067. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9062. top1: 87.66. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9047. top1: 87.66. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9072. top1: 87.35. top5: 99.85. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9033. top1: 87.50. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8986. top1: 88.04. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8952. top1: 88.28. top5: 99.87. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8911. top1: 88.50. top5: 99.88. :  25%|██▌       | 16/63 [00:01<00:03, 13.85it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8911. top1: 88.50. top5: 99.88. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8980. top1: 87.98. top5: 99.88. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8984. top1: 87.85. top5: 99.88. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9032. top1: 87.61. top5: 99.89. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8989. top1: 87.93. top5: 99.89. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8983. top1: 88.02. top5: 99.90. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.8969. top1: 88.21. top5: 99.90. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9136. top1: 87.50. top5: 99.80. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9184. top1: 87.31. top5: 99.81. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9249. top1: 87.04. top5: 99.82. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9343. top1: 86.61. top5: 99.82. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9515. top1: 86.02. top5: 99.65. :  40%|███▉      | 25/63 [00:01<00:01, 23.85it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9515. top1: 86.02. top5: 99.65. :  57%|█████▋    | 36/63 [00:01<00:00, 37.07it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9535. top1: 85.90. top5: 99.66. :  57%|█████▋    | 36/63 [00:01<00:00, 37.07it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9606. top1: 85.53. top5: 99.67. :  57%|█████▋    | 36/63 [00:01<00:00, 37.07it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9694. top1: 85.10. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 37.07it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9757. top1: 84.84. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 37.07it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9800. top1: 84.68. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 37.07it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9916. top1: 84.08. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 37.07it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9995. top1: 83.79. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 37.07it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0030. top1: 83.59. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 37.07it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.54. top5: 99.51. :  57%|█████▋    | 36/63 [00:02<00:00, 37.07it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.54. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0087. top1: 83.29. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0109. top1: 83.11. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0132. top1: 82.94. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0169. top1: 82.91. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0195. top1: 82.75. top5: 99.44. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0278. top1: 82.17. top5: 99.45. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0299. top1: 82.15. top5: 99.40. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0352. top1: 81.90. top5: 99.41. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0423. top1: 81.54. top5: 99.36. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0428. top1: 81.48. top5: 99.38. :  71%|███████▏  | 45/63 [00:02<00:00, 46.30it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0428. top1: 81.48. top5: 99.38. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0443. top1: 81.42. top5: 99.39. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0512. top1: 80.98. top5: 99.34. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0578. top1: 80.60. top5: 99.35. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0618. top1: 80.46. top5: 99.31. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0617. top1: 80.52. top5: 99.32. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0662. top1: 80.23. top5: 99.33. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0732. top1: 79.79. top5: 99.34. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0741. top1: 79.75. top5: 99.35. :  87%|████████▋ | 55/63 [00:02<00:00, 57.24it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0741. top1: 79.75. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 25.93it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 26/60. Data: 1.61s. Batch: 1.68s. Loss: 1.0510. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 26/60. Data: 1.61s. Batch: 1.68s. Loss: 1.0510. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 26/60. Data: 1.65s. Batch: 1.70s. Loss: 1.1125. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 26/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0672. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 26/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0672. :  12%|█▏        | 3/25 [00:01<00:10,  2.11it/s]Finetune Epoch: 26/60. Data: 1.70s. Batch: 1.76s. Loss: 1.0464. :  12%|█▏        | 3/25 [00:01<00:10,  2.11it/s]Finetune Epoch: 26/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0249. :  12%|█▏        | 3/25 [00:01<00:10,  2.11it/s]Finetune Epoch: 26/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0249. :  20%|██        | 5/25 [00:01<00:05,  3.88it/s]Finetune Epoch: 26/60. Data: 1.76s. Batch: 1.81s. Loss: 1.0277. :  20%|██        | 5/25 [00:01<00:05,  3.88it/s]Finetune Epoch: 26/60. Data: 1.78s. Batch: 1.84s. Loss: 1.0394. :  20%|██        | 5/25 [00:01<00:05,  3.88it/s]Finetune Epoch: 26/60. Data: 1.81s. Batch: 1.86s. Loss: 1.0355. :  20%|██        | 5/25 [00:02<00:05,  3.88it/s]Finetune Epoch: 26/60. Data: 1.81s. Batch: 1.86s. Loss: 1.0355. :  32%|███▏      | 8/25 [00:02<00:02,  6.72it/s]Finetune Epoch: 26/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0440. :  32%|███▏      | 8/25 [00:02<00:02,  6.72it/s]Finetune Epoch: 26/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0255. :  32%|███▏      | 8/25 [00:02<00:02,  6.72it/s]Finetune Epoch: 26/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0255. :  40%|████      | 10/25 [00:02<00:01,  8.44it/s]Finetune Epoch: 26/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0367. :  40%|████      | 10/25 [00:02<00:01,  8.44it/s]Finetune Epoch: 26/60. Data: 1.92s. Batch: 1.97s. Loss: 1.0350. :  40%|████      | 10/25 [00:02<00:01,  8.44it/s]Finetune Epoch: 26/60. Data: 1.92s. Batch: 1.97s. Loss: 1.0350. :  48%|████▊     | 12/25 [00:02<00:01, 10.20it/s]Finetune Epoch: 26/60. Data: 1.94s. Batch: 1.99s. Loss: 1.0324. :  48%|████▊     | 12/25 [00:02<00:01, 10.20it/s]Finetune Epoch: 26/60. Data: 1.97s. Batch: 2.02s. Loss: 1.0191. :  48%|████▊     | 12/25 [00:02<00:01, 10.20it/s]Finetune Epoch: 26/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0191. :  48%|████▊     | 12/25 [00:02<00:01, 10.20it/s]Finetune Epoch: 26/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0191. :  60%|██████    | 15/25 [00:02<00:00, 13.11it/s]Finetune Epoch: 26/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0157. :  60%|██████    | 15/25 [00:02<00:00, 13.11it/s]Finetune Epoch: 26/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0166. :  60%|██████    | 15/25 [00:02<00:00, 13.11it/s]Finetune Epoch: 26/60. Data: 2.07s. Batch: 2.12s. Loss: 1.0209. :  60%|██████    | 15/25 [00:02<00:00, 13.11it/s]Finetune Epoch: 26/60. Data: 2.07s. Batch: 2.12s. Loss: 1.0209. :  72%|███████▏  | 18/25 [00:02<00:00, 15.48it/s]Finetune Epoch: 26/60. Data: 2.10s. Batch: 2.14s. Loss: 1.0245. :  72%|███████▏  | 18/25 [00:02<00:00, 15.48it/s]Finetune Epoch: 26/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0161. :  72%|███████▏  | 18/25 [00:02<00:00, 15.48it/s]Finetune Epoch: 26/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0177. :  72%|███████▏  | 18/25 [00:02<00:00, 15.48it/s]Finetune Epoch: 26/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0177. :  84%|████████▍ | 21/25 [00:02<00:00, 17.86it/s]Finetune Epoch: 26/60. Data: 2.17s. Batch: 2.22s. Loss: 1.0184. :  84%|████████▍ | 21/25 [00:02<00:00, 17.86it/s]Finetune Epoch: 26/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0140. :  84%|████████▍ | 21/25 [00:02<00:00, 17.86it/s]Finetune Epoch: 26/60. Data: 2.22s. Batch: 2.26s. Loss: 1.0139. :  84%|████████▍ | 21/25 [00:02<00:00, 17.86it/s]Finetune Epoch: 26/60. Data: 2.22s. Batch: 2.26s. Loss: 1.0139. :  96%|█████████▌| 24/25 [00:02<00:00, 18.34it/s]Finetune Epoch: 26/60. Data: 2.24s. Batch: 2.29s. Loss: 1.0176. :  96%|█████████▌| 24/25 [00:02<00:00, 18.34it/s]Finetune Epoch: 26/60. Data: 2.24s. Batch: 2.29s. Loss: 1.0176. : 100%|██████████| 25/25 [00:03<00:00,  8.15it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.59s. Loss: 0.9910. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.59s. Loss: 0.9910. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.81s. Loss: 0.9751. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9280. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9385. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9166. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9131. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9320. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:38,  1.59s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9320. top1: 85.27. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9306. top1: 84.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9323. top1: 84.72. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9352. top1: 85.31. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9199. top1: 86.36. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9237. top1: 86.20. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9171. top1: 86.30. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9100. top1: 86.83. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9072. top1: 87.29. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9082. top1: 87.30. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9082. top1: 87.30. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9064. top1: 87.32. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9079. top1: 87.33. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9075. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9059. top1: 87.50. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9084. top1: 87.20. top5: 99.85. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9045. top1: 87.36. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8998. top1: 87.91. top5: 99.86. :  25%|██▌       | 16/63 [00:01<00:03, 13.91it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8998. top1: 87.91. top5: 99.86. :  37%|███▋      | 23/63 [00:01<00:01, 20.91it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8964. top1: 88.15. top5: 99.87. :  37%|███▋      | 23/63 [00:01<00:01, 20.91it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8923. top1: 88.38. top5: 99.88. :  37%|███▋      | 23/63 [00:01<00:01, 20.91it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8993. top1: 87.86. top5: 99.88. :  37%|███▋      | 23/63 [00:01<00:01, 20.91it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8996. top1: 87.73. top5: 99.88. :  37%|███▋      | 23/63 [00:01<00:01, 20.91it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9045. top1: 87.50. top5: 99.89. :  37%|███▋      | 23/63 [00:02<00:01, 20.91it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9001. top1: 87.82. top5: 99.89. :  37%|███▋      | 23/63 [00:02<00:01, 20.91it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8995. top1: 87.92. top5: 99.90. :  37%|███▋      | 23/63 [00:02<00:01, 20.91it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8981. top1: 88.10. top5: 99.90. :  37%|███▋      | 23/63 [00:02<00:01, 20.91it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8981. top1: 88.10. top5: 99.90. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9147. top1: 87.40. top5: 99.80. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9194. top1: 87.22. top5: 99.81. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9258. top1: 86.95. top5: 99.82. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9351. top1: 86.52. top5: 99.82. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9521. top1: 85.94. top5: 99.65. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9540. top1: 85.81. top5: 99.66. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9610. top1: 85.44. top5: 99.67. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9698. top1: 85.02. top5: 99.60. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9760. top1: 84.77. top5: 99.61. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9802. top1: 84.60. top5: 99.54. :  49%|████▉     | 31/63 [00:02<00:01, 29.89it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9802. top1: 84.60. top5: 99.54. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9917. top1: 84.00. top5: 99.55. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9996. top1: 83.72. top5: 99.49. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0030. top1: 83.52. top5: 99.50. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0044. top1: 83.47. top5: 99.51. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0085. top1: 83.22. top5: 99.52. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0107. top1: 83.05. top5: 99.53. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0130. top1: 82.88. top5: 99.54. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0166. top1: 82.84. top5: 99.49. :  65%|██████▌   | 41/63 [00:02<00:00, 42.19it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0166. top1: 82.84. top5: 99.49. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0192. top1: 82.69. top5: 99.44. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0274. top1: 82.11. top5: 99.45. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0294. top1: 82.09. top5: 99.40. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0347. top1: 81.84. top5: 99.41. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0417. top1: 81.48. top5: 99.36. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0421. top1: 81.42. top5: 99.38. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0436. top1: 81.36. top5: 99.39. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0504. top1: 80.92. top5: 99.34. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0569. top1: 80.55. top5: 99.35. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0610. top1: 80.40. top5: 99.31. :  78%|███████▊  | 49/63 [00:02<00:00, 47.93it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0610. top1: 80.40. top5: 99.31. :  94%|█████████▎| 59/63 [00:02<00:00, 58.20it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0609. top1: 80.47. top5: 99.32. :  94%|█████████▎| 59/63 [00:02<00:00, 58.20it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0653. top1: 80.17. top5: 99.33. :  94%|█████████▎| 59/63 [00:02<00:00, 58.20it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0723. top1: 79.74. top5: 99.34. :  94%|█████████▎| 59/63 [00:02<00:00, 58.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0731. top1: 79.70. top5: 99.35. :  94%|█████████▎| 59/63 [00:02<00:00, 58.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0731. top1: 79.70. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 24.33it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 27/60. Data: 1.68s. Batch: 1.74s. Loss: 1.0972. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 27/60. Data: 1.68s. Batch: 1.74s. Loss: 1.0972. :   4%|▍         | 1/25 [00:01<00:41,  1.74s/it]Finetune Epoch: 27/60. Data: 1.71s. Batch: 1.77s. Loss: 1.0349. :   4%|▍         | 1/25 [00:01<00:41,  1.74s/it]Finetune Epoch: 27/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9799. :   4%|▍         | 1/25 [00:01<00:41,  1.74s/it]Finetune Epoch: 27/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9799. :  12%|█▏        | 3/25 [00:01<00:10,  2.03it/s]Finetune Epoch: 27/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0073. :  12%|█▏        | 3/25 [00:01<00:10,  2.03it/s]Finetune Epoch: 27/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9959. :  12%|█▏        | 3/25 [00:01<00:10,  2.03it/s]Finetune Epoch: 27/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9959. :  20%|██        | 5/25 [00:01<00:05,  3.77it/s]Finetune Epoch: 27/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9777. :  20%|██        | 5/25 [00:02<00:05,  3.77it/s]Finetune Epoch: 27/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9951. :  20%|██        | 5/25 [00:02<00:05,  3.77it/s]Finetune Epoch: 27/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9951. :  28%|██▊       | 7/25 [00:02<00:03,  5.72it/s]Finetune Epoch: 27/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9769. :  28%|██▊       | 7/25 [00:02<00:03,  5.72it/s]Finetune Epoch: 27/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9809. :  28%|██▊       | 7/25 [00:02<00:03,  5.72it/s]Finetune Epoch: 27/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9809. :  36%|███▌      | 9/25 [00:02<00:02,  7.82it/s]Finetune Epoch: 27/60. Data: 1.93s. Batch: 1.98s. Loss: 0.9787. :  36%|███▌      | 9/25 [00:02<00:02,  7.82it/s]Finetune Epoch: 27/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9850. :  36%|███▌      | 9/25 [00:02<00:02,  7.82it/s]Finetune Epoch: 27/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9850. :  44%|████▍     | 11/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 27/60. Data: 1.98s. Batch: 2.03s. Loss: 0.9737. :  44%|████▍     | 11/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 27/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9755. :  44%|████▍     | 11/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 27/60. Data: 2.03s. Batch: 2.08s. Loss: 0.9694. :  44%|████▍     | 11/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 27/60. Data: 2.03s. Batch: 2.08s. Loss: 0.9694. :  56%|█████▌    | 14/25 [00:02<00:00, 12.55it/s]Finetune Epoch: 27/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9648. :  56%|█████▌    | 14/25 [00:02<00:00, 12.55it/s]Finetune Epoch: 27/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9709. :  56%|█████▌    | 14/25 [00:02<00:00, 12.55it/s]Finetune Epoch: 27/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9731. :  56%|█████▌    | 14/25 [00:02<00:00, 12.55it/s]Finetune Epoch: 27/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9731. :  68%|██████▊   | 17/25 [00:02<00:00, 15.16it/s]Finetune Epoch: 27/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9777. :  68%|██████▊   | 17/25 [00:02<00:00, 15.16it/s]Finetune Epoch: 27/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9748. :  68%|██████▊   | 17/25 [00:02<00:00, 15.16it/s]Finetune Epoch: 27/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9780. :  68%|██████▊   | 17/25 [00:02<00:00, 15.16it/s]Finetune Epoch: 27/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9780. :  80%|████████  | 20/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 27/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9806. :  80%|████████  | 20/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 27/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9762. :  80%|████████  | 20/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 27/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9837. :  80%|████████  | 20/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 27/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9837. :  92%|█████████▏| 23/25 [00:02<00:00, 17.61it/s]Finetune Epoch: 27/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9831. :  92%|█████████▏| 23/25 [00:02<00:00, 17.61it/s]Finetune Epoch: 27/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9948. :  92%|█████████▏| 23/25 [00:02<00:00, 17.61it/s]Finetune Epoch: 27/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9948. : 100%|██████████| 25/25 [00:03<00:00,  8.09it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 0.9933. top1: 81.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 0.9933. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 0.9774. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.9299. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.9404. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9184. top1: 86.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9149. top1: 85.94. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9340. top1: 85.27. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9340. top1: 85.27. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9326. top1: 84.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9342. top1: 84.72. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9372. top1: 85.31. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9218. top1: 86.36. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9256. top1: 86.20. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9190. top1: 86.30. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9118. top1: 86.83. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  4.90it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9090. top1: 87.29. top5: 100.00. :  11%|█         | 7/63 [00:02<00:11,  4.90it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9090. top1: 87.29. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.87it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9100. top1: 87.30. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.87it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9082. top1: 87.32. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.87it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9097. top1: 87.33. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.87it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9093. top1: 87.34. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.87it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9077. top1: 87.34. top5: 100.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.87it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9103. top1: 87.05. top5: 99.85. :  24%|██▍       | 15/63 [00:02<00:04, 11.87it/s] Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9103. top1: 87.05. top5: 99.85. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9063. top1: 87.22. top5: 99.86. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9015. top1: 87.77. top5: 99.86. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8981. top1: 88.02. top5: 99.87. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8940. top1: 88.25. top5: 99.88. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9010. top1: 87.74. top5: 99.88. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9014. top1: 87.62. top5: 99.88. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9062. top1: 87.39. top5: 99.89. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9019. top1: 87.72. top5: 99.89. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9012. top1: 87.81. top5: 99.90. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.8999. top1: 88.00. top5: 99.90. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9163. top1: 87.30. top5: 99.80. :  33%|███▎      | 21/63 [00:02<00:02, 17.47it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9163. top1: 87.30. top5: 99.80. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9209. top1: 87.12. top5: 99.81. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9271. top1: 86.86. top5: 99.82. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9362. top1: 86.43. top5: 99.82. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9531. top1: 85.85. top5: 99.65. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9548. top1: 85.73. top5: 99.66. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9617. top1: 85.36. top5: 99.67. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9703. top1: 84.94. top5: 99.60. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9765. top1: 84.69. top5: 99.61. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9806. top1: 84.60. top5: 99.54. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9920. top1: 84.00. top5: 99.55. :  51%|█████     | 32/63 [00:02<00:01, 30.31it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9920. top1: 84.00. top5: 99.55. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9998. top1: 83.72. top5: 99.49. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0031. top1: 83.52. top5: 99.50. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0044. top1: 83.47. top5: 99.51. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0085. top1: 83.22. top5: 99.52. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0106. top1: 83.05. top5: 99.53. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0128. top1: 82.88. top5: 99.54. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0164. top1: 82.84. top5: 99.49. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0188. top1: 82.69. top5: 99.44. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0269. top1: 82.11. top5: 99.45. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0289. top1: 82.09. top5: 99.40. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0289. top1: 82.09. top5: 99.40. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0341. top1: 81.84. top5: 99.41. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0410. top1: 81.48. top5: 99.36. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0414. top1: 81.42. top5: 99.38. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0428. top1: 81.42. top5: 99.39. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0496. top1: 80.98. top5: 99.34. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0560. top1: 80.60. top5: 99.35. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0601. top1: 80.46. top5: 99.31. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0599. top1: 80.52. top5: 99.32. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0643. top1: 80.23. top5: 99.33. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0711. top1: 79.79. top5: 99.34. :  83%|████████▎ | 52/63 [00:02<00:00, 52.14it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0711. top1: 79.79. top5: 99.34. :  98%|█████████▊| 62/63 [00:02<00:00, 60.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0720. top1: 79.80. top5: 99.35. :  98%|█████████▊| 62/63 [00:02<00:00, 60.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0720. top1: 79.80. top5: 99.35. : 100%|██████████| 63/63 [00:02<00:00, 22.66it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 28/60. Data: 1.74s. Batch: 1.80s. Loss: 0.9053. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 28/60. Data: 1.74s. Batch: 1.80s. Loss: 0.9053. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 28/60. Data: 1.78s. Batch: 1.83s. Loss: 0.9359. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 28/60. Data: 1.81s. Batch: 1.86s. Loss: 0.9091. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 28/60. Data: 1.81s. Batch: 1.86s. Loss: 0.9091. :  12%|█▏        | 3/25 [00:01<00:11,  1.95it/s]Finetune Epoch: 28/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9770. :  12%|█▏        | 3/25 [00:01<00:11,  1.95it/s]Finetune Epoch: 28/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9886. :  12%|█▏        | 3/25 [00:02<00:11,  1.95it/s]Finetune Epoch: 28/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9868. :  12%|█▏        | 3/25 [00:02<00:11,  1.95it/s]Finetune Epoch: 28/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9868. :  24%|██▍       | 6/25 [00:02<00:04,  4.36it/s]Finetune Epoch: 28/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9981. :  24%|██▍       | 6/25 [00:02<00:04,  4.36it/s]Finetune Epoch: 28/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0335. :  24%|██▍       | 6/25 [00:02<00:04,  4.36it/s]Finetune Epoch: 28/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0335. :  32%|███▏      | 8/25 [00:02<00:02,  6.11it/s]Finetune Epoch: 28/60. Data: 1.97s. Batch: 2.02s. Loss: 1.0328. :  32%|███▏      | 8/25 [00:02<00:02,  6.11it/s]Finetune Epoch: 28/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0277. :  32%|███▏      | 8/25 [00:02<00:02,  6.11it/s]Finetune Epoch: 28/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0277. :  40%|████      | 10/25 [00:02<00:01,  8.00it/s]Finetune Epoch: 28/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0289. :  40%|████      | 10/25 [00:02<00:01,  8.00it/s]Finetune Epoch: 28/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0320. :  40%|████      | 10/25 [00:02<00:01,  8.00it/s]Finetune Epoch: 28/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0320. :  48%|████▊     | 12/25 [00:02<00:01,  9.94it/s]Finetune Epoch: 28/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0404. :  48%|████▊     | 12/25 [00:02<00:01,  9.94it/s]Finetune Epoch: 28/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0428. :  48%|████▊     | 12/25 [00:02<00:01,  9.94it/s]Finetune Epoch: 28/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0428. :  56%|█████▌    | 14/25 [00:02<00:00, 11.84it/s]Finetune Epoch: 28/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0397. :  56%|█████▌    | 14/25 [00:02<00:00, 11.84it/s]Finetune Epoch: 28/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0268. :  56%|█████▌    | 14/25 [00:02<00:00, 11.84it/s]Finetune Epoch: 28/60. Data: 2.15s. Batch: 2.20s. Loss: 1.0268. :  64%|██████▍   | 16/25 [00:02<00:00, 12.77it/s]Finetune Epoch: 28/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0267. :  64%|██████▍   | 16/25 [00:02<00:00, 12.77it/s]Finetune Epoch: 28/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0224. :  64%|██████▍   | 16/25 [00:02<00:00, 12.77it/s]Finetune Epoch: 28/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0224. :  72%|███████▏  | 18/25 [00:02<00:00, 13.56it/s]Finetune Epoch: 28/60. Data: 2.24s. Batch: 2.29s. Loss: 1.0194. :  72%|███████▏  | 18/25 [00:02<00:00, 13.56it/s]Finetune Epoch: 28/60. Data: 2.26s. Batch: 2.31s. Loss: 1.0247. :  72%|███████▏  | 18/25 [00:02<00:00, 13.56it/s]Finetune Epoch: 28/60. Data: 2.29s. Batch: 2.34s. Loss: 1.0233. :  72%|███████▏  | 18/25 [00:02<00:00, 13.56it/s]Finetune Epoch: 28/60. Data: 2.29s. Batch: 2.34s. Loss: 1.0233. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 28/60. Data: 2.32s. Batch: 2.37s. Loss: 1.0222. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 28/60. Data: 2.34s. Batch: 2.39s. Loss: 1.0153. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 28/60. Data: 2.37s. Batch: 2.42s. Loss: 1.0086. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 28/60. Data: 2.37s. Batch: 2.42s. Loss: 1.0086. :  96%|█████████▌| 24/25 [00:02<00:00, 18.64it/s]Finetune Epoch: 28/60. Data: 2.39s. Batch: 2.44s. Loss: 1.0017. :  96%|█████████▌| 24/25 [00:03<00:00, 18.64it/s]Finetune Epoch: 28/60. Data: 2.39s. Batch: 2.44s. Loss: 1.0017. : 100%|██████████| 25/25 [00:03<00:00,  7.75it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 0.9959. top1: 78.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 0.9959. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.93s. Loss: 0.9798. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.9318. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.9425. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.9203. top1: 85.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.9203. top1: 85.62. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.41it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9169. top1: 85.42. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.41it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9359. top1: 84.82. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.41it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9346. top1: 83.98. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.41it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9362. top1: 84.38. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.41it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9392. top1: 85.00. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:16,  3.41it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9237. top1: 86.08. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:16,  3.41it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9237. top1: 86.08. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  8.67it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9275. top1: 85.94. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  8.67it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9209. top1: 86.06. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  8.67it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9137. top1: 86.61. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  8.67it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9108. top1: 87.08. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  8.67it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9118. top1: 87.11. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  8.67it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9118. top1: 87.11. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9100. top1: 87.13. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9116. top1: 87.15. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9111. top1: 87.17. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9095. top1: 87.19. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9121. top1: 86.90. top5: 99.85. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9081. top1: 87.07. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9033. top1: 87.64. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8999. top1: 87.89. top5: 99.87. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.8958. top1: 88.12. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9028. top1: 87.62. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.44it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9028. top1: 87.62. top5: 99.88. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9031. top1: 87.50. top5: 99.88. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9080. top1: 87.28. top5: 99.89. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9037. top1: 87.61. top5: 99.89. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9030. top1: 87.71. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9016. top1: 87.80. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9179. top1: 87.11. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9223. top1: 86.93. top5: 99.81. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9284. top1: 86.76. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9374. top1: 86.34. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9540. top1: 85.76. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 25.60it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9540. top1: 85.76. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9557. top1: 85.64. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9625. top1: 85.28. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9709. top1: 84.86. top5: 99.68. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9769. top1: 84.61. top5: 99.69. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9810. top1: 84.53. top5: 99.62. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9922. top1: 83.93. top5: 99.63. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0000. top1: 83.65. top5: 99.56. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0032. top1: 83.45. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.40. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0084. top1: 83.15. top5: 99.59. :  57%|█████▋    | 36/63 [00:02<00:00, 37.88it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0084. top1: 83.15. top5: 99.59. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0104. top1: 82.98. top5: 99.60. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0125. top1: 82.81. top5: 99.61. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0160. top1: 82.78. top5: 99.55. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0185. top1: 82.62. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0264. top1: 82.05. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0283. top1: 82.03. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0335. top1: 81.78. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0403. top1: 81.42. top5: 99.42. :  73%|███████▎  | 46/63 [00:02<00:00, 48.84it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0403. top1: 81.42. top5: 99.42. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0406. top1: 81.36. top5: 99.43. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0420. top1: 81.36. top5: 99.44. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0487. top1: 80.92. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0551. top1: 80.55. top5: 99.41. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0590. top1: 80.40. top5: 99.36. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0588. top1: 80.47. top5: 99.38. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0632. top1: 80.17. top5: 99.39. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0699. top1: 79.74. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0708. top1: 79.75. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 53.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0708. top1: 79.75. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 60.36it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0708. top1: 79.75. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 21.43it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 29/60. Data: 1.68s. Batch: 1.75s. Loss: 1.0276. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 29/60. Data: 1.68s. Batch: 1.75s. Loss: 1.0276. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 29/60. Data: 1.72s. Batch: 1.77s. Loss: 0.9881. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 29/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9330. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 29/60. Data: 1.76s. Batch: 1.81s. Loss: 0.9184. :   4%|▍         | 1/25 [00:01<00:42,  1.75s/it]Finetune Epoch: 29/60. Data: 1.76s. Batch: 1.81s. Loss: 0.9184. :  16%|█▌        | 4/25 [00:01<00:07,  2.76it/s]Finetune Epoch: 29/60. Data: 1.78s. Batch: 1.83s. Loss: 0.9350. :  16%|█▌        | 4/25 [00:01<00:07,  2.76it/s]Finetune Epoch: 29/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9379. :  16%|█▌        | 4/25 [00:01<00:07,  2.76it/s]Finetune Epoch: 29/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9332. :  16%|█▌        | 4/25 [00:01<00:07,  2.76it/s]Finetune Epoch: 29/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9332. :  28%|██▊       | 7/25 [00:01<00:03,  5.36it/s]Finetune Epoch: 29/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9643. :  28%|██▊       | 7/25 [00:02<00:03,  5.36it/s]Finetune Epoch: 29/60. Data: 1.86s. Batch: 1.90s. Loss: 0.9747. :  28%|██▊       | 7/25 [00:02<00:03,  5.36it/s]Finetune Epoch: 29/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9857. :  28%|██▊       | 7/25 [00:02<00:03,  5.36it/s]Finetune Epoch: 29/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9857. :  40%|████      | 10/25 [00:02<00:01,  8.21it/s]Finetune Epoch: 29/60. Data: 1.90s. Batch: 1.93s. Loss: 0.9942. :  40%|████      | 10/25 [00:02<00:01,  8.21it/s]Finetune Epoch: 29/60. Data: 1.92s. Batch: 1.95s. Loss: 0.9981. :  40%|████      | 10/25 [00:02<00:01,  8.21it/s]Finetune Epoch: 29/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0048. :  40%|████      | 10/25 [00:02<00:01,  8.21it/s]Finetune Epoch: 29/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0048. :  52%|█████▏    | 13/25 [00:02<00:01, 11.15it/s]Finetune Epoch: 29/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9988. :  52%|█████▏    | 13/25 [00:02<00:01, 11.15it/s]Finetune Epoch: 29/60. Data: 1.97s. Batch: 2.01s. Loss: 1.0114. :  52%|█████▏    | 13/25 [00:02<00:01, 11.15it/s]Finetune Epoch: 29/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0039. :  52%|█████▏    | 13/25 [00:02<00:01, 11.15it/s]Finetune Epoch: 29/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0039. :  64%|██████▍   | 16/25 [00:02<00:00, 13.08it/s]Finetune Epoch: 29/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9954. :  64%|██████▍   | 16/25 [00:02<00:00, 13.08it/s]Finetune Epoch: 29/60. Data: 2.04s. Batch: 2.08s. Loss: 0.9990. :  64%|██████▍   | 16/25 [00:02<00:00, 13.08it/s]Finetune Epoch: 29/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0052. :  64%|██████▍   | 16/25 [00:02<00:00, 13.08it/s]Finetune Epoch: 29/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0052. :  76%|███████▌  | 19/25 [00:02<00:00, 14.92it/s]Finetune Epoch: 29/60. Data: 2.08s. Batch: 2.12s. Loss: 0.9968. :  76%|███████▌  | 19/25 [00:02<00:00, 14.92it/s]Finetune Epoch: 29/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9944. :  76%|███████▌  | 19/25 [00:02<00:00, 14.92it/s]Finetune Epoch: 29/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0015. :  76%|███████▌  | 19/25 [00:02<00:00, 14.92it/s]Finetune Epoch: 29/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0015. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 29/60. Data: 2.15s. Batch: 2.19s. Loss: 0.9946. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 29/60. Data: 2.17s. Batch: 2.21s. Loss: 0.9930. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 29/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9868. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 29/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9868. : 100%|██████████| 25/25 [00:02<00:00, 17.07it/s]Finetune Epoch: 29/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9868. : 100%|██████████| 25/25 [00:03<00:00,  8.20it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 0.9982. top1: 78.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 0.9982. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.90s. Loss: 0.9820. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 0.9335. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.9443. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.9443. top1: 82.81. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9221. top1: 85.62. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9186. top1: 85.42. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9378. top1: 84.82. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9364. top1: 83.98. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9381. top1: 84.38. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9410. top1: 85.00. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9256. top1: 86.08. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9294. top1: 85.94. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9227. top1: 86.06. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9154. top1: 86.61. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:21,  2.79it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9154. top1: 86.61. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:03, 12.26it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9125. top1: 87.08. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:03, 12.26it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9135. top1: 87.11. top5: 100.00. :  22%|██▏       | 14/63 [00:01<00:03, 12.26it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9117. top1: 87.13. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:03, 12.26it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9133. top1: 87.15. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:03, 12.26it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9129. top1: 87.17. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:03, 12.26it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9112. top1: 87.19. top5: 100.00. :  22%|██▏       | 14/63 [00:02<00:03, 12.26it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9112. top1: 87.19. top5: 100.00. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9138. top1: 86.90. top5: 99.85. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9097. top1: 87.07. top5: 99.86. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9050. top1: 87.64. top5: 99.86. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9016. top1: 87.76. top5: 99.87. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8974. top1: 88.00. top5: 99.88. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9045. top1: 87.50. top5: 99.88. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9048. top1: 87.38. top5: 99.88. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9098. top1: 87.17. top5: 99.89. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9054. top1: 87.50. top5: 99.89. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9047. top1: 87.60. top5: 99.90. :  32%|███▏      | 20/63 [00:02<00:02, 17.98it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9047. top1: 87.60. top5: 99.90. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9034. top1: 87.70. top5: 99.90. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9195. top1: 87.01. top5: 99.80. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9237. top1: 86.84. top5: 99.81. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9297. top1: 86.67. top5: 99.82. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9385. top1: 86.25. top5: 99.82. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9549. top1: 85.68. top5: 99.65. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9564. top1: 85.56. top5: 99.66. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9631. top1: 85.20. top5: 99.67. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9715. top1: 84.78. top5: 99.68. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9774. top1: 84.53. top5: 99.69. :  48%|████▊     | 30/63 [00:02<00:01, 30.00it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9774. top1: 84.53. top5: 99.69. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9813. top1: 84.45. top5: 99.62. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9925. top1: 83.85. top5: 99.63. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0002. top1: 83.58. top5: 99.56. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0033. top1: 83.38. top5: 99.57. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 83.33. top5: 99.58. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0084. top1: 83.08. top5: 99.59. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0103. top1: 82.91. top5: 99.60. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0123. top1: 82.75. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 41.95it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0123. top1: 82.75. top5: 99.61. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0158. top1: 82.72. top5: 99.55. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0182. top1: 82.56. top5: 99.56. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0260. top1: 81.99. top5: 99.57. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0278. top1: 81.97. top5: 99.52. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0329. top1: 81.72. top5: 99.53. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0397. top1: 81.42. top5: 99.48. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0400. top1: 81.42. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0413. top1: 81.42. top5: 99.50. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0479. top1: 80.98. top5: 99.45. :  76%|███████▌  | 48/63 [00:02<00:00, 49.47it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0479. top1: 80.98. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 57.22it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0542. top1: 80.66. top5: 99.46. :  90%|█████████ | 57/63 [00:02<00:00, 57.22it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0581. top1: 80.51. top5: 99.42. :  90%|█████████ | 57/63 [00:02<00:00, 57.22it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0579. top1: 80.57. top5: 99.43. :  90%|█████████ | 57/63 [00:02<00:00, 57.22it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0622. top1: 80.28. top5: 99.44. :  90%|█████████ | 57/63 [00:02<00:00, 57.22it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0689. top1: 79.84. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 57.22it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0697. top1: 79.85. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 57.22it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0697. top1: 79.85. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.27it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 30/60. Data: 1.52s. Batch: 1.58s. Loss: 1.0344. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 30/60. Data: 1.52s. Batch: 1.58s. Loss: 1.0344. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 30/60. Data: 1.55s. Batch: 1.60s. Loss: 1.0152. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 30/60. Data: 1.57s. Batch: 1.62s. Loss: 1.0547. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 30/60. Data: 1.60s. Batch: 1.65s. Loss: 1.0125. :   4%|▍         | 1/25 [00:01<00:37,  1.58s/it]Finetune Epoch: 30/60. Data: 1.60s. Batch: 1.65s. Loss: 1.0125. :  16%|█▌        | 4/25 [00:01<00:07,  2.96it/s]Finetune Epoch: 30/60. Data: 1.62s. Batch: 1.67s. Loss: 0.9841. :  16%|█▌        | 4/25 [00:01<00:07,  2.96it/s]Finetune Epoch: 30/60. Data: 1.65s. Batch: 1.70s. Loss: 0.9847. :  16%|█▌        | 4/25 [00:01<00:07,  2.96it/s]Finetune Epoch: 30/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9852. :  16%|█▌        | 4/25 [00:01<00:07,  2.96it/s]Finetune Epoch: 30/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9852. :  28%|██▊       | 7/25 [00:01<00:03,  5.42it/s]Finetune Epoch: 30/60. Data: 1.70s. Batch: 1.75s. Loss: 1.0168. :  28%|██▊       | 7/25 [00:01<00:03,  5.42it/s]Finetune Epoch: 30/60. Data: 1.73s. Batch: 1.78s. Loss: 0.9967. :  28%|██▊       | 7/25 [00:01<00:03,  5.42it/s]Finetune Epoch: 30/60. Data: 1.73s. Batch: 1.78s. Loss: 0.9967. :  36%|███▌      | 9/25 [00:01<00:02,  7.19it/s]Finetune Epoch: 30/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9990. :  36%|███▌      | 9/25 [00:02<00:02,  7.19it/s]Finetune Epoch: 30/60. Data: 1.78s. Batch: 1.83s. Loss: 0.9963. :  36%|███▌      | 9/25 [00:02<00:02,  7.19it/s]Finetune Epoch: 30/60. Data: 1.78s. Batch: 1.83s. Loss: 0.9963. :  44%|████▍     | 11/25 [00:02<00:01,  8.92it/s]Finetune Epoch: 30/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9951. :  44%|████▍     | 11/25 [00:02<00:01,  8.92it/s]Finetune Epoch: 30/60. Data: 1.83s. Batch: 1.88s. Loss: 0.9849. :  44%|████▍     | 11/25 [00:02<00:01,  8.92it/s]Finetune Epoch: 30/60. Data: 1.83s. Batch: 1.88s. Loss: 0.9849. :  52%|█████▏    | 13/25 [00:02<00:01, 10.83it/s]Finetune Epoch: 30/60. Data: 1.86s. Batch: 1.91s. Loss: 0.9756. :  52%|█████▏    | 13/25 [00:02<00:01, 10.83it/s]Finetune Epoch: 30/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9881. :  52%|█████▏    | 13/25 [00:02<00:01, 10.83it/s]Finetune Epoch: 30/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9881. :  60%|██████    | 15/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 30/60. Data: 1.91s. Batch: 1.96s. Loss: 0.9956. :  60%|██████    | 15/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 30/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9962. :  60%|██████    | 15/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 30/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9962. :  68%|██████▊   | 17/25 [00:02<00:00, 13.73it/s]Finetune Epoch: 30/60. Data: 1.96s. Batch: 2.01s. Loss: 0.9928. :  68%|██████▊   | 17/25 [00:02<00:00, 13.73it/s]Finetune Epoch: 30/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9996. :  68%|██████▊   | 17/25 [00:02<00:00, 13.73it/s]Finetune Epoch: 30/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9996. :  76%|███████▌  | 19/25 [00:02<00:00, 15.00it/s]Finetune Epoch: 30/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0068. :  76%|███████▌  | 19/25 [00:02<00:00, 15.00it/s]Finetune Epoch: 30/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0089. :  76%|███████▌  | 19/25 [00:02<00:00, 15.00it/s]Finetune Epoch: 30/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0089. :  84%|████████▍ | 21/25 [00:02<00:00, 16.22it/s]Finetune Epoch: 30/60. Data: 2.07s. Batch: 2.12s. Loss: 1.0046. :  84%|████████▍ | 21/25 [00:02<00:00, 16.22it/s]Finetune Epoch: 30/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0098. :  84%|████████▍ | 21/25 [00:02<00:00, 16.22it/s]Finetune Epoch: 30/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0085. :  84%|████████▍ | 21/25 [00:02<00:00, 16.22it/s]Finetune Epoch: 30/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0085. :  96%|█████████▌| 24/25 [00:02<00:00, 17.80it/s]Finetune Epoch: 30/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0112. :  96%|█████████▌| 24/25 [00:02<00:00, 17.80it/s]Finetune Epoch: 30/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0112. : 100%|██████████| 25/25 [00:03<00:00,  8.25it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0003. top1: 78.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0003. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.89s. Loss: 0.9839. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 0.9351. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 0.9460. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 0.9236. top1: 85.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9201. top1: 85.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9393. top1: 84.82. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9393. top1: 84.82. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9380. top1: 83.98. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9396. top1: 84.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9426. top1: 85.00. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9271. top1: 86.08. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9309. top1: 85.94. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9242. top1: 86.06. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9169. top1: 86.61. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9139. top1: 87.08. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9149. top1: 87.11. top5: 100.00. :  11%|█         | 7/63 [00:01<00:11,  5.05it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9149. top1: 87.11. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.10it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9131. top1: 87.13. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.10it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9148. top1: 87.15. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.10it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9143. top1: 87.17. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.10it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9126. top1: 87.19. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 13.10it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9152. top1: 86.90. top5: 99.85. :  25%|██▌       | 16/63 [00:02<00:03, 13.10it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9111. top1: 87.07. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 13.10it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9064. top1: 87.64. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 13.10it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9030. top1: 87.76. top5: 99.87. :  25%|██▌       | 16/63 [00:02<00:03, 13.10it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.8988. top1: 88.00. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.10it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9059. top1: 87.50. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.10it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9059. top1: 87.50. top5: 99.88. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9062. top1: 87.38. top5: 99.88. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9112. top1: 87.17. top5: 99.89. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9068. top1: 87.50. top5: 99.89. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9061. top1: 87.60. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9048. top1: 87.70. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9208. top1: 87.01. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9249. top1: 86.84. top5: 99.81. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9308. top1: 86.67. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 23.55it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9308. top1: 86.67. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9394. top1: 86.25. top5: 99.82. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9557. top1: 85.68. top5: 99.65. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9571. top1: 85.56. top5: 99.66. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9637. top1: 85.20. top5: 99.67. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9720. top1: 84.78. top5: 99.68. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9778. top1: 84.53. top5: 99.69. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9817. top1: 84.45. top5: 99.62. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9928. top1: 83.85. top5: 99.63. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0004. top1: 83.58. top5: 99.56. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0034. top1: 83.38. top5: 99.57. :  54%|█████▍    | 34/63 [00:02<00:00, 31.79it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0034. top1: 83.38. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0046. top1: 83.33. top5: 99.58. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0084. top1: 83.08. top5: 99.59. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0102. top1: 82.91. top5: 99.60. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0122. top1: 82.75. top5: 99.61. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0156. top1: 82.72. top5: 99.55. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0179. top1: 82.56. top5: 99.56. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0256. top1: 81.99. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0274. top1: 81.97. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0325. top1: 81.72. top5: 99.53. :  70%|██████▉   | 44/63 [00:02<00:00, 43.02it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0325. top1: 81.72. top5: 99.53. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0392. top1: 81.42. top5: 99.48. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0395. top1: 81.42. top5: 99.49. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0407. top1: 81.42. top5: 99.50. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0473. top1: 80.98. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0535. top1: 80.66. top5: 99.46. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0574. top1: 80.51. top5: 99.42. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0571. top1: 80.57. top5: 99.43. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0614. top1: 80.28. top5: 99.44. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0680. top1: 79.84. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 50.27it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0680. top1: 79.84. top5: 99.45. :  98%|█████████▊| 62/63 [00:02<00:00, 58.50it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0688. top1: 79.85. top5: 99.45. :  98%|█████████▊| 62/63 [00:02<00:00, 58.50it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0688. top1: 79.85. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.39it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 31/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9152. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 31/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9152. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 31/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9120. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 31/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9826. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 31/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9709. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 31/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9709. :  16%|█▌        | 4/25 [00:01<00:07,  2.71it/s]Finetune Epoch: 31/60. Data: 1.84s. Batch: 1.87s. Loss: 0.9595. :  16%|█▌        | 4/25 [00:01<00:07,  2.71it/s]Finetune Epoch: 31/60. Data: 1.86s. Batch: 1.89s. Loss: 0.9546. :  16%|█▌        | 4/25 [00:01<00:07,  2.71it/s]Finetune Epoch: 31/60. Data: 1.87s. Batch: 1.91s. Loss: 0.9537. :  16%|█▌        | 4/25 [00:02<00:07,  2.71it/s]Finetune Epoch: 31/60. Data: 1.87s. Batch: 1.91s. Loss: 0.9537. :  28%|██▊       | 7/25 [00:02<00:03,  5.27it/s]Finetune Epoch: 31/60. Data: 1.89s. Batch: 1.93s. Loss: 0.9338. :  28%|██▊       | 7/25 [00:02<00:03,  5.27it/s]Finetune Epoch: 31/60. Data: 1.91s. Batch: 1.95s. Loss: 0.9641. :  28%|██▊       | 7/25 [00:02<00:03,  5.27it/s]Finetune Epoch: 31/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9696. :  28%|██▊       | 7/25 [00:02<00:03,  5.27it/s]Finetune Epoch: 31/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9696. :  40%|████      | 10/25 [00:02<00:01,  7.72it/s]Finetune Epoch: 31/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9732. :  40%|████      | 10/25 [00:02<00:01,  7.72it/s]Finetune Epoch: 31/60. Data: 1.98s. Batch: 2.02s. Loss: 0.9706. :  40%|████      | 10/25 [00:02<00:01,  7.72it/s]Finetune Epoch: 31/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9745. :  40%|████      | 10/25 [00:02<00:01,  7.72it/s]Finetune Epoch: 31/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9745. :  52%|█████▏    | 13/25 [00:02<00:01,  9.86it/s]Finetune Epoch: 31/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9932. :  52%|█████▏    | 13/25 [00:02<00:01,  9.86it/s]Finetune Epoch: 31/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9851. :  52%|█████▏    | 13/25 [00:02<00:01,  9.86it/s]Finetune Epoch: 31/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9811. :  52%|█████▏    | 13/25 [00:02<00:01,  9.86it/s]Finetune Epoch: 31/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9811. :  64%|██████▍   | 16/25 [00:02<00:00, 11.80it/s]Finetune Epoch: 31/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9766. :  64%|██████▍   | 16/25 [00:02<00:00, 11.80it/s]Finetune Epoch: 31/60. Data: 2.12s. Batch: 2.17s. Loss: 0.9920. :  64%|██████▍   | 16/25 [00:02<00:00, 11.80it/s]Finetune Epoch: 31/60. Data: 2.15s. Batch: 2.19s. Loss: 0.9878. :  64%|██████▍   | 16/25 [00:02<00:00, 11.80it/s]Finetune Epoch: 31/60. Data: 2.15s. Batch: 2.19s. Loss: 0.9878. :  76%|███████▌  | 19/25 [00:02<00:00, 13.75it/s]Finetune Epoch: 31/60. Data: 2.17s. Batch: 2.22s. Loss: 0.9875. :  76%|███████▌  | 19/25 [00:02<00:00, 13.75it/s]Finetune Epoch: 31/60. Data: 2.20s. Batch: 2.24s. Loss: 0.9859. :  76%|███████▌  | 19/25 [00:02<00:00, 13.75it/s]Finetune Epoch: 31/60. Data: 2.20s. Batch: 2.24s. Loss: 0.9859. :  84%|████████▍ | 21/25 [00:02<00:00, 14.70it/s]Finetune Epoch: 31/60. Data: 2.22s. Batch: 2.27s. Loss: 0.9840. :  84%|████████▍ | 21/25 [00:02<00:00, 14.70it/s]Finetune Epoch: 31/60. Data: 2.25s. Batch: 2.29s. Loss: 0.9834. :  84%|████████▍ | 21/25 [00:02<00:00, 14.70it/s]Finetune Epoch: 31/60. Data: 2.27s. Batch: 2.32s. Loss: 0.9855. :  84%|████████▍ | 21/25 [00:02<00:00, 14.70it/s]Finetune Epoch: 31/60. Data: 2.27s. Batch: 2.32s. Loss: 0.9855. :  96%|█████████▌| 24/25 [00:02<00:00, 16.70it/s]Finetune Epoch: 31/60. Data: 2.30s. Batch: 2.34s. Loss: 0.9864. :  96%|█████████▌| 24/25 [00:02<00:00, 16.70it/s]Finetune Epoch: 31/60. Data: 2.30s. Batch: 2.34s. Loss: 0.9864. : 100%|██████████| 25/25 [00:03<00:00,  8.04it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.72s. Loss: 1.0028. top1: 78.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.72s. Loss: 1.0028. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 0.9864. top1: 78.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.59s. Loss: 0.9371. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9481. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 0.9256. top1: 85.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9221. top1: 85.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9414. top1: 84.82. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9414. top1: 84.82. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9401. top1: 83.98. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9417. top1: 84.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9447. top1: 85.00. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9291. top1: 86.08. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9329. top1: 85.94. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9262. top1: 86.06. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9188. top1: 86.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9158. top1: 86.88. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9168. top1: 86.91. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.13it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9168. top1: 86.91. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.26it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9150. top1: 86.95. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.26it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9167. top1: 86.98. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.26it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9162. top1: 87.01. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.26it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9145. top1: 87.03. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 13.26it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9171. top1: 86.76. top5: 99.85. :  25%|██▌       | 16/63 [00:01<00:03, 13.26it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9130. top1: 86.93. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 13.26it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9082. top1: 87.50. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 13.26it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9048. top1: 87.63. top5: 99.87. :  25%|██▌       | 16/63 [00:02<00:03, 13.26it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9006. top1: 87.88. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.26it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9077. top1: 87.38. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 13.26it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9077. top1: 87.38. top5: 99.88. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9081. top1: 87.27. top5: 99.88. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9131. top1: 87.05. top5: 99.89. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9086. top1: 87.39. top5: 99.89. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9079. top1: 87.50. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9066. top1: 87.60. top5: 99.90. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9224. top1: 86.91. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9264. top1: 86.74. top5: 99.81. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9322. top1: 86.58. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9406. top1: 86.16. top5: 99.82. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9568. top1: 85.59. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 23.72it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9568. top1: 85.59. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9580. top1: 85.56. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9645. top1: 85.20. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9726. top1: 84.78. top5: 99.68. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9783. top1: 84.53. top5: 99.69. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9821. top1: 84.45. top5: 99.62. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9931. top1: 83.85. top5: 99.63. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0006. top1: 83.58. top5: 99.56. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0036. top1: 83.38. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0047. top1: 83.33. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0084. top1: 83.15. top5: 99.59. :  57%|█████▋    | 36/63 [00:02<00:00, 34.90it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0084. top1: 83.15. top5: 99.59. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0101. top1: 82.98. top5: 99.60. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0120. top1: 82.81. top5: 99.61. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0154. top1: 82.78. top5: 99.55. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0176. top1: 82.69. top5: 99.56. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0252. top1: 82.11. top5: 99.57. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0269. top1: 82.09. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0319. top1: 81.84. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0386. top1: 81.54. top5: 99.48. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0388. top1: 81.53. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 45.48it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0388. top1: 81.53. top5: 99.49. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0400. top1: 81.53. top5: 99.50. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0464. top1: 81.14. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0526. top1: 80.82. top5: 99.46. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0564. top1: 80.67. top5: 99.42. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0562. top1: 80.73. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0604. top1: 80.43. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0669. top1: 79.99. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0676. top1: 80.00. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 54.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0676. top1: 80.00. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.77it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 32/60. Data: 1.73s. Batch: 1.80s. Loss: 0.9939. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 32/60. Data: 1.73s. Batch: 1.80s. Loss: 0.9939. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 32/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9610. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 32/60. Data: 1.79s. Batch: 1.84s. Loss: 0.9840. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 32/60. Data: 1.81s. Batch: 1.86s. Loss: 0.9617. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 32/60. Data: 1.81s. Batch: 1.86s. Loss: 0.9617. :  16%|█▌        | 4/25 [00:01<00:07,  2.67it/s]Finetune Epoch: 32/60. Data: 1.84s. Batch: 1.88s. Loss: 0.9420. :  16%|█▌        | 4/25 [00:01<00:07,  2.67it/s]Finetune Epoch: 32/60. Data: 1.86s. Batch: 1.90s. Loss: 0.9407. :  16%|█▌        | 4/25 [00:02<00:07,  2.67it/s]Finetune Epoch: 32/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9362. :  16%|█▌        | 4/25 [00:02<00:07,  2.67it/s]Finetune Epoch: 32/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9362. :  28%|██▊       | 7/25 [00:02<00:03,  5.07it/s]Finetune Epoch: 32/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9369. :  28%|██▊       | 7/25 [00:02<00:03,  5.07it/s]Finetune Epoch: 32/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9751. :  28%|██▊       | 7/25 [00:02<00:03,  5.07it/s]Finetune Epoch: 32/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9800. :  28%|██▊       | 7/25 [00:02<00:03,  5.07it/s]Finetune Epoch: 32/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9800. :  40%|████      | 10/25 [00:02<00:01,  7.68it/s]Finetune Epoch: 32/60. Data: 1.97s. Batch: 2.01s. Loss: 1.0004. :  40%|████      | 10/25 [00:02<00:01,  7.68it/s]Finetune Epoch: 32/60. Data: 1.99s. Batch: 2.03s. Loss: 0.9908. :  40%|████      | 10/25 [00:02<00:01,  7.68it/s]Finetune Epoch: 32/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0032. :  40%|████      | 10/25 [00:02<00:01,  7.68it/s]Finetune Epoch: 32/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0032. :  52%|█████▏    | 13/25 [00:02<00:01, 10.26it/s]Finetune Epoch: 32/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0052. :  52%|█████▏    | 13/25 [00:02<00:01, 10.26it/s]Finetune Epoch: 32/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0150. :  52%|█████▏    | 13/25 [00:02<00:01, 10.26it/s]Finetune Epoch: 32/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0054. :  52%|█████▏    | 13/25 [00:02<00:01, 10.26it/s]Finetune Epoch: 32/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0054. :  64%|██████▍   | 16/25 [00:02<00:00, 12.69it/s]Finetune Epoch: 32/60. Data: 2.10s. Batch: 2.14s. Loss: 1.0026. :  64%|██████▍   | 16/25 [00:02<00:00, 12.69it/s]Finetune Epoch: 32/60. Data: 2.12s. Batch: 2.17s. Loss: 0.9920. :  64%|██████▍   | 16/25 [00:02<00:00, 12.69it/s]Finetune Epoch: 32/60. Data: 2.15s. Batch: 2.19s. Loss: 0.9845. :  64%|██████▍   | 16/25 [00:02<00:00, 12.69it/s]Finetune Epoch: 32/60. Data: 2.15s. Batch: 2.19s. Loss: 0.9845. :  76%|███████▌  | 19/25 [00:02<00:00, 14.80it/s]Finetune Epoch: 32/60. Data: 2.17s. Batch: 2.21s. Loss: 0.9808. :  76%|███████▌  | 19/25 [00:02<00:00, 14.80it/s]Finetune Epoch: 32/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9856. :  76%|███████▌  | 19/25 [00:02<00:00, 14.80it/s]Finetune Epoch: 32/60. Data: 2.21s. Batch: 2.25s. Loss: 0.9883. :  76%|███████▌  | 19/25 [00:02<00:00, 14.80it/s]Finetune Epoch: 32/60. Data: 2.21s. Batch: 2.25s. Loss: 0.9883. :  88%|████████▊ | 22/25 [00:02<00:00, 17.09it/s]Finetune Epoch: 32/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9944. :  88%|████████▊ | 22/25 [00:02<00:00, 17.09it/s]Finetune Epoch: 32/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9953. :  88%|████████▊ | 22/25 [00:02<00:00, 17.09it/s]Finetune Epoch: 32/60. Data: 2.28s. Batch: 2.32s. Loss: 0.9994. :  88%|████████▊ | 22/25 [00:02<00:00, 17.09it/s]Finetune Epoch: 32/60. Data: 2.28s. Batch: 2.32s. Loss: 0.9994. : 100%|██████████| 25/25 [00:02<00:00, 18.12it/s]Finetune Epoch: 32/60. Data: 2.28s. Batch: 2.32s. Loss: 0.9994. : 100%|██████████| 25/25 [00:03<00:00,  8.18it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0046. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0046. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.88s. Loss: 0.9881. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.59s. Loss: 0.9385. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 0.9497. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9270. top1: 85.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9236. top1: 84.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9429. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9417. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9433. top1: 84.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.76s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9433. top1: 84.03. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9463. top1: 84.69. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9306. top1: 85.80. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9344. top1: 85.68. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9276. top1: 85.82. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9203. top1: 86.16. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9172. top1: 86.67. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9182. top1: 86.72. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.51it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9182. top1: 86.72. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9164. top1: 86.76. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9181. top1: 86.81. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9176. top1: 86.84. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.59it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9159. top1: 86.72. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9185. top1: 86.46. top5: 99.85. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9144. top1: 86.65. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9096. top1: 87.23. top5: 99.86. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9062. top1: 87.37. top5: 99.87. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9019. top1: 87.62. top5: 99.88. :  25%|██▌       | 16/63 [00:02<00:03, 12.59it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9019. top1: 87.62. top5: 99.88. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9090. top1: 87.14. top5: 99.88. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9094. top1: 87.04. top5: 99.88. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9144. top1: 86.83. top5: 99.89. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9099. top1: 87.18. top5: 99.89. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9093. top1: 87.29. top5: 99.90. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9080. top1: 87.40. top5: 99.90. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9237. top1: 86.72. top5: 99.80. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9276. top1: 86.55. top5: 99.81. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9332. top1: 86.40. top5: 99.82. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9415. top1: 85.98. top5: 99.82. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9575. top1: 85.42. top5: 99.65. :  40%|███▉      | 25/63 [00:02<00:01, 21.69it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9575. top1: 85.42. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9587. top1: 85.39. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9651. top1: 85.03. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9731. top1: 84.70. top5: 99.68. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9787. top1: 84.45. top5: 99.69. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9825. top1: 84.38. top5: 99.62. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9934. top1: 83.78. top5: 99.63. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0008. top1: 83.50. top5: 99.56. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0038. top1: 83.31. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 34.18it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0038. top1: 83.31. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0048. top1: 83.26. top5: 99.58. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0084. top1: 83.08. top5: 99.59. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0100. top1: 82.91. top5: 99.60. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0119. top1: 82.75. top5: 99.61. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0152. top1: 82.72. top5: 99.55. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0174. top1: 82.62. top5: 99.56. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0249. top1: 82.11. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0265. top1: 82.09. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0315. top1: 81.84. top5: 99.53. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0381. top1: 81.54. top5: 99.48. :  70%|██████▉   | 44/63 [00:02<00:00, 41.95it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0381. top1: 81.54. top5: 99.48. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0383. top1: 81.53. top5: 99.49. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0394. top1: 81.53. top5: 99.50. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0458. top1: 81.14. top5: 99.45. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0519. top1: 80.82. top5: 99.46. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0557. top1: 80.67. top5: 99.42. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0554. top1: 80.73. top5: 99.43. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0596. top1: 80.43. top5: 99.44. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0661. top1: 79.99. top5: 99.45. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0668. top1: 80.00. top5: 99.45. :  86%|████████▌ | 54/63 [00:02<00:00, 52.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0668. top1: 80.00. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.14it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 33/60. Data: 1.75s. Batch: 1.81s. Loss: 0.8713. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 33/60. Data: 1.75s. Batch: 1.81s. Loss: 0.8713. :   4%|▍         | 1/25 [00:01<00:43,  1.81s/it]Finetune Epoch: 33/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0440. :   4%|▍         | 1/25 [00:01<00:43,  1.81s/it]Finetune Epoch: 33/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0155. :   4%|▍         | 1/25 [00:01<00:43,  1.81s/it]Finetune Epoch: 33/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9765. :   4%|▍         | 1/25 [00:01<00:43,  1.81s/it]Finetune Epoch: 33/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9765. :  16%|█▌        | 4/25 [00:01<00:07,  2.68it/s]Finetune Epoch: 33/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9802. :  16%|█▌        | 4/25 [00:01<00:07,  2.68it/s]Finetune Epoch: 33/60. Data: 1.86s. Batch: 1.91s. Loss: 1.0024. :  16%|█▌        | 4/25 [00:02<00:07,  2.68it/s]Finetune Epoch: 33/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9904. :  16%|█▌        | 4/25 [00:02<00:07,  2.68it/s]Finetune Epoch: 33/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9904. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 33/60. Data: 1.91s. Batch: 1.95s. Loss: 0.9871. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 33/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9953. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 33/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9831. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 33/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9831. :  40%|████      | 10/25 [00:02<00:01,  7.85it/s]Finetune Epoch: 33/60. Data: 1.97s. Batch: 2.01s. Loss: 0.9774. :  40%|████      | 10/25 [00:02<00:01,  7.85it/s]Finetune Epoch: 33/60. Data: 1.99s. Batch: 2.03s. Loss: 0.9781. :  40%|████      | 10/25 [00:02<00:01,  7.85it/s]Finetune Epoch: 33/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9954. :  40%|████      | 10/25 [00:02<00:01,  7.85it/s]Finetune Epoch: 33/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9954. :  52%|█████▏    | 13/25 [00:02<00:01, 10.45it/s]Finetune Epoch: 33/60. Data: 2.03s. Batch: 2.07s. Loss: 0.9895. :  52%|█████▏    | 13/25 [00:02<00:01, 10.45it/s]Finetune Epoch: 33/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9924. :  52%|█████▏    | 13/25 [00:02<00:01, 10.45it/s]Finetune Epoch: 33/60. Data: 2.07s. Batch: 2.11s. Loss: 0.9955. :  52%|█████▏    | 13/25 [00:02<00:01, 10.45it/s]Finetune Epoch: 33/60. Data: 2.07s. Batch: 2.11s. Loss: 0.9955. :  64%|██████▍   | 16/25 [00:02<00:00, 12.79it/s]Finetune Epoch: 33/60. Data: 2.09s. Batch: 2.13s. Loss: 0.9890. :  64%|██████▍   | 16/25 [00:02<00:00, 12.79it/s]Finetune Epoch: 33/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9941. :  64%|██████▍   | 16/25 [00:02<00:00, 12.79it/s]Finetune Epoch: 33/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9978. :  64%|██████▍   | 16/25 [00:02<00:00, 12.79it/s]Finetune Epoch: 33/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9978. :  76%|███████▌  | 19/25 [00:02<00:00, 14.71it/s]Finetune Epoch: 33/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9918. :  76%|███████▌  | 19/25 [00:02<00:00, 14.71it/s]Finetune Epoch: 33/60. Data: 2.18s. Batch: 2.22s. Loss: 1.0029. :  76%|███████▌  | 19/25 [00:02<00:00, 14.71it/s]Finetune Epoch: 33/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0101. :  76%|███████▌  | 19/25 [00:02<00:00, 14.71it/s]Finetune Epoch: 33/60. Data: 2.20s. Batch: 2.25s. Loss: 1.0101. :  88%|████████▊ | 22/25 [00:02<00:00, 16.17it/s]Finetune Epoch: 33/60. Data: 2.23s. Batch: 2.27s. Loss: 1.0153. :  88%|████████▊ | 22/25 [00:02<00:00, 16.17it/s]Finetune Epoch: 33/60. Data: 2.25s. Batch: 2.29s. Loss: 1.0114. :  88%|████████▊ | 22/25 [00:02<00:00, 16.17it/s]Finetune Epoch: 33/60. Data: 2.27s. Batch: 2.32s. Loss: 1.0045. :  88%|████████▊ | 22/25 [00:02<00:00, 16.17it/s]Finetune Epoch: 33/60. Data: 2.27s. Batch: 2.32s. Loss: 1.0045. : 100%|██████████| 25/25 [00:02<00:00, 17.22it/s]Finetune Epoch: 33/60. Data: 2.27s. Batch: 2.32s. Loss: 1.0045. : 100%|██████████| 25/25 [00:03<00:00,  8.25it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.47s. Loss: 1.0064. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.47s. Loss: 1.0064. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.74s. Loss: 0.9897. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.50s. Loss: 0.9398. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.9510. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9283. top1: 85.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9248. top1: 84.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9442. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9430. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9446. top1: 84.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:31,  1.47s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9446. top1: 84.03. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.67it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9476. top1: 84.69. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.67it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9320. top1: 85.80. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.67it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9358. top1: 85.68. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.67it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9290. top1: 85.82. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.67it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9215. top1: 86.16. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.67it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9184. top1: 86.67. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  7.67it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9184. top1: 86.67. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9194. top1: 86.72. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9177. top1: 86.76. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9194. top1: 86.81. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9189. top1: 86.84. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9171. top1: 86.72. top5: 100.00. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9198. top1: 86.46. top5: 99.85. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9156. top1: 86.65. top5: 99.86. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9109. top1: 87.23. top5: 99.86. :  24%|██▍       | 15/63 [00:01<00:03, 13.52it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9109. top1: 87.23. top5: 99.86. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9074. top1: 87.37. top5: 99.87. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9031. top1: 87.62. top5: 99.88. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9103. top1: 87.14. top5: 99.88. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9107. top1: 87.04. top5: 99.88. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9157. top1: 86.83. top5: 99.89. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9112. top1: 87.18. top5: 99.89. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9105. top1: 87.29. top5: 99.90. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9092. top1: 87.40. top5: 99.90. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9248. top1: 86.72. top5: 99.80. :  37%|███▋      | 23/63 [00:01<00:01, 22.41it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9248. top1: 86.72. top5: 99.80. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9286. top1: 86.55. top5: 99.81. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9341. top1: 86.40. top5: 99.82. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9423. top1: 85.98. top5: 99.82. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9582. top1: 85.42. top5: 99.65. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9593. top1: 85.39. top5: 99.66. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9656. top1: 85.03. top5: 99.67. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9735. top1: 84.70. top5: 99.68. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9791. top1: 84.45. top5: 99.69. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9828. top1: 84.38. top5: 99.62. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9936. top1: 83.78. top5: 99.63. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0010. top1: 83.50. top5: 99.56. :  51%|█████     | 32/63 [00:01<00:00, 33.23it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0010. top1: 83.50. top5: 99.56. :  68%|██████▊   | 43/63 [00:01<00:00, 47.48it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0039. top1: 83.31. top5: 99.57. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0048. top1: 83.26. top5: 99.58. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0084. top1: 83.08. top5: 99.59. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0100. top1: 82.91. top5: 99.60. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0117. top1: 82.75. top5: 99.61. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0150. top1: 82.72. top5: 99.55. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0172. top1: 82.62. top5: 99.56. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0246. top1: 82.11. top5: 99.57. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0262. top1: 82.09. top5: 99.52. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0311. top1: 81.84. top5: 99.53. :  68%|██████▊   | 43/63 [00:02<00:00, 47.48it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0311. top1: 81.84. top5: 99.53. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0377. top1: 81.54. top5: 99.48. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0378. top1: 81.59. top5: 99.49. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0389. top1: 81.58. top5: 99.50. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0453. top1: 81.20. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0513. top1: 80.87. top5: 99.46. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0551. top1: 80.72. top5: 99.42. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0548. top1: 80.78. top5: 99.43. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0590. top1: 80.48. top5: 99.44. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0653. top1: 80.04. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 1.0661. top1: 80.05. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 57.67it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 1.0661. top1: 80.05. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 66.82it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 1.0661. top1: 80.05. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 26.51it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 34/60. Data: 1.46s. Batch: 1.51s. Loss: 1.0595. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 34/60. Data: 1.46s. Batch: 1.51s. Loss: 1.0595. :   4%|▍         | 1/25 [00:01<00:36,  1.51s/it]Finetune Epoch: 34/60. Data: 1.49s. Batch: 1.53s. Loss: 1.0709. :   4%|▍         | 1/25 [00:01<00:36,  1.51s/it]Finetune Epoch: 34/60. Data: 1.52s. Batch: 1.55s. Loss: 1.0370. :   4%|▍         | 1/25 [00:01<00:36,  1.51s/it]Finetune Epoch: 34/60. Data: 1.54s. Batch: 1.57s. Loss: 1.0817. :   4%|▍         | 1/25 [00:01<00:36,  1.51s/it]Finetune Epoch: 34/60. Data: 1.54s. Batch: 1.57s. Loss: 1.0817. :  16%|█▌        | 4/25 [00:01<00:06,  3.15it/s]Finetune Epoch: 34/60. Data: 1.56s. Batch: 1.59s. Loss: 1.0508. :  16%|█▌        | 4/25 [00:01<00:06,  3.15it/s]Finetune Epoch: 34/60. Data: 1.57s. Batch: 1.61s. Loss: 1.0223. :  16%|█▌        | 4/25 [00:01<00:06,  3.15it/s]Finetune Epoch: 34/60. Data: 1.59s. Batch: 1.63s. Loss: 1.0045. :  16%|█▌        | 4/25 [00:01<00:06,  3.15it/s]Finetune Epoch: 34/60. Data: 1.59s. Batch: 1.63s. Loss: 1.0045. :  28%|██▊       | 7/25 [00:01<00:02,  6.04it/s]Finetune Epoch: 34/60. Data: 1.61s. Batch: 1.64s. Loss: 1.0280. :  28%|██▊       | 7/25 [00:01<00:02,  6.04it/s]Finetune Epoch: 34/60. Data: 1.63s. Batch: 1.66s. Loss: 1.0280. :  28%|██▊       | 7/25 [00:01<00:02,  6.04it/s]Finetune Epoch: 34/60. Data: 1.65s. Batch: 1.68s. Loss: 1.0234. :  28%|██▊       | 7/25 [00:01<00:02,  6.04it/s]Finetune Epoch: 34/60. Data: 1.65s. Batch: 1.68s. Loss: 1.0234. :  40%|████      | 10/25 [00:01<00:01,  8.82it/s]Finetune Epoch: 34/60. Data: 1.67s. Batch: 1.70s. Loss: 1.0310. :  40%|████      | 10/25 [00:01<00:01,  8.82it/s]Finetune Epoch: 34/60. Data: 1.69s. Batch: 1.73s. Loss: 1.0205. :  40%|████      | 10/25 [00:01<00:01,  8.82it/s]Finetune Epoch: 34/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0157. :  40%|████      | 10/25 [00:01<00:01,  8.82it/s]Finetune Epoch: 34/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0157. :  52%|█████▏    | 13/25 [00:01<00:01, 11.52it/s]Finetune Epoch: 34/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0066. :  52%|█████▏    | 13/25 [00:02<00:01, 11.52it/s]Finetune Epoch: 34/60. Data: 1.75s. Batch: 1.79s. Loss: 0.9992. :  52%|█████▏    | 13/25 [00:02<00:01, 11.52it/s]Finetune Epoch: 34/60. Data: 1.77s. Batch: 1.81s. Loss: 0.9926. :  52%|█████▏    | 13/25 [00:02<00:01, 11.52it/s]Finetune Epoch: 34/60. Data: 1.77s. Batch: 1.81s. Loss: 0.9926. :  64%|██████▍   | 16/25 [00:02<00:00, 14.14it/s]Finetune Epoch: 34/60. Data: 1.79s. Batch: 1.83s. Loss: 0.9906. :  64%|██████▍   | 16/25 [00:02<00:00, 14.14it/s]Finetune Epoch: 34/60. Data: 1.81s. Batch: 1.85s. Loss: 0.9851. :  64%|██████▍   | 16/25 [00:02<00:00, 14.14it/s]Finetune Epoch: 34/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9996. :  64%|██████▍   | 16/25 [00:02<00:00, 14.14it/s]Finetune Epoch: 34/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9996. :  76%|███████▌  | 19/25 [00:02<00:00, 16.28it/s]Finetune Epoch: 34/60. Data: 1.85s. Batch: 1.89s. Loss: 0.9912. :  76%|███████▌  | 19/25 [00:02<00:00, 16.28it/s]Finetune Epoch: 34/60. Data: 1.87s. Batch: 1.91s. Loss: 0.9870. :  76%|███████▌  | 19/25 [00:02<00:00, 16.28it/s]Finetune Epoch: 34/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9862. :  76%|███████▌  | 19/25 [00:02<00:00, 16.28it/s]Finetune Epoch: 34/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9862. :  88%|████████▊ | 22/25 [00:02<00:00, 17.16it/s]Finetune Epoch: 34/60. Data: 1.92s. Batch: 1.96s. Loss: 0.9897. :  88%|████████▊ | 22/25 [00:02<00:00, 17.16it/s]Finetune Epoch: 34/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9903. :  88%|████████▊ | 22/25 [00:02<00:00, 17.16it/s]Finetune Epoch: 34/60. Data: 1.96s. Batch: 2.00s. Loss: 0.9948. :  88%|████████▊ | 22/25 [00:02<00:00, 17.16it/s]Finetune Epoch: 34/60. Data: 1.96s. Batch: 2.00s. Loss: 0.9948. : 100%|██████████| 25/25 [00:02<00:00, 17.97it/s]Finetune Epoch: 34/60. Data: 1.96s. Batch: 2.00s. Loss: 0.9948. : 100%|██████████| 25/25 [00:02<00:00,  9.16it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.84s. Loss: 1.0081. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.84s. Loss: 1.0081. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 0.9912. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 0.9410. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.9525. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.9297. top1: 85.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9262. top1: 84.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9456. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9444. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9461. top1: 84.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9490. top1: 84.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.84s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9490. top1: 84.69. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.91it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9333. top1: 85.80. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.91it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9371. top1: 85.68. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.91it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9303. top1: 85.82. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.91it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9228. top1: 86.16. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  6.91it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9197. top1: 86.67. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.91it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9207. top1: 86.72. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.91it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9189. top1: 86.76. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  6.91it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9189. top1: 86.76. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9206. top1: 86.81. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9201. top1: 86.84. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9184. top1: 86.72. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9210. top1: 86.46. top5: 99.85. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s] Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9168. top1: 86.65. top5: 99.86. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9120. top1: 87.23. top5: 99.86. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9086. top1: 87.37. top5: 99.87. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9043. top1: 87.62. top5: 99.88. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9114. top1: 87.14. top5: 99.88. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9118. top1: 87.04. top5: 99.88. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9169. top1: 86.83. top5: 99.89. :  27%|██▋       | 17/63 [00:02<00:03, 12.73it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9169. top1: 86.83. top5: 99.89. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9123. top1: 87.18. top5: 99.89. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9117. top1: 87.29. top5: 99.90. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9104. top1: 87.40. top5: 99.90. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9258. top1: 86.72. top5: 99.80. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9296. top1: 86.55. top5: 99.81. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9350. top1: 86.40. top5: 99.82. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9431. top1: 85.98. top5: 99.82. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9588. top1: 85.42. top5: 99.65. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9598. top1: 85.39. top5: 99.66. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9661. top1: 85.03. top5: 99.67. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9739. top1: 84.70. top5: 99.68. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9794. top1: 84.45. top5: 99.69. :  44%|████▍     | 28/63 [00:02<00:01, 23.95it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9794. top1: 84.45. top5: 99.69. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9830. top1: 84.38. top5: 99.62. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9938. top1: 83.78. top5: 99.63. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0011. top1: 83.50. top5: 99.56. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0040. top1: 83.31. top5: 99.57. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0049. top1: 83.26. top5: 99.58. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0083. top1: 83.08. top5: 99.59. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0099. top1: 82.91. top5: 99.60. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0116. top1: 82.75. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0148. top1: 82.72. top5: 99.55. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0169. top1: 82.62. top5: 99.56. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0243. top1: 82.11. top5: 99.57. :  63%|██████▎   | 40/63 [00:02<00:00, 37.14it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0243. top1: 82.11. top5: 99.57. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0258. top1: 82.09. top5: 99.52. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0307. top1: 81.84. top5: 99.53. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0372. top1: 81.54. top5: 99.48. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0373. top1: 81.59. top5: 99.49. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0385. top1: 81.58. top5: 99.50. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0448. top1: 81.20. top5: 99.45. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0508. top1: 80.87. top5: 99.46. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0545. top1: 80.72. top5: 99.42. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0542. top1: 80.78. top5: 99.43. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0583. top1: 80.48. top5: 99.44. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0646. top1: 80.04. top5: 99.45. :  81%|████████  | 51/63 [00:02<00:00, 48.54it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0646. top1: 80.04. top5: 99.45. :  98%|█████████▊| 62/63 [00:02<00:00, 59.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0654. top1: 80.05. top5: 99.45. :  98%|█████████▊| 62/63 [00:02<00:00, 59.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0654. top1: 80.05. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.62it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 35/60. Data: 1.70s. Batch: 1.75s. Loss: 1.1024. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 35/60. Data: 1.70s. Batch: 1.75s. Loss: 1.1024. :   4%|▍         | 1/25 [00:01<00:41,  1.75s/it]Finetune Epoch: 35/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0722. :   4%|▍         | 1/25 [00:01<00:41,  1.75s/it]Finetune Epoch: 35/60. Data: 1.76s. Batch: 1.81s. Loss: 1.0387. :   4%|▍         | 1/25 [00:01<00:41,  1.75s/it]Finetune Epoch: 35/60. Data: 1.76s. Batch: 1.81s. Loss: 1.0387. :  12%|█▏        | 3/25 [00:01<00:10,  2.02it/s]Finetune Epoch: 35/60. Data: 1.79s. Batch: 1.84s. Loss: 1.0342. :  12%|█▏        | 3/25 [00:01<00:10,  2.02it/s]Finetune Epoch: 35/60. Data: 1.81s. Batch: 1.86s. Loss: 1.0496. :  12%|█▏        | 3/25 [00:01<00:10,  2.02it/s]Finetune Epoch: 35/60. Data: 1.81s. Batch: 1.86s. Loss: 1.0496. :  20%|██        | 5/25 [00:01<00:05,  3.71it/s]Finetune Epoch: 35/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0501. :  20%|██        | 5/25 [00:02<00:05,  3.71it/s]Finetune Epoch: 35/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0454. :  20%|██        | 5/25 [00:02<00:05,  3.71it/s]Finetune Epoch: 35/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0454. :  28%|██▊       | 7/25 [00:02<00:03,  5.65it/s]Finetune Epoch: 35/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0381. :  28%|██▊       | 7/25 [00:02<00:03,  5.65it/s]Finetune Epoch: 35/60. Data: 1.92s. Batch: 1.97s. Loss: 1.0257. :  28%|██▊       | 7/25 [00:02<00:03,  5.65it/s]Finetune Epoch: 35/60. Data: 1.94s. Batch: 1.99s. Loss: 1.0150. :  28%|██▊       | 7/25 [00:02<00:03,  5.65it/s]Finetune Epoch: 35/60. Data: 1.94s. Batch: 1.99s. Loss: 1.0150. :  40%|████      | 10/25 [00:02<00:01,  8.55it/s]Finetune Epoch: 35/60. Data: 1.97s. Batch: 2.02s. Loss: 1.0044. :  40%|████      | 10/25 [00:02<00:01,  8.55it/s]Finetune Epoch: 35/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0058. :  40%|████      | 10/25 [00:02<00:01,  8.55it/s]Finetune Epoch: 35/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9980. :  40%|████      | 10/25 [00:02<00:01,  8.55it/s]Finetune Epoch: 35/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9980. :  52%|█████▏    | 13/25 [00:02<00:01, 11.18it/s]Finetune Epoch: 35/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9889. :  52%|█████▏    | 13/25 [00:02<00:01, 11.18it/s]Finetune Epoch: 35/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9831. :  52%|█████▏    | 13/25 [00:02<00:01, 11.18it/s]Finetune Epoch: 35/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9831. :  60%|██████    | 15/25 [00:02<00:00, 12.59it/s]Finetune Epoch: 35/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9905. :  60%|██████    | 15/25 [00:02<00:00, 12.59it/s]Finetune Epoch: 35/60. Data: 2.12s. Batch: 2.17s. Loss: 0.9882. :  60%|██████    | 15/25 [00:02<00:00, 12.59it/s]Finetune Epoch: 35/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9861. :  60%|██████    | 15/25 [00:02<00:00, 12.59it/s]Finetune Epoch: 35/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9861. :  72%|███████▏  | 18/25 [00:02<00:00, 14.37it/s]Finetune Epoch: 35/60. Data: 2.18s. Batch: 2.22s. Loss: 0.9870. :  72%|███████▏  | 18/25 [00:02<00:00, 14.37it/s]Finetune Epoch: 35/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9820. :  72%|███████▏  | 18/25 [00:02<00:00, 14.37it/s]Finetune Epoch: 35/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9820. :  80%|████████  | 20/25 [00:02<00:00, 15.36it/s]Finetune Epoch: 35/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9837. :  80%|████████  | 20/25 [00:02<00:00, 15.36it/s]Finetune Epoch: 35/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9801. :  80%|████████  | 20/25 [00:02<00:00, 15.36it/s]Finetune Epoch: 35/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9780. :  80%|████████  | 20/25 [00:02<00:00, 15.36it/s]Finetune Epoch: 35/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9780. :  92%|█████████▏| 23/25 [00:02<00:00, 16.93it/s]Finetune Epoch: 35/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9863. :  92%|█████████▏| 23/25 [00:02<00:00, 16.93it/s]Finetune Epoch: 35/60. Data: 2.33s. Batch: 2.38s. Loss: 0.9868. :  92%|█████████▏| 23/25 [00:02<00:00, 16.93it/s]Finetune Epoch: 35/60. Data: 2.33s. Batch: 2.38s. Loss: 0.9868. : 100%|██████████| 25/25 [00:03<00:00,  7.80it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.57s. Loss: 1.0097. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.57s. Loss: 1.0097. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.79s. Loss: 0.9928. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 0.9424. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.41s. Loss: 0.9539. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9310. top1: 85.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9275. top1: 84.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9469. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:37,  1.57s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9469. top1: 84.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9458. top1: 83.59. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9474. top1: 84.03. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9504. top1: 84.69. top5: 99.69. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9346. top1: 85.51. top5: 99.72. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9385. top1: 85.42. top5: 99.74. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9316. top1: 85.58. top5: 99.76. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9241. top1: 85.94. top5: 99.78. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9209. top1: 86.46. top5: 99.79. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9219. top1: 86.52. top5: 99.80. :  11%|█         | 7/63 [00:01<00:10,  5.57it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9219. top1: 86.52. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9202. top1: 86.40. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9219. top1: 86.46. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9214. top1: 86.51. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9197. top1: 86.41. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9223. top1: 86.16. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9180. top1: 86.36. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9133. top1: 86.96. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9098. top1: 87.11. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9055. top1: 87.38. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9127. top1: 86.90. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9131. top1: 86.81. top5: 99.77. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9182. top1: 86.61. top5: 99.78. :  25%|██▌       | 16/63 [00:01<00:03, 13.97it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9182. top1: 86.61. top5: 99.78. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9136. top1: 86.96. top5: 99.78. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9130. top1: 87.08. top5: 99.79. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9117. top1: 87.20. top5: 99.80. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9270. top1: 86.52. top5: 99.71. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9306. top1: 86.36. top5: 99.72. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9359. top1: 86.21. top5: 99.72. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9439. top1: 85.80. top5: 99.73. :  44%|████▍     | 28/63 [00:01<00:01, 27.22it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9595. top1: 85.24. top5: 99.57. :  44%|████▍     | 28/63 [00:02<00:01, 27.22it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9604. top1: 85.22. top5: 99.58. :  44%|████▍     | 28/63 [00:02<00:01, 27.22it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9666. top1: 84.87. top5: 99.59. :  44%|████▍     | 28/63 [00:02<00:01, 27.22it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9666. top1: 84.87. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9743. top1: 84.54. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9798. top1: 84.30. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9833. top1: 84.22. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9940. top1: 83.63. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0013. top1: 83.36. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0041. top1: 83.17. top5: 99.50. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0049. top1: 83.12. top5: 99.51. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0083. top1: 82.95. top5: 99.52. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0098. top1: 82.78. top5: 99.53. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0115. top1: 82.62. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 38.21it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0115. top1: 82.62. top5: 99.54. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0146. top1: 82.59. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0167. top1: 82.50. top5: 99.50. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0239. top1: 81.99. top5: 99.51. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0255. top1: 81.97. top5: 99.46. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0303. top1: 81.72. top5: 99.47. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0367. top1: 81.42. top5: 99.42. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0368. top1: 81.48. top5: 99.43. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0379. top1: 81.47. top5: 99.44. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0441. top1: 81.09. top5: 99.40. :  76%|███████▌  | 48/63 [00:02<00:00, 49.03it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0441. top1: 81.09. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 56.29it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0501. top1: 80.77. top5: 99.41. :  90%|█████████ | 57/63 [00:02<00:00, 56.29it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0538. top1: 80.61. top5: 99.36. :  90%|█████████ | 57/63 [00:02<00:00, 56.29it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0535. top1: 80.73. top5: 99.38. :  90%|█████████ | 57/63 [00:02<00:00, 56.29it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0576. top1: 80.43. top5: 99.39. :  90%|█████████ | 57/63 [00:02<00:00, 56.29it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0638. top1: 79.99. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 56.29it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0645. top1: 80.00. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 56.29it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0645. top1: 80.00. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 25.39it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 36/60. Data: 1.63s. Batch: 1.68s. Loss: 1.2045. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 36/60. Data: 1.63s. Batch: 1.68s. Loss: 1.2045. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 36/60. Data: 1.66s. Batch: 1.72s. Loss: 1.2343. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 36/60. Data: 1.69s. Batch: 1.74s. Loss: 1.0990. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 36/60. Data: 1.69s. Batch: 1.74s. Loss: 1.0990. :  12%|█▏        | 3/25 [00:01<00:10,  2.09it/s]Finetune Epoch: 36/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0453. :  12%|█▏        | 3/25 [00:01<00:10,  2.09it/s]Finetune Epoch: 36/60. Data: 1.74s. Batch: 1.79s. Loss: 1.0354. :  12%|█▏        | 3/25 [00:01<00:10,  2.09it/s]Finetune Epoch: 36/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0203. :  12%|█▏        | 3/25 [00:01<00:10,  2.09it/s]Finetune Epoch: 36/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0203. :  24%|██▍       | 6/25 [00:01<00:04,  4.66it/s]Finetune Epoch: 36/60. Data: 1.79s. Batch: 1.84s. Loss: 1.0483. :  24%|██▍       | 6/25 [00:01<00:04,  4.66it/s]Finetune Epoch: 36/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0421. :  24%|██▍       | 6/25 [00:02<00:04,  4.66it/s]Finetune Epoch: 36/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0421. :  32%|███▏      | 8/25 [00:02<00:02,  6.49it/s]Finetune Epoch: 36/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0381. :  32%|███▏      | 8/25 [00:02<00:02,  6.49it/s]Finetune Epoch: 36/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0305. :  32%|███▏      | 8/25 [00:02<00:02,  6.49it/s]Finetune Epoch: 36/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0465. :  32%|███▏      | 8/25 [00:02<00:02,  6.49it/s]Finetune Epoch: 36/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0465. :  44%|████▍     | 11/25 [00:02<00:01,  9.33it/s]Finetune Epoch: 36/60. Data: 1.92s. Batch: 1.97s. Loss: 1.0357. :  44%|████▍     | 11/25 [00:02<00:01,  9.33it/s]Finetune Epoch: 36/60. Data: 1.94s. Batch: 1.99s. Loss: 1.0320. :  44%|████▍     | 11/25 [00:02<00:01,  9.33it/s]Finetune Epoch: 36/60. Data: 1.97s. Batch: 2.01s. Loss: 1.0387. :  44%|████▍     | 11/25 [00:02<00:01,  9.33it/s]Finetune Epoch: 36/60. Data: 1.97s. Batch: 2.01s. Loss: 1.0387. :  56%|█████▌    | 14/25 [00:02<00:00, 12.07it/s]Finetune Epoch: 36/60. Data: 1.99s. Batch: 2.04s. Loss: 1.0405. :  56%|█████▌    | 14/25 [00:02<00:00, 12.07it/s]Finetune Epoch: 36/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0333. :  56%|█████▌    | 14/25 [00:02<00:00, 12.07it/s]Finetune Epoch: 36/60. Data: 2.01s. Batch: 2.06s. Loss: 1.0333. :  64%|██████▍   | 16/25 [00:02<00:00, 12.96it/s]Finetune Epoch: 36/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0250. :  64%|██████▍   | 16/25 [00:02<00:00, 12.96it/s]Finetune Epoch: 36/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0211. :  64%|██████▍   | 16/25 [00:02<00:00, 12.96it/s]Finetune Epoch: 36/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0211. :  72%|███████▏  | 18/25 [00:02<00:00, 14.35it/s]Finetune Epoch: 36/60. Data: 2.09s. Batch: 2.14s. Loss: 1.0125. :  72%|███████▏  | 18/25 [00:02<00:00, 14.35it/s]Finetune Epoch: 36/60. Data: 2.11s. Batch: 2.16s. Loss: 1.0162. :  72%|███████▏  | 18/25 [00:02<00:00, 14.35it/s]Finetune Epoch: 36/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0179. :  72%|███████▏  | 18/25 [00:02<00:00, 14.35it/s]Finetune Epoch: 36/60. Data: 2.14s. Batch: 2.19s. Loss: 1.0179. :  84%|████████▍ | 21/25 [00:02<00:00, 16.69it/s]Finetune Epoch: 36/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0144. :  84%|████████▍ | 21/25 [00:02<00:00, 16.69it/s]Finetune Epoch: 36/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0079. :  84%|████████▍ | 21/25 [00:02<00:00, 16.69it/s]Finetune Epoch: 36/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0077. :  84%|████████▍ | 21/25 [00:02<00:00, 16.69it/s]Finetune Epoch: 36/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0077. :  96%|█████████▌| 24/25 [00:02<00:00, 17.54it/s]Finetune Epoch: 36/60. Data: 2.24s. Batch: 2.28s. Loss: 1.0052. :  96%|█████████▌| 24/25 [00:02<00:00, 17.54it/s]Finetune Epoch: 36/60. Data: 2.24s. Batch: 2.28s. Loss: 1.0052. : 100%|██████████| 25/25 [00:03<00:00,  8.17it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.63s. Loss: 1.0101. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.63s. Loss: 1.0101. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.82s. Loss: 0.9933. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9427. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9543. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9315. top1: 85.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9280. top1: 84.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9473. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9461. top1: 83.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9478. top1: 84.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.63s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9478. top1: 84.03. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9508. top1: 84.69. top5: 99.69. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9350. top1: 85.51. top5: 99.72. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9388. top1: 85.42. top5: 99.74. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9320. top1: 85.58. top5: 99.76. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9245. top1: 85.94. top5: 99.78. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9212. top1: 86.46. top5: 99.79. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9223. top1: 86.52. top5: 99.80. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9206. top1: 86.40. top5: 99.82. :  14%|█▍        | 9/63 [00:01<00:07,  6.99it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9206. top1: 86.40. top5: 99.82. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9223. top1: 86.46. top5: 99.83. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9218. top1: 86.51. top5: 99.84. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9200. top1: 86.41. top5: 99.84. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9226. top1: 86.16. top5: 99.70. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9184. top1: 86.36. top5: 99.72. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9136. top1: 86.96. top5: 99.73. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9102. top1: 87.11. top5: 99.74. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9058. top1: 87.38. top5: 99.75. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9130. top1: 86.90. top5: 99.76. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9134. top1: 86.81. top5: 99.77. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9185. top1: 86.61. top5: 99.78. :  27%|██▋       | 17/63 [00:01<00:03, 14.49it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9185. top1: 86.61. top5: 99.78. :  44%|████▍     | 28/63 [00:01<00:01, 26.70it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9139. top1: 86.96. top5: 99.78. :  44%|████▍     | 28/63 [00:01<00:01, 26.70it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9133. top1: 87.08. top5: 99.79. :  44%|████▍     | 28/63 [00:01<00:01, 26.70it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9120. top1: 87.10. top5: 99.80. :  44%|████▍     | 28/63 [00:01<00:01, 26.70it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9273. top1: 86.43. top5: 99.71. :  44%|████▍     | 28/63 [00:01<00:01, 26.70it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9309. top1: 86.27. top5: 99.72. :  44%|████▍     | 28/63 [00:01<00:01, 26.70it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9361. top1: 86.12. top5: 99.72. :  44%|████▍     | 28/63 [00:01<00:01, 26.70it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9441. top1: 85.71. top5: 99.73. :  44%|████▍     | 28/63 [00:02<00:01, 26.70it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9597. top1: 85.16. top5: 99.57. :  44%|████▍     | 28/63 [00:02<00:01, 26.70it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9605. top1: 85.14. top5: 99.58. :  44%|████▍     | 28/63 [00:02<00:01, 26.70it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9667. top1: 84.79. top5: 99.59. :  44%|████▍     | 28/63 [00:02<00:01, 26.70it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9744. top1: 84.46. top5: 99.60. :  44%|████▍     | 28/63 [00:02<00:01, 26.70it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9744. top1: 84.46. top5: 99.60. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9798. top1: 84.22. top5: 99.61. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9833. top1: 84.15. top5: 99.54. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9940. top1: 83.56. top5: 99.55. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0012. top1: 83.28. top5: 99.49. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0040. top1: 83.10. top5: 99.50. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0048. top1: 83.06. top5: 99.51. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.88. top5: 99.52. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0096. top1: 82.71. top5: 99.53. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0113. top1: 82.55. top5: 99.54. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0144. top1: 82.53. top5: 99.49. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0165. top1: 82.44. top5: 99.50. :  62%|██████▏   | 39/63 [00:02<00:00, 39.47it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0165. top1: 82.44. top5: 99.50. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0237. top1: 81.92. top5: 99.51. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0252. top1: 81.91. top5: 99.46. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0300. top1: 81.66. top5: 99.47. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0365. top1: 81.37. top5: 99.42. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0365. top1: 81.42. top5: 99.43. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0376. top1: 81.42. top5: 99.44. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0438. top1: 81.03. top5: 99.40. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0498. top1: 80.71. top5: 99.41. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0535. top1: 80.56. top5: 99.36. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0531. top1: 80.68. top5: 99.38. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0572. top1: 80.38. top5: 99.39. :  79%|███████▉  | 50/63 [00:02<00:00, 51.54it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0572. top1: 80.38. top5: 99.39. :  97%|█████████▋| 61/63 [00:02<00:00, 62.34it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0634. top1: 79.94. top5: 99.40. :  97%|█████████▋| 61/63 [00:02<00:00, 62.34it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0642. top1: 79.95. top5: 99.40. :  97%|█████████▋| 61/63 [00:02<00:00, 62.34it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0642. top1: 79.95. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 25.83it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 37/60. Data: 1.58s. Batch: 1.67s. Loss: 0.9000. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 37/60. Data: 1.58s. Batch: 1.67s. Loss: 0.9000. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch: 37/60. Data: 1.63s. Batch: 1.69s. Loss: 0.8778. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch: 37/60. Data: 1.66s. Batch: 1.72s. Loss: 0.8804. :   4%|▍         | 1/25 [00:01<00:40,  1.67s/it]Finetune Epoch: 37/60. Data: 1.66s. Batch: 1.72s. Loss: 0.8804. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 37/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9789. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 37/60. Data: 1.72s. Batch: 1.77s. Loss: 0.9664. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 37/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9570. :  12%|█▏        | 3/25 [00:01<00:10,  2.13it/s]Finetune Epoch: 37/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9570. :  24%|██▍       | 6/25 [00:01<00:04,  4.71it/s]Finetune Epoch: 37/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9898. :  24%|██▍       | 6/25 [00:01<00:04,  4.71it/s]Finetune Epoch: 37/60. Data: 1.79s. Batch: 1.85s. Loss: 0.9730. :  24%|██▍       | 6/25 [00:02<00:04,  4.71it/s]Finetune Epoch: 37/60. Data: 1.79s. Batch: 1.85s. Loss: 0.9730. :  32%|███▏      | 8/25 [00:02<00:02,  6.47it/s]Finetune Epoch: 37/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9678. :  32%|███▏      | 8/25 [00:02<00:02,  6.47it/s]Finetune Epoch: 37/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9691. :  32%|███▏      | 8/25 [00:02<00:02,  6.47it/s]Finetune Epoch: 37/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9691. :  40%|████      | 10/25 [00:02<00:01,  8.37it/s]Finetune Epoch: 37/60. Data: 1.87s. Batch: 1.93s. Loss: 0.9845. :  40%|████      | 10/25 [00:02<00:01,  8.37it/s]Finetune Epoch: 37/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9820. :  40%|████      | 10/25 [00:02<00:01,  8.37it/s]Finetune Epoch: 37/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9820. :  48%|████▊     | 12/25 [00:02<00:01, 10.35it/s]Finetune Epoch: 37/60. Data: 1.93s. Batch: 1.98s. Loss: 0.9822. :  48%|████▊     | 12/25 [00:02<00:01, 10.35it/s]Finetune Epoch: 37/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9885. :  48%|████▊     | 12/25 [00:02<00:01, 10.35it/s]Finetune Epoch: 37/60. Data: 1.98s. Batch: 2.03s. Loss: 0.9789. :  48%|████▊     | 12/25 [00:02<00:01, 10.35it/s]Finetune Epoch: 37/60. Data: 1.98s. Batch: 2.03s. Loss: 0.9789. :  60%|██████    | 15/25 [00:02<00:00, 13.23it/s]Finetune Epoch: 37/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9825. :  60%|██████    | 15/25 [00:02<00:00, 13.23it/s]Finetune Epoch: 37/60. Data: 2.03s. Batch: 2.08s. Loss: 0.9830. :  60%|██████    | 15/25 [00:02<00:00, 13.23it/s]Finetune Epoch: 37/60. Data: 2.03s. Batch: 2.08s. Loss: 0.9830. :  68%|██████▊   | 17/25 [00:02<00:00, 14.22it/s]Finetune Epoch: 37/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9835. :  68%|██████▊   | 17/25 [00:02<00:00, 14.22it/s]Finetune Epoch: 37/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9783. :  68%|██████▊   | 17/25 [00:02<00:00, 14.22it/s]Finetune Epoch: 37/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9783. :  76%|███████▌  | 19/25 [00:02<00:00, 15.37it/s]Finetune Epoch: 37/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9714. :  76%|███████▌  | 19/25 [00:02<00:00, 15.37it/s]Finetune Epoch: 37/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9698. :  76%|███████▌  | 19/25 [00:02<00:00, 15.37it/s]Finetune Epoch: 37/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9726. :  76%|███████▌  | 19/25 [00:02<00:00, 15.37it/s]Finetune Epoch: 37/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9726. :  88%|████████▊ | 22/25 [00:02<00:00, 16.97it/s]Finetune Epoch: 37/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9778. :  88%|████████▊ | 22/25 [00:02<00:00, 16.97it/s]Finetune Epoch: 37/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9826. :  88%|████████▊ | 22/25 [00:02<00:00, 16.97it/s]Finetune Epoch: 37/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9826. :  96%|█████████▌| 24/25 [00:02<00:00, 17.34it/s]Finetune Epoch: 37/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9841. :  96%|█████████▌| 24/25 [00:02<00:00, 17.34it/s]Finetune Epoch: 37/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9841. : 100%|██████████| 25/25 [00:03<00:00,  8.18it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.55s. Loss: 1.0117. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.55s. Loss: 1.0117. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.79s. Loss: 0.9950. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 0.9441. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 0.9558. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9328. top1: 85.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9293. top1: 84.90. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9487. top1: 84.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9487. top1: 84.38. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9476. top1: 83.59. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9493. top1: 84.03. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9522. top1: 84.69. top5: 99.69. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9364. top1: 85.51. top5: 99.72. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9403. top1: 85.42. top5: 99.74. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9334. top1: 85.58. top5: 99.76. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9258. top1: 85.94. top5: 99.78. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9226. top1: 86.46. top5: 99.79. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9236. top1: 86.52. top5: 99.80. :  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9236. top1: 86.52. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9219. top1: 86.40. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9237. top1: 86.46. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9231. top1: 86.51. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9213. top1: 86.41. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9240. top1: 86.16. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9197. top1: 86.36. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9149. top1: 86.96. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9115. top1: 87.11. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9071. top1: 87.38. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 14.50it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9071. top1: 87.38. top5: 99.75. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9143. top1: 86.90. top5: 99.76. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9147. top1: 86.81. top5: 99.77. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9198. top1: 86.61. top5: 99.78. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9152. top1: 86.96. top5: 99.78. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9146. top1: 87.08. top5: 99.79. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9133. top1: 87.10. top5: 99.80. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9285. top1: 86.43. top5: 99.71. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9319. top1: 86.27. top5: 99.72. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9371. top1: 86.12. top5: 99.72. :  40%|███▉      | 25/63 [00:01<00:01, 24.38it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9371. top1: 86.12. top5: 99.72. :  54%|█████▍    | 34/63 [00:01<00:00, 34.27it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9449. top1: 85.71. top5: 99.73. :  54%|█████▍    | 34/63 [00:01<00:00, 34.27it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9604. top1: 85.16. top5: 99.57. :  54%|█████▍    | 34/63 [00:01<00:00, 34.27it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9612. top1: 85.14. top5: 99.58. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9672. top1: 84.79. top5: 99.59. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9748. top1: 84.46. top5: 99.60. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9801. top1: 84.22. top5: 99.61. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9836. top1: 84.15. top5: 99.54. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9942. top1: 83.56. top5: 99.55. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0014. top1: 83.28. top5: 99.49. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0041. top1: 83.10. top5: 99.50. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0049. top1: 83.06. top5: 99.51. :  54%|█████▍    | 34/63 [00:02<00:00, 34.27it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0049. top1: 83.06. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.88. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 82.71. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0111. top1: 82.55. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0142. top1: 82.53. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0162. top1: 82.44. top5: 99.50. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0233. top1: 81.92. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0248. top1: 81.91. top5: 99.46. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0296. top1: 81.66. top5: 99.47. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0360. top1: 81.37. top5: 99.42. :  71%|███████▏  | 45/63 [00:02<00:00, 47.60it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0360. top1: 81.37. top5: 99.42. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0360. top1: 81.42. top5: 99.43. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0370. top1: 81.42. top5: 99.44. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0432. top1: 81.03. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0491. top1: 80.71. top5: 99.41. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0528. top1: 80.56. top5: 99.36. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0524. top1: 80.68. top5: 99.38. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0564. top1: 80.38. top5: 99.39. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0626. top1: 79.94. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0633. top1: 79.95. top5: 99.40. :  86%|████████▌ | 54/63 [00:02<00:00, 53.63it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0633. top1: 79.95. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 25.16it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 38/60. Data: 1.60s. Batch: 1.65s. Loss: 0.8308. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 38/60. Data: 1.60s. Batch: 1.65s. Loss: 0.8308. :   4%|▍         | 1/25 [00:01<00:39,  1.65s/it]Finetune Epoch: 38/60. Data: 1.63s. Batch: 1.68s. Loss: 0.9687. :   4%|▍         | 1/25 [00:01<00:39,  1.65s/it]Finetune Epoch: 38/60. Data: 1.65s. Batch: 1.71s. Loss: 0.9476. :   4%|▍         | 1/25 [00:01<00:39,  1.65s/it]Finetune Epoch: 38/60. Data: 1.65s. Batch: 1.71s. Loss: 0.9476. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 38/60. Data: 1.68s. Batch: 1.73s. Loss: 0.9501. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 38/60. Data: 1.71s. Batch: 1.75s. Loss: 0.9632. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 38/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9669. :  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s]Finetune Epoch: 38/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9669. :  24%|██▍       | 6/25 [00:01<00:03,  4.87it/s]Finetune Epoch: 38/60. Data: 1.75s. Batch: 1.79s. Loss: 0.9740. :  24%|██▍       | 6/25 [00:01<00:03,  4.87it/s]Finetune Epoch: 38/60. Data: 1.77s. Batch: 1.81s. Loss: 0.9723. :  24%|██▍       | 6/25 [00:01<00:03,  4.87it/s]Finetune Epoch: 38/60. Data: 1.79s. Batch: 1.83s. Loss: 0.9670. :  24%|██▍       | 6/25 [00:01<00:03,  4.87it/s]Finetune Epoch: 38/60. Data: 1.79s. Batch: 1.83s. Loss: 0.9670. :  36%|███▌      | 9/25 [00:01<00:02,  7.79it/s]Finetune Epoch: 38/60. Data: 1.81s. Batch: 1.86s. Loss: 0.9689. :  36%|███▌      | 9/25 [00:02<00:02,  7.79it/s]Finetune Epoch: 38/60. Data: 1.83s. Batch: 1.88s. Loss: 0.9610. :  36%|███▌      | 9/25 [00:02<00:02,  7.79it/s]Finetune Epoch: 38/60. Data: 1.86s. Batch: 1.90s. Loss: 0.9623. :  36%|███▌      | 9/25 [00:02<00:02,  7.79it/s]Finetune Epoch: 38/60. Data: 1.86s. Batch: 1.90s. Loss: 0.9623. :  48%|████▊     | 12/25 [00:02<00:01, 10.18it/s]Finetune Epoch: 38/60. Data: 1.88s. Batch: 1.93s. Loss: 0.9623. :  48%|████▊     | 12/25 [00:02<00:01, 10.18it/s]Finetune Epoch: 38/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9739. :  48%|████▊     | 12/25 [00:02<00:01, 10.18it/s]Finetune Epoch: 38/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9832. :  48%|████▊     | 12/25 [00:02<00:01, 10.18it/s]Finetune Epoch: 38/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9832. :  60%|██████    | 15/25 [00:02<00:00, 12.72it/s]Finetune Epoch: 38/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9851. :  60%|██████    | 15/25 [00:02<00:00, 12.72it/s]Finetune Epoch: 38/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9917. :  60%|██████    | 15/25 [00:02<00:00, 12.72it/s]Finetune Epoch: 38/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9926. :  60%|██████    | 15/25 [00:02<00:00, 12.72it/s]Finetune Epoch: 38/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9926. :  72%|███████▏  | 18/25 [00:02<00:00, 14.08it/s]Finetune Epoch: 38/60. Data: 2.02s. Batch: 2.07s. Loss: 1.0118. :  72%|███████▏  | 18/25 [00:02<00:00, 14.08it/s]Finetune Epoch: 38/60. Data: 2.05s. Batch: 2.09s. Loss: 1.0145. :  72%|███████▏  | 18/25 [00:02<00:00, 14.08it/s]Finetune Epoch: 38/60. Data: 2.07s. Batch: 2.12s. Loss: 1.0091. :  72%|███████▏  | 18/25 [00:02<00:00, 14.08it/s]Finetune Epoch: 38/60. Data: 2.07s. Batch: 2.12s. Loss: 1.0091. :  84%|████████▍ | 21/25 [00:02<00:00, 15.55it/s]Finetune Epoch: 38/60. Data: 2.10s. Batch: 2.14s. Loss: 1.0097. :  84%|████████▍ | 21/25 [00:02<00:00, 15.55it/s]Finetune Epoch: 38/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0090. :  84%|████████▍ | 21/25 [00:02<00:00, 15.55it/s]Finetune Epoch: 38/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0090. :  92%|█████████▏| 23/25 [00:02<00:00, 16.38it/s]Finetune Epoch: 38/60. Data: 2.15s. Batch: 2.19s. Loss: 1.0066. :  92%|█████████▏| 23/25 [00:02<00:00, 16.38it/s]Finetune Epoch: 38/60. Data: 2.17s. Batch: 2.22s. Loss: 1.0034. :  92%|█████████▏| 23/25 [00:02<00:00, 16.38it/s]Finetune Epoch: 38/60. Data: 2.17s. Batch: 2.22s. Loss: 1.0034. : 100%|██████████| 25/25 [00:02<00:00,  8.40it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.69s. Loss: 1.0134. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.69s. Loss: 1.0134. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.86s. Loss: 0.9965. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.9453. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9570. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9340. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9305. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9499. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9499. top1: 83.48. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9488. top1: 82.42. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9505. top1: 82.99. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9535. top1: 83.75. top5: 99.69. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9376. top1: 84.66. top5: 99.72. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9415. top1: 84.64. top5: 99.74. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9345. top1: 84.86. top5: 99.76. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9270. top1: 85.27. top5: 99.78. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9237. top1: 85.83. top5: 99.79. :  11%|█         | 7/63 [00:01<00:10,  5.21it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9237. top1: 85.83. top5: 99.79. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9247. top1: 85.94. top5: 99.80. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9231. top1: 85.85. top5: 99.82. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9248. top1: 85.94. top5: 99.83. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9243. top1: 86.02. top5: 99.84. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9225. top1: 85.94. top5: 99.84. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9251. top1: 85.71. top5: 99.70. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9208. top1: 85.94. top5: 99.72. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9160. top1: 86.55. top5: 99.73. :  24%|██▍       | 15/63 [00:01<00:03, 12.68it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9160. top1: 86.55. top5: 99.73. :  37%|███▋      | 23/63 [00:01<00:01, 21.00it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9126. top1: 86.72. top5: 99.74. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9082. top1: 87.00. top5: 99.75. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9154. top1: 86.54. top5: 99.76. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9158. top1: 86.46. top5: 99.77. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9209. top1: 86.27. top5: 99.78. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9163. top1: 86.64. top5: 99.78. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9157. top1: 86.77. top5: 99.79. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9144. top1: 86.79. top5: 99.80. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9295. top1: 86.13. top5: 99.71. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9329. top1: 85.98. top5: 99.72. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9379. top1: 85.85. top5: 99.72. :  37%|███▋      | 23/63 [00:02<00:01, 21.00it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9379. top1: 85.85. top5: 99.72. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9457. top1: 85.45. top5: 99.73. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9610. top1: 84.90. top5: 99.57. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9617. top1: 84.88. top5: 99.58. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9677. top1: 84.54. top5: 99.59. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9752. top1: 84.21. top5: 99.60. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9805. top1: 83.98. top5: 99.61. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9839. top1: 83.92. top5: 99.54. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9945. top1: 83.33. top5: 99.55. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0016. top1: 83.07. top5: 99.49. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0042. top1: 82.88. top5: 99.50. :  54%|█████▍    | 34/63 [00:02<00:00, 34.02it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0042. top1: 82.88. top5: 99.50. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0049. top1: 82.85. top5: 99.51. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.68. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 82.51. top5: 99.53. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0110. top1: 82.42. top5: 99.54. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0141. top1: 82.40. top5: 99.49. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0161. top1: 82.31. top5: 99.50. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0231. top1: 81.80. top5: 99.51. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0245. top1: 81.79. top5: 99.46. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0292. top1: 81.54. top5: 99.47. :  70%|██████▉   | 44/63 [00:02<00:00, 45.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0292. top1: 81.54. top5: 99.47. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0356. top1: 81.25. top5: 99.42. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0356. top1: 81.31. top5: 99.43. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0366. top1: 81.31. top5: 99.44. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0427. top1: 80.92. top5: 99.40. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0486. top1: 80.60. top5: 99.41. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0522. top1: 80.51. top5: 99.36. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0518. top1: 80.62. top5: 99.38. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0558. top1: 80.33. top5: 99.39. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0619. top1: 79.89. top5: 99.40. :  84%|████████▍ | 53/63 [00:02<00:00, 52.88it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0619. top1: 79.89. top5: 99.40. :  98%|█████████▊| 62/63 [00:02<00:00, 57.19it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0626. top1: 79.90. top5: 99.40. :  98%|█████████▊| 62/63 [00:02<00:00, 57.19it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0626. top1: 79.90. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 23.86it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 39/60. Data: 1.63s. Batch: 1.68s. Loss: 1.0830. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 39/60. Data: 1.63s. Batch: 1.68s. Loss: 1.0830. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 39/60. Data: 1.66s. Batch: 1.70s. Loss: 1.0506. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 39/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0138. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 39/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0208. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 39/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0208. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch: 39/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0216. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch: 39/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9922. :  16%|█▌        | 4/25 [00:01<00:07,  2.81it/s]Finetune Epoch: 39/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9922. :  24%|██▍       | 6/25 [00:01<00:04,  4.48it/s]Finetune Epoch: 39/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0003. :  24%|██▍       | 6/25 [00:01<00:04,  4.48it/s]Finetune Epoch: 39/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0047. :  24%|██▍       | 6/25 [00:02<00:04,  4.48it/s]Finetune Epoch: 39/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0047. :  32%|███▏      | 8/25 [00:02<00:02,  6.36it/s]Finetune Epoch: 39/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9926. :  32%|███▏      | 8/25 [00:02<00:02,  6.36it/s]Finetune Epoch: 39/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9896. :  32%|███▏      | 8/25 [00:02<00:02,  6.36it/s]Finetune Epoch: 39/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0030. :  32%|███▏      | 8/25 [00:02<00:02,  6.36it/s]Finetune Epoch: 39/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0030. :  44%|████▍     | 11/25 [00:02<00:01,  9.55it/s]Finetune Epoch: 39/60. Data: 1.90s. Batch: 1.94s. Loss: 1.0031. :  44%|████▍     | 11/25 [00:02<00:01,  9.55it/s]Finetune Epoch: 39/60. Data: 1.92s. Batch: 1.96s. Loss: 0.9938. :  44%|████▍     | 11/25 [00:02<00:01,  9.55it/s]Finetune Epoch: 39/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9909. :  44%|████▍     | 11/25 [00:02<00:01,  9.55it/s]Finetune Epoch: 39/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9909. :  56%|█████▌    | 14/25 [00:02<00:00, 12.98it/s]Finetune Epoch: 39/60. Data: 1.96s. Batch: 2.01s. Loss: 0.9870. :  56%|█████▌    | 14/25 [00:02<00:00, 12.98it/s]Finetune Epoch: 39/60. Data: 1.98s. Batch: 2.03s. Loss: 0.9901. :  56%|█████▌    | 14/25 [00:02<00:00, 12.98it/s]Finetune Epoch: 39/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9911. :  56%|█████▌    | 14/25 [00:02<00:00, 12.98it/s]Finetune Epoch: 39/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9911. :  68%|██████▊   | 17/25 [00:02<00:00, 15.58it/s]Finetune Epoch: 39/60. Data: 2.03s. Batch: 2.07s. Loss: 0.9952. :  68%|██████▊   | 17/25 [00:02<00:00, 15.58it/s]Finetune Epoch: 39/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9900. :  68%|██████▊   | 17/25 [00:02<00:00, 15.58it/s]Finetune Epoch: 39/60. Data: 2.07s. Batch: 2.11s. Loss: 0.9979. :  68%|██████▊   | 17/25 [00:02<00:00, 15.58it/s]Finetune Epoch: 39/60. Data: 2.07s. Batch: 2.11s. Loss: 0.9979. :  80%|████████  | 20/25 [00:02<00:00, 18.24it/s]Finetune Epoch: 39/60. Data: 2.09s. Batch: 2.13s. Loss: 0.9960. :  80%|████████  | 20/25 [00:02<00:00, 18.24it/s]Finetune Epoch: 39/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9907. :  80%|████████  | 20/25 [00:02<00:00, 18.24it/s]Finetune Epoch: 39/60. Data: 2.13s. Batch: 2.17s. Loss: 0.9944. :  80%|████████  | 20/25 [00:02<00:00, 18.24it/s]Finetune Epoch: 39/60. Data: 2.13s. Batch: 2.17s. Loss: 0.9944. :  92%|█████████▏| 23/25 [00:02<00:00, 19.32it/s]Finetune Epoch: 39/60. Data: 2.15s. Batch: 2.19s. Loss: 1.0004. :  92%|█████████▏| 23/25 [00:02<00:00, 19.32it/s]Finetune Epoch: 39/60. Data: 2.17s. Batch: 2.21s. Loss: 0.9986. :  92%|█████████▏| 23/25 [00:02<00:00, 19.32it/s]Finetune Epoch: 39/60. Data: 2.17s. Batch: 2.21s. Loss: 0.9986. : 100%|██████████| 25/25 [00:02<00:00,  8.58it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.61s. Loss: 1.0151. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.61s. Loss: 1.0151. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.81s. Loss: 0.9982. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9467. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.41s. Loss: 0.9586. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9355. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9321. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9515. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9504. top1: 82.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9521. top1: 82.99. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9550. top1: 83.44. top5: 99.69. :   2%|▏         | 1/63 [00:01<01:39,  1.61s/it] Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9550. top1: 83.44. top5: 99.69. :  16%|█▌        | 10/63 [00:01<00:06,  7.85it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9392. top1: 84.38. top5: 99.72. :  16%|█▌        | 10/63 [00:01<00:06,  7.85it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9430. top1: 84.38. top5: 99.74. :  16%|█▌        | 10/63 [00:01<00:06,  7.85it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9360. top1: 84.62. top5: 99.76. :  16%|█▌        | 10/63 [00:01<00:06,  7.85it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9284. top1: 85.04. top5: 99.78. :  16%|█▌        | 10/63 [00:01<00:06,  7.85it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9251. top1: 85.62. top5: 99.79. :  16%|█▌        | 10/63 [00:01<00:06,  7.85it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9261. top1: 85.74. top5: 99.80. :  16%|█▌        | 10/63 [00:01<00:06,  7.85it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9261. top1: 85.74. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9245. top1: 85.66. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9263. top1: 85.76. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9257. top1: 85.86. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9239. top1: 85.78. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9265. top1: 85.57. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9222. top1: 85.80. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9174. top1: 86.41. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9140. top1: 86.59. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9095. top1: 86.88. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9168. top1: 86.42. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9172. top1: 86.34. top5: 99.77. :  25%|██▌       | 16/63 [00:01<00:03, 13.08it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9172. top1: 86.34. top5: 99.77. :  43%|████▎     | 27/63 [00:01<00:01, 25.21it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9223. top1: 86.16. top5: 99.78. :  43%|████▎     | 27/63 [00:01<00:01, 25.21it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9177. top1: 86.53. top5: 99.78. :  43%|████▎     | 27/63 [00:01<00:01, 25.21it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9171. top1: 86.67. top5: 99.79. :  43%|████▎     | 27/63 [00:01<00:01, 25.21it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9158. top1: 86.69. top5: 99.80. :  43%|████▎     | 27/63 [00:01<00:01, 25.21it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9307. top1: 86.04. top5: 99.71. :  43%|████▎     | 27/63 [00:01<00:01, 25.21it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9340. top1: 85.89. top5: 99.72. :  43%|████▎     | 27/63 [00:01<00:01, 25.21it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9390. top1: 85.75. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 25.21it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9466. top1: 85.36. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 25.21it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9618. top1: 84.81. top5: 99.57. :  43%|████▎     | 27/63 [00:02<00:01, 25.21it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9624. top1: 84.80. top5: 99.58. :  43%|████▎     | 27/63 [00:02<00:01, 25.21it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9683. top1: 84.46. top5: 99.59. :  43%|████▎     | 27/63 [00:02<00:01, 25.21it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9683. top1: 84.46. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9757. top1: 84.13. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9809. top1: 83.91. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9843. top1: 83.84. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9948. top1: 83.26. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0018. top1: 82.99. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0044. top1: 82.81. top5: 99.50. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0051. top1: 82.78. top5: 99.51. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.61. top5: 99.52. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 82.45. top5: 99.53. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0110. top1: 82.36. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0140. top1: 82.33. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 37.80it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0140. top1: 82.33. top5: 99.49. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0159. top1: 82.25. top5: 99.50. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0228. top1: 81.74. top5: 99.51. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0242. top1: 81.73. top5: 99.46. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0289. top1: 81.49. top5: 99.47. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0352. top1: 81.19. top5: 99.42. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0352. top1: 81.25. top5: 99.43. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0362. top1: 81.25. top5: 99.44. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0422. top1: 80.87. top5: 99.40. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0480. top1: 80.55. top5: 99.41. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0516. top1: 80.46. top5: 99.36. :  78%|███████▊  | 49/63 [00:02<00:00, 50.12it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0516. top1: 80.46. top5: 99.36. :  94%|█████████▎| 59/63 [00:02<00:00, 57.89it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0512. top1: 80.57. top5: 99.38. :  94%|█████████▎| 59/63 [00:02<00:00, 57.89it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0552. top1: 80.28. top5: 99.39. :  94%|█████████▎| 59/63 [00:02<00:00, 57.89it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0612. top1: 79.84. top5: 99.40. :  94%|█████████▎| 59/63 [00:02<00:00, 57.89it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0619. top1: 79.85. top5: 99.40. :  94%|█████████▎| 59/63 [00:02<00:00, 57.89it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0619. top1: 79.85. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 24.97it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 40/60. Data: 1.59s. Batch: 1.64s. Loss: 1.0486. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 40/60. Data: 1.59s. Batch: 1.64s. Loss: 1.0486. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 40/60. Data: 1.62s. Batch: 1.67s. Loss: 0.9686. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 40/60. Data: 1.64s. Batch: 1.69s. Loss: 0.9877. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 40/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9686. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 40/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9686. :  16%|█▌        | 4/25 [00:01<00:07,  2.87it/s]Finetune Epoch: 40/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9653. :  16%|█▌        | 4/25 [00:01<00:07,  2.87it/s]Finetune Epoch: 40/60. Data: 1.72s. Batch: 1.77s. Loss: 0.9738. :  16%|█▌        | 4/25 [00:01<00:07,  2.87it/s]Finetune Epoch: 40/60. Data: 1.72s. Batch: 1.77s. Loss: 0.9738. :  24%|██▍       | 6/25 [00:01<00:04,  4.53it/s]Finetune Epoch: 40/60. Data: 1.74s. Batch: 1.79s. Loss: 0.9640. :  24%|██▍       | 6/25 [00:01<00:04,  4.53it/s]Finetune Epoch: 40/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9610. :  24%|██▍       | 6/25 [00:01<00:04,  4.53it/s]Finetune Epoch: 40/60. Data: 1.79s. Batch: 1.84s. Loss: 0.9651. :  24%|██▍       | 6/25 [00:02<00:04,  4.53it/s]Finetune Epoch: 40/60. Data: 1.79s. Batch: 1.84s. Loss: 0.9651. :  36%|███▌      | 9/25 [00:02<00:02,  7.32it/s]Finetune Epoch: 40/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9638. :  36%|███▌      | 9/25 [00:02<00:02,  7.32it/s]Finetune Epoch: 40/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9567. :  36%|███▌      | 9/25 [00:02<00:02,  7.32it/s]Finetune Epoch: 40/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9567. :  44%|████▍     | 11/25 [00:02<00:01,  9.10it/s]Finetune Epoch: 40/60. Data: 1.87s. Batch: 1.91s. Loss: 0.9596. :  44%|████▍     | 11/25 [00:02<00:01,  9.10it/s]Finetune Epoch: 40/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9685. :  44%|████▍     | 11/25 [00:02<00:01,  9.10it/s]Finetune Epoch: 40/60. Data: 1.91s. Batch: 1.96s. Loss: 0.9667. :  44%|████▍     | 11/25 [00:02<00:01,  9.10it/s]Finetune Epoch: 40/60. Data: 1.91s. Batch: 1.96s. Loss: 0.9667. :  56%|█████▌    | 14/25 [00:02<00:00, 11.71it/s]Finetune Epoch: 40/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9631. :  56%|█████▌    | 14/25 [00:02<00:00, 11.71it/s]Finetune Epoch: 40/60. Data: 1.97s. Batch: 2.01s. Loss: 0.9694. :  56%|█████▌    | 14/25 [00:02<00:00, 11.71it/s]Finetune Epoch: 40/60. Data: 1.97s. Batch: 2.01s. Loss: 0.9694. :  64%|██████▍   | 16/25 [00:02<00:00, 12.82it/s]Finetune Epoch: 40/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9751. :  64%|██████▍   | 16/25 [00:02<00:00, 12.82it/s]Finetune Epoch: 40/60. Data: 2.02s. Batch: 2.06s. Loss: 0.9781. :  64%|██████▍   | 16/25 [00:02<00:00, 12.82it/s]Finetune Epoch: 40/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9776. :  64%|██████▍   | 16/25 [00:02<00:00, 12.82it/s]Finetune Epoch: 40/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9776. :  76%|███████▌  | 19/25 [00:02<00:00, 15.21it/s]Finetune Epoch: 40/60. Data: 2.07s. Batch: 2.11s. Loss: 0.9814. :  76%|███████▌  | 19/25 [00:02<00:00, 15.21it/s]Finetune Epoch: 40/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9816. :  76%|███████▌  | 19/25 [00:02<00:00, 15.21it/s]Finetune Epoch: 40/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9861. :  76%|███████▌  | 19/25 [00:02<00:00, 15.21it/s]Finetune Epoch: 40/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9861. :  88%|████████▊ | 22/25 [00:02<00:00, 17.57it/s]Finetune Epoch: 40/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9901. :  88%|████████▊ | 22/25 [00:02<00:00, 17.57it/s]Finetune Epoch: 40/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9851. :  88%|████████▊ | 22/25 [00:02<00:00, 17.57it/s]Finetune Epoch: 40/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9809. :  88%|████████▊ | 22/25 [00:02<00:00, 17.57it/s]Finetune Epoch: 40/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9809. : 100%|██████████| 25/25 [00:02<00:00, 18.04it/s]Finetune Epoch: 40/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9809. : 100%|██████████| 25/25 [00:02<00:00,  8.37it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.0169. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.0169. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 0.9999. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9481. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9601. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9370. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9335. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9530. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9518. top1: 82.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9536. top1: 82.99. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9536. top1: 82.99. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9565. top1: 83.44. top5: 99.69. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9406. top1: 84.38. top5: 99.72. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9445. top1: 84.38. top5: 99.74. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9374. top1: 84.62. top5: 99.76. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9298. top1: 85.04. top5: 99.78. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9264. top1: 85.62. top5: 99.79. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9275. top1: 85.74. top5: 99.80. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9258. top1: 85.48. top5: 99.82. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9276. top1: 85.59. top5: 99.83. :  14%|█▍        | 9/63 [00:01<00:07,  6.90it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9276. top1: 85.59. top5: 99.83. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9271. top1: 85.69. top5: 99.84. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9252. top1: 85.62. top5: 99.84. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9278. top1: 85.42. top5: 99.70. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9234. top1: 85.65. top5: 99.72. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9187. top1: 86.28. top5: 99.73. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9152. top1: 86.46. top5: 99.74. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9108. top1: 86.75. top5: 99.75. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9180. top1: 86.18. top5: 99.76. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9185. top1: 86.11. top5: 99.77. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9236. top1: 85.94. top5: 99.78. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9190. top1: 86.31. top5: 99.78. :  29%|██▊       | 18/63 [00:01<00:02, 15.28it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9190. top1: 86.31. top5: 99.78. :  46%|████▌     | 29/63 [00:01<00:01, 27.24it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9183. top1: 86.46. top5: 99.79. :  46%|████▌     | 29/63 [00:01<00:01, 27.24it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9171. top1: 86.49. top5: 99.80. :  46%|████▌     | 29/63 [00:01<00:01, 27.24it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9319. top1: 85.84. top5: 99.71. :  46%|████▌     | 29/63 [00:01<00:01, 27.24it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9351. top1: 85.70. top5: 99.72. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9399. top1: 85.57. top5: 99.72. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9474. top1: 85.18. top5: 99.73. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9625. top1: 84.64. top5: 99.57. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9630. top1: 84.63. top5: 99.58. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9689. top1: 84.29. top5: 99.59. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9762. top1: 83.97. top5: 99.60. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9813. top1: 83.75. top5: 99.61. :  46%|████▌     | 29/63 [00:02<00:01, 27.24it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9813. top1: 83.75. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9846. top1: 83.69. top5: 99.54. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9950. top1: 83.11. top5: 99.55. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0020. top1: 82.85. top5: 99.49. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0045. top1: 82.67. top5: 99.50. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0052. top1: 82.64. top5: 99.51. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.47. top5: 99.52. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 82.31. top5: 99.53. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0109. top1: 82.23. top5: 99.54. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0139. top1: 82.21. top5: 99.49. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0158. top1: 82.12. top5: 99.50. :  63%|██████▎   | 40/63 [00:02<00:00, 39.81it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0158. top1: 82.12. top5: 99.50. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0226. top1: 81.62. top5: 99.51. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0239. top1: 81.61. top5: 99.46. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0286. top1: 81.37. top5: 99.47. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0348. top1: 81.08. top5: 99.42. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0348. top1: 81.14. top5: 99.43. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0357. top1: 81.14. top5: 99.44. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0417. top1: 80.76. top5: 99.40. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0475. top1: 80.44. top5: 99.41. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0510. top1: 80.35. top5: 99.36. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0506. top1: 80.47. top5: 99.38. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0546. top1: 80.17. top5: 99.39. :  79%|███████▉  | 50/63 [00:02<00:00, 49.31it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0546. top1: 80.17. top5: 99.39. :  97%|█████████▋| 61/63 [00:02<00:00, 60.35it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0605. top1: 79.74. top5: 99.40. :  97%|█████████▋| 61/63 [00:02<00:00, 60.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0612. top1: 79.75. top5: 99.40. :  97%|█████████▋| 61/63 [00:02<00:00, 60.35it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0612. top1: 79.75. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 25.39it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 41/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9354. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 41/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9354. :   4%|▍         | 1/25 [00:01<00:41,  1.74s/it]Finetune Epoch: 41/60. Data: 1.72s. Batch: 1.76s. Loss: 0.9886. :   4%|▍         | 1/25 [00:01<00:41,  1.74s/it]Finetune Epoch: 41/60. Data: 1.74s. Batch: 1.78s. Loss: 1.0011. :   4%|▍         | 1/25 [00:01<00:41,  1.74s/it]Finetune Epoch: 41/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9884. :   4%|▍         | 1/25 [00:01<00:41,  1.74s/it]Finetune Epoch: 41/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9884. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 41/60. Data: 1.78s. Batch: 1.82s. Loss: 1.0088. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 41/60. Data: 1.80s. Batch: 1.83s. Loss: 0.9947. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 41/60. Data: 1.81s. Batch: 1.85s. Loss: 0.9954. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 41/60. Data: 1.81s. Batch: 1.85s. Loss: 0.9954. :  28%|██▊       | 7/25 [00:01<00:03,  5.38it/s]Finetune Epoch: 41/60. Data: 1.83s. Batch: 1.87s. Loss: 1.0007. :  28%|██▊       | 7/25 [00:02<00:03,  5.38it/s]Finetune Epoch: 41/60. Data: 1.85s. Batch: 1.89s. Loss: 0.9844. :  28%|██▊       | 7/25 [00:02<00:03,  5.38it/s]Finetune Epoch: 41/60. Data: 1.87s. Batch: 1.91s. Loss: 0.9898. :  28%|██▊       | 7/25 [00:02<00:03,  5.38it/s]Finetune Epoch: 41/60. Data: 1.87s. Batch: 1.91s. Loss: 0.9898. :  40%|████      | 10/25 [00:02<00:01,  8.11it/s]Finetune Epoch: 41/60. Data: 1.89s. Batch: 1.93s. Loss: 0.9869. :  40%|████      | 10/25 [00:02<00:01,  8.11it/s]Finetune Epoch: 41/60. Data: 1.91s. Batch: 1.95s. Loss: 0.9952. :  40%|████      | 10/25 [00:02<00:01,  8.11it/s]Finetune Epoch: 41/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9854. :  40%|████      | 10/25 [00:02<00:01,  8.11it/s]Finetune Epoch: 41/60. Data: 1.93s. Batch: 1.97s. Loss: 0.9854. :  52%|█████▏    | 13/25 [00:02<00:01, 11.16it/s]Finetune Epoch: 41/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9792. :  52%|█████▏    | 13/25 [00:02<00:01, 11.16it/s]Finetune Epoch: 41/60. Data: 1.97s. Batch: 2.01s. Loss: 0.9860. :  52%|█████▏    | 13/25 [00:02<00:01, 11.16it/s]Finetune Epoch: 41/60. Data: 1.99s. Batch: 2.03s. Loss: 0.9845. :  52%|█████▏    | 13/25 [00:02<00:01, 11.16it/s]Finetune Epoch: 41/60. Data: 1.99s. Batch: 2.03s. Loss: 0.9845. :  64%|██████▍   | 16/25 [00:02<00:00, 13.59it/s]Finetune Epoch: 41/60. Data: 2.01s. Batch: 2.05s. Loss: 0.9805. :  64%|██████▍   | 16/25 [00:02<00:00, 13.59it/s]Finetune Epoch: 41/60. Data: 2.03s. Batch: 2.07s. Loss: 0.9706. :  64%|██████▍   | 16/25 [00:02<00:00, 13.59it/s]Finetune Epoch: 41/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9675. :  64%|██████▍   | 16/25 [00:02<00:00, 13.59it/s]Finetune Epoch: 41/60. Data: 2.05s. Batch: 2.09s. Loss: 0.9675. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch: 41/60. Data: 2.07s. Batch: 2.11s. Loss: 0.9723. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch: 41/60. Data: 2.09s. Batch: 2.13s. Loss: 0.9717. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch: 41/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9785. :  76%|███████▌  | 19/25 [00:02<00:00, 15.12it/s]Finetune Epoch: 41/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9785. :  88%|████████▊ | 22/25 [00:02<00:00, 16.46it/s]Finetune Epoch: 41/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9786. :  88%|████████▊ | 22/25 [00:02<00:00, 16.46it/s]Finetune Epoch: 41/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9808. :  88%|████████▊ | 22/25 [00:02<00:00, 16.46it/s]Finetune Epoch: 41/60. Data: 2.18s. Batch: 2.22s. Loss: 0.9865. :  88%|████████▊ | 22/25 [00:02<00:00, 16.46it/s]Finetune Epoch: 41/60. Data: 2.18s. Batch: 2.22s. Loss: 0.9865. : 100%|██████████| 25/25 [00:02<00:00, 17.38it/s]Finetune Epoch: 41/60. Data: 2.18s. Batch: 2.22s. Loss: 0.9865. : 100%|██████████| 25/25 [00:02<00:00,  8.39it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.55s. Loss: 1.0190. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.55s. Loss: 1.0190. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.78s. Loss: 1.0018. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 0.9496. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 0.9618. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9385. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9350. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9545. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9535. top1: 82.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:36,  1.55s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9535. top1: 82.42. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9552. top1: 82.99. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9581. top1: 83.44. top5: 99.69. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9422. top1: 84.38. top5: 99.72. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9461. top1: 84.38. top5: 99.74. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9390. top1: 84.62. top5: 99.76. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9314. top1: 85.04. top5: 99.78. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9279. top1: 85.62. top5: 99.79. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9290. top1: 85.74. top5: 99.80. :  13%|█▎        | 8/63 [00:01<00:08,  6.47it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9290. top1: 85.74. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9273. top1: 85.48. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9291. top1: 85.59. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9286. top1: 85.69. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9267. top1: 85.62. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9294. top1: 85.42. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9249. top1: 85.65. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9202. top1: 86.28. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9167. top1: 86.46. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 14.08it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9167. top1: 86.46. top5: 99.74. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9122. top1: 86.75. top5: 99.75. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9195. top1: 86.18. top5: 99.76. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9200. top1: 86.11. top5: 99.77. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9251. top1: 85.94. top5: 99.78. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9205. top1: 86.31. top5: 99.78. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9198. top1: 86.46. top5: 99.79. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9186. top1: 86.49. top5: 99.80. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9333. top1: 85.84. top5: 99.71. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9363. top1: 85.70. top5: 99.72. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9411. top1: 85.57. top5: 99.72. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9485. top1: 85.18. top5: 99.73. :  38%|███▊      | 24/63 [00:01<00:01, 22.53it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9485. top1: 85.18. top5: 99.73. :  56%|█████▌    | 35/63 [00:01<00:00, 35.76it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9634. top1: 84.64. top5: 99.57. :  56%|█████▌    | 35/63 [00:01<00:00, 35.76it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9638. top1: 84.63. top5: 99.58. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9696. top1: 84.29. top5: 99.59. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9768. top1: 83.97. top5: 99.60. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9818. top1: 83.75. top5: 99.61. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9851. top1: 83.69. top5: 99.54. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9954. top1: 83.11. top5: 99.55. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0023. top1: 82.85. top5: 99.49. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0048. top1: 82.67. top5: 99.50. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0054. top1: 82.64. top5: 99.51. :  56%|█████▌    | 35/63 [00:02<00:00, 35.76it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0054. top1: 82.64. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0083. top1: 82.47. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0095. top1: 82.31. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0109. top1: 82.23. top5: 99.54. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0138. top1: 82.21. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0156. top1: 82.12. top5: 99.50. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0224. top1: 81.62. top5: 99.51. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0237. top1: 81.61. top5: 99.46. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0283. top1: 81.37. top5: 99.47. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0345. top1: 81.08. top5: 99.42. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0344. top1: 81.14. top5: 99.43. :  71%|███████▏  | 45/63 [00:02<00:00, 47.08it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0344. top1: 81.14. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0353. top1: 81.14. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0412. top1: 80.87. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0469. top1: 80.55. top5: 99.41. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0504. top1: 80.46. top5: 99.36. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0500. top1: 80.57. top5: 99.38. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0539. top1: 80.28. top5: 99.39. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0598. top1: 79.84. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0604. top1: 79.85. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 56.63it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0604. top1: 79.85. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 25.35it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 42/60. Data: 1.66s. Batch: 1.71s. Loss: 1.0826. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 42/60. Data: 1.66s. Batch: 1.71s. Loss: 1.0826. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 42/60. Data: 1.69s. Batch: 1.73s. Loss: 1.0940. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 42/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0637. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 42/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0637. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 42/60. Data: 1.75s. Batch: 1.79s. Loss: 1.0506. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 42/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0270. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 42/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0062. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 42/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0062. :  24%|██▍       | 6/25 [00:01<00:04,  4.57it/s]Finetune Epoch: 42/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0184. :  24%|██▍       | 6/25 [00:02<00:04,  4.57it/s]Finetune Epoch: 42/60. Data: 1.85s. Batch: 1.90s. Loss: 1.0279. :  24%|██▍       | 6/25 [00:02<00:04,  4.57it/s]Finetune Epoch: 42/60. Data: 1.85s. Batch: 1.90s. Loss: 1.0279. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 42/60. Data: 1.88s. Batch: 1.92s. Loss: 1.0259. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 42/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0347. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 42/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0364. :  32%|███▏      | 8/25 [00:02<00:02,  6.37it/s]Finetune Epoch: 42/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0364. :  44%|████▍     | 11/25 [00:02<00:01,  9.19it/s]Finetune Epoch: 42/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0433. :  44%|████▍     | 11/25 [00:02<00:01,  9.19it/s]Finetune Epoch: 42/60. Data: 1.98s. Batch: 2.02s. Loss: 1.0380. :  44%|████▍     | 11/25 [00:02<00:01,  9.19it/s]Finetune Epoch: 42/60. Data: 1.98s. Batch: 2.02s. Loss: 1.0380. :  52%|█████▏    | 13/25 [00:02<00:01, 10.75it/s]Finetune Epoch: 42/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0265. :  52%|█████▏    | 13/25 [00:02<00:01, 10.75it/s]Finetune Epoch: 42/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0246. :  52%|█████▏    | 13/25 [00:02<00:01, 10.75it/s]Finetune Epoch: 42/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0227. :  52%|█████▏    | 13/25 [00:02<00:01, 10.75it/s]Finetune Epoch: 42/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0227. :  64%|██████▍   | 16/25 [00:02<00:00, 12.91it/s]Finetune Epoch: 42/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0191. :  64%|██████▍   | 16/25 [00:02<00:00, 12.91it/s]Finetune Epoch: 42/60. Data: 2.11s. Batch: 2.15s. Loss: 1.0180. :  64%|██████▍   | 16/25 [00:02<00:00, 12.91it/s]Finetune Epoch: 42/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0152. :  64%|██████▍   | 16/25 [00:02<00:00, 12.91it/s]Finetune Epoch: 42/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0152. :  76%|███████▌  | 19/25 [00:02<00:00, 15.03it/s]Finetune Epoch: 42/60. Data: 2.16s. Batch: 2.20s. Loss: 1.0098. :  76%|███████▌  | 19/25 [00:02<00:00, 15.03it/s]Finetune Epoch: 42/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0056. :  76%|███████▌  | 19/25 [00:02<00:00, 15.03it/s]Finetune Epoch: 42/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0056. :  84%|████████▍ | 21/25 [00:02<00:00, 15.89it/s]Finetune Epoch: 42/60. Data: 2.21s. Batch: 2.25s. Loss: 1.0092. :  84%|████████▍ | 21/25 [00:02<00:00, 15.89it/s]Finetune Epoch: 42/60. Data: 2.23s. Batch: 2.28s. Loss: 1.0066. :  84%|████████▍ | 21/25 [00:02<00:00, 15.89it/s]Finetune Epoch: 42/60. Data: 2.26s. Batch: 2.30s. Loss: 1.0051. :  84%|████████▍ | 21/25 [00:02<00:00, 15.89it/s]Finetune Epoch: 42/60. Data: 2.26s. Batch: 2.30s. Loss: 1.0051. :  96%|█████████▌| 24/25 [00:02<00:00, 17.51it/s]Finetune Epoch: 42/60. Data: 2.28s. Batch: 2.33s. Loss: 1.0014. :  96%|█████████▌| 24/25 [00:02<00:00, 17.51it/s]Finetune Epoch: 42/60. Data: 2.28s. Batch: 2.33s. Loss: 1.0014. : 100%|██████████| 25/25 [00:03<00:00,  8.07it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.83s. Loss: 1.0196. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.83s. Loss: 1.0196. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 1.0024. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 0.9500. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.9622. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.83s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.9622. top1: 81.25. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 0.9389. top1: 83.75. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9354. top1: 83.85. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9549. top1: 83.48. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9538. top1: 82.42. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9556. top1: 82.99. top5: 100.00. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9585. top1: 83.44. top5: 99.69. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9426. top1: 84.38. top5: 99.72. :   6%|▋         | 4/63 [00:01<00:22,  2.68it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9464. top1: 84.38. top5: 99.74. :   6%|▋         | 4/63 [00:02<00:22,  2.68it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9394. top1: 84.62. top5: 99.76. :   6%|▋         | 4/63 [00:02<00:22,  2.68it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9317. top1: 85.04. top5: 99.78. :   6%|▋         | 4/63 [00:02<00:22,  2.68it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9283. top1: 85.62. top5: 99.79. :   6%|▋         | 4/63 [00:02<00:22,  2.68it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9283. top1: 85.62. top5: 99.79. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9293. top1: 85.74. top5: 99.80. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9277. top1: 85.48. top5: 99.82. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9295. top1: 85.59. top5: 99.83. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9290. top1: 85.69. top5: 99.84. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9271. top1: 85.62. top5: 99.84. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9297. top1: 85.42. top5: 99.70. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9253. top1: 85.65. top5: 99.72. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9206. top1: 86.28. top5: 99.73. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9171. top1: 86.46. top5: 99.74. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9126. top1: 86.75. top5: 99.75. :  24%|██▍       | 15/63 [00:02<00:03, 12.71it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9126. top1: 86.75. top5: 99.75. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9199. top1: 86.18. top5: 99.76. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9203. top1: 86.11. top5: 99.77. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9255. top1: 85.94. top5: 99.78. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9208. top1: 86.31. top5: 99.78. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9202. top1: 86.46. top5: 99.79. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9189. top1: 86.49. top5: 99.80. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9336. top1: 85.84. top5: 99.71. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9366. top1: 85.70. top5: 99.72. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9413. top1: 85.57. top5: 99.72. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9487. top1: 85.18. top5: 99.73. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9635. top1: 84.64. top5: 99.57. :  40%|███▉      | 25/63 [00:02<00:01, 22.84it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9635. top1: 84.64. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9639. top1: 84.63. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9696. top1: 84.29. top5: 99.59. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9768. top1: 83.97. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9818. top1: 83.75. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9851. top1: 83.69. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9954. top1: 83.11. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0023. top1: 82.85. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0047. top1: 82.67. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0053. top1: 82.64. top5: 99.51. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0083. top1: 82.47. top5: 99.52. :  57%|█████▋    | 36/63 [00:02<00:00, 35.10it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0083. top1: 82.47. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0094. top1: 82.31. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0108. top1: 82.23. top5: 99.54. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0137. top1: 82.21. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0155. top1: 82.12. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0222. top1: 81.62. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0235. top1: 81.61. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0281. top1: 81.37. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0342. top1: 81.08. top5: 99.42. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0341. top1: 81.14. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0350. top1: 81.14. top5: 99.44. :  73%|███████▎  | 46/63 [00:02<00:00, 45.64it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0350. top1: 81.14. top5: 99.44. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0409. top1: 80.87. top5: 99.40. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0466. top1: 80.55. top5: 99.41. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0501. top1: 80.46. top5: 99.36. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0497. top1: 80.57. top5: 99.38. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0536. top1: 80.28. top5: 99.39. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0595. top1: 79.84. top5: 99.40. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0601. top1: 79.85. top5: 99.40. :  89%|████████▉ | 56/63 [00:02<00:00, 55.93it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0601. top1: 79.85. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 23.48it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 43/60. Data: 1.62s. Batch: 1.68s. Loss: 1.0001. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 43/60. Data: 1.62s. Batch: 1.68s. Loss: 1.0001. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 43/60. Data: 1.65s. Batch: 1.70s. Loss: 1.0156. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 43/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9994. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 43/60. Data: 1.70s. Batch: 1.74s. Loss: 1.0218. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 43/60. Data: 1.70s. Batch: 1.74s. Loss: 1.0218. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 43/60. Data: 1.72s. Batch: 1.76s. Loss: 1.0435. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 43/60. Data: 1.74s. Batch: 1.78s. Loss: 1.0118. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 43/60. Data: 1.76s. Batch: 1.80s. Loss: 1.0114. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 43/60. Data: 1.76s. Batch: 1.80s. Loss: 1.0114. :  28%|██▊       | 7/25 [00:01<00:03,  5.52it/s]Finetune Epoch: 43/60. Data: 1.78s. Batch: 1.82s. Loss: 1.0258. :  28%|██▊       | 7/25 [00:01<00:03,  5.52it/s]Finetune Epoch: 43/60. Data: 1.80s. Batch: 1.84s. Loss: 1.0197. :  28%|██▊       | 7/25 [00:01<00:03,  5.52it/s]Finetune Epoch: 43/60. Data: 1.82s. Batch: 1.86s. Loss: 1.0098. :  28%|██▊       | 7/25 [00:02<00:03,  5.52it/s]Finetune Epoch: 43/60. Data: 1.82s. Batch: 1.86s. Loss: 1.0098. :  40%|████      | 10/25 [00:02<00:01,  8.30it/s]Finetune Epoch: 43/60. Data: 1.84s. Batch: 1.88s. Loss: 1.0143. :  40%|████      | 10/25 [00:02<00:01,  8.30it/s]Finetune Epoch: 43/60. Data: 1.86s. Batch: 1.90s. Loss: 1.0051. :  40%|████      | 10/25 [00:02<00:01,  8.30it/s]Finetune Epoch: 43/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9972. :  40%|████      | 10/25 [00:02<00:01,  8.30it/s]Finetune Epoch: 43/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9972. :  52%|█████▏    | 13/25 [00:02<00:01, 10.98it/s]Finetune Epoch: 43/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9987. :  52%|█████▏    | 13/25 [00:02<00:01, 10.98it/s]Finetune Epoch: 43/60. Data: 1.92s. Batch: 1.96s. Loss: 1.0042. :  52%|█████▏    | 13/25 [00:02<00:01, 10.98it/s]Finetune Epoch: 43/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9943. :  52%|█████▏    | 13/25 [00:02<00:01, 10.98it/s]Finetune Epoch: 43/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9943. :  64%|██████▍   | 16/25 [00:02<00:00, 13.72it/s]Finetune Epoch: 43/60. Data: 1.96s. Batch: 2.00s. Loss: 1.0027. :  64%|██████▍   | 16/25 [00:02<00:00, 13.72it/s]Finetune Epoch: 43/60. Data: 1.98s. Batch: 2.02s. Loss: 1.0016. :  64%|██████▍   | 16/25 [00:02<00:00, 13.72it/s]Finetune Epoch: 43/60. Data: 2.00s. Batch: 2.04s. Loss: 1.0036. :  64%|██████▍   | 16/25 [00:02<00:00, 13.72it/s]Finetune Epoch: 43/60. Data: 2.00s. Batch: 2.04s. Loss: 1.0036. :  76%|███████▌  | 19/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 43/60. Data: 2.02s. Batch: 2.06s. Loss: 1.0097. :  76%|███████▌  | 19/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 43/60. Data: 2.04s. Batch: 2.08s. Loss: 1.0026. :  76%|███████▌  | 19/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 43/60. Data: 2.06s. Batch: 2.10s. Loss: 0.9993. :  76%|███████▌  | 19/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 43/60. Data: 2.06s. Batch: 2.10s. Loss: 0.9993. :  88%|████████▊ | 22/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 43/60. Data: 2.09s. Batch: 2.13s. Loss: 0.9953. :  88%|████████▊ | 22/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 43/60. Data: 2.11s. Batch: 2.15s. Loss: 1.0038. :  88%|████████▊ | 22/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 43/60. Data: 2.13s. Batch: 2.17s. Loss: 1.0044. :  88%|████████▊ | 22/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 43/60. Data: 2.13s. Batch: 2.17s. Loss: 1.0044. : 100%|██████████| 25/25 [00:02<00:00, 18.57it/s]Finetune Epoch: 43/60. Data: 2.13s. Batch: 2.17s. Loss: 1.0044. : 100%|██████████| 25/25 [00:02<00:00,  8.61it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 1.0208. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.64s. Loss: 1.0208. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.82s. Loss: 1.0035. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9509. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9631. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9398. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9362. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9558. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9547. top1: 82.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9565. top1: 82.99. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9594. top1: 83.44. top5: 99.69. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9434. top1: 84.38. top5: 99.72. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9472. top1: 84.38. top5: 99.74. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9402. top1: 84.62. top5: 99.76. :   2%|▏         | 1/63 [00:01<01:41,  1.64s/it]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9402. top1: 84.62. top5: 99.76. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9325. top1: 85.04. top5: 99.78. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9290. top1: 85.62. top5: 99.79. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9301. top1: 85.74. top5: 99.80. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9285. top1: 85.48. top5: 99.82. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9303. top1: 85.59. top5: 99.83. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9297. top1: 85.69. top5: 99.84. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9278. top1: 85.62. top5: 99.84. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9305. top1: 85.42. top5: 99.70. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9260. top1: 85.65. top5: 99.72. :  21%|██        | 13/63 [00:01<00:04, 10.13it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9260. top1: 85.65. top5: 99.72. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9213. top1: 86.14. top5: 99.73. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9178. top1: 86.33. top5: 99.74. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9133. top1: 86.62. top5: 99.75. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9206. top1: 86.06. top5: 99.76. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9211. top1: 86.00. top5: 99.77. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9263. top1: 85.83. top5: 99.78. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9216. top1: 86.21. top5: 99.78. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9209. top1: 86.35. top5: 99.79. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9197. top1: 86.39. top5: 99.80. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9343. top1: 85.74. top5: 99.71. :  35%|███▍      | 22/63 [00:01<00:02, 18.17it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9343. top1: 85.74. top5: 99.71. :  51%|█████     | 32/63 [00:01<00:01, 28.35it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9373. top1: 85.61. top5: 99.72. :  51%|█████     | 32/63 [00:01<00:01, 28.35it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9419. top1: 85.48. top5: 99.72. :  51%|█████     | 32/63 [00:01<00:01, 28.35it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9492. top1: 85.09. top5: 99.73. :  51%|█████     | 32/63 [00:01<00:01, 28.35it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9640. top1: 84.55. top5: 99.57. :  51%|█████     | 32/63 [00:01<00:01, 28.35it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9643. top1: 84.54. top5: 99.58. :  51%|█████     | 32/63 [00:02<00:01, 28.35it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9699. top1: 84.21. top5: 99.59. :  51%|█████     | 32/63 [00:02<00:01, 28.35it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9771. top1: 83.89. top5: 99.60. :  51%|█████     | 32/63 [00:02<00:01, 28.35it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9820. top1: 83.67. top5: 99.61. :  51%|█████     | 32/63 [00:02<00:01, 28.35it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9853. top1: 83.61. top5: 99.54. :  51%|█████     | 32/63 [00:02<00:01, 28.35it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9853. top1: 83.61. top5: 99.54. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9955. top1: 83.04. top5: 99.55. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0024. top1: 82.78. top5: 99.49. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0048. top1: 82.67. top5: 99.50. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0053. top1: 82.64. top5: 99.51. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.47. top5: 99.52. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0094. top1: 82.31. top5: 99.53. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0107. top1: 82.23. top5: 99.54. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0136. top1: 82.21. top5: 99.49. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0154. top1: 82.12. top5: 99.50. :  65%|██████▌   | 41/63 [00:02<00:00, 37.25it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0154. top1: 82.12. top5: 99.50. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0220. top1: 81.62. top5: 99.51. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0232. top1: 81.61. top5: 99.46. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0278. top1: 81.37. top5: 99.47. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0340. top1: 81.08. top5: 99.42. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0338. top1: 81.14. top5: 99.43. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0347. top1: 81.14. top5: 99.44. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0406. top1: 80.87. top5: 99.40. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0462. top1: 80.55. top5: 99.41. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0497. top1: 80.46. top5: 99.36. :  79%|███████▉  | 50/63 [00:02<00:00, 45.87it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0497. top1: 80.46. top5: 99.36. :  94%|█████████▎| 59/63 [00:02<00:00, 54.20it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0492. top1: 80.57. top5: 99.38. :  94%|█████████▎| 59/63 [00:02<00:00, 54.20it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0531. top1: 80.28. top5: 99.39. :  94%|█████████▎| 59/63 [00:02<00:00, 54.20it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0590. top1: 79.84. top5: 99.40. :  94%|█████████▎| 59/63 [00:02<00:00, 54.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0596. top1: 79.85. top5: 99.40. :  94%|█████████▎| 59/63 [00:02<00:00, 54.20it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0596. top1: 79.85. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 25.31it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 44/60. Data: 1.59s. Batch: 1.64s. Loss: 1.0913. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 44/60. Data: 1.59s. Batch: 1.64s. Loss: 1.0913. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 44/60. Data: 1.62s. Batch: 1.66s. Loss: 1.0815. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 44/60. Data: 1.64s. Batch: 1.68s. Loss: 1.0376. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 44/60. Data: 1.66s. Batch: 1.70s. Loss: 0.9885. :   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Finetune Epoch: 44/60. Data: 1.66s. Batch: 1.70s. Loss: 0.9885. :  16%|█▌        | 4/25 [00:01<00:07,  2.91it/s]Finetune Epoch: 44/60. Data: 1.68s. Batch: 1.72s. Loss: 0.9837. :  16%|█▌        | 4/25 [00:01<00:07,  2.91it/s]Finetune Epoch: 44/60. Data: 1.70s. Batch: 1.75s. Loss: 0.9921. :  16%|█▌        | 4/25 [00:01<00:07,  2.91it/s]Finetune Epoch: 44/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9956. :  16%|█▌        | 4/25 [00:01<00:07,  2.91it/s]Finetune Epoch: 44/60. Data: 1.73s. Batch: 1.77s. Loss: 0.9956. :  28%|██▊       | 7/25 [00:01<00:03,  5.41it/s]Finetune Epoch: 44/60. Data: 1.75s. Batch: 1.79s. Loss: 1.0204. :  28%|██▊       | 7/25 [00:01<00:03,  5.41it/s]Finetune Epoch: 44/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0138. :  28%|██▊       | 7/25 [00:02<00:03,  5.41it/s]Finetune Epoch: 44/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0138. :  36%|███▌      | 9/25 [00:02<00:02,  7.13it/s]Finetune Epoch: 44/60. Data: 1.80s. Batch: 1.84s. Loss: 1.0133. :  36%|███▌      | 9/25 [00:02<00:02,  7.13it/s]Finetune Epoch: 44/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0040. :  36%|███▌      | 9/25 [00:02<00:02,  7.13it/s]Finetune Epoch: 44/60. Data: 1.82s. Batch: 1.87s. Loss: 1.0040. :  44%|████▍     | 11/25 [00:02<00:01,  9.00it/s]Finetune Epoch: 44/60. Data: 1.85s. Batch: 1.89s. Loss: 1.0095. :  44%|████▍     | 11/25 [00:02<00:01,  9.00it/s]Finetune Epoch: 44/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0067. :  44%|████▍     | 11/25 [00:02<00:01,  9.00it/s]Finetune Epoch: 44/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0013. :  44%|████▍     | 11/25 [00:02<00:01,  9.00it/s]Finetune Epoch: 44/60. Data: 1.89s. Batch: 1.94s. Loss: 1.0013. :  56%|█████▌    | 14/25 [00:02<00:00, 11.59it/s]Finetune Epoch: 44/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9948. :  56%|█████▌    | 14/25 [00:02<00:00, 11.59it/s]Finetune Epoch: 44/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9871. :  56%|█████▌    | 14/25 [00:02<00:00, 11.59it/s]Finetune Epoch: 44/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9871. :  64%|██████▍   | 16/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 44/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9848. :  64%|██████▍   | 16/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 44/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9929. :  64%|██████▍   | 16/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 44/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9929. :  72%|███████▏  | 18/25 [00:02<00:00, 13.73it/s]Finetune Epoch: 44/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9901. :  72%|███████▏  | 18/25 [00:02<00:00, 13.73it/s]Finetune Epoch: 44/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9862. :  72%|███████▏  | 18/25 [00:02<00:00, 13.73it/s]Finetune Epoch: 44/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9862. :  80%|████████  | 20/25 [00:02<00:00, 15.02it/s]Finetune Epoch: 44/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9862. :  80%|████████  | 20/25 [00:02<00:00, 15.02it/s]Finetune Epoch: 44/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9851. :  80%|████████  | 20/25 [00:02<00:00, 15.02it/s]Finetune Epoch: 44/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9851. :  88%|████████▊ | 22/25 [00:02<00:00, 15.73it/s]Finetune Epoch: 44/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9817. :  88%|████████▊ | 22/25 [00:02<00:00, 15.73it/s]Finetune Epoch: 44/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9856. :  88%|████████▊ | 22/25 [00:02<00:00, 15.73it/s]Finetune Epoch: 44/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9856. :  96%|█████████▌| 24/25 [00:02<00:00, 16.76it/s]Finetune Epoch: 44/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9842. :  96%|█████████▌| 24/25 [00:02<00:00, 16.76it/s]Finetune Epoch: 44/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9842. : 100%|██████████| 25/25 [00:03<00:00,  8.19it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 1.0219. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.73s. Loss: 1.0219. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 1.0046. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.9518. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9642. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 0.9408. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9373. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9568. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9557. top1: 82.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9576. top1: 82.99. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9604. top1: 83.44. top5: 99.69. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9444. top1: 84.38. top5: 99.72. :   2%|▏         | 1/63 [00:01<01:47,  1.73s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9444. top1: 84.38. top5: 99.72. :  17%|█▋        | 11/63 [00:01<00:06,  8.12it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9483. top1: 84.38. top5: 99.74. :  17%|█▋        | 11/63 [00:01<00:06,  8.12it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9412. top1: 84.62. top5: 99.76. :  17%|█▋        | 11/63 [00:01<00:06,  8.12it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9335. top1: 85.04. top5: 99.78. :  17%|█▋        | 11/63 [00:01<00:06,  8.12it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9300. top1: 85.62. top5: 99.79. :  17%|█▋        | 11/63 [00:01<00:06,  8.12it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9310. top1: 85.74. top5: 99.80. :  17%|█▋        | 11/63 [00:01<00:06,  8.12it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9294. top1: 85.48. top5: 99.82. :  17%|█▋        | 11/63 [00:01<00:06,  8.12it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9294. top1: 85.48. top5: 99.82. :  27%|██▋       | 17/63 [00:01<00:03, 13.14it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9313. top1: 85.59. top5: 99.83. :  27%|██▋       | 17/63 [00:01<00:03, 13.14it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9307. top1: 85.69. top5: 99.84. :  27%|██▋       | 17/63 [00:01<00:03, 13.14it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9288. top1: 85.62. top5: 99.84. :  27%|██▋       | 17/63 [00:01<00:03, 13.14it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9314. top1: 85.42. top5: 99.70. :  27%|██▋       | 17/63 [00:01<00:03, 13.14it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9269. top1: 85.65. top5: 99.72. :  27%|██▋       | 17/63 [00:01<00:03, 13.14it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9223. top1: 86.01. top5: 99.73. :  27%|██▋       | 17/63 [00:02<00:03, 13.14it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9188. top1: 86.20. top5: 99.74. :  27%|██▋       | 17/63 [00:02<00:03, 13.14it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9142. top1: 86.50. top5: 99.75. :  27%|██▋       | 17/63 [00:02<00:03, 13.14it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9216. top1: 85.94. top5: 99.76. :  27%|██▋       | 17/63 [00:02<00:03, 13.14it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9220. top1: 85.88. top5: 99.77. :  27%|██▋       | 17/63 [00:02<00:03, 13.14it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9220. top1: 85.88. top5: 99.77. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9272. top1: 85.71. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9225. top1: 85.99. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9218. top1: 86.15. top5: 99.79. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9206. top1: 86.19. top5: 99.80. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9351. top1: 85.55. top5: 99.71. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9380. top1: 85.42. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9426. top1: 85.29. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9497. top1: 85.00. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9644. top1: 84.46. top5: 99.57. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9647. top1: 84.46. top5: 99.58. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9703. top1: 84.13. top5: 99.59. :  43%|████▎     | 27/63 [00:02<00:01, 23.58it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9703. top1: 84.13. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9774. top1: 83.81. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9823. top1: 83.59. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9855. top1: 83.54. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9957. top1: 82.96. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0024. top1: 82.70. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0048. top1: 82.60. top5: 99.50. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0053. top1: 82.57. top5: 99.51. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.47. top5: 99.52. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0092. top1: 82.31. top5: 99.53. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0105. top1: 82.23. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0134. top1: 82.21. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 36.28it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0134. top1: 82.21. top5: 99.49. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0151. top1: 82.12. top5: 99.50. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0217. top1: 81.62. top5: 99.51. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0229. top1: 81.61. top5: 99.46. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0275. top1: 81.37. top5: 99.47. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0336. top1: 81.08. top5: 99.42. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0334. top1: 81.14. top5: 99.43. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0342. top1: 81.14. top5: 99.44. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0401. top1: 80.87. top5: 99.40. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0457. top1: 80.60. top5: 99.41. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0491. top1: 80.51. top5: 99.36. :  78%|███████▊  | 49/63 [00:02<00:00, 48.46it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0491. top1: 80.51. top5: 99.36. :  94%|█████████▎| 59/63 [00:02<00:00, 57.71it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0487. top1: 80.62. top5: 99.38. :  94%|█████████▎| 59/63 [00:02<00:00, 57.71it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0525. top1: 80.33. top5: 99.39. :  94%|█████████▎| 59/63 [00:02<00:00, 57.71it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0583. top1: 79.89. top5: 99.40. :  94%|█████████▎| 59/63 [00:02<00:00, 57.71it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0590. top1: 79.90. top5: 99.40. :  94%|█████████▎| 59/63 [00:02<00:00, 57.71it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0590. top1: 79.90. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 24.38it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 45/60. Data: 1.58s. Batch: 1.62s. Loss: 0.8451. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 45/60. Data: 1.58s. Batch: 1.62s. Loss: 0.8451. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 45/60. Data: 1.61s. Batch: 1.65s. Loss: 0.9499. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 45/60. Data: 1.63s. Batch: 1.68s. Loss: 1.0067. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 45/60. Data: 1.63s. Batch: 1.68s. Loss: 1.0067. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch: 45/60. Data: 1.66s. Batch: 1.71s. Loss: 0.9798. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch: 45/60. Data: 1.68s. Batch: 1.73s. Loss: 0.9623. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch: 45/60. Data: 1.71s. Batch: 1.75s. Loss: 0.9747. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch: 45/60. Data: 1.71s. Batch: 1.75s. Loss: 0.9747. :  24%|██▍       | 6/25 [00:01<00:03,  4.81it/s]Finetune Epoch: 45/60. Data: 1.73s. Batch: 1.78s. Loss: 0.9535. :  24%|██▍       | 6/25 [00:01<00:03,  4.81it/s]Finetune Epoch: 45/60. Data: 1.76s. Batch: 1.80s. Loss: 0.9849. :  24%|██▍       | 6/25 [00:01<00:03,  4.81it/s]Finetune Epoch: 45/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0060. :  24%|██▍       | 6/25 [00:02<00:03,  4.81it/s]Finetune Epoch: 45/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0060. :  36%|███▌      | 9/25 [00:02<00:02,  7.47it/s]Finetune Epoch: 45/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9996. :  36%|███▌      | 9/25 [00:02<00:02,  7.47it/s]Finetune Epoch: 45/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0032. :  36%|███▌      | 9/25 [00:02<00:02,  7.47it/s]Finetune Epoch: 45/60. Data: 1.83s. Batch: 1.88s. Loss: 1.0032. :  44%|████▍     | 11/25 [00:02<00:01,  9.22it/s]Finetune Epoch: 45/60. Data: 1.85s. Batch: 1.90s. Loss: 1.0091. :  44%|████▍     | 11/25 [00:02<00:01,  9.22it/s]Finetune Epoch: 45/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0107. :  44%|████▍     | 11/25 [00:02<00:01,  9.22it/s]Finetune Epoch: 45/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0128. :  44%|████▍     | 11/25 [00:02<00:01,  9.22it/s]Finetune Epoch: 45/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0128. :  56%|█████▌    | 14/25 [00:02<00:00, 11.90it/s]Finetune Epoch: 45/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0055. :  56%|█████▌    | 14/25 [00:02<00:00, 11.90it/s]Finetune Epoch: 45/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9974. :  56%|█████▌    | 14/25 [00:02<00:00, 11.90it/s]Finetune Epoch: 45/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0038. :  56%|█████▌    | 14/25 [00:02<00:00, 11.90it/s]Finetune Epoch: 45/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0038. :  68%|██████▊   | 17/25 [00:02<00:00, 14.01it/s]Finetune Epoch: 45/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0050. :  68%|██████▊   | 17/25 [00:02<00:00, 14.01it/s]Finetune Epoch: 45/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0066. :  68%|██████▊   | 17/25 [00:02<00:00, 14.01it/s]Finetune Epoch: 45/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0101. :  68%|██████▊   | 17/25 [00:02<00:00, 14.01it/s]Finetune Epoch: 45/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0101. :  80%|████████  | 20/25 [00:02<00:00, 15.75it/s]Finetune Epoch: 45/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0062. :  80%|████████  | 20/25 [00:02<00:00, 15.75it/s]Finetune Epoch: 45/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0079. :  80%|████████  | 20/25 [00:02<00:00, 15.75it/s]Finetune Epoch: 45/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0079. :  88%|████████▊ | 22/25 [00:02<00:00, 16.39it/s]Finetune Epoch: 45/60. Data: 2.12s. Batch: 2.17s. Loss: 1.0047. :  88%|████████▊ | 22/25 [00:02<00:00, 16.39it/s]Finetune Epoch: 45/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9957. :  88%|████████▊ | 22/25 [00:02<00:00, 16.39it/s]Finetune Epoch: 45/60. Data: 2.17s. Batch: 2.22s. Loss: 0.9990. :  88%|████████▊ | 22/25 [00:02<00:00, 16.39it/s]Finetune Epoch: 45/60. Data: 2.17s. Batch: 2.22s. Loss: 0.9990. : 100%|██████████| 25/25 [00:02<00:00, 17.77it/s]Finetune Epoch: 45/60. Data: 2.17s. Batch: 2.22s. Loss: 0.9990. : 100%|██████████| 25/25 [00:02<00:00,  8.35it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.60s. Loss: 1.0225. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.60s. Loss: 1.0225. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.82s. Loss: 1.0052. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9524. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9648. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9413. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9378. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9378. top1: 83.85. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9573. top1: 83.48. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9563. top1: 82.42. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9581. top1: 82.99. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9610. top1: 83.44. top5: 99.69. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9450. top1: 84.38. top5: 99.72. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9488. top1: 84.38. top5: 99.74. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9417. top1: 84.62. top5: 99.76. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9340. top1: 85.04. top5: 99.78. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9305. top1: 85.62. top5: 99.79. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9315. top1: 85.74. top5: 99.80. :  10%|▉         | 6/63 [00:01<00:12,  4.66it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9315. top1: 85.74. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9300. top1: 85.48. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9318. top1: 85.59. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9312. top1: 85.69. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9293. top1: 85.62. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9320. top1: 85.42. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9274. top1: 85.65. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9228. top1: 86.01. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9193. top1: 86.20. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9147. top1: 86.50. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9221. top1: 85.94. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 14.21it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9221. top1: 85.94. top5: 99.76. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9225. top1: 85.88. top5: 99.77. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9277. top1: 85.71. top5: 99.78. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9230. top1: 85.99. top5: 99.78. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9224. top1: 86.15. top5: 99.79. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9211. top1: 86.19. top5: 99.80. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9355. top1: 85.55. top5: 99.71. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9384. top1: 85.42. top5: 99.72. :  41%|████▏     | 26/63 [00:01<00:01, 25.04it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9429. top1: 85.29. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 25.04it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9501. top1: 85.00. top5: 99.73. :  41%|████▏     | 26/63 [00:02<00:01, 25.04it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9647. top1: 84.46. top5: 99.57. :  41%|████▏     | 26/63 [00:02<00:01, 25.04it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9649. top1: 84.46. top5: 99.58. :  41%|████▏     | 26/63 [00:02<00:01, 25.04it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9704. top1: 84.13. top5: 99.59. :  41%|████▏     | 26/63 [00:02<00:01, 25.04it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9704. top1: 84.13. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9775. top1: 83.89. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9824. top1: 83.67. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9855. top1: 83.61. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9957. top1: 83.04. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0025. top1: 82.78. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0048. top1: 82.67. top5: 99.50. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0053. top1: 82.64. top5: 99.51. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.54. top5: 99.52. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0091. top1: 82.38. top5: 99.53. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0104. top1: 82.29. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 39.09it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0104. top1: 82.29. top5: 99.54. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0132. top1: 82.27. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0150. top1: 82.19. top5: 99.50. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0215. top1: 81.68. top5: 99.51. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0227. top1: 81.67. top5: 99.46. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0272. top1: 81.43. top5: 99.47. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0333. top1: 81.13. top5: 99.42. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0331. top1: 81.19. top5: 99.43. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0339. top1: 81.19. top5: 99.44. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0398. top1: 80.92. top5: 99.40. :  76%|███████▌  | 48/63 [00:02<00:00, 49.65it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0398. top1: 80.92. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 56.30it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0453. top1: 80.66. top5: 99.41. :  90%|█████████ | 57/63 [00:02<00:00, 56.30it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0488. top1: 80.56. top5: 99.36. :  90%|█████████ | 57/63 [00:02<00:00, 56.30it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0483. top1: 80.68. top5: 99.38. :  90%|█████████ | 57/63 [00:02<00:00, 56.30it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0521. top1: 80.38. top5: 99.39. :  90%|█████████ | 57/63 [00:02<00:00, 56.30it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0579. top1: 79.94. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 56.30it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0585. top1: 79.95. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 56.30it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0585. top1: 79.95. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 24.76it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 46/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9410. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 46/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9410. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 46/60. Data: 1.78s. Batch: 1.82s. Loss: 0.9839. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 46/60. Data: 1.80s. Batch: 1.85s. Loss: 0.9609. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 46/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9322. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 46/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9322. :  16%|█▌        | 4/25 [00:01<00:07,  2.65it/s]Finetune Epoch: 46/60. Data: 1.85s. Batch: 1.89s. Loss: 0.9355. :  16%|█▌        | 4/25 [00:01<00:07,  2.65it/s]Finetune Epoch: 46/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9206. :  16%|█▌        | 4/25 [00:02<00:07,  2.65it/s]Finetune Epoch: 46/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9206. :  24%|██▍       | 6/25 [00:02<00:04,  4.24it/s]Finetune Epoch: 46/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9369. :  24%|██▍       | 6/25 [00:02<00:04,  4.24it/s]Finetune Epoch: 46/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9381. :  24%|██▍       | 6/25 [00:02<00:04,  4.24it/s]Finetune Epoch: 46/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9381. :  32%|███▏      | 8/25 [00:02<00:02,  5.98it/s]Finetune Epoch: 46/60. Data: 1.95s. Batch: 2.00s. Loss: 0.9395. :  32%|███▏      | 8/25 [00:02<00:02,  5.98it/s]Finetune Epoch: 46/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9440. :  32%|███▏      | 8/25 [00:02<00:02,  5.98it/s]Finetune Epoch: 46/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9440. :  40%|████      | 10/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 46/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9354. :  40%|████      | 10/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 46/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9403. :  40%|████      | 10/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 46/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9403. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 46/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9413. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 46/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9385. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 46/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9385. :  56%|█████▌    | 14/25 [00:02<00:00, 11.42it/s]Finetune Epoch: 46/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9408. :  56%|█████▌    | 14/25 [00:02<00:00, 11.42it/s]Finetune Epoch: 46/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9601. :  56%|█████▌    | 14/25 [00:02<00:00, 11.42it/s]Finetune Epoch: 46/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9601. :  64%|██████▍   | 16/25 [00:02<00:00, 12.87it/s]Finetune Epoch: 46/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9561. :  64%|██████▍   | 16/25 [00:02<00:00, 12.87it/s]Finetune Epoch: 46/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9599. :  64%|██████▍   | 16/25 [00:02<00:00, 12.87it/s]Finetune Epoch: 46/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9599. :  72%|███████▏  | 18/25 [00:02<00:00, 14.45it/s]Finetune Epoch: 46/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9628. :  72%|███████▏  | 18/25 [00:02<00:00, 14.45it/s]Finetune Epoch: 46/60. Data: 2.24s. Batch: 2.29s. Loss: 0.9622. :  72%|███████▏  | 18/25 [00:02<00:00, 14.45it/s]Finetune Epoch: 46/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9694. :  72%|███████▏  | 18/25 [00:02<00:00, 14.45it/s]Finetune Epoch: 46/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9694. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 46/60. Data: 2.29s. Batch: 2.34s. Loss: 0.9708. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 46/60. Data: 2.32s. Batch: 2.37s. Loss: 0.9818. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 46/60. Data: 2.34s. Batch: 2.39s. Loss: 0.9832. :  84%|████████▍ | 21/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 46/60. Data: 2.34s. Batch: 2.39s. Loss: 0.9832. :  96%|█████████▌| 24/25 [00:02<00:00, 18.05it/s]Finetune Epoch: 46/60. Data: 2.37s. Batch: 2.42s. Loss: 0.9909. :  96%|█████████▌| 24/25 [00:03<00:00, 18.05it/s]Finetune Epoch: 46/60. Data: 2.37s. Batch: 2.42s. Loss: 0.9909. : 100%|██████████| 25/25 [00:03<00:00,  7.81it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.17s. Loss: 1.0230. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.17s. Loss: 1.0230. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.09s. Loss: 1.0057. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.73s. Loss: 0.9527. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9651. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9418. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9382. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9577. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9566. top1: 82.42. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9585. top1: 82.99. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9585. top1: 82.99. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9613. top1: 83.44. top5: 99.69. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9454. top1: 84.38. top5: 99.72. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9492. top1: 84.38. top5: 99.74. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9421. top1: 84.62. top5: 99.76. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9344. top1: 85.04. top5: 99.78. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9308. top1: 85.62. top5: 99.79. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9319. top1: 85.74. top5: 99.80. :  14%|█▍        | 9/63 [00:02<00:10,  5.36it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9319. top1: 85.74. top5: 99.80. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9303. top1: 85.48. top5: 99.82. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9322. top1: 85.59. top5: 99.83. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9316. top1: 85.69. top5: 99.84. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9297. top1: 85.62. top5: 99.84. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9323. top1: 85.42. top5: 99.70. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9278. top1: 85.65. top5: 99.72. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9232. top1: 86.01. top5: 99.73. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9197. top1: 86.20. top5: 99.74. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9151. top1: 86.50. top5: 99.75. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9224. top1: 85.94. top5: 99.76. :  25%|██▌       | 16/63 [00:02<00:04, 10.23it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9224. top1: 85.94. top5: 99.76. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9229. top1: 85.88. top5: 99.77. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9281. top1: 85.71. top5: 99.78. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9234. top1: 85.99. top5: 99.78. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9227. top1: 86.15. top5: 99.79. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9215. top1: 86.19. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9358. top1: 85.55. top5: 99.71. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9387. top1: 85.42. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9432. top1: 85.29. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9503. top1: 85.00. top5: 99.73. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9648. top1: 84.46. top5: 99.57. :  41%|████▏     | 26/63 [00:02<00:01, 19.15it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9648. top1: 84.46. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9650. top1: 84.46. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9705. top1: 84.13. top5: 99.59. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9775. top1: 83.89. top5: 99.60. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9824. top1: 83.67. top5: 99.61. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9856. top1: 83.61. top5: 99.54. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9957. top1: 83.04. top5: 99.55. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0024. top1: 82.78. top5: 99.49. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0047. top1: 82.67. top5: 99.50. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0053. top1: 82.64. top5: 99.51. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0080. top1: 82.54. top5: 99.52. :  57%|█████▋    | 36/63 [00:02<00:00, 29.09it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0080. top1: 82.54. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0091. top1: 82.38. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0103. top1: 82.29. top5: 99.54. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0131. top1: 82.27. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0148. top1: 82.19. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0213. top1: 81.68. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0225. top1: 81.67. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0270. top1: 81.43. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0331. top1: 81.13. top5: 99.42. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0329. top1: 81.19. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 39.60it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0329. top1: 81.19. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0337. top1: 81.19. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0395. top1: 80.92. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0450. top1: 80.66. top5: 99.41. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0485. top1: 80.56. top5: 99.36. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0480. top1: 80.68. top5: 99.38. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0518. top1: 80.38. top5: 99.39. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0576. top1: 79.94. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0582. top1: 79.95. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 48.28it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0582. top1: 79.95. top5: 99.40. : 100%|██████████| 63/63 [00:03<00:00, 20.11it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 47/60. Data: 1.90s. Batch: 1.97s. Loss: 1.0781. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 47/60. Data: 1.90s. Batch: 1.97s. Loss: 1.0781. :   4%|▍         | 1/25 [00:01<00:47,  1.97s/it]Finetune Epoch: 47/60. Data: 1.93s. Batch: 1.98s. Loss: 1.0723. :   4%|▍         | 1/25 [00:02<00:47,  1.97s/it]Finetune Epoch: 47/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0425. :   4%|▍         | 1/25 [00:02<00:47,  1.97s/it]Finetune Epoch: 47/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0260. :   4%|▍         | 1/25 [00:02<00:47,  1.97s/it]Finetune Epoch: 47/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0260. :  16%|█▌        | 4/25 [00:02<00:08,  2.46it/s]Finetune Epoch: 47/60. Data: 2.00s. Batch: 2.05s. Loss: 1.0128. :  16%|█▌        | 4/25 [00:02<00:08,  2.46it/s]Finetune Epoch: 47/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0134. :  16%|█▌        | 4/25 [00:02<00:08,  2.46it/s]Finetune Epoch: 47/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0022. :  16%|█▌        | 4/25 [00:02<00:08,  2.46it/s]Finetune Epoch: 47/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0022. :  28%|██▊       | 7/25 [00:02<00:03,  4.63it/s]Finetune Epoch: 47/60. Data: 2.08s. Batch: 2.12s. Loss: 1.0056. :  28%|██▊       | 7/25 [00:02<00:03,  4.63it/s]Finetune Epoch: 47/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0005. :  28%|██▊       | 7/25 [00:02<00:03,  4.63it/s]Finetune Epoch: 47/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0005. :  36%|███▌      | 9/25 [00:02<00:02,  6.19it/s]Finetune Epoch: 47/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0001. :  36%|███▌      | 9/25 [00:02<00:02,  6.19it/s]Finetune Epoch: 47/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9937. :  36%|███▌      | 9/25 [00:02<00:02,  6.19it/s]Finetune Epoch: 47/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9937. :  44%|████▍     | 11/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 47/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9878. :  44%|████▍     | 11/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 47/60. Data: 2.21s. Batch: 2.25s. Loss: 0.9935. :  44%|████▍     | 11/25 [00:02<00:01,  7.95it/s]Finetune Epoch: 47/60. Data: 2.21s. Batch: 2.25s. Loss: 0.9935. :  52%|█████▏    | 13/25 [00:02<00:01,  9.80it/s]Finetune Epoch: 47/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9941. :  52%|█████▏    | 13/25 [00:02<00:01,  9.80it/s]Finetune Epoch: 47/60. Data: 2.26s. Batch: 2.30s. Loss: 0.9938. :  52%|█████▏    | 13/25 [00:02<00:01,  9.80it/s]Finetune Epoch: 47/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9937. :  52%|█████▏    | 13/25 [00:02<00:01,  9.80it/s]Finetune Epoch: 47/60. Data: 2.28s. Batch: 2.33s. Loss: 0.9937. :  64%|██████▍   | 16/25 [00:02<00:00, 12.26it/s]Finetune Epoch: 47/60. Data: 2.31s. Batch: 2.35s. Loss: 0.9903. :  64%|██████▍   | 16/25 [00:02<00:00, 12.26it/s]Finetune Epoch: 47/60. Data: 2.33s. Batch: 2.38s. Loss: 0.9983. :  64%|██████▍   | 16/25 [00:02<00:00, 12.26it/s]Finetune Epoch: 47/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0016. :  64%|██████▍   | 16/25 [00:02<00:00, 12.26it/s]Finetune Epoch: 47/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0016. :  76%|███████▌  | 19/25 [00:02<00:00, 14.40it/s]Finetune Epoch: 47/60. Data: 2.38s. Batch: 2.43s. Loss: 1.0043. :  76%|███████▌  | 19/25 [00:02<00:00, 14.40it/s]Finetune Epoch: 47/60. Data: 2.41s. Batch: 2.46s. Loss: 1.0064. :  76%|███████▌  | 19/25 [00:02<00:00, 14.40it/s]Finetune Epoch: 47/60. Data: 2.41s. Batch: 2.46s. Loss: 1.0064. :  84%|████████▍ | 21/25 [00:02<00:00, 15.35it/s]Finetune Epoch: 47/60. Data: 2.43s. Batch: 2.48s. Loss: 1.0004. :  84%|████████▍ | 21/25 [00:03<00:00, 15.35it/s]Finetune Epoch: 47/60. Data: 2.46s. Batch: 2.51s. Loss: 1.0002. :  84%|████████▍ | 21/25 [00:03<00:00, 15.35it/s]Finetune Epoch: 47/60. Data: 2.46s. Batch: 2.51s. Loss: 1.0002. :  92%|█████████▏| 23/25 [00:03<00:00, 16.28it/s]Finetune Epoch: 47/60. Data: 2.49s. Batch: 2.53s. Loss: 1.0009. :  92%|█████████▏| 23/25 [00:03<00:00, 16.28it/s]Finetune Epoch: 47/60. Data: 2.51s. Batch: 2.56s. Loss: 0.9991. :  92%|█████████▏| 23/25 [00:03<00:00, 16.28it/s]Finetune Epoch: 47/60. Data: 2.51s. Batch: 2.56s. Loss: 0.9991. : 100%|██████████| 25/25 [00:03<00:00,  7.38it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.0249. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.0249. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.83s. Loss: 1.0075. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.9542. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9667. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9432. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9397. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9592. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9581. top1: 82.42. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9601. top1: 82.99. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9601. top1: 82.99. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9629. top1: 83.44. top5: 99.69. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9469. top1: 84.38. top5: 99.72. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9507. top1: 84.38. top5: 99.74. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9436. top1: 84.62. top5: 99.76. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9358. top1: 85.04. top5: 99.78. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9322. top1: 85.62. top5: 99.79. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9333. top1: 85.74. top5: 99.80. :  14%|█▍        | 9/63 [00:01<00:07,  6.91it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9333. top1: 85.74. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9317. top1: 85.48. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9336. top1: 85.59. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9330. top1: 85.69. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9311. top1: 85.62. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9337. top1: 85.42. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9292. top1: 85.65. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9245. top1: 86.01. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9210. top1: 86.20. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9164. top1: 86.50. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9238. top1: 85.94. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 13.06it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9238. top1: 85.94. top5: 99.76. :  41%|████▏     | 26/63 [00:01<00:01, 23.85it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9242. top1: 85.88. top5: 99.77. :  41%|████▏     | 26/63 [00:01<00:01, 23.85it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9294. top1: 85.71. top5: 99.78. :  41%|████▏     | 26/63 [00:01<00:01, 23.85it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9247. top1: 85.99. top5: 99.78. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9241. top1: 86.15. top5: 99.79. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9229. top1: 86.19. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9371. top1: 85.55. top5: 99.71. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9398. top1: 85.42. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9442. top1: 85.29. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9512. top1: 85.00. top5: 99.73. :  41%|████▏     | 26/63 [00:02<00:01, 23.85it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9512. top1: 85.00. top5: 99.73. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9656. top1: 84.46. top5: 99.57. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9657. top1: 84.46. top5: 99.58. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9712. top1: 84.13. top5: 99.59. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9781. top1: 83.89. top5: 99.60. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9829. top1: 83.67. top5: 99.61. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9859. top1: 83.61. top5: 99.54. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9960. top1: 83.04. top5: 99.55. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0027. top1: 82.78. top5: 99.49. :  56%|█████▌    | 35/63 [00:02<00:00, 33.36it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0027. top1: 82.78. top5: 99.49. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0049. top1: 82.67. top5: 99.50. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0054. top1: 82.64. top5: 99.51. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.54. top5: 99.52. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0090. top1: 82.38. top5: 99.53. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0102. top1: 82.29. top5: 99.54. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0130. top1: 82.27. top5: 99.49. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0147. top1: 82.19. top5: 99.50. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0211. top1: 81.68. top5: 99.51. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0222. top1: 81.67. top5: 99.46. :  68%|██████▊   | 43/63 [00:02<00:00, 41.37it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0222. top1: 81.67. top5: 99.46. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0267. top1: 81.43. top5: 99.47. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0327. top1: 81.13. top5: 99.42. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0325. top1: 81.19. top5: 99.43. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0333. top1: 81.19. top5: 99.44. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0390. top1: 80.92. top5: 99.40. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0445. top1: 80.66. top5: 99.41. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0479. top1: 80.56. top5: 99.36. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0474. top1: 80.68. top5: 99.38. :  83%|████████▎ | 52/63 [00:02<00:00, 50.80it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0474. top1: 80.68. top5: 99.38. :  95%|█████████▌| 60/63 [00:02<00:00, 56.75it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0512. top1: 80.38. top5: 99.39. :  95%|█████████▌| 60/63 [00:02<00:00, 56.75it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0569. top1: 79.94. top5: 99.40. :  95%|█████████▌| 60/63 [00:02<00:00, 56.75it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0575. top1: 79.95. top5: 99.40. :  95%|█████████▌| 60/63 [00:02<00:00, 56.75it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0575. top1: 79.95. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 23.23it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 48/60. Data: 1.67s. Batch: 1.73s. Loss: 1.0583. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 48/60. Data: 1.67s. Batch: 1.73s. Loss: 1.0583. :   4%|▍         | 1/25 [00:01<00:41,  1.73s/it]Finetune Epoch: 48/60. Data: 1.70s. Batch: 1.75s. Loss: 1.0338. :   4%|▍         | 1/25 [00:01<00:41,  1.73s/it]Finetune Epoch: 48/60. Data: 1.72s. Batch: 1.77s. Loss: 0.9812. :   4%|▍         | 1/25 [00:01<00:41,  1.73s/it]Finetune Epoch: 48/60. Data: 1.75s. Batch: 1.79s. Loss: 1.0402. :   4%|▍         | 1/25 [00:01<00:41,  1.73s/it]Finetune Epoch: 48/60. Data: 1.75s. Batch: 1.79s. Loss: 1.0402. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 48/60. Data: 1.77s. Batch: 1.81s. Loss: 1.0371. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 48/60. Data: 1.79s. Batch: 1.83s. Loss: 1.0154. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 48/60. Data: 1.81s. Batch: 1.85s. Loss: 0.9978. :  16%|█▌        | 4/25 [00:01<00:07,  2.77it/s]Finetune Epoch: 48/60. Data: 1.81s. Batch: 1.85s. Loss: 0.9978. :  28%|██▊       | 7/25 [00:01<00:03,  5.30it/s]Finetune Epoch: 48/60. Data: 1.83s. Batch: 1.87s. Loss: 1.0292. :  28%|██▊       | 7/25 [00:02<00:03,  5.30it/s]Finetune Epoch: 48/60. Data: 1.85s. Batch: 1.89s. Loss: 1.0162. :  28%|██▊       | 7/25 [00:02<00:03,  5.30it/s]Finetune Epoch: 48/60. Data: 1.85s. Batch: 1.89s. Loss: 1.0162. :  36%|███▌      | 9/25 [00:02<00:02,  7.02it/s]Finetune Epoch: 48/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0132. :  36%|███▌      | 9/25 [00:02<00:02,  7.02it/s]Finetune Epoch: 48/60. Data: 1.90s. Batch: 1.94s. Loss: 1.0026. :  36%|███▌      | 9/25 [00:02<00:02,  7.02it/s]Finetune Epoch: 48/60. Data: 1.90s. Batch: 1.94s. Loss: 1.0026. :  44%|████▍     | 11/25 [00:02<00:01,  8.83it/s]Finetune Epoch: 48/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9974. :  44%|████▍     | 11/25 [00:02<00:01,  8.83it/s]Finetune Epoch: 48/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9988. :  44%|████▍     | 11/25 [00:02<00:01,  8.83it/s]Finetune Epoch: 48/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9988. :  52%|█████▏    | 13/25 [00:02<00:01, 10.50it/s]Finetune Epoch: 48/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9930. :  52%|█████▏    | 13/25 [00:02<00:01, 10.50it/s]Finetune Epoch: 48/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9910. :  52%|█████▏    | 13/25 [00:02<00:01, 10.50it/s]Finetune Epoch: 48/60. Data: 2.00s. Batch: 2.04s. Loss: 0.9910. :  60%|██████    | 15/25 [00:02<00:00, 12.15it/s]Finetune Epoch: 48/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9861. :  60%|██████    | 15/25 [00:02<00:00, 12.15it/s]Finetune Epoch: 48/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9872. :  60%|██████    | 15/25 [00:02<00:00, 12.15it/s]Finetune Epoch: 48/60. Data: 2.05s. Batch: 2.10s. Loss: 0.9872. :  68%|██████▊   | 17/25 [00:02<00:00, 12.89it/s]Finetune Epoch: 48/60. Data: 2.08s. Batch: 2.13s. Loss: 0.9812. :  68%|██████▊   | 17/25 [00:02<00:00, 12.89it/s]Finetune Epoch: 48/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0018. :  68%|██████▊   | 17/25 [00:02<00:00, 12.89it/s]Finetune Epoch: 48/60. Data: 2.10s. Batch: 2.15s. Loss: 1.0018. :  76%|███████▌  | 19/25 [00:02<00:00, 14.20it/s]Finetune Epoch: 48/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0036. :  76%|███████▌  | 19/25 [00:02<00:00, 14.20it/s]Finetune Epoch: 48/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0057. :  76%|███████▌  | 19/25 [00:02<00:00, 14.20it/s]Finetune Epoch: 48/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0057. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 48/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9974. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 48/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9947. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 48/60. Data: 2.24s. Batch: 2.29s. Loss: 0.9977. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 48/60. Data: 2.24s. Batch: 2.29s. Loss: 0.9977. :  96%|█████████▌| 24/25 [00:02<00:00, 17.41it/s]Finetune Epoch: 48/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9998. :  96%|█████████▌| 24/25 [00:02<00:00, 17.41it/s]Finetune Epoch: 48/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9998. : 100%|██████████| 25/25 [00:03<00:00,  8.06it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.90s. Loss: 1.0265. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.90s. Loss: 1.0265. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:57,  1.90s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.96s. Loss: 1.0089. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:57,  1.90s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 0.9554. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:57,  1.90s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 0.9680. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:57,  1.90s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.40s. Loss: 0.9445. top1: 83.75. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:57,  1.90s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 0.9410. top1: 83.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:57,  1.90s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9605. top1: 83.48. top5: 100.00. :   2%|▏         | 1/63 [00:02<01:57,  1.90s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9605. top1: 83.48. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9595. top1: 82.42. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9614. top1: 82.99. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9642. top1: 83.44. top5: 99.69. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9482. top1: 84.38. top5: 99.72. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9520. top1: 84.38. top5: 99.74. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9448. top1: 84.62. top5: 99.76. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9370. top1: 85.04. top5: 99.78. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9334. top1: 85.62. top5: 99.79. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9345. top1: 85.74. top5: 99.80. :  11%|█         | 7/63 [00:02<00:12,  4.65it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9345. top1: 85.74. top5: 99.80. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9329. top1: 85.48. top5: 99.82. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9348. top1: 85.59. top5: 99.83. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9342. top1: 85.69. top5: 99.84. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9323. top1: 85.62. top5: 99.84. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9349. top1: 85.42. top5: 99.70. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9304. top1: 85.65. top5: 99.72. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9257. top1: 86.01. top5: 99.73. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9222. top1: 86.20. top5: 99.74. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9176. top1: 86.50. top5: 99.75. :  25%|██▌       | 16/63 [00:02<00:03, 12.19it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9176. top1: 86.50. top5: 99.75. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9250. top1: 85.82. top5: 99.76. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9254. top1: 85.76. top5: 99.77. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9306. top1: 85.60. top5: 99.78. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9259. top1: 85.88. top5: 99.78. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9253. top1: 86.04. top5: 99.79. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9240. top1: 86.09. top5: 99.80. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9382. top1: 85.45. top5: 99.71. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9408. top1: 85.32. top5: 99.72. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9451. top1: 85.20. top5: 99.72. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9451. top1: 85.20. top5: 99.72. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9520. top1: 84.91. top5: 99.73. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9663. top1: 84.38. top5: 99.57. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9663. top1: 84.38. top5: 99.58. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9717. top1: 84.05. top5: 99.59. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9785. top1: 83.81. top5: 99.60. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9832. top1: 83.59. top5: 99.61. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9863. top1: 83.54. top5: 99.54. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9963. top1: 83.04. top5: 99.55. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0029. top1: 82.78. top5: 99.49. :  54%|█████▍    | 34/63 [00:02<00:00, 30.17it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0029. top1: 82.78. top5: 99.49. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0051. top1: 82.67. top5: 99.50. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0055. top1: 82.64. top5: 99.51. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.54. top5: 99.52. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0090. top1: 82.45. top5: 99.53. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0102. top1: 82.36. top5: 99.54. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0129. top1: 82.33. top5: 99.49. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0145. top1: 82.31. top5: 99.50. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0208. top1: 81.80. top5: 99.51. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0219. top1: 81.79. top5: 99.46. :  68%|██████▊   | 43/63 [00:02<00:00, 39.59it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0219. top1: 81.79. top5: 99.46. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0263. top1: 81.54. top5: 99.47. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0323. top1: 81.25. top5: 99.42. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0321. top1: 81.31. top5: 99.43. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0328. top1: 81.31. top5: 99.44. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0385. top1: 81.03. top5: 99.40. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0440. top1: 80.77. top5: 99.41. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0474. top1: 80.67. top5: 99.36. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0468. top1: 80.78. top5: 99.38. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0506. top1: 80.48. top5: 99.39. :  83%|████████▎ | 52/63 [00:02<00:00, 48.70it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0506. top1: 80.48. top5: 99.39. :  97%|█████████▋| 61/63 [00:02<00:00, 56.54it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0562. top1: 80.04. top5: 99.40. :  97%|█████████▋| 61/63 [00:02<00:00, 56.54it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0568. top1: 80.05. top5: 99.40. :  97%|█████████▋| 61/63 [00:02<00:00, 56.54it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0568. top1: 80.05. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 21.91it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 49/60. Data: 1.75s. Batch: 1.82s. Loss: 0.8496. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 49/60. Data: 1.75s. Batch: 1.82s. Loss: 0.8496. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch: 49/60. Data: 1.80s. Batch: 1.85s. Loss: 0.8994. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch: 49/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9179. :   4%|▍         | 1/25 [00:01<00:43,  1.82s/it]Finetune Epoch: 49/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9179. :  12%|█▏        | 3/25 [00:01<00:11,  1.96it/s]Finetune Epoch: 49/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9603. :  12%|█▏        | 3/25 [00:01<00:11,  1.96it/s]Finetune Epoch: 49/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9929. :  12%|█▏        | 3/25 [00:02<00:11,  1.96it/s]Finetune Epoch: 49/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9800. :  12%|█▏        | 3/25 [00:02<00:11,  1.96it/s]Finetune Epoch: 49/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9800. :  24%|██▍       | 6/25 [00:02<00:04,  4.39it/s]Finetune Epoch: 49/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9823. :  24%|██▍       | 6/25 [00:02<00:04,  4.39it/s]Finetune Epoch: 49/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9840. :  24%|██▍       | 6/25 [00:02<00:04,  4.39it/s]Finetune Epoch: 49/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9998. :  24%|██▍       | 6/25 [00:02<00:04,  4.39it/s]Finetune Epoch: 49/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9998. :  36%|███▌      | 9/25 [00:02<00:02,  7.05it/s]Finetune Epoch: 49/60. Data: 1.99s. Batch: 2.04s. Loss: 1.0010. :  36%|███▌      | 9/25 [00:02<00:02,  7.05it/s]Finetune Epoch: 49/60. Data: 2.02s. Batch: 2.06s. Loss: 1.0019. :  36%|███▌      | 9/25 [00:02<00:02,  7.05it/s]Finetune Epoch: 49/60. Data: 2.02s. Batch: 2.06s. Loss: 1.0019. :  44%|████▍     | 11/25 [00:02<00:01,  8.79it/s]Finetune Epoch: 49/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9959. :  44%|████▍     | 11/25 [00:02<00:01,  8.79it/s]Finetune Epoch: 49/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9983. :  44%|████▍     | 11/25 [00:02<00:01,  8.79it/s]Finetune Epoch: 49/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9983. :  52%|█████▏    | 13/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 49/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9995. :  52%|█████▏    | 13/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 49/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9956. :  52%|█████▏    | 13/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 49/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9964. :  52%|█████▏    | 13/25 [00:02<00:01, 10.60it/s]Finetune Epoch: 49/60. Data: 2.14s. Batch: 2.19s. Loss: 0.9964. :  64%|██████▍   | 16/25 [00:02<00:00, 12.68it/s]Finetune Epoch: 49/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0038. :  64%|██████▍   | 16/25 [00:02<00:00, 12.68it/s]Finetune Epoch: 49/60. Data: 2.19s. Batch: 2.24s. Loss: 1.0035. :  64%|██████▍   | 16/25 [00:02<00:00, 12.68it/s]Finetune Epoch: 49/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0027. :  64%|██████▍   | 16/25 [00:02<00:00, 12.68it/s]Finetune Epoch: 49/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0027. :  76%|███████▌  | 19/25 [00:02<00:00, 14.60it/s]Finetune Epoch: 49/60. Data: 2.24s. Batch: 2.29s. Loss: 1.0018. :  76%|███████▌  | 19/25 [00:02<00:00, 14.60it/s]Finetune Epoch: 49/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9989. :  76%|███████▌  | 19/25 [00:02<00:00, 14.60it/s]Finetune Epoch: 49/60. Data: 2.29s. Batch: 2.34s. Loss: 0.9994. :  76%|███████▌  | 19/25 [00:02<00:00, 14.60it/s]Finetune Epoch: 49/60. Data: 2.29s. Batch: 2.34s. Loss: 0.9994. :  88%|████████▊ | 22/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 49/60. Data: 2.31s. Batch: 2.36s. Loss: 1.0008. :  88%|████████▊ | 22/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 49/60. Data: 2.34s. Batch: 2.39s. Loss: 1.0028. :  88%|████████▊ | 22/25 [00:02<00:00, 16.52it/s]Finetune Epoch: 49/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0002. :  88%|████████▊ | 22/25 [00:03<00:00, 16.52it/s]Finetune Epoch: 49/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0002. : 100%|██████████| 25/25 [00:03<00:00, 17.28it/s]Finetune Epoch: 49/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0002. : 100%|██████████| 25/25 [00:03<00:00,  7.68it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 1.0277. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 1.0277. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 1.0101. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 0.9563. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 0.9689. top1: 80.47. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.9454. top1: 83.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9419. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9419. top1: 83.33. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.19it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9614. top1: 83.04. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.19it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9604. top1: 82.03. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.19it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9623. top1: 82.64. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:13,  4.19it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9651. top1: 83.12. top5: 99.69. :  10%|▉         | 6/63 [00:01<00:13,  4.19it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9491. top1: 84.09. top5: 99.72. :  10%|▉         | 6/63 [00:01<00:13,  4.19it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9529. top1: 84.11. top5: 99.74. :  10%|▉         | 6/63 [00:01<00:13,  4.19it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9529. top1: 84.11. top5: 99.74. :  19%|█▉        | 12/63 [00:01<00:05,  9.46it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9457. top1: 84.38. top5: 99.76. :  19%|█▉        | 12/63 [00:02<00:05,  9.46it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9379. top1: 84.82. top5: 99.78. :  19%|█▉        | 12/63 [00:02<00:05,  9.46it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9342. top1: 85.42. top5: 99.79. :  19%|█▉        | 12/63 [00:02<00:05,  9.46it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9353. top1: 85.55. top5: 99.80. :  19%|█▉        | 12/63 [00:02<00:05,  9.46it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9338. top1: 85.29. top5: 99.82. :  19%|█▉        | 12/63 [00:02<00:05,  9.46it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9357. top1: 85.42. top5: 99.83. :  19%|█▉        | 12/63 [00:02<00:05,  9.46it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9357. top1: 85.42. top5: 99.83. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9351. top1: 85.53. top5: 99.84. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9331. top1: 85.47. top5: 99.84. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9358. top1: 85.27. top5: 99.70. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9312. top1: 85.51. top5: 99.72. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9265. top1: 85.87. top5: 99.73. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9230. top1: 86.07. top5: 99.74. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9184. top1: 86.38. top5: 99.75. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9258. top1: 85.70. top5: 99.76. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9263. top1: 85.65. top5: 99.77. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9315. top1: 85.49. top5: 99.78. :  29%|██▊       | 18/63 [00:02<00:02, 15.39it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9315. top1: 85.49. top5: 99.78. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9267. top1: 85.78. top5: 99.78. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9261. top1: 85.83. top5: 99.79. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9249. top1: 85.89. top5: 99.80. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9389. top1: 85.25. top5: 99.71. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9415. top1: 85.13. top5: 99.72. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9457. top1: 85.02. top5: 99.72. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9525. top1: 84.73. top5: 99.73. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9667. top1: 84.20. top5: 99.57. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9667. top1: 84.21. top5: 99.58. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9720. top1: 83.88. top5: 99.59. :  44%|████▍     | 28/63 [00:02<00:01, 27.51it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9720. top1: 83.88. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9788. top1: 83.65. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9834. top1: 83.44. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9864. top1: 83.38. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9964. top1: 82.89. top5: 99.55. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0030. top1: 82.63. top5: 99.49. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0051. top1: 82.53. top5: 99.50. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0055. top1: 82.50. top5: 99.51. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.40. top5: 99.52. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0090. top1: 82.31. top5: 99.53. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0101. top1: 82.23. top5: 99.54. :  60%|██████    | 38/63 [00:02<00:00, 39.32it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0101. top1: 82.23. top5: 99.54. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0128. top1: 82.21. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0144. top1: 82.19. top5: 99.50. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0206. top1: 81.74. top5: 99.51. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0217. top1: 81.73. top5: 99.46. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0261. top1: 81.49. top5: 99.47. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0320. top1: 81.19. top5: 99.42. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0318. top1: 81.25. top5: 99.43. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0325. top1: 81.25. top5: 99.44. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0381. top1: 80.98. top5: 99.40. :  76%|███████▌  | 48/63 [00:02<00:00, 49.98it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0381. top1: 80.98. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 57.26it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0435. top1: 80.71. top5: 99.41. :  90%|█████████ | 57/63 [00:02<00:00, 57.26it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0469. top1: 80.61. top5: 99.36. :  90%|█████████ | 57/63 [00:02<00:00, 57.26it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0464. top1: 80.73. top5: 99.38. :  90%|█████████ | 57/63 [00:02<00:00, 57.26it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0501. top1: 80.43. top5: 99.39. :  90%|█████████ | 57/63 [00:02<00:00, 57.26it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0557. top1: 79.99. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 57.26it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0563. top1: 80.00. top5: 99.40. :  90%|█████████ | 57/63 [00:02<00:00, 57.26it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0563. top1: 80.00. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 21.92it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 50/60. Data: 1.86s. Batch: 1.93s. Loss: 1.0473. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 50/60. Data: 1.86s. Batch: 1.93s. Loss: 1.0473. :   4%|▍         | 1/25 [00:01<00:46,  1.93s/it]Finetune Epoch: 50/60. Data: 1.90s. Batch: 1.94s. Loss: 0.9809. :   4%|▍         | 1/25 [00:01<00:46,  1.93s/it]Finetune Epoch: 50/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9615. :   4%|▍         | 1/25 [00:02<00:46,  1.93s/it]Finetune Epoch: 50/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9889. :   4%|▍         | 1/25 [00:02<00:46,  1.93s/it]Finetune Epoch: 50/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9889. :  16%|█▌        | 4/25 [00:02<00:08,  2.49it/s]Finetune Epoch: 50/60. Data: 1.97s. Batch: 2.01s. Loss: 0.9801. :  16%|█▌        | 4/25 [00:02<00:08,  2.49it/s]Finetune Epoch: 50/60. Data: 1.99s. Batch: 2.03s. Loss: 0.9910. :  16%|█▌        | 4/25 [00:02<00:08,  2.49it/s]Finetune Epoch: 50/60. Data: 2.01s. Batch: 2.05s. Loss: 1.0052. :  16%|█▌        | 4/25 [00:02<00:08,  2.49it/s]Finetune Epoch: 50/60. Data: 2.01s. Batch: 2.05s. Loss: 1.0052. :  28%|██▊       | 7/25 [00:02<00:03,  4.85it/s]Finetune Epoch: 50/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0113. :  28%|██▊       | 7/25 [00:02<00:03,  4.85it/s]Finetune Epoch: 50/60. Data: 2.05s. Batch: 2.09s. Loss: 1.0096. :  28%|██▊       | 7/25 [00:02<00:03,  4.85it/s]Finetune Epoch: 50/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9926. :  28%|██▊       | 7/25 [00:02<00:03,  4.85it/s]Finetune Epoch: 50/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9926. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch: 50/60. Data: 2.09s. Batch: 2.14s. Loss: 0.9785. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch: 50/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9952. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch: 50/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9887. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch: 50/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9887. :  52%|█████▏    | 13/25 [00:02<00:01, 10.07it/s]Finetune Epoch: 50/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9801. :  52%|█████▏    | 13/25 [00:02<00:01, 10.07it/s]Finetune Epoch: 50/60. Data: 2.18s. Batch: 2.22s. Loss: 0.9728. :  52%|█████▏    | 13/25 [00:02<00:01, 10.07it/s]Finetune Epoch: 50/60. Data: 2.20s. Batch: 2.24s. Loss: 0.9730. :  52%|█████▏    | 13/25 [00:02<00:01, 10.07it/s]Finetune Epoch: 50/60. Data: 2.20s. Batch: 2.24s. Loss: 0.9730. :  64%|██████▍   | 16/25 [00:02<00:00, 12.30it/s]Finetune Epoch: 50/60. Data: 2.22s. Batch: 2.26s. Loss: 0.9753. :  64%|██████▍   | 16/25 [00:02<00:00, 12.30it/s]Finetune Epoch: 50/60. Data: 2.24s. Batch: 2.28s. Loss: 0.9830. :  64%|██████▍   | 16/25 [00:02<00:00, 12.30it/s]Finetune Epoch: 50/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9921. :  64%|██████▍   | 16/25 [00:02<00:00, 12.30it/s]Finetune Epoch: 50/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9921. :  76%|███████▌  | 19/25 [00:02<00:00, 14.32it/s]Finetune Epoch: 50/60. Data: 2.29s. Batch: 2.33s. Loss: 0.9915. :  76%|███████▌  | 19/25 [00:02<00:00, 14.32it/s]Finetune Epoch: 50/60. Data: 2.31s. Batch: 2.35s. Loss: 0.9946. :  76%|███████▌  | 19/25 [00:02<00:00, 14.32it/s]Finetune Epoch: 50/60. Data: 2.33s. Batch: 2.37s. Loss: 0.9906. :  76%|███████▌  | 19/25 [00:02<00:00, 14.32it/s]Finetune Epoch: 50/60. Data: 2.33s. Batch: 2.37s. Loss: 0.9906. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 50/60. Data: 2.35s. Batch: 2.40s. Loss: 1.0006. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 50/60. Data: 2.38s. Batch: 2.42s. Loss: 1.0057. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 50/60. Data: 2.40s. Batch: 2.44s. Loss: 1.0059. :  88%|████████▊ | 22/25 [00:02<00:00, 16.15it/s]Finetune Epoch: 50/60. Data: 2.40s. Batch: 2.44s. Loss: 1.0059. : 100%|██████████| 25/25 [00:02<00:00, 17.96it/s]Finetune Epoch: 50/60. Data: 2.40s. Batch: 2.44s. Loss: 1.0059. : 100%|██████████| 25/25 [00:03<00:00,  7.91it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.54s. Loss: 1.0290. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.54s. Loss: 1.0290. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.79s. Loss: 1.0114. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 0.9573. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 0.9700. top1: 80.47. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9463. top1: 83.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9428. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9623. top1: 83.04. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9614. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.54s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9614. top1: 82.03. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9633. top1: 82.64. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9661. top1: 83.12. top5: 99.69. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9500. top1: 84.09. top5: 99.72. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9538. top1: 84.11. top5: 99.74. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9466. top1: 84.38. top5: 99.76. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9388. top1: 84.82. top5: 99.78. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9351. top1: 85.42. top5: 99.79. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9362. top1: 85.55. top5: 99.80. :  13%|█▎        | 8/63 [00:01<00:08,  6.50it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9362. top1: 85.55. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9347. top1: 85.29. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9366. top1: 85.42. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9360. top1: 85.53. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9340. top1: 85.47. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9367. top1: 85.27. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9321. top1: 85.51. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9274. top1: 85.87. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9239. top1: 86.07. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9193. top1: 86.38. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9267. top1: 85.70. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9271. top1: 85.65. top5: 99.77. :  25%|██▌       | 16/63 [00:01<00:03, 14.35it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9271. top1: 85.65. top5: 99.77. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9324. top1: 85.49. top5: 99.78. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9276. top1: 85.78. top5: 99.78. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9270. top1: 85.83. top5: 99.79. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9258. top1: 85.89. top5: 99.80. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9397. top1: 85.25. top5: 99.71. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9423. top1: 85.13. top5: 99.72. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9464. top1: 85.02. top5: 99.72. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9531. top1: 84.73. top5: 99.73. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9672. top1: 84.29. top5: 99.57. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9671. top1: 84.29. top5: 99.58. :  43%|████▎     | 27/63 [00:01<00:01, 26.75it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9671. top1: 84.29. top5: 99.58. :  59%|█████▊    | 37/63 [00:01<00:00, 38.21it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9724. top1: 83.96. top5: 99.59. :  59%|█████▊    | 37/63 [00:01<00:00, 38.21it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9791. top1: 83.73. top5: 99.60. :  59%|█████▊    | 37/63 [00:01<00:00, 38.21it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9837. top1: 83.52. top5: 99.61. :  59%|█████▊    | 37/63 [00:01<00:00, 38.21it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9867. top1: 83.46. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 38.21it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9966. top1: 82.96. top5: 99.55. :  59%|█████▊    | 37/63 [00:02<00:00, 38.21it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0031. top1: 82.70. top5: 99.49. :  59%|█████▊    | 37/63 [00:02<00:00, 38.21it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0052. top1: 82.60. top5: 99.50. :  59%|█████▊    | 37/63 [00:02<00:00, 38.21it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0056. top1: 82.57. top5: 99.51. :  59%|█████▊    | 37/63 [00:02<00:00, 38.21it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0081. top1: 82.47. top5: 99.52. :  59%|█████▊    | 37/63 [00:02<00:00, 38.21it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0081. top1: 82.47. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0089. top1: 82.38. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0100. top1: 82.29. top5: 99.54. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0126. top1: 82.27. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0143. top1: 82.25. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0204. top1: 81.80. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0215. top1: 81.79. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0258. top1: 81.54. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0317. top1: 81.25. top5: 99.42. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0314. top1: 81.31. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 47.27it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0314. top1: 81.31. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0321. top1: 81.31. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0377. top1: 81.03. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0431. top1: 80.77. top5: 99.41. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0465. top1: 80.67. top5: 99.36. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0459. top1: 80.78. top5: 99.38. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0496. top1: 80.48. top5: 99.39. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0552. top1: 80.04. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0557. top1: 80.05. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 54.31it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0557. top1: 80.05. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 25.55it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 51/60. Data: 1.57s. Batch: 1.63s. Loss: 0.9158. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 51/60. Data: 1.57s. Batch: 1.63s. Loss: 0.9158. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 51/60. Data: 1.60s. Batch: 1.65s. Loss: 0.9496. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 51/60. Data: 1.63s. Batch: 1.67s. Loss: 0.9722. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 51/60. Data: 1.65s. Batch: 1.70s. Loss: 0.9817. :   4%|▍         | 1/25 [00:01<00:39,  1.63s/it]Finetune Epoch: 51/60. Data: 1.65s. Batch: 1.70s. Loss: 0.9817. :  16%|█▌        | 4/25 [00:01<00:07,  2.88it/s]Finetune Epoch: 51/60. Data: 1.68s. Batch: 1.72s. Loss: 0.9919. :  16%|█▌        | 4/25 [00:01<00:07,  2.88it/s]Finetune Epoch: 51/60. Data: 1.70s. Batch: 1.75s. Loss: 0.9778. :  16%|█▌        | 4/25 [00:01<00:07,  2.88it/s]Finetune Epoch: 51/60. Data: 1.72s. Batch: 1.77s. Loss: 0.9691. :  16%|█▌        | 4/25 [00:01<00:07,  2.88it/s]Finetune Epoch: 51/60. Data: 1.72s. Batch: 1.77s. Loss: 0.9691. :  28%|██▊       | 7/25 [00:01<00:03,  5.39it/s]Finetune Epoch: 51/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9848. :  28%|██▊       | 7/25 [00:01<00:03,  5.39it/s]Finetune Epoch: 51/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9963. :  28%|██▊       | 7/25 [00:02<00:03,  5.39it/s]Finetune Epoch: 51/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9963. :  36%|███▌      | 9/25 [00:02<00:02,  6.96it/s]Finetune Epoch: 51/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0000. :  36%|███▌      | 9/25 [00:02<00:02,  6.96it/s]Finetune Epoch: 51/60. Data: 1.83s. Batch: 1.87s. Loss: 0.9848. :  36%|███▌      | 9/25 [00:02<00:02,  6.96it/s]Finetune Epoch: 51/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9890. :  36%|███▌      | 9/25 [00:02<00:02,  6.96it/s]Finetune Epoch: 51/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9890. :  48%|████▊     | 12/25 [00:02<00:01,  9.70it/s]Finetune Epoch: 51/60. Data: 1.88s. Batch: 1.92s. Loss: 0.9984. :  48%|████▊     | 12/25 [00:02<00:01,  9.70it/s]Finetune Epoch: 51/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0092. :  48%|████▊     | 12/25 [00:02<00:01,  9.70it/s]Finetune Epoch: 51/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0141. :  48%|████▊     | 12/25 [00:02<00:01,  9.70it/s]Finetune Epoch: 51/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0141. :  60%|██████    | 15/25 [00:02<00:00, 11.90it/s]Finetune Epoch: 51/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0130. :  60%|██████    | 15/25 [00:02<00:00, 11.90it/s]Finetune Epoch: 51/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0177. :  60%|██████    | 15/25 [00:02<00:00, 11.90it/s]Finetune Epoch: 51/60. Data: 1.98s. Batch: 2.03s. Loss: 1.0177. :  68%|██████▊   | 17/25 [00:02<00:00, 13.10it/s]Finetune Epoch: 51/60. Data: 2.01s. Batch: 2.05s. Loss: 1.0210. :  68%|██████▊   | 17/25 [00:02<00:00, 13.10it/s]Finetune Epoch: 51/60. Data: 2.03s. Batch: 2.08s. Loss: 1.0233. :  68%|██████▊   | 17/25 [00:02<00:00, 13.10it/s]Finetune Epoch: 51/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0283. :  68%|██████▊   | 17/25 [00:02<00:00, 13.10it/s]Finetune Epoch: 51/60. Data: 2.06s. Batch: 2.10s. Loss: 1.0283. :  80%|████████  | 20/25 [00:02<00:00, 15.01it/s]Finetune Epoch: 51/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0261. :  80%|████████  | 20/25 [00:02<00:00, 15.01it/s]Finetune Epoch: 51/60. Data: 2.11s. Batch: 2.15s. Loss: 1.0206. :  80%|████████  | 20/25 [00:02<00:00, 15.01it/s]Finetune Epoch: 51/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0141. :  80%|████████  | 20/25 [00:02<00:00, 15.01it/s]Finetune Epoch: 51/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0141. :  92%|█████████▏| 23/25 [00:02<00:00, 16.26it/s]Finetune Epoch: 51/60. Data: 2.16s. Batch: 2.21s. Loss: 1.0102. :  92%|█████████▏| 23/25 [00:02<00:00, 16.26it/s]Finetune Epoch: 51/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0037. :  92%|█████████▏| 23/25 [00:02<00:00, 16.26it/s]Finetune Epoch: 51/60. Data: 2.18s. Batch: 2.23s. Loss: 1.0037. : 100%|██████████| 25/25 [00:03<00:00,  8.17it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 1.0296. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.70s. Loss: 1.0296. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.86s. Loss: 1.0120. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 0.9578. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9706. top1: 80.47. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9470. top1: 83.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9435. top1: 83.33. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9630. top1: 83.04. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9621. top1: 82.03. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9640. top1: 82.64. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:45,  1.70s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9640. top1: 82.64. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9668. top1: 83.12. top5: 99.69. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9507. top1: 84.09. top5: 99.72. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9545. top1: 84.11. top5: 99.74. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9473. top1: 84.38. top5: 99.76. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9395. top1: 84.82. top5: 99.78. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9357. top1: 85.42. top5: 99.79. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9368. top1: 85.55. top5: 99.80. :  14%|█▍        | 9/63 [00:01<00:08,  6.71it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9368. top1: 85.55. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9353. top1: 85.29. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9372. top1: 85.42. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9366. top1: 85.53. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9346. top1: 85.47. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9373. top1: 85.27. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9327. top1: 85.51. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9280. top1: 85.87. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9245. top1: 86.07. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 12.86it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9198. top1: 86.38. top5: 99.75. :  25%|██▌       | 16/63 [00:02<00:03, 12.86it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9273. top1: 85.70. top5: 99.76. :  25%|██▌       | 16/63 [00:02<00:03, 12.86it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9277. top1: 85.65. top5: 99.77. :  25%|██▌       | 16/63 [00:02<00:03, 12.86it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9277. top1: 85.65. top5: 99.77. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9330. top1: 85.49. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9282. top1: 85.78. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9275. top1: 85.83. top5: 99.79. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9264. top1: 85.89. top5: 99.80. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9402. top1: 85.25. top5: 99.71. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9427. top1: 85.13. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9468. top1: 85.02. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9535. top1: 84.73. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9675. top1: 84.29. top5: 99.57. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9674. top1: 84.29. top5: 99.58. :  43%|████▎     | 27/63 [00:02<00:01, 24.77it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9674. top1: 84.29. top5: 99.58. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9726. top1: 83.96. top5: 99.59. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9792. top1: 83.73. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9839. top1: 83.52. top5: 99.61. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9868. top1: 83.46. top5: 99.54. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9967. top1: 82.96. top5: 99.55. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0032. top1: 82.70. top5: 99.49. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0052. top1: 82.60. top5: 99.50. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0056. top1: 82.57. top5: 99.51. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.47. top5: 99.52. :  59%|█████▊    | 37/63 [00:02<00:00, 35.67it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.47. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0089. top1: 82.38. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0099. top1: 82.29. top5: 99.54. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0125. top1: 82.27. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0141. top1: 82.25. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0202. top1: 81.80. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0212. top1: 81.79. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0256. top1: 81.54. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0315. top1: 81.25. top5: 99.42. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0312. top1: 81.31. top5: 99.43. :  73%|███████▎  | 46/63 [00:02<00:00, 44.72it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0312. top1: 81.31. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0319. top1: 81.31. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0374. top1: 81.03. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0428. top1: 80.77. top5: 99.41. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0461. top1: 80.67. top5: 99.36. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0456. top1: 80.78. top5: 99.38. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0493. top1: 80.48. top5: 99.39. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0548. top1: 80.04. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0553. top1: 80.05. top5: 99.40. :  87%|████████▋ | 55/63 [00:02<00:00, 52.64it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0553. top1: 80.05. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 24.16it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 52/60. Data: 1.96s. Batch: 2.02s. Loss: 0.9925. :   0%|          | 0/25 [00:02<?, ?it/s]Finetune Epoch: 52/60. Data: 1.96s. Batch: 2.02s. Loss: 0.9925. :   4%|▍         | 1/25 [00:02<00:48,  2.02s/it]Finetune Epoch: 52/60. Data: 2.00s. Batch: 2.06s. Loss: 0.9830. :   4%|▍         | 1/25 [00:02<00:48,  2.02s/it]Finetune Epoch: 52/60. Data: 2.03s. Batch: 2.09s. Loss: 0.9733. :   4%|▍         | 1/25 [00:02<00:48,  2.02s/it]Finetune Epoch: 52/60. Data: 2.03s. Batch: 2.09s. Loss: 0.9733. :  12%|█▏        | 3/25 [00:02<00:12,  1.74it/s]Finetune Epoch: 52/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9504. :  12%|█▏        | 3/25 [00:02<00:12,  1.74it/s]Finetune Epoch: 52/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9806. :  12%|█▏        | 3/25 [00:02<00:12,  1.74it/s]Finetune Epoch: 52/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9806. :  20%|██        | 5/25 [00:02<00:06,  3.25it/s]Finetune Epoch: 52/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9886. :  20%|██        | 5/25 [00:02<00:06,  3.25it/s]Finetune Epoch: 52/60. Data: 2.15s. Batch: 2.21s. Loss: 0.9824. :  20%|██        | 5/25 [00:02<00:06,  3.25it/s]Finetune Epoch: 52/60. Data: 2.15s. Batch: 2.21s. Loss: 0.9824. :  28%|██▊       | 7/25 [00:02<00:03,  5.03it/s]Finetune Epoch: 52/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9983. :  28%|██▊       | 7/25 [00:02<00:03,  5.03it/s]Finetune Epoch: 52/60. Data: 2.21s. Batch: 2.26s. Loss: 1.0108. :  28%|██▊       | 7/25 [00:02<00:03,  5.03it/s]Finetune Epoch: 52/60. Data: 2.23s. Batch: 2.29s. Loss: 1.0089. :  28%|██▊       | 7/25 [00:02<00:03,  5.03it/s]Finetune Epoch: 52/60. Data: 2.23s. Batch: 2.29s. Loss: 1.0089. :  40%|████      | 10/25 [00:02<00:01,  7.78it/s]Finetune Epoch: 52/60. Data: 2.26s. Batch: 2.31s. Loss: 1.0107. :  40%|████      | 10/25 [00:02<00:01,  7.78it/s]Finetune Epoch: 52/60. Data: 2.29s. Batch: 2.34s. Loss: 1.0105. :  40%|████      | 10/25 [00:02<00:01,  7.78it/s]Finetune Epoch: 52/60. Data: 2.31s. Batch: 2.36s. Loss: 1.0072. :  40%|████      | 10/25 [00:02<00:01,  7.78it/s]Finetune Epoch: 52/60. Data: 2.31s. Batch: 2.36s. Loss: 1.0072. :  52%|█████▏    | 13/25 [00:02<00:01, 10.36it/s]Finetune Epoch: 52/60. Data: 2.34s. Batch: 2.39s. Loss: 1.0016. :  52%|█████▏    | 13/25 [00:02<00:01, 10.36it/s]Finetune Epoch: 52/60. Data: 2.36s. Batch: 2.41s. Loss: 1.0026. :  52%|█████▏    | 13/25 [00:02<00:01, 10.36it/s]Finetune Epoch: 52/60. Data: 2.39s. Batch: 2.44s. Loss: 0.9975. :  52%|█████▏    | 13/25 [00:02<00:01, 10.36it/s]Finetune Epoch: 52/60. Data: 2.39s. Batch: 2.44s. Loss: 0.9975. :  64%|██████▍   | 16/25 [00:02<00:00, 12.61it/s]Finetune Epoch: 52/60. Data: 2.41s. Batch: 2.47s. Loss: 0.9873. :  64%|██████▍   | 16/25 [00:02<00:00, 12.61it/s]Finetune Epoch: 52/60. Data: 2.44s. Batch: 2.49s. Loss: 0.9869. :  64%|██████▍   | 16/25 [00:02<00:00, 12.61it/s]Finetune Epoch: 52/60. Data: 2.46s. Batch: 2.52s. Loss: 0.9807. :  64%|██████▍   | 16/25 [00:02<00:00, 12.61it/s]Finetune Epoch: 52/60. Data: 2.46s. Batch: 2.52s. Loss: 0.9807. :  76%|███████▌  | 19/25 [00:02<00:00, 14.53it/s]Finetune Epoch: 52/60. Data: 2.49s. Batch: 2.54s. Loss: 0.9827. :  76%|███████▌  | 19/25 [00:03<00:00, 14.53it/s]Finetune Epoch: 52/60. Data: 2.52s. Batch: 2.57s. Loss: 0.9739. :  76%|███████▌  | 19/25 [00:03<00:00, 14.53it/s]Finetune Epoch: 52/60. Data: 2.52s. Batch: 2.57s. Loss: 0.9739. :  84%|████████▍ | 21/25 [00:03<00:00, 15.51it/s]Finetune Epoch: 52/60. Data: 2.54s. Batch: 2.59s. Loss: 0.9711. :  84%|████████▍ | 21/25 [00:03<00:00, 15.51it/s]Finetune Epoch: 52/60. Data: 2.57s. Batch: 2.62s. Loss: 0.9780. :  84%|████████▍ | 21/25 [00:03<00:00, 15.51it/s]Finetune Epoch: 52/60. Data: 2.57s. Batch: 2.62s. Loss: 0.9780. :  92%|█████████▏| 23/25 [00:03<00:00, 16.39it/s]Finetune Epoch: 52/60. Data: 2.59s. Batch: 2.64s. Loss: 0.9815. :  92%|█████████▏| 23/25 [00:03<00:00, 16.39it/s]Finetune Epoch: 52/60. Data: 2.62s. Batch: 2.67s. Loss: 0.9867. :  92%|█████████▏| 23/25 [00:03<00:00, 16.39it/s]Finetune Epoch: 52/60. Data: 2.62s. Batch: 2.67s. Loss: 0.9867. : 100%|██████████| 25/25 [00:03<00:00,  7.16it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 1.0308. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 1.0308. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.98s. Loss: 1.0131. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.98s. Loss: 1.0131. top1: 76.56. top5: 100.00. :   3%|▎         | 2/63 [00:01<00:50,  1.21it/s]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.66s. Loss: 0.9587. top1: 81.25. top5: 100.00. :   3%|▎         | 2/63 [00:01<00:50,  1.21it/s]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.50s. Loss: 0.9716. top1: 80.47. top5: 100.00. :   3%|▎         | 2/63 [00:01<00:50,  1.21it/s]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.40s. Loss: 0.9480. top1: 83.12. top5: 100.00. :   3%|▎         | 2/63 [00:01<00:50,  1.21it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9445. top1: 83.33. top5: 100.00. :   3%|▎         | 2/63 [00:02<00:50,  1.21it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9445. top1: 83.33. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9640. top1: 83.04. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9631. top1: 82.03. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9650. top1: 82.64. top5: 100.00. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9677. top1: 83.12. top5: 99.69. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9517. top1: 84.09. top5: 99.72. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9555. top1: 84.11. top5: 99.74. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9483. top1: 84.38. top5: 99.76. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9404. top1: 84.82. top5: 99.78. :  10%|▉         | 6/63 [00:02<00:17,  3.28it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9404. top1: 84.82. top5: 99.78. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9366. top1: 85.42. top5: 99.79. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9377. top1: 85.55. top5: 99.80. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9362. top1: 85.29. top5: 99.82. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9382. top1: 85.42. top5: 99.83. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9375. top1: 85.53. top5: 99.84. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9355. top1: 85.47. top5: 99.84. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9382. top1: 85.27. top5: 99.70. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9335. top1: 85.51. top5: 99.72. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9289. top1: 85.87. top5: 99.73. :  22%|██▏       | 14/63 [00:02<00:05,  9.61it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9289. top1: 85.87. top5: 99.73. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9254. top1: 86.07. top5: 99.74. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9207. top1: 86.38. top5: 99.75. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9281. top1: 85.70. top5: 99.76. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9286. top1: 85.65. top5: 99.77. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9338. top1: 85.49. top5: 99.78. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9290. top1: 85.78. top5: 99.78. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9284. top1: 85.83. top5: 99.79. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9272. top1: 85.89. top5: 99.80. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9410. top1: 85.25. top5: 99.71. :  37%|███▋      | 23/63 [00:02<00:02, 18.06it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9410. top1: 85.25. top5: 99.71. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9435. top1: 85.13. top5: 99.72. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9475. top1: 85.02. top5: 99.72. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9541. top1: 84.73. top5: 99.73. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9680. top1: 84.29. top5: 99.57. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9678. top1: 84.29. top5: 99.58. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9730. top1: 83.96. top5: 99.59. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9795. top1: 83.73. top5: 99.60. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9841. top1: 83.52. top5: 99.61. :  51%|█████     | 32/63 [00:02<00:01, 27.35it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9841. top1: 83.52. top5: 99.61. :  63%|██████▎   | 40/63 [00:02<00:00, 35.45it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9870. top1: 83.46. top5: 99.54. :  63%|██████▎   | 40/63 [00:02<00:00, 35.45it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9968. top1: 82.96. top5: 99.55. :  63%|██████▎   | 40/63 [00:02<00:00, 35.45it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0033. top1: 82.70. top5: 99.49. :  63%|██████▎   | 40/63 [00:03<00:00, 35.45it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0053. top1: 82.60. top5: 99.50. :  63%|██████▎   | 40/63 [00:03<00:00, 35.45it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0056. top1: 82.57. top5: 99.51. :  63%|██████▎   | 40/63 [00:03<00:00, 35.45it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0081. top1: 82.47. top5: 99.52. :  63%|██████▎   | 40/63 [00:03<00:00, 35.45it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.0088. top1: 82.38. top5: 99.53. :  63%|██████▎   | 40/63 [00:03<00:00, 35.45it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0098. top1: 82.29. top5: 99.54. :  63%|██████▎   | 40/63 [00:03<00:00, 35.45it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0098. top1: 82.29. top5: 99.54. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0124. top1: 82.27. top5: 99.49. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0140. top1: 82.25. top5: 99.50. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0200. top1: 81.80. top5: 99.51. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0210. top1: 81.79. top5: 99.46. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0253. top1: 81.54. top5: 99.47. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0312. top1: 81.25. top5: 99.42. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0309. top1: 81.31. top5: 99.43. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0315. top1: 81.31. top5: 99.44. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0370. top1: 81.03. top5: 99.40. :  76%|███████▌  | 48/63 [00:03<00:00, 42.82it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0370. top1: 81.03. top5: 99.40. :  90%|█████████ | 57/63 [00:03<00:00, 51.63it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0424. top1: 80.77. top5: 99.41. :  90%|█████████ | 57/63 [00:03<00:00, 51.63it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0457. top1: 80.67. top5: 99.36. :  90%|█████████ | 57/63 [00:03<00:00, 51.63it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0451. top1: 80.78. top5: 99.38. :  90%|█████████ | 57/63 [00:03<00:00, 51.63it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0488. top1: 80.48. top5: 99.39. :  90%|█████████ | 57/63 [00:03<00:00, 51.63it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0543. top1: 80.04. top5: 99.40. :  90%|█████████ | 57/63 [00:03<00:00, 51.63it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0548. top1: 80.05. top5: 99.40. :  90%|█████████ | 57/63 [00:03<00:00, 51.63it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0548. top1: 80.05. top5: 99.40. : 100%|██████████| 63/63 [00:03<00:00, 17.81it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 53/60. Data: 1.60s. Batch: 1.67s. Loss: 0.9933. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 53/60. Data: 1.60s. Batch: 1.67s. Loss: 0.9933. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 53/60. Data: 1.64s. Batch: 1.70s. Loss: 0.9611. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 53/60. Data: 1.67s. Batch: 1.72s. Loss: 0.9033. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 53/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9758. :   4%|▍         | 1/25 [00:01<00:40,  1.68s/it]Finetune Epoch: 53/60. Data: 1.69s. Batch: 1.74s. Loss: 0.9758. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 53/60. Data: 1.71s. Batch: 1.76s. Loss: 0.9875. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 53/60. Data: 1.74s. Batch: 1.78s. Loss: 1.0044. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 53/60. Data: 1.76s. Batch: 1.81s. Loss: 0.9944. :  16%|█▌        | 4/25 [00:01<00:07,  2.84it/s]Finetune Epoch: 53/60. Data: 1.76s. Batch: 1.81s. Loss: 0.9944. :  28%|██▊       | 7/25 [00:01<00:03,  5.36it/s]Finetune Epoch: 53/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0013. :  28%|██▊       | 7/25 [00:01<00:03,  5.36it/s]Finetune Epoch: 53/60. Data: 1.81s. Batch: 1.85s. Loss: 1.0179. :  28%|██▊       | 7/25 [00:02<00:03,  5.36it/s]Finetune Epoch: 53/60. Data: 1.83s. Batch: 1.87s. Loss: 1.0036. :  28%|██▊       | 7/25 [00:02<00:03,  5.36it/s]Finetune Epoch: 53/60. Data: 1.83s. Batch: 1.87s. Loss: 1.0036. :  40%|████      | 10/25 [00:02<00:01,  7.86it/s]Finetune Epoch: 53/60. Data: 1.85s. Batch: 1.90s. Loss: 1.0084. :  40%|████      | 10/25 [00:02<00:01,  7.86it/s]Finetune Epoch: 53/60. Data: 1.87s. Batch: 1.92s. Loss: 1.0192. :  40%|████      | 10/25 [00:02<00:01,  7.86it/s]Finetune Epoch: 53/60. Data: 1.90s. Batch: 1.94s. Loss: 1.0123. :  40%|████      | 10/25 [00:02<00:01,  7.86it/s]Finetune Epoch: 53/60. Data: 1.90s. Batch: 1.94s. Loss: 1.0123. :  52%|█████▏    | 13/25 [00:02<00:01, 10.61it/s]Finetune Epoch: 53/60. Data: 1.92s. Batch: 1.96s. Loss: 1.0218. :  52%|█████▏    | 13/25 [00:02<00:01, 10.61it/s]Finetune Epoch: 53/60. Data: 1.94s. Batch: 1.98s. Loss: 1.0076. :  52%|█████▏    | 13/25 [00:02<00:01, 10.61it/s]Finetune Epoch: 53/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0194. :  52%|█████▏    | 13/25 [00:02<00:01, 10.61it/s]Finetune Epoch: 53/60. Data: 1.96s. Batch: 2.01s. Loss: 1.0194. :  64%|██████▍   | 16/25 [00:02<00:00, 12.86it/s]Finetune Epoch: 53/60. Data: 1.99s. Batch: 2.03s. Loss: 1.0174. :  64%|██████▍   | 16/25 [00:02<00:00, 12.86it/s]Finetune Epoch: 53/60. Data: 2.01s. Batch: 2.05s. Loss: 1.0120. :  64%|██████▍   | 16/25 [00:02<00:00, 12.86it/s]Finetune Epoch: 53/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0049. :  64%|██████▍   | 16/25 [00:02<00:00, 12.86it/s]Finetune Epoch: 53/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0049. :  76%|███████▌  | 19/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 53/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0006. :  76%|███████▌  | 19/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 53/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9962. :  76%|███████▌  | 19/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 53/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9889. :  76%|███████▌  | 19/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 53/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9889. :  88%|████████▊ | 22/25 [00:02<00:00, 17.51it/s]Finetune Epoch: 53/60. Data: 2.12s. Batch: 2.16s. Loss: 0.9959. :  88%|████████▊ | 22/25 [00:02<00:00, 17.51it/s]Finetune Epoch: 53/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9969. :  88%|████████▊ | 22/25 [00:02<00:00, 17.51it/s]Finetune Epoch: 53/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9889. :  88%|████████▊ | 22/25 [00:02<00:00, 17.51it/s]Finetune Epoch: 53/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9889. : 100%|██████████| 25/25 [00:02<00:00, 19.46it/s]Finetune Epoch: 53/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9889. : 100%|██████████| 25/25 [00:02<00:00,  8.65it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0318. top1: 75.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.75s. Loss: 1.0318. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.89s. Loss: 1.0139. top1: 76.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 0.9594. top1: 81.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 0.9723. top1: 80.47. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9486. top1: 83.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:48,  1.75s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 0.9486. top1: 83.12. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 0.9451. top1: 83.33. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 0.9646. top1: 83.04. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9637. top1: 82.03. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9657. top1: 82.64. top5: 100.00. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9684. top1: 83.12. top5: 99.69. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9523. top1: 84.09. top5: 99.72. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9561. top1: 84.11. top5: 99.74. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9489. top1: 84.38. top5: 99.76. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9410. top1: 84.82. top5: 99.78. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9372. top1: 85.42. top5: 99.79. :   8%|▊         | 5/63 [00:01<00:16,  3.51it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9372. top1: 85.42. top5: 99.79. :  24%|██▍       | 15/63 [00:01<00:03, 12.74it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9383. top1: 85.55. top5: 99.80. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9368. top1: 85.29. top5: 99.82. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9388. top1: 85.42. top5: 99.83. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9382. top1: 85.53. top5: 99.84. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9361. top1: 85.47. top5: 99.84. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9388. top1: 85.27. top5: 99.70. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9341. top1: 85.51. top5: 99.72. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9295. top1: 85.87. top5: 99.73. :  24%|██▍       | 15/63 [00:02<00:03, 12.74it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9295. top1: 85.87. top5: 99.73. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9260. top1: 86.07. top5: 99.74. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9213. top1: 86.38. top5: 99.75. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9287. top1: 85.70. top5: 99.76. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9292. top1: 85.65. top5: 99.77. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9345. top1: 85.49. top5: 99.78. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9297. top1: 85.78. top5: 99.78. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9290. top1: 85.83. top5: 99.79. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9278. top1: 85.89. top5: 99.80. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9415. top1: 85.25. top5: 99.71. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9440. top1: 85.13. top5: 99.72. :  37%|███▋      | 23/63 [00:02<00:01, 20.69it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9440. top1: 85.13. top5: 99.72. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9479. top1: 85.02. top5: 99.72. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9545. top1: 84.73. top5: 99.73. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9683. top1: 84.29. top5: 99.65. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9681. top1: 84.29. top5: 99.66. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9732. top1: 83.96. top5: 99.67. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9797. top1: 83.73. top5: 99.68. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9843. top1: 83.52. top5: 99.69. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9871. top1: 83.46. top5: 99.62. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9969. top1: 82.96. top5: 99.63. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0033. top1: 82.70. top5: 99.56. :  52%|█████▏    | 33/63 [00:02<00:00, 32.25it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0033. top1: 82.70. top5: 99.56. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0054. top1: 82.60. top5: 99.57. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0056. top1: 82.57. top5: 99.58. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0081. top1: 82.47. top5: 99.59. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0088. top1: 82.38. top5: 99.60. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0097. top1: 82.29. top5: 99.61. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0123. top1: 82.27. top5: 99.55. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0139. top1: 82.25. top5: 99.56. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0199. top1: 81.80. top5: 99.57. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0208. top1: 81.79. top5: 99.52. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0251. top1: 81.60. top5: 99.53. :  68%|██████▊   | 43/63 [00:02<00:00, 43.54it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0251. top1: 81.60. top5: 99.53. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0309. top1: 81.31. top5: 99.48. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0306. top1: 81.36. top5: 99.49. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0312. top1: 81.36. top5: 99.50. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0367. top1: 81.09. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0420. top1: 80.82. top5: 99.46. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0453. top1: 80.72. top5: 99.42. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0448. top1: 80.83. top5: 99.43. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0484. top1: 80.53. top5: 99.44. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0538. top1: 80.09. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0544. top1: 80.10. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 53.61it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0544. top1: 80.10. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 62.14it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0544. top1: 80.10. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.58it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 54/60. Data: 1.66s. Batch: 1.71s. Loss: 1.0611. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 54/60. Data: 1.66s. Batch: 1.71s. Loss: 1.0611. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 54/60. Data: 1.69s. Batch: 1.73s. Loss: 1.0456. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 54/60. Data: 1.71s. Batch: 1.75s. Loss: 1.0987. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 54/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0497. :   4%|▍         | 1/25 [00:01<00:41,  1.71s/it]Finetune Epoch: 54/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0497. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 54/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0274. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 54/60. Data: 1.78s. Batch: 1.82s. Loss: 1.0336. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 54/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0193. :  16%|█▌        | 4/25 [00:01<00:07,  2.78it/s]Finetune Epoch: 54/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0193. :  28%|██▊       | 7/25 [00:01<00:03,  5.19it/s]Finetune Epoch: 54/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9987. :  28%|██▊       | 7/25 [00:02<00:03,  5.19it/s]Finetune Epoch: 54/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9915. :  28%|██▊       | 7/25 [00:02<00:03,  5.19it/s]Finetune Epoch: 54/60. Data: 1.85s. Batch: 1.90s. Loss: 0.9915. :  36%|███▌      | 9/25 [00:02<00:02,  6.88it/s]Finetune Epoch: 54/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9844. :  36%|███▌      | 9/25 [00:02<00:02,  6.88it/s]Finetune Epoch: 54/60. Data: 1.90s. Batch: 1.95s. Loss: 0.9830. :  36%|███▌      | 9/25 [00:02<00:02,  6.88it/s]Finetune Epoch: 54/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9664. :  36%|███▌      | 9/25 [00:02<00:02,  6.88it/s]Finetune Epoch: 54/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9664. :  48%|████▊     | 12/25 [00:02<00:01,  9.52it/s]Finetune Epoch: 54/60. Data: 1.95s. Batch: 1.99s. Loss: 0.9653. :  48%|████▊     | 12/25 [00:02<00:01,  9.52it/s]Finetune Epoch: 54/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9666. :  48%|████▊     | 12/25 [00:02<00:01,  9.52it/s]Finetune Epoch: 54/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9628. :  48%|████▊     | 12/25 [00:02<00:01,  9.52it/s]Finetune Epoch: 54/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9628. :  60%|██████    | 15/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 54/60. Data: 2.02s. Batch: 2.06s. Loss: 0.9666. :  60%|██████    | 15/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 54/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9793. :  60%|██████    | 15/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 54/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9911. :  60%|██████    | 15/25 [00:02<00:00, 12.58it/s]Finetune Epoch: 54/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9911. :  72%|███████▏  | 18/25 [00:02<00:00, 14.23it/s]Finetune Epoch: 54/60. Data: 2.09s. Batch: 2.13s. Loss: 0.9860. :  72%|███████▏  | 18/25 [00:02<00:00, 14.23it/s]Finetune Epoch: 54/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9803. :  72%|███████▏  | 18/25 [00:02<00:00, 14.23it/s]Finetune Epoch: 54/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9911. :  72%|███████▏  | 18/25 [00:02<00:00, 14.23it/s]Finetune Epoch: 54/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9911. :  84%|████████▍ | 21/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 54/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9882. :  84%|████████▍ | 21/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 54/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9850. :  84%|████████▍ | 21/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 54/60. Data: 2.21s. Batch: 2.25s. Loss: 0.9928. :  84%|████████▍ | 21/25 [00:02<00:00, 15.70it/s]Finetune Epoch: 54/60. Data: 2.21s. Batch: 2.25s. Loss: 0.9928. :  96%|█████████▌| 24/25 [00:02<00:00, 16.82it/s]Finetune Epoch: 54/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9927. :  96%|█████████▌| 24/25 [00:02<00:00, 16.82it/s]Finetune Epoch: 54/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9927. : 100%|██████████| 25/25 [00:03<00:00,  8.07it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.66s. Loss: 1.0335. top1: 71.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.66s. Loss: 1.0335. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.84s. Loss: 1.0156. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.9608. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9739. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9501. top1: 82.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9467. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9662. top1: 82.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9653. top1: 81.64. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.66s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9653. top1: 81.64. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9673. top1: 82.29. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9700. top1: 82.81. top5: 99.69. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9539. top1: 83.81. top5: 99.72. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9576. top1: 83.85. top5: 99.74. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9504. top1: 84.13. top5: 99.76. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9424. top1: 84.60. top5: 99.78. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9386. top1: 85.21. top5: 99.79. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9397. top1: 85.35. top5: 99.80. :  13%|█▎        | 8/63 [00:01<00:09,  6.09it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9397. top1: 85.35. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9382. top1: 85.11. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9402. top1: 85.24. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9396. top1: 85.36. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9375. top1: 85.31. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9402. top1: 85.12. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9355. top1: 85.37. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9309. top1: 85.73. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9273. top1: 85.94. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9226. top1: 86.25. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9301. top1: 85.58. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 13.19it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9306. top1: 85.53. top5: 99.77. :  25%|██▌       | 16/63 [00:02<00:03, 13.19it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9306. top1: 85.53. top5: 99.77. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9358. top1: 85.38. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9310. top1: 85.67. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9303. top1: 85.73. top5: 99.79. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9292. top1: 85.79. top5: 99.80. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9428. top1: 85.16. top5: 99.71. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9451. top1: 85.04. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9489. top1: 84.93. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9554. top1: 84.64. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9691. top1: 84.20. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9688. top1: 84.21. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 24.89it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9688. top1: 84.21. top5: 99.66. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9738. top1: 83.88. top5: 99.67. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9803. top1: 83.65. top5: 99.68. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9848. top1: 83.44. top5: 99.69. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9876. top1: 83.38. top5: 99.62. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9973. top1: 82.89. top5: 99.63. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0037. top1: 82.63. top5: 99.56. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0056. top1: 82.53. top5: 99.57. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0058. top1: 82.50. top5: 99.58. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.40. top5: 99.59. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0089. top1: 82.31. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0098. top1: 82.23. top5: 99.61. :  59%|█████▊    | 37/63 [00:02<00:00, 35.94it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0098. top1: 82.23. top5: 99.61. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0123. top1: 82.21. top5: 99.55. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0138. top1: 82.19. top5: 99.56. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0197. top1: 81.74. top5: 99.57. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0206. top1: 81.73. top5: 99.52. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0249. top1: 81.54. top5: 99.53. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0306. top1: 81.25. top5: 99.48. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0303. top1: 81.31. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0309. top1: 81.31. top5: 99.50. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0363. top1: 81.09. top5: 99.45. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0416. top1: 80.82. top5: 99.46. :  76%|███████▌  | 48/63 [00:02<00:00, 48.12it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0416. top1: 80.82. top5: 99.46. :  92%|█████████▏| 58/63 [00:02<00:00, 57.66it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0449. top1: 80.72. top5: 99.42. :  92%|█████████▏| 58/63 [00:02<00:00, 57.66it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0443. top1: 80.83. top5: 99.43. :  92%|█████████▏| 58/63 [00:02<00:00, 57.66it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0479. top1: 80.53. top5: 99.44. :  92%|█████████▏| 58/63 [00:02<00:00, 57.66it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0533. top1: 80.09. top5: 99.45. :  92%|█████████▏| 58/63 [00:02<00:00, 57.66it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0538. top1: 80.10. top5: 99.45. :  92%|█████████▏| 58/63 [00:02<00:00, 57.66it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0538. top1: 80.10. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 24.61it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 55/60. Data: 1.71s. Batch: 1.76s. Loss: 0.9210. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 55/60. Data: 1.71s. Batch: 1.76s. Loss: 0.9210. :   4%|▍         | 1/25 [00:01<00:42,  1.76s/it]Finetune Epoch: 55/60. Data: 1.75s. Batch: 1.79s. Loss: 0.9138. :   4%|▍         | 1/25 [00:01<00:42,  1.76s/it]Finetune Epoch: 55/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9362. :   4%|▍         | 1/25 [00:01<00:42,  1.76s/it]Finetune Epoch: 55/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9362. :  12%|█▏        | 3/25 [00:01<00:10,  2.02it/s]Finetune Epoch: 55/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9259. :  12%|█▏        | 3/25 [00:01<00:10,  2.02it/s]Finetune Epoch: 55/60. Data: 1.82s. Batch: 1.86s. Loss: 0.9256. :  12%|█▏        | 3/25 [00:01<00:10,  2.02it/s]Finetune Epoch: 55/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9207. :  12%|█▏        | 3/25 [00:02<00:10,  2.02it/s]Finetune Epoch: 55/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9207. :  24%|██▍       | 6/25 [00:02<00:04,  4.54it/s]Finetune Epoch: 55/60. Data: 1.87s. Batch: 1.91s. Loss: 0.9734. :  24%|██▍       | 6/25 [00:02<00:04,  4.54it/s]Finetune Epoch: 55/60. Data: 1.89s. Batch: 1.93s. Loss: 0.9729. :  24%|██▍       | 6/25 [00:02<00:04,  4.54it/s]Finetune Epoch: 55/60. Data: 1.89s. Batch: 1.93s. Loss: 0.9729. :  32%|███▏      | 8/25 [00:02<00:02,  6.34it/s]Finetune Epoch: 55/60. Data: 1.91s. Batch: 1.96s. Loss: 0.9683. :  32%|███▏      | 8/25 [00:02<00:02,  6.34it/s]Finetune Epoch: 55/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9586. :  32%|███▏      | 8/25 [00:02<00:02,  6.34it/s]Finetune Epoch: 55/60. Data: 1.94s. Batch: 1.98s. Loss: 0.9586. :  40%|████      | 10/25 [00:02<00:01,  8.27it/s]Finetune Epoch: 55/60. Data: 1.96s. Batch: 2.01s. Loss: 0.9688. :  40%|████      | 10/25 [00:02<00:01,  8.27it/s]Finetune Epoch: 55/60. Data: 1.99s. Batch: 2.03s. Loss: 0.9639. :  40%|████      | 10/25 [00:02<00:01,  8.27it/s]Finetune Epoch: 55/60. Data: 2.01s. Batch: 2.06s. Loss: 0.9616. :  40%|████      | 10/25 [00:02<00:01,  8.27it/s]Finetune Epoch: 55/60. Data: 2.01s. Batch: 2.06s. Loss: 0.9616. :  52%|█████▏    | 13/25 [00:02<00:01, 11.38it/s]Finetune Epoch: 55/60. Data: 2.04s. Batch: 2.08s. Loss: 0.9604. :  52%|█████▏    | 13/25 [00:02<00:01, 11.38it/s]Finetune Epoch: 55/60. Data: 2.06s. Batch: 2.10s. Loss: 0.9663. :  52%|█████▏    | 13/25 [00:02<00:01, 11.38it/s]Finetune Epoch: 55/60. Data: 2.08s. Batch: 2.12s. Loss: 0.9765. :  52%|█████▏    | 13/25 [00:02<00:01, 11.38it/s]Finetune Epoch: 55/60. Data: 2.08s. Batch: 2.12s. Loss: 0.9765. :  64%|██████▍   | 16/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 55/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9802. :  64%|██████▍   | 16/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 55/60. Data: 2.13s. Batch: 2.17s. Loss: 0.9932. :  64%|██████▍   | 16/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 55/60. Data: 2.15s. Batch: 2.19s. Loss: 0.9913. :  64%|██████▍   | 16/25 [00:02<00:00, 14.42it/s]Finetune Epoch: 55/60. Data: 2.15s. Batch: 2.19s. Loss: 0.9913. :  76%|███████▌  | 19/25 [00:02<00:00, 15.98it/s]Finetune Epoch: 55/60. Data: 2.17s. Batch: 2.21s. Loss: 0.9950. :  76%|███████▌  | 19/25 [00:02<00:00, 15.98it/s]Finetune Epoch: 55/60. Data: 2.19s. Batch: 2.24s. Loss: 0.9999. :  76%|███████▌  | 19/25 [00:02<00:00, 15.98it/s]Finetune Epoch: 55/60. Data: 2.22s. Batch: 2.26s. Loss: 1.0024. :  76%|███████▌  | 19/25 [00:02<00:00, 15.98it/s]Finetune Epoch: 55/60. Data: 2.22s. Batch: 2.26s. Loss: 1.0024. :  88%|████████▊ | 22/25 [00:02<00:00, 18.65it/s]Finetune Epoch: 55/60. Data: 2.24s. Batch: 2.28s. Loss: 1.0134. :  88%|████████▊ | 22/25 [00:02<00:00, 18.65it/s]Finetune Epoch: 55/60. Data: 2.26s. Batch: 2.30s. Loss: 1.0119. :  88%|████████▊ | 22/25 [00:02<00:00, 18.65it/s]Finetune Epoch: 55/60. Data: 2.28s. Batch: 2.32s. Loss: 1.0132. :  88%|████████▊ | 22/25 [00:02<00:00, 18.65it/s]Finetune Epoch: 55/60. Data: 2.28s. Batch: 2.32s. Loss: 1.0132. : 100%|██████████| 25/25 [00:02<00:00, 20.47it/s]Finetune Epoch: 55/60. Data: 2.28s. Batch: 2.32s. Loss: 1.0132. : 100%|██████████| 25/25 [00:03<00:00,  8.32it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.0345. top1: 71.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.65s. Loss: 1.0345. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 1.0166. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9617. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9748. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9511. top1: 82.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9476. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9671. top1: 82.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:42,  1.65s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9671. top1: 82.59. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9662. top1: 81.64. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9682. top1: 82.29. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9709. top1: 82.81. top5: 99.69. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9548. top1: 83.81. top5: 99.72. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9585. top1: 83.85. top5: 99.74. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9513. top1: 84.13. top5: 99.76. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9433. top1: 84.60. top5: 99.78. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9394. top1: 85.21. top5: 99.79. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9405. top1: 85.35. top5: 99.80. :  11%|█         | 7/63 [00:01<00:10,  5.31it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9405. top1: 85.35. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9391. top1: 85.11. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9410. top1: 85.24. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9404. top1: 85.36. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9384. top1: 85.31. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9411. top1: 85.12. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9363. top1: 85.37. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9317. top1: 85.60. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9281. top1: 85.81. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9234. top1: 86.12. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9309. top1: 85.46. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 13.79it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9309. top1: 85.46. top5: 99.76. :  41%|████▏     | 26/63 [00:01<00:01, 24.50it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9314. top1: 85.42. top5: 99.77. :  41%|████▏     | 26/63 [00:01<00:01, 24.50it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9367. top1: 85.27. top5: 99.78. :  41%|████▏     | 26/63 [00:01<00:01, 24.50it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9318. top1: 85.56. top5: 99.78. :  41%|████▏     | 26/63 [00:01<00:01, 24.50it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9312. top1: 85.62. top5: 99.79. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9300. top1: 85.69. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9435. top1: 85.06. top5: 99.71. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9458. top1: 84.94. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9496. top1: 84.83. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9559. top1: 84.55. top5: 99.73. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9696. top1: 84.11. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9692. top1: 84.12. top5: 99.66. :  41%|████▏     | 26/63 [00:02<00:01, 24.50it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9692. top1: 84.12. top5: 99.66. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9742. top1: 83.80. top5: 99.67. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9806. top1: 83.57. top5: 99.68. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9850. top1: 83.36. top5: 99.69. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9878. top1: 83.31. top5: 99.62. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9975. top1: 82.81. top5: 99.63. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0038. top1: 82.56. top5: 99.56. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0057. top1: 82.46. top5: 99.57. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0059. top1: 82.43. top5: 99.58. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.34. top5: 99.59. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0089. top1: 82.25. top5: 99.60. :  59%|█████▊    | 37/63 [00:02<00:00, 37.21it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0089. top1: 82.25. top5: 99.60. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0097. top1: 82.16. top5: 99.61. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0122. top1: 82.14. top5: 99.55. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0137. top1: 82.12. top5: 99.56. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0196. top1: 81.68. top5: 99.57. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0205. top1: 81.67. top5: 99.52. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0247. top1: 81.49. top5: 99.53. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0304. top1: 81.19. top5: 99.48. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0300. top1: 81.25. top5: 99.49. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0306. top1: 81.25. top5: 99.50. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0360. top1: 81.03. top5: 99.45. :  75%|███████▍  | 47/63 [00:02<00:00, 47.55it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0360. top1: 81.03. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 57.39it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0413. top1: 80.77. top5: 99.46. :  90%|█████████ | 57/63 [00:02<00:00, 57.39it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0445. top1: 80.67. top5: 99.42. :  90%|█████████ | 57/63 [00:02<00:00, 57.39it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0439. top1: 80.78. top5: 99.43. :  90%|█████████ | 57/63 [00:02<00:00, 57.39it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0475. top1: 80.53. top5: 99.44. :  90%|█████████ | 57/63 [00:02<00:00, 57.39it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0528. top1: 80.09. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 57.39it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0533. top1: 80.10. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 57.39it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0533. top1: 80.10. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 24.86it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 56/60. Data: 1.72s. Batch: 1.78s. Loss: 0.8893. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 56/60. Data: 1.72s. Batch: 1.78s. Loss: 0.8893. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 56/60. Data: 1.75s. Batch: 1.80s. Loss: 0.9178. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 56/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9024. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 56/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9439. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch: 56/60. Data: 1.80s. Batch: 1.84s. Loss: 0.9439. :  16%|█▌        | 4/25 [00:01<00:07,  2.68it/s]Finetune Epoch: 56/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9388. :  16%|█▌        | 4/25 [00:01<00:07,  2.68it/s]Finetune Epoch: 56/60. Data: 1.84s. Batch: 1.89s. Loss: 0.9600. :  16%|█▌        | 4/25 [00:02<00:07,  2.68it/s]Finetune Epoch: 56/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9445. :  16%|█▌        | 4/25 [00:02<00:07,  2.68it/s]Finetune Epoch: 56/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9445. :  28%|██▊       | 7/25 [00:02<00:03,  5.00it/s]Finetune Epoch: 56/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9552. :  28%|██▊       | 7/25 [00:02<00:03,  5.00it/s]Finetune Epoch: 56/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9403. :  28%|██▊       | 7/25 [00:02<00:03,  5.00it/s]Finetune Epoch: 56/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9403. :  36%|███▌      | 9/25 [00:02<00:02,  6.67it/s]Finetune Epoch: 56/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9548. :  36%|███▌      | 9/25 [00:02<00:02,  6.67it/s]Finetune Epoch: 56/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9551. :  36%|███▌      | 9/25 [00:02<00:02,  6.67it/s]Finetune Epoch: 56/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9585. :  36%|███▌      | 9/25 [00:02<00:02,  6.67it/s]Finetune Epoch: 56/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9585. :  48%|████▊     | 12/25 [00:02<00:01,  9.59it/s]Finetune Epoch: 56/60. Data: 2.02s. Batch: 2.06s. Loss: 0.9634. :  48%|████▊     | 12/25 [00:02<00:01,  9.59it/s]Finetune Epoch: 56/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9550. :  48%|████▊     | 12/25 [00:02<00:01,  9.59it/s]Finetune Epoch: 56/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9629. :  48%|████▊     | 12/25 [00:02<00:01,  9.59it/s]Finetune Epoch: 56/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9629. :  60%|██████    | 15/25 [00:02<00:00, 12.45it/s]Finetune Epoch: 56/60. Data: 2.09s. Batch: 2.13s. Loss: 0.9684. :  60%|██████    | 15/25 [00:02<00:00, 12.45it/s]Finetune Epoch: 56/60. Data: 2.11s. Batch: 2.15s. Loss: 0.9884. :  60%|██████    | 15/25 [00:02<00:00, 12.45it/s]Finetune Epoch: 56/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9879. :  60%|██████    | 15/25 [00:02<00:00, 12.45it/s]Finetune Epoch: 56/60. Data: 2.13s. Batch: 2.18s. Loss: 0.9879. :  72%|███████▏  | 18/25 [00:02<00:00, 13.82it/s]Finetune Epoch: 56/60. Data: 2.16s. Batch: 2.20s. Loss: 0.9806. :  72%|███████▏  | 18/25 [00:02<00:00, 13.82it/s]Finetune Epoch: 56/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9771. :  72%|███████▏  | 18/25 [00:02<00:00, 13.82it/s]Finetune Epoch: 56/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9694. :  72%|███████▏  | 18/25 [00:02<00:00, 13.82it/s]Finetune Epoch: 56/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9694. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 56/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9744. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 56/60. Data: 2.25s. Batch: 2.30s. Loss: 0.9749. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 56/60. Data: 2.28s. Batch: 2.32s. Loss: 0.9893. :  84%|████████▍ | 21/25 [00:02<00:00, 15.52it/s]Finetune Epoch: 56/60. Data: 2.28s. Batch: 2.32s. Loss: 0.9893. :  96%|█████████▌| 24/25 [00:02<00:00, 16.42it/s]Finetune Epoch: 56/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9884. :  96%|█████████▌| 24/25 [00:02<00:00, 16.42it/s]Finetune Epoch: 56/60. Data: 2.30s. Batch: 2.35s. Loss: 0.9884. : 100%|██████████| 25/25 [00:03<00:00,  8.01it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 1.0354. top1: 71.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 1.0354. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 1.0173. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9623. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 0.9754. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9516. top1: 82.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9481. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 0.9481. top1: 82.81. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 0.9676. top1: 82.59. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9667. top1: 81.64. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9687. top1: 82.29. top5: 100.00. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9714. top1: 82.81. top5: 99.69. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9553. top1: 83.81. top5: 99.72. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9591. top1: 83.85. top5: 99.74. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9518. top1: 84.13. top5: 99.76. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9438. top1: 84.60. top5: 99.78. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9399. top1: 85.21. top5: 99.79. :  10%|▉         | 6/63 [00:01<00:12,  4.46it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9399. top1: 85.21. top5: 99.79. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9410. top1: 85.35. top5: 99.80. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9396. top1: 85.11. top5: 99.82. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9416. top1: 85.24. top5: 99.83. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9410. top1: 85.36. top5: 99.84. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9389. top1: 85.31. top5: 99.84. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9416. top1: 85.12. top5: 99.70. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9368. top1: 85.37. top5: 99.72. :  24%|██▍       | 15/63 [00:01<00:03, 12.97it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9368. top1: 85.37. top5: 99.72. :  35%|███▍      | 22/63 [00:01<00:02, 20.09it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9322. top1: 85.60. top5: 99.73. :  35%|███▍      | 22/63 [00:01<00:02, 20.09it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9286. top1: 85.81. top5: 99.74. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9239. top1: 86.12. top5: 99.75. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9314. top1: 85.46. top5: 99.76. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9319. top1: 85.42. top5: 99.77. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9372. top1: 85.27. top5: 99.78. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9323. top1: 85.56. top5: 99.78. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9317. top1: 85.62. top5: 99.79. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9305. top1: 85.69. top5: 99.80. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9440. top1: 85.06. top5: 99.71. :  35%|███▍      | 22/63 [00:02<00:02, 20.09it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9440. top1: 85.06. top5: 99.71. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9462. top1: 84.94. top5: 99.72. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9499. top1: 84.83. top5: 99.72. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9563. top1: 84.55. top5: 99.73. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9698. top1: 84.11. top5: 99.65. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9694. top1: 84.12. top5: 99.66. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9744. top1: 83.80. top5: 99.67. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9807. top1: 83.57. top5: 99.68. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9851. top1: 83.36. top5: 99.69. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9879. top1: 83.31. top5: 99.62. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9975. top1: 82.81. top5: 99.63. :  51%|█████     | 32/63 [00:02<00:00, 31.61it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9975. top1: 82.81. top5: 99.63. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0038. top1: 82.56. top5: 99.56. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0057. top1: 82.46. top5: 99.57. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0059. top1: 82.43. top5: 99.58. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.34. top5: 99.59. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0088. top1: 82.25. top5: 99.60. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0096. top1: 82.16. top5: 99.61. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0121. top1: 82.14. top5: 99.55. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0136. top1: 82.12. top5: 99.56. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0194. top1: 81.68. top5: 99.57. :  67%|██████▋   | 42/63 [00:02<00:00, 42.74it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0194. top1: 81.68. top5: 99.57. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0203. top1: 81.67. top5: 99.52. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0244. top1: 81.54. top5: 99.53. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0301. top1: 81.25. top5: 99.48. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0298. top1: 81.31. top5: 99.49. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0303. top1: 81.31. top5: 99.50. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0357. top1: 81.09. top5: 99.45. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0409. top1: 80.82. top5: 99.46. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0441. top1: 80.72. top5: 99.42. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0436. top1: 80.83. top5: 99.43. :  81%|████████  | 51/63 [00:02<00:00, 51.49it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0436. top1: 80.83. top5: 99.43. :  95%|█████████▌| 60/63 [00:02<00:00, 59.40it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0471. top1: 80.58. top5: 99.44. :  95%|█████████▌| 60/63 [00:02<00:00, 59.40it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0524. top1: 80.14. top5: 99.45. :  95%|█████████▌| 60/63 [00:02<00:00, 59.40it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0530. top1: 80.15. top5: 99.45. :  95%|█████████▌| 60/63 [00:02<00:00, 59.40it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0530. top1: 80.15. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.77it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 57/60. Data: 1.57s. Batch: 1.62s. Loss: 0.9164. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 57/60. Data: 1.57s. Batch: 1.62s. Loss: 0.9164. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 57/60. Data: 1.60s. Batch: 1.64s. Loss: 1.0289. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 57/60. Data: 1.62s. Batch: 1.67s. Loss: 1.0648. :   4%|▍         | 1/25 [00:01<00:38,  1.62s/it]Finetune Epoch: 57/60. Data: 1.62s. Batch: 1.67s. Loss: 1.0648. :  12%|█▏        | 3/25 [00:01<00:10,  2.19it/s]Finetune Epoch: 57/60. Data: 1.65s. Batch: 1.70s. Loss: 1.0383. :  12%|█▏        | 3/25 [00:01<00:10,  2.19it/s]Finetune Epoch: 57/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0257. :  12%|█▏        | 3/25 [00:01<00:10,  2.19it/s]Finetune Epoch: 57/60. Data: 1.68s. Batch: 1.73s. Loss: 1.0257. :  20%|██        | 5/25 [00:01<00:05,  3.97it/s]Finetune Epoch: 57/60. Data: 1.70s. Batch: 1.75s. Loss: 1.0299. :  20%|██        | 5/25 [00:01<00:05,  3.97it/s]Finetune Epoch: 57/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0246. :  20%|██        | 5/25 [00:01<00:05,  3.97it/s]Finetune Epoch: 57/60. Data: 1.73s. Batch: 1.78s. Loss: 1.0246. :  28%|██▊       | 7/25 [00:01<00:03,  5.99it/s]Finetune Epoch: 57/60. Data: 1.76s. Batch: 1.81s. Loss: 1.0177. :  28%|██▊       | 7/25 [00:01<00:03,  5.99it/s]Finetune Epoch: 57/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0111. :  28%|██▊       | 7/25 [00:02<00:03,  5.99it/s]Finetune Epoch: 57/60. Data: 1.78s. Batch: 1.83s. Loss: 1.0111. :  36%|███▌      | 9/25 [00:02<00:01,  8.04it/s]Finetune Epoch: 57/60. Data: 1.81s. Batch: 1.86s. Loss: 1.0093. :  36%|███▌      | 9/25 [00:02<00:01,  8.04it/s]Finetune Epoch: 57/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0005. :  36%|███▌      | 9/25 [00:02<00:01,  8.04it/s]Finetune Epoch: 57/60. Data: 1.84s. Batch: 1.89s. Loss: 1.0005. :  44%|████▍     | 11/25 [00:02<00:01, 10.03it/s]Finetune Epoch: 57/60. Data: 1.86s. Batch: 1.91s. Loss: 0.9872. :  44%|████▍     | 11/25 [00:02<00:01, 10.03it/s]Finetune Epoch: 57/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9842. :  44%|████▍     | 11/25 [00:02<00:01, 10.03it/s]Finetune Epoch: 57/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9842. :  52%|█████▏    | 13/25 [00:02<00:01, 11.94it/s]Finetune Epoch: 57/60. Data: 1.91s. Batch: 1.96s. Loss: 0.9826. :  52%|█████▏    | 13/25 [00:02<00:01, 11.94it/s]Finetune Epoch: 57/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9866. :  52%|█████▏    | 13/25 [00:02<00:01, 11.94it/s]Finetune Epoch: 57/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9860. :  52%|█████▏    | 13/25 [00:02<00:01, 11.94it/s]Finetune Epoch: 57/60. Data: 1.97s. Batch: 2.02s. Loss: 0.9860. :  64%|██████▍   | 16/25 [00:02<00:00, 14.44it/s]Finetune Epoch: 57/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9880. :  64%|██████▍   | 16/25 [00:02<00:00, 14.44it/s]Finetune Epoch: 57/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9794. :  64%|██████▍   | 16/25 [00:02<00:00, 14.44it/s]Finetune Epoch: 57/60. Data: 2.02s. Batch: 2.07s. Loss: 0.9794. :  72%|███████▏  | 18/25 [00:02<00:00, 15.63it/s]Finetune Epoch: 57/60. Data: 2.04s. Batch: 2.09s. Loss: 0.9788. :  72%|███████▏  | 18/25 [00:02<00:00, 15.63it/s]Finetune Epoch: 57/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9855. :  72%|███████▏  | 18/25 [00:02<00:00, 15.63it/s]Finetune Epoch: 57/60. Data: 2.07s. Batch: 2.12s. Loss: 0.9855. :  80%|████████  | 20/25 [00:02<00:00, 16.57it/s]Finetune Epoch: 57/60. Data: 2.10s. Batch: 2.14s. Loss: 0.9881. :  80%|████████  | 20/25 [00:02<00:00, 16.57it/s]Finetune Epoch: 57/60. Data: 2.12s. Batch: 2.17s. Loss: 0.9942. :  80%|████████  | 20/25 [00:02<00:00, 16.57it/s]Finetune Epoch: 57/60. Data: 2.12s. Batch: 2.17s. Loss: 0.9942. :  88%|████████▊ | 22/25 [00:02<00:00, 17.44it/s]Finetune Epoch: 57/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9920. :  88%|████████▊ | 22/25 [00:02<00:00, 17.44it/s]Finetune Epoch: 57/60. Data: 2.17s. Batch: 2.22s. Loss: 0.9923. :  88%|████████▊ | 22/25 [00:02<00:00, 17.44it/s]Finetune Epoch: 57/60. Data: 2.17s. Batch: 2.22s. Loss: 0.9923. :  96%|█████████▌| 24/25 [00:02<00:00, 18.06it/s]Finetune Epoch: 57/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9946. :  96%|█████████▌| 24/25 [00:02<00:00, 18.06it/s]Finetune Epoch: 57/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9946. : 100%|██████████| 25/25 [00:03<00:00,  8.13it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 1.0364. top1: 71.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.68s. Loss: 1.0364. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 1.0183. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9631. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9764. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9526. top1: 82.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9492. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9687. top1: 82.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9678. top1: 81.64. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9699. top1: 82.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9725. top1: 82.81. top5: 99.69. :   2%|▏         | 1/63 [00:01<01:44,  1.68s/it] Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9725. top1: 82.81. top5: 99.69. :  16%|█▌        | 10/63 [00:01<00:06,  7.58it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9564. top1: 83.81. top5: 99.72. :  16%|█▌        | 10/63 [00:01<00:06,  7.58it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9602. top1: 83.85. top5: 99.74. :  16%|█▌        | 10/63 [00:01<00:06,  7.58it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9528. top1: 84.13. top5: 99.76. :  16%|█▌        | 10/63 [00:01<00:06,  7.58it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9448. top1: 84.60. top5: 99.78. :  16%|█▌        | 10/63 [00:01<00:06,  7.58it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9409. top1: 85.21. top5: 99.79. :  16%|█▌        | 10/63 [00:01<00:06,  7.58it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9420. top1: 85.35. top5: 99.80. :  16%|█▌        | 10/63 [00:01<00:06,  7.58it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9420. top1: 85.35. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9406. top1: 85.11. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9426. top1: 85.24. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9419. top1: 85.36. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9398. top1: 85.31. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9425. top1: 85.12. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9377. top1: 85.37. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9331. top1: 85.60. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9296. top1: 85.81. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9248. top1: 86.12. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9323. top1: 85.46. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9328. top1: 85.42. top5: 99.77. :  25%|██▌       | 16/63 [00:01<00:03, 12.82it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9328. top1: 85.42. top5: 99.77. :  43%|████▎     | 27/63 [00:01<00:01, 24.85it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9381. top1: 85.27. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9332. top1: 85.56. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9325. top1: 85.62. top5: 99.79. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9314. top1: 85.69. top5: 99.80. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9448. top1: 85.06. top5: 99.71. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9469. top1: 84.94. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9506. top1: 84.83. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9569. top1: 84.55. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9703. top1: 84.11. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9699. top1: 84.12. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9748. top1: 83.80. top5: 99.67. :  43%|████▎     | 27/63 [00:02<00:01, 24.85it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9748. top1: 83.80. top5: 99.67. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9811. top1: 83.57. top5: 99.68. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9854. top1: 83.36. top5: 99.69. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9881. top1: 83.31. top5: 99.62. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9978. top1: 82.81. top5: 99.63. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0040. top1: 82.56. top5: 99.56. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0059. top1: 82.46. top5: 99.57. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0060. top1: 82.43. top5: 99.58. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0082. top1: 82.34. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0088. top1: 82.25. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0096. top1: 82.16. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 37.10it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0096. top1: 82.16. top5: 99.61. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0121. top1: 82.14. top5: 99.55. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0135. top1: 82.12. top5: 99.56. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0193. top1: 81.68. top5: 99.57. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0201. top1: 81.67. top5: 99.52. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0242. top1: 81.54. top5: 99.53. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0299. top1: 81.25. top5: 99.48. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0295. top1: 81.31. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0301. top1: 81.31. top5: 99.50. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0354. top1: 81.09. top5: 99.45. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0406. top1: 80.82. top5: 99.46. :  76%|███████▌  | 48/63 [00:02<00:00, 47.66it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0406. top1: 80.82. top5: 99.46. :  92%|█████████▏| 58/63 [00:02<00:00, 56.84it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0438. top1: 80.72. top5: 99.42. :  92%|█████████▏| 58/63 [00:02<00:00, 56.84it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0432. top1: 80.83. top5: 99.43. :  92%|█████████▏| 58/63 [00:02<00:00, 56.84it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0467. top1: 80.58. top5: 99.44. :  92%|█████████▏| 58/63 [00:02<00:00, 56.84it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0520. top1: 80.19. top5: 99.45. :  92%|█████████▏| 58/63 [00:02<00:00, 56.84it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0525. top1: 80.20. top5: 99.45. :  92%|█████████▏| 58/63 [00:02<00:00, 56.84it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0525. top1: 80.20. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 24.50it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 58/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0184. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 58/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0184. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 58/60. Data: 1.77s. Batch: 1.82s. Loss: 0.9892. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 58/60. Data: 1.80s. Batch: 1.84s. Loss: 1.0381. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 58/60. Data: 1.82s. Batch: 1.86s. Loss: 1.0558. :   4%|▍         | 1/25 [00:01<00:43,  1.80s/it]Finetune Epoch: 58/60. Data: 1.82s. Batch: 1.86s. Loss: 1.0558. :  16%|█▌        | 4/25 [00:01<00:07,  2.67it/s]Finetune Epoch: 58/60. Data: 1.84s. Batch: 1.88s. Loss: 1.0665. :  16%|█▌        | 4/25 [00:01<00:07,  2.67it/s]Finetune Epoch: 58/60. Data: 1.86s. Batch: 1.90s. Loss: 1.0652. :  16%|█▌        | 4/25 [00:02<00:07,  2.67it/s]Finetune Epoch: 58/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0573. :  16%|█▌        | 4/25 [00:02<00:07,  2.67it/s]Finetune Epoch: 58/60. Data: 1.88s. Batch: 1.93s. Loss: 1.0573. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 58/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0353. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 58/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0164. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 58/60. Data: 1.95s. Batch: 1.99s. Loss: 1.0005. :  28%|██▊       | 7/25 [00:02<00:03,  5.11it/s]Finetune Epoch: 58/60. Data: 1.95s. Batch: 1.99s. Loss: 1.0005. :  40%|████      | 10/25 [00:02<00:01,  7.60it/s]Finetune Epoch: 58/60. Data: 1.97s. Batch: 2.01s. Loss: 1.0113. :  40%|████      | 10/25 [00:02<00:01,  7.60it/s]Finetune Epoch: 58/60. Data: 1.99s. Batch: 2.04s. Loss: 1.0092. :  40%|████      | 10/25 [00:02<00:01,  7.60it/s]Finetune Epoch: 58/60. Data: 2.02s. Batch: 2.06s. Loss: 1.0159. :  40%|████      | 10/25 [00:02<00:01,  7.60it/s]Finetune Epoch: 58/60. Data: 2.02s. Batch: 2.06s. Loss: 1.0159. :  52%|█████▏    | 13/25 [00:02<00:01,  9.93it/s]Finetune Epoch: 58/60. Data: 2.04s. Batch: 2.09s. Loss: 1.0071. :  52%|█████▏    | 13/25 [00:02<00:01,  9.93it/s]Finetune Epoch: 58/60. Data: 2.06s. Batch: 2.11s. Loss: 1.0062. :  52%|█████▏    | 13/25 [00:02<00:01,  9.93it/s]Finetune Epoch: 58/60. Data: 2.09s. Batch: 2.13s. Loss: 1.0038. :  52%|█████▏    | 13/25 [00:02<00:01,  9.93it/s]Finetune Epoch: 58/60. Data: 2.09s. Batch: 2.13s. Loss: 1.0038. :  64%|██████▍   | 16/25 [00:02<00:00, 11.87it/s]Finetune Epoch: 58/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9989. :  64%|██████▍   | 16/25 [00:02<00:00, 11.87it/s]Finetune Epoch: 58/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9989. :  64%|██████▍   | 16/25 [00:02<00:00, 11.87it/s]Finetune Epoch: 58/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9920. :  64%|██████▍   | 16/25 [00:02<00:00, 11.87it/s]Finetune Epoch: 58/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9920. :  76%|███████▌  | 19/25 [00:02<00:00, 13.81it/s]Finetune Epoch: 58/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9916. :  76%|███████▌  | 19/25 [00:02<00:00, 13.81it/s]Finetune Epoch: 58/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9907. :  76%|███████▌  | 19/25 [00:02<00:00, 13.81it/s]Finetune Epoch: 58/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9907. :  84%|████████▍ | 21/25 [00:02<00:00, 14.75it/s]Finetune Epoch: 58/60. Data: 2.24s. Batch: 2.28s. Loss: 0.9874. :  84%|████████▍ | 21/25 [00:02<00:00, 14.75it/s]Finetune Epoch: 58/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9862. :  84%|████████▍ | 21/25 [00:02<00:00, 14.75it/s]Finetune Epoch: 58/60. Data: 2.29s. Batch: 2.33s. Loss: 0.9836. :  84%|████████▍ | 21/25 [00:02<00:00, 14.75it/s]Finetune Epoch: 58/60. Data: 2.29s. Batch: 2.33s. Loss: 0.9836. :  96%|█████████▌| 24/25 [00:02<00:00, 16.11it/s]Finetune Epoch: 58/60. Data: 2.31s. Batch: 2.36s. Loss: 0.9871. :  96%|█████████▌| 24/25 [00:02<00:00, 16.11it/s]Finetune Epoch: 58/60. Data: 2.31s. Batch: 2.36s. Loss: 0.9871. : 100%|██████████| 25/25 [00:03<00:00,  7.92it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.17s. Loss: 1.0378. top1: 71.88. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.17s. Loss: 1.0378. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.10s. Loss: 1.0196. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.74s. Loss: 0.9641. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.56s. Loss: 0.9776. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.45s. Loss: 0.9537. top1: 82.50. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.38s. Loss: 0.9502. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.32s. Loss: 0.9698. top1: 82.59. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9689. top1: 81.64. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:14,  2.17s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9689. top1: 81.64. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9710. top1: 82.29. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.23s. Loss: 0.9736. top1: 82.81. top5: 99.69. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9575. top1: 83.81. top5: 99.72. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9613. top1: 83.85. top5: 99.74. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9539. top1: 84.13. top5: 99.76. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9459. top1: 84.60. top5: 99.78. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9419. top1: 85.21. top5: 99.79. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9430. top1: 85.35. top5: 99.80. :  13%|█▎        | 8/63 [00:02<00:11,  4.73it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9430. top1: 85.35. top5: 99.80. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9416. top1: 85.11. top5: 99.82. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9436. top1: 85.24. top5: 99.83. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9429. top1: 85.36. top5: 99.84. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9408. top1: 85.31. top5: 99.84. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9435. top1: 85.12. top5: 99.70. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9387. top1: 85.37. top5: 99.72. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9341. top1: 85.60. top5: 99.73. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9305. top1: 85.81. top5: 99.74. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9258. top1: 86.12. top5: 99.75. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9333. top1: 85.46. top5: 99.76. :  25%|██▌       | 16/63 [00:02<00:04, 10.55it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9333. top1: 85.46. top5: 99.76. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9337. top1: 85.42. top5: 99.77. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9390. top1: 85.27. top5: 99.78. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9342. top1: 85.56. top5: 99.78. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9335. top1: 85.62. top5: 99.79. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9324. top1: 85.69. top5: 99.80. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9457. top1: 85.06. top5: 99.71. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9477. top1: 84.94. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9514. top1: 84.83. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 19.59it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9514. top1: 84.83. top5: 99.72. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9575. top1: 84.55. top5: 99.73. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9709. top1: 84.11. top5: 99.65. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9704. top1: 84.12. top5: 99.66. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9752. top1: 83.80. top5: 99.67. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9815. top1: 83.57. top5: 99.68. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9858. top1: 83.36. top5: 99.69. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9885. top1: 83.31. top5: 99.62. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9980. top1: 82.81. top5: 99.63. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0042. top1: 82.56. top5: 99.56. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0060. top1: 82.46. top5: 99.57. :  54%|█████▍    | 34/63 [00:02<00:01, 27.18it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0060. top1: 82.46. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0062. top1: 82.43. top5: 99.58. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0083. top1: 82.34. top5: 99.59. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0089. top1: 82.25. top5: 99.60. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0096. top1: 82.16. top5: 99.61. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0120. top1: 82.14. top5: 99.55. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0134. top1: 82.12. top5: 99.56. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.0191. top1: 81.68. top5: 99.57. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0199. top1: 81.67. top5: 99.52. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0241. top1: 81.54. top5: 99.53. :  70%|██████▉   | 44/63 [00:02<00:00, 38.08it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0241. top1: 81.54. top5: 99.53. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0297. top1: 81.25. top5: 99.48. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0293. top1: 81.31. top5: 99.49. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0298. top1: 81.31. top5: 99.50. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0351. top1: 81.09. top5: 99.45. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0403. top1: 80.82. top5: 99.46. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0434. top1: 80.72. top5: 99.42. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0428. top1: 80.83. top5: 99.43. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0463. top1: 80.58. top5: 99.44. :  84%|████████▍ | 53/63 [00:02<00:00, 44.73it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0463. top1: 80.58. top5: 99.44. :  97%|█████████▋| 61/63 [00:02<00:00, 51.09it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0516. top1: 80.19. top5: 99.45. :  97%|█████████▋| 61/63 [00:02<00:00, 51.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0521. top1: 80.20. top5: 99.45. :  97%|█████████▋| 61/63 [00:02<00:00, 51.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0521. top1: 80.20. top5: 99.45. : 100%|██████████| 63/63 [00:03<00:00, 19.82it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 59/60. Data: 1.65s. Batch: 1.71s. Loss: 1.1538. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 59/60. Data: 1.65s. Batch: 1.71s. Loss: 1.1538. :   4%|▍         | 1/25 [00:01<00:40,  1.71s/it]Finetune Epoch: 59/60. Data: 1.69s. Batch: 1.74s. Loss: 1.0879. :   4%|▍         | 1/25 [00:01<00:40,  1.71s/it]Finetune Epoch: 59/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0206. :   4%|▍         | 1/25 [00:01<00:40,  1.71s/it]Finetune Epoch: 59/60. Data: 1.72s. Batch: 1.77s. Loss: 1.0206. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 59/60. Data: 1.75s. Batch: 1.80s. Loss: 1.0403. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 59/60. Data: 1.77s. Batch: 1.82s. Loss: 1.0354. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 59/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0117. :  12%|█▏        | 3/25 [00:01<00:10,  2.05it/s]Finetune Epoch: 59/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0117. :  24%|██▍       | 6/25 [00:01<00:04,  4.61it/s]Finetune Epoch: 59/60. Data: 1.82s. Batch: 1.87s. Loss: 0.9883. :  24%|██▍       | 6/25 [00:02<00:04,  4.61it/s]Finetune Epoch: 59/60. Data: 1.85s. Batch: 1.89s. Loss: 0.9878. :  24%|██▍       | 6/25 [00:02<00:04,  4.61it/s]Finetune Epoch: 59/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9913. :  24%|██▍       | 6/25 [00:02<00:04,  4.61it/s]Finetune Epoch: 59/60. Data: 1.87s. Batch: 1.92s. Loss: 0.9913. :  36%|███▌      | 9/25 [00:02<00:02,  7.24it/s]Finetune Epoch: 59/60. Data: 1.89s. Batch: 1.94s. Loss: 0.9857. :  36%|███▌      | 9/25 [00:02<00:02,  7.24it/s]Finetune Epoch: 59/60. Data: 1.92s. Batch: 1.97s. Loss: 0.9912. :  36%|███▌      | 9/25 [00:02<00:02,  7.24it/s]Finetune Epoch: 59/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9885. :  36%|███▌      | 9/25 [00:02<00:02,  7.24it/s]Finetune Epoch: 59/60. Data: 1.94s. Batch: 1.99s. Loss: 0.9885. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 59/60. Data: 1.97s. Batch: 2.01s. Loss: 0.9912. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 59/60. Data: 1.99s. Batch: 2.04s. Loss: 0.9924. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 59/60. Data: 2.01s. Batch: 2.06s. Loss: 0.9938. :  48%|████▊     | 12/25 [00:02<00:01,  9.92it/s]Finetune Epoch: 59/60. Data: 2.01s. Batch: 2.06s. Loss: 0.9938. :  60%|██████    | 15/25 [00:02<00:00, 12.24it/s]Finetune Epoch: 59/60. Data: 2.04s. Batch: 2.08s. Loss: 0.9870. :  60%|██████    | 15/25 [00:02<00:00, 12.24it/s]Finetune Epoch: 59/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9856. :  60%|██████    | 15/25 [00:02<00:00, 12.24it/s]Finetune Epoch: 59/60. Data: 2.06s. Batch: 2.11s. Loss: 0.9856. :  68%|██████▊   | 17/25 [00:02<00:00, 13.33it/s]Finetune Epoch: 59/60. Data: 2.09s. Batch: 2.13s. Loss: 0.9868. :  68%|██████▊   | 17/25 [00:02<00:00, 13.33it/s]Finetune Epoch: 59/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9861. :  68%|██████▊   | 17/25 [00:02<00:00, 13.33it/s]Finetune Epoch: 59/60. Data: 2.11s. Batch: 2.16s. Loss: 0.9861. :  76%|███████▌  | 19/25 [00:02<00:00, 14.47it/s]Finetune Epoch: 59/60. Data: 2.14s. Batch: 2.18s. Loss: 0.9893. :  76%|███████▌  | 19/25 [00:02<00:00, 14.47it/s]Finetune Epoch: 59/60. Data: 2.16s. Batch: 2.21s. Loss: 0.9928. :  76%|███████▌  | 19/25 [00:02<00:00, 14.47it/s]Finetune Epoch: 59/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9958. :  76%|███████▌  | 19/25 [00:02<00:00, 14.47it/s]Finetune Epoch: 59/60. Data: 2.19s. Batch: 2.23s. Loss: 0.9958. :  88%|████████▊ | 22/25 [00:02<00:00, 16.65it/s]Finetune Epoch: 59/60. Data: 2.21s. Batch: 2.26s. Loss: 0.9947. :  88%|████████▊ | 22/25 [00:02<00:00, 16.65it/s]Finetune Epoch: 59/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9938. :  88%|████████▊ | 22/25 [00:02<00:00, 16.65it/s]Finetune Epoch: 59/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9909. :  88%|████████▊ | 22/25 [00:02<00:00, 16.65it/s]Finetune Epoch: 59/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9909. : 100%|██████████| 25/25 [00:02<00:00, 17.98it/s]Finetune Epoch: 59/60. Data: 2.26s. Batch: 2.31s. Loss: 0.9909. : 100%|██████████| 25/25 [00:03<00:00,  8.11it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.69s. Loss: 1.0382. top1: 71.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.69s. Loss: 1.0382. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.85s. Loss: 1.0201. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.57s. Loss: 0.9645. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.43s. Loss: 0.9779. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.35s. Loss: 0.9541. top1: 82.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.29s. Loss: 0.9506. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.25s. Loss: 0.9701. top1: 82.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9692. top1: 81.64. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:44,  1.69s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.22s. Loss: 0.9692. top1: 81.64. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 0.9713. top1: 82.29. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 0.9739. top1: 82.50. top5: 99.69. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9578. top1: 83.52. top5: 99.72. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9616. top1: 83.59. top5: 99.74. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9542. top1: 83.89. top5: 99.76. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9462. top1: 84.38. top5: 99.78. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9422. top1: 85.00. top5: 99.79. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9433. top1: 85.16. top5: 99.80. :  13%|█▎        | 8/63 [00:01<00:09,  6.01it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9433. top1: 85.16. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9419. top1: 84.93. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9439. top1: 85.07. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9432. top1: 85.20. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9411. top1: 85.16. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9438. top1: 84.97. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9390. top1: 85.23. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9344. top1: 85.46. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9308. top1: 85.68. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9261. top1: 86.00. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9336. top1: 85.34. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 13.24it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9341. top1: 85.30. top5: 99.77. :  25%|██▌       | 16/63 [00:02<00:03, 13.24it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9341. top1: 85.30. top5: 99.77. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9394. top1: 85.16. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9345. top1: 85.45. top5: 99.78. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9338. top1: 85.52. top5: 99.79. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9327. top1: 85.58. top5: 99.80. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9459. top1: 84.96. top5: 99.71. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9480. top1: 84.85. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9516. top1: 84.74. top5: 99.72. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9577. top1: 84.46. top5: 99.73. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9711. top1: 84.03. top5: 99.65. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9706. top1: 84.04. top5: 99.66. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9754. top1: 83.72. top5: 99.67. :  43%|████▎     | 27/63 [00:02<00:01, 24.97it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9754. top1: 83.72. top5: 99.67. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9816. top1: 83.49. top5: 99.68. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9858. top1: 83.28. top5: 99.69. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9885. top1: 83.23. top5: 99.62. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9981. top1: 82.74. top5: 99.63. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0042. top1: 82.49. top5: 99.56. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0060. top1: 82.39. top5: 99.57. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0061. top1: 82.36. top5: 99.58. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0083. top1: 82.27. top5: 99.59. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0088. top1: 82.18. top5: 99.60. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 82.10. top5: 99.61. :  60%|██████    | 38/63 [00:02<00:00, 37.22it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 82.10. top5: 99.61. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0120. top1: 82.08. top5: 99.55. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0133. top1: 82.06. top5: 99.56. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0190. top1: 81.62. top5: 99.57. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0198. top1: 81.61. top5: 99.52. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0239. top1: 81.49. top5: 99.53. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0295. top1: 81.19. top5: 99.48. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0291. top1: 81.25. top5: 99.49. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0296. top1: 81.25. top5: 99.50. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0349. top1: 81.03. top5: 99.45. :  76%|███████▌  | 48/63 [00:02<00:00, 47.49it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0349. top1: 81.03. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 54.47it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0401. top1: 80.77. top5: 99.46. :  90%|█████████ | 57/63 [00:02<00:00, 54.47it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0432. top1: 80.67. top5: 99.42. :  90%|█████████ | 57/63 [00:02<00:00, 54.47it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0426. top1: 80.78. top5: 99.43. :  90%|█████████ | 57/63 [00:02<00:00, 54.47it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0461. top1: 80.53. top5: 99.44. :  90%|█████████ | 57/63 [00:02<00:00, 54.47it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0513. top1: 80.14. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 54.47it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0518. top1: 80.15. top5: 99.45. :  90%|█████████ | 57/63 [00:02<00:00, 54.47it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0518. top1: 80.15. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 23.46it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch: 60/60. Data: 1.65s. Batch: 1.70s. Loss: 1.1560. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch: 60/60. Data: 1.65s. Batch: 1.70s. Loss: 1.1560. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 60/60. Data: 1.68s. Batch: 1.72s. Loss: 1.0091. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 60/60. Data: 1.70s. Batch: 1.73s. Loss: 1.0160. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 60/60. Data: 1.72s. Batch: 1.75s. Loss: 1.0190. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 60/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0227. :   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Finetune Epoch: 60/60. Data: 1.73s. Batch: 1.77s. Loss: 1.0227. :  20%|██        | 5/25 [00:01<00:05,  3.51it/s]Finetune Epoch: 60/60. Data: 1.75s. Batch: 1.79s. Loss: 1.0709. :  20%|██        | 5/25 [00:01<00:05,  3.51it/s]Finetune Epoch: 60/60. Data: 1.78s. Batch: 1.82s. Loss: 1.0533. :  20%|██        | 5/25 [00:01<00:05,  3.51it/s]Finetune Epoch: 60/60. Data: 1.78s. Batch: 1.82s. Loss: 1.0533. :  28%|██▊       | 7/25 [00:01<00:03,  5.00it/s]Finetune Epoch: 60/60. Data: 1.80s. Batch: 1.85s. Loss: 1.0245. :  28%|██▊       | 7/25 [00:02<00:03,  5.00it/s]Finetune Epoch: 60/60. Data: 1.83s. Batch: 1.87s. Loss: 1.0346. :  28%|██▊       | 7/25 [00:02<00:03,  5.00it/s]Finetune Epoch: 60/60. Data: 1.83s. Batch: 1.87s. Loss: 1.0346. :  36%|███▌      | 9/25 [00:02<00:02,  6.72it/s]Finetune Epoch: 60/60. Data: 1.85s. Batch: 1.90s. Loss: 1.0171. :  36%|███▌      | 9/25 [00:02<00:02,  6.72it/s]Finetune Epoch: 60/60. Data: 1.88s. Batch: 1.92s. Loss: 1.0225. :  36%|███▌      | 9/25 [00:02<00:02,  6.72it/s]Finetune Epoch: 60/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0261. :  36%|███▌      | 9/25 [00:02<00:02,  6.72it/s]Finetune Epoch: 60/60. Data: 1.90s. Batch: 1.95s. Loss: 1.0261. :  48%|████▊     | 12/25 [00:02<00:01,  9.48it/s]Finetune Epoch: 60/60. Data: 1.93s. Batch: 1.97s. Loss: 1.0219. :  48%|████▊     | 12/25 [00:02<00:01,  9.48it/s]Finetune Epoch: 60/60. Data: 1.95s. Batch: 2.00s. Loss: 1.0142. :  48%|████▊     | 12/25 [00:02<00:01,  9.48it/s]Finetune Epoch: 60/60. Data: 1.98s. Batch: 2.02s. Loss: 1.0028. :  48%|████▊     | 12/25 [00:02<00:01,  9.48it/s]Finetune Epoch: 60/60. Data: 1.98s. Batch: 2.02s. Loss: 1.0028. :  60%|██████    | 15/25 [00:02<00:00, 11.86it/s]Finetune Epoch: 60/60. Data: 2.00s. Batch: 2.05s. Loss: 0.9988. :  60%|██████    | 15/25 [00:02<00:00, 11.86it/s]Finetune Epoch: 60/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0071. :  60%|██████    | 15/25 [00:02<00:00, 11.86it/s]Finetune Epoch: 60/60. Data: 2.03s. Batch: 2.07s. Loss: 1.0071. :  68%|██████▊   | 17/25 [00:02<00:00, 13.03it/s]Finetune Epoch: 60/60. Data: 2.05s. Batch: 2.10s. Loss: 1.0053. :  68%|██████▊   | 17/25 [00:02<00:00, 13.03it/s]Finetune Epoch: 60/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0000. :  68%|██████▊   | 17/25 [00:02<00:00, 13.03it/s]Finetune Epoch: 60/60. Data: 2.08s. Batch: 2.13s. Loss: 1.0000. :  76%|███████▌  | 19/25 [00:02<00:00, 14.34it/s]Finetune Epoch: 60/60. Data: 2.10s. Batch: 2.15s. Loss: 0.9998. :  76%|███████▌  | 19/25 [00:02<00:00, 14.34it/s]Finetune Epoch: 60/60. Data: 2.13s. Batch: 2.18s. Loss: 1.0002. :  76%|███████▌  | 19/25 [00:02<00:00, 14.34it/s]Finetune Epoch: 60/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9980. :  76%|███████▌  | 19/25 [00:02<00:00, 14.34it/s]Finetune Epoch: 60/60. Data: 2.15s. Batch: 2.20s. Loss: 0.9980. :  88%|████████▊ | 22/25 [00:02<00:00, 16.32it/s]Finetune Epoch: 60/60. Data: 2.18s. Batch: 2.23s. Loss: 0.9958. :  88%|████████▊ | 22/25 [00:02<00:00, 16.32it/s]Finetune Epoch: 60/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9998. :  88%|████████▊ | 22/25 [00:02<00:00, 16.32it/s]Finetune Epoch: 60/60. Data: 2.20s. Batch: 2.25s. Loss: 0.9998. :  96%|█████████▌| 24/25 [00:02<00:00, 17.00it/s]Finetune Epoch: 60/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9975. :  96%|█████████▌| 24/25 [00:02<00:00, 17.00it/s]Finetune Epoch: 60/60. Data: 2.23s. Batch: 2.28s. Loss: 0.9975. : 100%|██████████| 25/25 [00:03<00:00,  8.02it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.60s. Loss: 1.0389. top1: 71.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.60s. Loss: 1.0389. top1: 71.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.82s. Loss: 1.0208. top1: 75.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.55s. Loss: 0.9651. top1: 80.21. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.42s. Loss: 0.9786. top1: 79.69. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.34s. Loss: 0.9547. top1: 82.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.28s. Loss: 0.9512. top1: 82.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9707. top1: 82.59. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:39,  1.60s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.24s. Loss: 0.9707. top1: 82.59. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.21s. Loss: 0.9699. top1: 81.64. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.19s. Loss: 0.9720. top1: 82.29. top5: 100.00. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 0.9746. top1: 82.50. top5: 99.69. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s] Test Iter:  11/ 63. Data: 0.00s. Batch: 0.16s. Loss: 0.9585. top1: 83.52. top5: 99.72. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 0.9622. top1: 83.59. top5: 99.74. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 0.9548. top1: 83.89. top5: 99.76. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 0.9468. top1: 84.38. top5: 99.78. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 0.9428. top1: 85.00. top5: 99.79. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9439. top1: 85.16. top5: 99.80. :  11%|█         | 7/63 [00:01<00:10,  5.47it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9439. top1: 85.16. top5: 99.80. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 0.9425. top1: 84.93. top5: 99.82. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9445. top1: 85.07. top5: 99.83. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 0.9438. top1: 85.20. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9417. top1: 85.16. top5: 99.84. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9444. top1: 84.97. top5: 99.70. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 0.9396. top1: 85.23. top5: 99.72. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9350. top1: 85.46. top5: 99.73. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9314. top1: 85.68. top5: 99.74. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 0.9266. top1: 86.00. top5: 99.75. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9341. top1: 85.34. top5: 99.76. :  25%|██▌       | 16/63 [00:01<00:03, 13.93it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9341. top1: 85.34. top5: 99.76. :  41%|████▏     | 26/63 [00:01<00:01, 24.77it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9346. top1: 85.30. top5: 99.77. :  41%|████▏     | 26/63 [00:01<00:01, 24.77it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9399. top1: 85.16. top5: 99.78. :  41%|████▏     | 26/63 [00:01<00:01, 24.77it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9350. top1: 85.45. top5: 99.78. :  41%|████▏     | 26/63 [00:01<00:01, 24.77it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 0.9344. top1: 85.42. top5: 99.79. :  41%|████▏     | 26/63 [00:01<00:01, 24.77it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9333. top1: 85.48. top5: 99.80. :  41%|████▏     | 26/63 [00:01<00:01, 24.77it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9464. top1: 84.86. top5: 99.71. :  41%|████▏     | 26/63 [00:01<00:01, 24.77it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9485. top1: 84.75. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 24.77it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9520. top1: 84.65. top5: 99.72. :  41%|████▏     | 26/63 [00:02<00:01, 24.77it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9581. top1: 84.38. top5: 99.73. :  41%|████▏     | 26/63 [00:02<00:01, 24.77it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9714. top1: 83.94. top5: 99.65. :  41%|████▏     | 26/63 [00:02<00:01, 24.77it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9714. top1: 83.94. top5: 99.65. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 0.9708. top1: 83.95. top5: 99.66. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9756. top1: 83.63. top5: 99.67. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9818. top1: 83.41. top5: 99.68. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9860. top1: 83.20. top5: 99.69. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9886. top1: 83.16. top5: 99.62. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 0.9982. top1: 82.66. top5: 99.63. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0043. top1: 82.41. top5: 99.56. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0061. top1: 82.32. top5: 99.57. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0062. top1: 82.29. top5: 99.58. :  57%|█████▋    | 36/63 [00:02<00:00, 36.28it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0062. top1: 82.29. top5: 99.58. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0083. top1: 82.20. top5: 99.59. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0088. top1: 82.18. top5: 99.60. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0095. top1: 82.10. top5: 99.61. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.0119. top1: 82.08. top5: 99.55. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0132. top1: 82.06. top5: 99.56. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0189. top1: 81.62. top5: 99.57. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0196. top1: 81.61. top5: 99.52. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0237. top1: 81.49. top5: 99.53. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0293. top1: 81.19. top5: 99.48. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0289. top1: 81.25. top5: 99.49. :  71%|███████▏  | 45/63 [00:02<00:00, 43.43it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0289. top1: 81.25. top5: 99.49. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0294. top1: 81.25. top5: 99.50. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0347. top1: 81.03. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0398. top1: 80.77. top5: 99.46. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0429. top1: 80.72. top5: 99.42. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0423. top1: 80.83. top5: 99.43. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0458. top1: 80.58. top5: 99.44. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0510. top1: 80.19. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0515. top1: 80.20. top5: 99.45. :  87%|████████▋ | 55/63 [00:02<00:00, 53.39it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 1.0515. top1: 80.20. top5: 99.45. : 100%|██████████| 63/63 [00:02<00:00, 24.35it/s]
Traceback (most recent call last):
  File "main.py", line 438, in <module>
    main()
  File "main.py", line 334, in main
    pseudo_images, pseudo_targets = metapseudo.train_loop()
  File "/home/vision/minhyuk/smh_real_origin/pseudo_main.py", line 444, in train_loop
    compare = torch.Tensor.tolist(hard_pseudo_label==return_data["label"])
TypeError: descriptor 'tolist' requires a 'torch._C._TensorBase' object but received a 'bool'
